---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Exercise - ML Pipeline {.unnumbered}

## Exercise - Tuning Regularization

::: {.callout-warning}

#### Task: Tuning $\alpha$ and $\lambda$

1.  Extend the code from above (@sec-nested) and tune $\alpha$ and $\lambda$ (Nested-CV or via a simple CV)

2.  Train the model with best set of hyperparameters and submit your predictions

3.  Compare the predictive performance from the single best model with the ensemble model

Submit both predictions (<http://rhsbio7.uni-regensburg.de:8500/>), which model has a higher AUC?

```{r}
library(EcoData)
library(dplyr)
library(missRanger)
library(glmnet)
library(glmnetUtils)
data(titanic_ml)
data = titanic_ml
data = 
  data %>% select(survived, sex, age, fare, pclass)

# missRanger uses a random forest to impute NAs (RF is trained on the data to predict values for the NAs)
data[,-1] = missRanger(data[,-1], verbose = 0)

data_sub =
  data %>%
    mutate(age = scales::rescale(age, c(0, 1)),
           fare = scales::rescale(fare, c(0, 1))) %>%
    mutate(sex = as.integer(sex) - 1L,
           pclass = as.integer(pclass - 1L))
data_new = data_sub[is.na(data_sub$survived),] # for which we want to make predictions at the end
data_obs = data_sub[!is.na(data_sub$survived),] # data with known response
```

Bonus:

-   Try different features
-   Try cito
-   Try different datasets (see @sec-datasets)

Code template for a simple CV (only $\alpha$ is tuned, add the tuning for $\lambda$:

```{r}
library(glmnet)
library(glmnetUtils)
set.seed(42)
data_obs = data_sub[!is.na(data_sub$survived),] 
cv = 5
hyper_alpha = runif(20,0, 1)

outer_split = as.integer(cut(1:nrow(data_obs), breaks = cv))

results = data.frame(
  set = rep(NA, cv),
  alpha = rep(NA, cv),
  AUC = rep(NA, cv)
)

for(i in 1:cv) {
  train_outer = data_obs[outer_split != i, ]
  test_outer = data_obs[outer_split == i, ]
  
  tuning_results = 
      sapply(1:length(hyper_alpha), function(k) {
        model = glmnet(survived~.,data = train_outer, family = "binomial",alpha = hyper_alpha[k])
        return(Metrics::auc(test_outer$survived, predict(model, test_outer, 
                                                         alpha = hyper_alpha[k],
                                                         s = 0.01,
                                                         type = "response")))
      })
  best_alpha = hyper_alpha[which.max(tuning_results)]
  results[i, 1] = i
  results[i, 2] = best_alpha
  results[i, 3] = max(tuning_results)
}

print(results)
```

`r hide("Click here to see the solution for the single model")`

Nested CV:

```{r}
set.seed(42)
data_obs = data_sub[!is.na(data_sub$survived),] 
cv = 5
cv_inner = 5
hyper_alpha = runif(30,0, 1)
hyper_lambda = runif(30,0, 1)

outer_split = as.integer(cut(1:nrow(data_obs), breaks = cv))

results = data.frame(
  set = rep(NA, cv),
  alpha = rep(NA, cv),
  lambda = rep(NA, cv),
  AUC = rep(NA, cv)
)

for(i in 1:cv) {
  train_outer = data_obs[outer_split != i, ]
  test_outer = data_obs[outer_split == i, ]
  
  
  tuning_results_inner = 
      sapply(1:length(hyper_alpha), function(k) {
          best_alpha = NULL
          best_lambda = NULL
          best_auc = NULL  
          
          auc_inner = NULL
        
          for(j in 1:cv_inner) {
            inner_split = as.integer(cut(1:nrow(train_outer), breaks = cv_inner))
            train_inner = train_outer[inner_split != j, ]
            test_inner = train_outer[inner_split == j, ]
        
            model = glmnet(survived~.,data = train_inner, family = "binomial",alpha = hyper_alpha[k])
            
            
            auc_inner[j]= Metrics::auc(test_inner$survived, predict(model, test_inner, 
                                                         alpha = hyper_alpha[k],
                                                         s = hyper_lambda[k],
                                                         type = "response"))
            
          }
        return(mean(auc_inner))
      })
  
  
  best_alpha = hyper_alpha[which.max(tuning_results_inner)]
  best_lambda = hyper_lambda[which.max(tuning_results_inner)]
  best_auc = max(tuning_results_inner)
  
  model = glmnet(survived~., data = train_outer, alpha = best_alpha, family = "binomial")
  
  results[i, 1] = i
  results[i, 2] = best_alpha
  results[i, 3] = best_lambda
  results[i, 4] = Metrics::auc(test_outer$survived, predict(model, test_outer, s = best_lambda, alpha = best_alpha, type = "response"))
}

print(results)

```

Simple CV:

```{r}
set.seed(42)
data_obs = data_sub[!is.na(data_sub$survived),] 
cv = 5
hyper_alpha = runif(20,0, 1)
hyper_lambda = runif(20, 0, 1)
cv_outer = 10

tuning_results = 
      sapply(1:length(hyper_alpha), function(k) {
          best_alpha = NULL
          best_lambda = NULL
          best_auc = NULL  
          
          auc_inner = NULL
        
          for(j in 1:cv_outer) {
            inner_split = as.integer(cut(1:nrow(train_outer), breaks = cv_outer))
            train = train_outer[inner_split != j, ]
            test = train_outer[inner_split == j, ]
        
            model = glmnet(survived~.,data = train, family = "binomial",alpha = hyper_alpha[k])
            
            
            auc_inner[j]= Metrics::auc(test$survived, predict(model, test, 
                                                         alpha = hyper_alpha[k],
                                                         s = hyper_lambda[k],
                                                         type = "response"))
            
          }
        return(mean(auc_inner))
      })
results = data.frame(alpha = hyper_alpha, lambda = hyper_lambda, AUC = tuning_results)

print(results)
```

Predictions:

```{r, results='hide', message=FALSE, warning=FALSE}
prediction_ensemble = 
  sapply(1:nrow(results), function(i) {
    model = glmnet(survived~.,data = data_obs, family = "binomial",alpha = results$alpha[i])
    return(predict(model, data_new, alpha = results$alpha[i], s = results$lambda[i], type = "response")[,1])
  })

# Single predictions from the model with the highest AUC:
write.csv(data.frame(y = prediction_ensemble[,which.max(results$AUC)]), file = "Max_titanic_best_model.csv")

# Single predictions from the ensemble model:
write.csv(data.frame(y = apply(prediction_ensemble, 1, mean)), file = "Max_titanic_ensemble.csv")
```

`r unhide()`
:::



## Exercise - ML pipeline with mlr3

::: {.callout-warning}
#### Question: Use mlr3 for the titanic dataset

1.  Use `mlr3` to tune glmnet for the titanic dataset using nested CV
2.  Submit single predictions and multiple predictions

If you need help, take a look at the solution, go through it line by line and try to understand it.

`r hide("Click here to see the solution")`

Prepare data

```{r}
library(mlr3verse)
library(tidyverse)

data = titanic_ml %>% select(-name, -ticket, -name, -body)
data$pclass = as.factor(data$pclass)
data$sex = as.factor(data$sex)
data$survived = as.factor(data$survived)

# Change easy things manually:
data$embarked[data$embarked == ""] = "S"  # Fill in "empty" values.
data$embarked = droplevels(as.factor(data$embarked)) # Remove unused levels ("").
data$cabin = (data$cabin != "") * 1 # Dummy code the availability of a cabin.
data$fare[is.na(data$fare)] = mean(data$fare, na.rm = TRUE)
levels(data$home.dest)[levels(data$home.dest) == ""] = "unknown"
levels(data$boat)[levels(data$boat) == ""] = "none"

# Create a classification task.
task = TaskClassif$new(id = "titanic", backend = data,
                       target = "survived", positive = "1")
task$missings()

# Let's create the preprocessing graph.
preprocessing = po("imputeoor") %>>% po("scale") %>>% po("encode") 

# Run the task.
transformed_task = preprocessing$train(task)[[1]]

transformed_task$set_row_roles((1:nrow(data))[is.na(data$survived)], "holdout")
```

Hyperparameter tuning:

```{r, results='hide'}

cv10 = mlr3::rsmp("cv", folds = 10L)

inner3 = mlr3::rsmp("cv", folds = 3L)
measurement =  msr("classif.auc")
tuner =  mlr3tuning::tnr("random_search") 
terminator = mlr3tuning::trm("evals", n_evals = 5L)
EN = lrn("classif.glmnet", predict_type = "prob")
EN_pars = 
    paradox::ParamSet$new(
      list(paradox::ParamDbl$new("alpha", lower = 0, upper = 1L),
           paradox::ParamDbl$new("lambda", lower = 0, upper = 0.5 )) )

learner_tuner = AutoTuner$new(learner = EN, 
                              measure = measurement, 
                              tuner = tuner, 
                              terminator = terminator,
                              search_space = EN_pars,
                              resampling = inner3)


result = mlr3::resample(transformed_task, learner_tuner,
                        resampling = cv10, store_models = TRUE)
```

Evaluation:

```{r}
measurement =  msr("classif.auc")
result$aggregate(measurement)
```

Predictions:

We can extract a learner with optimized hyperparameters:

```{r}
model = result$learners[[1]]$learner$clone()
model$param_set$values
```

And we can fit it then on the full data set:

```{r}
model$train(transformed_task)
predictions = model$predict(transformed_task, row_ids = transformed_task$row_roles$holdout)
predictions = predictions$prob[,1]
head(predictions)
```

And submit to http://rhsbio7.uni-regensburg.de:8500

```{r}
write.csv(data.frame(y = predictions), file = "glmnet.csv")
```

`r unhide()`
:::

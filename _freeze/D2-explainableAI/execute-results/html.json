{
  "hash": "2f3cf9fe9c18e7eeca6d33c6910dd465",
  "result": {
    "markdown": "---\noutput: html_document\neditor_options:\n  chunk_output_type: console\n---\n\n\n# Explainable AI\n\n\n\n\n\nThe goal of explainable AI (xAI, aka interpretable machine learning) is to explain **why** a fitted machine learning model makes certain predictions. A typical example is to understand how important different variables are for predictions. The incentives for doing so range from a better technical understanding of the models over understanding which data is important for improving predictions to questions of fairness and discrimination (e.g. to understand if an algorithm uses skin color to make a decision).\n\n## A Practical Example\n\nIn this lecture we will work with an African Elephant occurrence dataset.\n\nWe will fit a random forest and use the iml package for xAI, see <a href=\"https://christophm.github.io/interpretable-ml-book/\" target=\"_blank\" rel=\"noopener\">https://christophm.github.io/interpretable-ml-book/</a>.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(iml)\nlibrary(ranger) # different random Forest package!\nlibrary(EcoData)\nset.seed(123)\n\n\ndata = EcoData::elephant$occurenceData\nhead(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      Presence       bio1       bio2       bio3       bio4        bio5\n3364         0 -0.4981747 -0.2738045  0.5368968 -0.5409999 -0.36843571\n6268         0  0.6085908 -0.5568352  1.0340686 -1.2492050 -0.11835651\n10285        0 -0.7973005  1.4648130 -1.0540532  2.0759423  0.07614953\n2247         0  0.6385034  1.3435141 -0.1591439 -0.5107148  1.10425291\n9821         0  0.6684160 -0.6781341  0.6363311 -0.9906170  0.15950927\n1351         0  0.9675418 -0.6781341 -0.3580126 -0.3748202  0.77081398\n            bio6       bio7       bio8       bio9       bio10       bio11\n3364   0.2947850 -0.5260099 -1.2253960  0.2494100 -0.64527314 -0.06267842\n6268   0.8221087 -0.8938475  0.4233787  0.7746249  0.09168503  0.94419518\n10285 -1.5860029  1.6284678  0.2768209 -1.5153122 -0.03648161 -1.44165748\n2247  -0.1622288  0.8577603  0.4600181  0.5855475  0.54026827  0.68153250\n9821   0.9099960 -0.8062671  0.3867393  0.8586593  0.31597665  0.94419518\n1351   0.8748411 -0.3858812  0.3134604  1.0477367  0.98885151  0.94419518\n           bio12      bio13       bio14        bio15      bio16      bio17\n3364   0.6285371  0.6807958 -0.29703736 -0.008455252  0.7124535 -0.2949994\n6268   1.1121516  0.5918442  0.01619202 -0.884507980  0.5607328  0.3506918\n10285 -1.2351482 -1.3396742 -0.50585695  0.201797403 -1.3499999 -0.5616980\n2247   0.5951165  0.8714061 -0.55806185  0.236839512  1.1012378 -0.5616980\n9821   1.1003561  0.5537222  0.59044589 -1.024676416  0.6413344  0.7437213\n1351   0.7287986  1.1255533 -0.50585695  0.236839512  1.2956300 -0.4494038\n            bio18       bio19\n3364  -1.06812752  1.96201807\n6268   1.22589281 -0.36205814\n10285 -0.42763181 -0.62895735\n2247  -0.20541902 -0.58378979\n9821   0.06254347 -0.05409751\n1351  -0.90473576  2.47939193\n```\n:::\n\n```{.r .cell-code}\n?EcoData::elephant\n```\n:::\n\n\nMeaning of the bioclim variables:\n\n| Bioclim variable | Meaning                                                    |\n|--------------------------------------|----------------------------------|\n| bio1             | Annual Mean Temperature                                    |\n| bio2             | Mean Diurnal Range (Mean of monthly (max temp - min temp)) |\n| bio3             | Isothermality (BIO2/BIO7) (×100)                           |\n| bio4             | Temperature Seasonality (standard deviation ×100)          |\n| bio5             | Max Temperature of Warmest Month                           |\n| bio6             | Min Temperature of Coldest Month                           |\n| bio7             | Temperature Annual Range (BIO5-BIO6)                       |\n| bio8             | Mean Temperature of Wettest Quarter                        |\n| bio9             | Mean Temperature of Driest Quarter                         |\n| bio10            | Mean Temperature of Warmest Quarter                        |\n| bio11            | Mean Temperature of Coldest Quarter                        |\n| bio12            | Annual Precipitation                                       |\n| bio13            | Precipitation of Wettest Month                             |\n| bio14            | Precipitation of Driest Month                              |\n| bio15            | Precipitation Seasonality (Coefficient of Variation)       |\n| bio16            | Precipitation of Wettest Quarter                           |\n| bio17            | Precipitation of Driest Quarter                            |\n| bio18            | Precipitation of Warmest Quarter                           |\n| bio19            | Precipitation of Coldest Quarter                           |\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf = ranger(as.factor(Presence) ~ ., data = data, probability = TRUE)\n```\n:::\n\n\nxAI packages are written generic, i.e. they can handle almost all machine learning models. When we want to use them, we first have to create a predictor object, that holds the model and the data. The `iml` package uses R6 classes, that means new objects can be created by calling `Predictor$new()`. (Do not worry if you do not know what R6 classes are, just use the command.)\n\nWe often have to warp our predict function inside a so called wrapper function so that the output of the predict function fits to iml (iml expects that the predict function returns a vector of predictions:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict_wrapper = function(model, newdata) predict(model, data=newdata)$predictions[,2]\n\npredictor = Predictor$new(rf, data = data[,-1], y = data[,1], predict.function = predict_wrapper)\npredictor$task = \"classif\" # set task to classification\n# \"Predictor\" is an object generator.\n```\n:::\n\n\n## Feature Importance\n\nFeature importance should not be mistaken with the random forest variable importance though they are related. It tells us how important the individual variables are for predictions, can be calculated for all machine learning models and is based on a permutation approach (have a look at the book):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimp = FeatureImp$new(predictor, loss = \"ce\")\nplot(imp)\n```\n\n::: {.cell-output-display}\n![](D2-explainableAI_files/figure-html/chunk_chapter6_2-1.png){width=672}\n:::\n:::\n\n\nbio9 (Precipitation of the wettest Quarter) is the most important variable.\n\n## Partial Dependencies\n\nPartial dependencies are similar to allEffects plots for normal regressions. The idea is to visualize \"marginal effects\" of predictors (with the \"feature\" argument we specify the variable we want to visualize):\n\n\n::: {.cell}\n\n```{.r .cell-code}\neff = FeatureEffect$new(predictor, feature = \"bio9\", method = \"pdp\",\n                        grid.size = 30)\nplot(eff)\n```\n\n::: {.cell-output-display}\n![](D2-explainableAI_files/figure-html/chunk_chapter6_3-1.png){width=672}\n:::\n:::\n\n\nOne disadvantage of partial dependencies is that they are sensitive to correlated predictors. Accumulated local effects can be used for accounting for correlation of predictors.\n\n## Accumulated Local Effects\n\nAccumulated local effects (ALE) are basically partial dependencies plots but try to correct for correlations between predictors.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nale = FeatureEffect$new(predictor, feature = \"bio9\", method = \"ale\")\nale$plot()\n```\n\n::: {.cell-output-display}\n![](D2-explainableAI_files/figure-html/chunk_chapter6_5-1.png){width=672}\n:::\n:::\n\n\nIf there is no collinearity, you shouldn't see much difference between partial dependencies and ALE plots.\n\n## Friedman's H-statistic\n\nThe H-statistic can be used to find interactions between predictors. However, again, keep in mind that the H-statistic is sensible to correlation between predictors:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninteract = Interaction$new(predictor, \"bio9\",grid.size = 5L)\nplot(interact)\n```\n\n::: {.cell-output-display}\n![](D2-explainableAI_files/figure-html/chunk_chapter6_6-1.png){width=672}\n:::\n:::\n\n\n## Global Explainer - Simplifying the Machine Learning Model\n\nAnother idea is simplifying the machine learning model with another simpler model such as a decision tree. We create predictions with the machine learning model for a lot of different input values and then we fit a decision tree on these predictions. We can then interpret the easier model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(partykit)\n\ntree = TreeSurrogate$new(predictor, maxdepth = 2)\nplot(tree$tree)\n```\n\n::: {.cell-output-display}\n![](D2-explainableAI_files/figure-html/chunk_chapter6_7-1.png){width=672}\n:::\n:::\n\n\n## Local Explainer - LIME Explaining Single Instances (observations)\n\nThe global approach is to simplify the entire machine learning-black-box model via a simpler model, which is then interpretable.\n\nHowever, sometimes we are only interested in understanding how single predictions are generated. The LIME (Local interpretable model-agnostic explanations) approach explores the feature space around one observation and based on this locally fits a simpler model (e.g. a linear model):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlime.explain = LocalModel$new(predictor, x.interest = data[1,-1])\nlime.explain$results\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             beta x.recoded       effect        x.original feature\nbio9  -0.03972318 0.2494100 -0.009907356 0.249409955204759    bio9\nbio16 -0.12035200 0.7124535 -0.085745198 0.712453479144842   bio16\n                feature.value\nbio9   bio9=0.249409955204759\nbio16 bio16=0.712453479144842\n```\n:::\n\n```{.r .cell-code}\nplot(lime.explain)\n```\n\n::: {.cell-output-display}\n![](D2-explainableAI_files/figure-html/chunk_chapter6_8-1.png){width=672}\n:::\n:::\n\n\n## Local Explainer - Shapley\n\nThe Shapley method computes the so called Shapley value, feature contributions for single predictions, and is based on an approach from cooperative game theory. The idea is that each feature value of the instance is a \"player\" in a game, where the prediction is the reward. The Shapley value tells us how to fairly distribute the reward among the features.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshapley = Shapley$new(predictor, x.interest = data[1,-1])\nshapley$plot()\n```\n\n::: {.cell-output-display}\n![](D2-explainableAI_files/figure-html/chunk_chapter6_9-1.png){width=672}\n:::\n:::\n\n\n## Exercises\n\n::: {.callout-caution icon=\"false\"}\n#### Question\n\nUse one of the non-image based data sets (preferably Wine, which is also described in the data sets section @sec-datasets but wasn't used yet, but you can also use Nasa or Titanic) and fit a random forest or a BRT using xgboost. Explore / interpret the fitted model using `iml` (see also the book: <a href=\"https://christophm.github.io/interpretable-ml-book/\" target=\"_blank\" rel=\"noopener\">https://christophm.github.io/interpretable-ml-book/</a>).\n\n\n<div class='webex-solution'><button>Click here to see the solution for RF</button>\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ranger)\nlibrary(\"iml\")\nset.seed(1234)\n\ndata = as.data.frame(EcoData::wine)\nsubmission = data[which(is.na(data$quality)), -which(colnames(data) == \"quality\")]\ndata = data[complete.cases(data), ] # Removes sumbmission data as well.\n\n# Remark: Features don't need to be scaled for regression trees.\n\nrf = ranger(quality ~ ., data = data, importance = \"impurity\")\npred = round(predict(rf, data)$predictions)\ntable(pred, data$quality)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    \npred   3   4   5   6   7   8\n   4   2   6   0   0   0   0\n   5   0   4 133   1   0   0\n   6   0   0   3 112   9   0\n   7   0   0   0   0  26   3\n```\n:::\n\n```{.r .cell-code}\n(accuracy = mean(pred == data$quality)) # Fits pretty well (on the training data...)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9264214\n```\n:::\n\n```{.r .cell-code}\n# For submission:\n#write.csv(round(predict(rf, submission)), file = \"wine_RF.csv\")\n\n# Standard depiction of importance:\nrf$importance\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"impurity\"\n```\n:::\n\n```{.r .cell-code}\n# Setup wrapper\npredict_wrapper = function(model, newdata) predict(model, data=newdata)$predictions\n\n\n# IML:\npredictor = Predictor$new(\n    rf, data = data[,which(names(data) != \"quality\")], y = data$quality,\n    predict.function = predict_wrapper\n    )\n\n# Mind: This is stochastical!\nimportance = FeatureImp$new(predictor, loss = \"mae\")\n\nplot(importance)\n```\n\n::: {.cell-output-display}\n![](D2-explainableAI_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Comparison between standard importance and IML importance:\nimportanceRf = names(rf$variable.importance)[order(rf$variable.importance, decreasing = TRUE)]\nimportanceIML = importance$results[1]\ncomparison = cbind(importanceIML, importanceRf)\ncolnames(comparison) = c(\"IML\", \"RF\")\nas.matrix(comparison)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      IML                    RF                    \n [1,] \"alcohol\"              \"alcohol\"             \n [2,] \"sulphates\"            \"volatile.acidity\"    \n [3,] \"volatile.acidity\"     \"sulphates\"           \n [4,] \"citric.acid\"          \"density\"             \n [5,] \"total.sulfur.dioxide\" \"total.sulfur.dioxide\"\n [6,] \"density\"              \"citric.acid\"         \n [7,] \"fixed.acidity\"        \"fixed.acidity\"       \n [8,] \"pH\"                   \"chlorides\"           \n [9,] \"free.sulfur.dioxide\"  \"pH\"                  \n[10,] \"chlorides\"            \"residual.sugar\"      \n[11,] \"residual.sugar\"       \"free.sulfur.dioxide\" \n```\n:::\n:::\n\n\nMind that feature importance, and the random forest's variable importance are related but not equal! Variable importance is a measure for determining importance while creating the forest (i.e. for fitting). Feature importance is a measure for how important a variable is for prediction.\n\nMaybe you want to see other explanation methods as well. Surely you can use the other techniques of this section on your own. \n\n\n</div>\n\n\n\n\n\n<div class='webex-solution'><button>Click here to see the solution for xgboost</button>\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(xgboost)\nlibrary(\"iml\")\nset.seed(1234)\n\ndata = as.data.frame(EcoData::wine)\nsubmission = data[which(is.na(data$quality)), -which(colnames(data) == \"quality\")]\ndata = data[complete.cases(data), ] # Removes sumbmission data as well.\n\n\ndata_xg = xgb.DMatrix(\n  data = as.matrix(data[,which(names(data) != \"quality\")]),\n  label = data$quality\n)\nbrt = xgboost(data_xg, nrounds = 24)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]\ttrain-rmse:3.656523 \n[2]\ttrain-rmse:2.609494 \n[3]\ttrain-rmse:1.884807 \n[4]\ttrain-rmse:1.384918 \n[5]\ttrain-rmse:1.037362 \n[6]\ttrain-rmse:0.800110 \n[7]\ttrain-rmse:0.629324 \n[8]\ttrain-rmse:0.508917 \n[9]\ttrain-rmse:0.426155 \n[10]\ttrain-rmse:0.369580 \n[11]\ttrain-rmse:0.313017 \n[12]\ttrain-rmse:0.274227 \n[13]\ttrain-rmse:0.236959 \n[14]\ttrain-rmse:0.207364 \n[15]\ttrain-rmse:0.195811 \n[16]\ttrain-rmse:0.182500 \n[17]\ttrain-rmse:0.173310 \n[18]\ttrain-rmse:0.154747 \n[19]\ttrain-rmse:0.144045 \n[20]\ttrain-rmse:0.139083 \n[21]\ttrain-rmse:0.129605 \n[22]\ttrain-rmse:0.118541 \n[23]\ttrain-rmse:0.110689 \n[24]\ttrain-rmse:0.097798 \n```\n:::\n\n```{.r .cell-code}\npred = round(predict(brt, newdata = data_xg)) # On\n\ntable(pred, data$quality)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    \npred   3   4   5   6   7   8\n   3   2   0   0   0   0   0\n   4   0  10   0   0   0   0\n   5   0   0 136   0   0   0\n   6   0   0   0 113   1   0\n   7   0   0   0   0  34   0\n   8   0   0   0   0   0   3\n```\n:::\n\n```{.r .cell-code}\n(accuracy = mean(pred == data$quality)) # Fits pretty well (on the training data...)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9966555\n```\n:::\n\n```{.r .cell-code}\n# For submission:\n#write.csv(round(predict(rf, submission)), file = \"wine_RF.csv\")\n\n# Standard depiction of importance:\nxgboost::xgb.importance(model = brt)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 Feature       Gain      Cover  Frequency\n 1:              alcohol 0.28363854 0.13667721 0.07073509\n 2:            sulphates 0.11331809 0.07015405 0.06657420\n 3:        fixed.acidity 0.09844424 0.11359510 0.19278779\n 4:     volatile.acidity 0.09582787 0.07098397 0.12760055\n 5: total.sulfur.dioxide 0.09207959 0.09147259 0.07212205\n 6:              density 0.07374571 0.14910006 0.08321775\n 7:            chlorides 0.06025507 0.07972405 0.08876560\n 8:       residual.sugar 0.05307941 0.07202137 0.08044383\n 9:  free.sulfur.dioxide 0.04602735 0.04743503 0.06518724\n10:                   pH 0.04477571 0.12562892 0.07489598\n11:          citric.acid 0.03880842 0.04320764 0.07766990\n```\n:::\n\n```{.r .cell-code}\n# Setup wrapper\npredict_wrapper = function(model, newdata) predict(model, as.matrix(newdata))\n\n\n# IML:\npredictor = Predictor$new(\n    brt, data = data[,which(names(data) != \"quality\")], y = data$quality,\n    predict.function = predict_wrapper\n    )\n\n# Mind: This is stochastical!\nimportance = FeatureImp$new(predictor, loss = \"mae\")\n\nplot(importance)\n```\n\n::: {.cell-output-display}\n![](D2-explainableAI_files/figure-html/chunk_chapter6_task_0-1.png){width=672}\n:::\n:::\n\n\n\n\n\n</div>\n\n\n:::\n\n::: {.callout-caution icon=\"false\"}\n#### Question\n\nAs we show in Section 13 of this chapter, a random forest will partition the importance of variables across collinear predictors, while a linear regression model (`lm()`) can identify which predictor is causally affecting the response (at least in theory, if all confounders are controlled). What about a boosted regression tree or an artificial neural network? Take the random forest example and add a boosted regression tree (easier, you can use e.g. <https://rdrr.io/cran/xgboost/man/xgb.importance.html>) or an artificial neural network and see if they are better than the random forest at identifying causal predictors.\n\n\n<div class='webex-solution'><button>Click here to see the solution</button>\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(xgboost)\nset.seed(1234)\n\ndata = as.data.frame(EcoData::wine)\nsubmission = data[which(is.na(data$quality)), -which(colnames(data) == \"quality\")]\ndata = data[complete.cases(data), ] # Removes sumbmission data as well.\n\ndata_xg = xgb.DMatrix(\n  data = as.matrix(data[,which(names(data) != \"quality\")]),\n  label = data$quality\n)\nbrt = xgboost(data_xg, nrounds = 24)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]\ttrain-rmse:3.656523 \n[2]\ttrain-rmse:2.609494 \n[3]\ttrain-rmse:1.884807 \n[4]\ttrain-rmse:1.384918 \n[5]\ttrain-rmse:1.037362 \n[6]\ttrain-rmse:0.800110 \n[7]\ttrain-rmse:0.629324 \n[8]\ttrain-rmse:0.508917 \n[9]\ttrain-rmse:0.426155 \n[10]\ttrain-rmse:0.369580 \n[11]\ttrain-rmse:0.313017 \n[12]\ttrain-rmse:0.274227 \n[13]\ttrain-rmse:0.236959 \n[14]\ttrain-rmse:0.207364 \n[15]\ttrain-rmse:0.195811 \n[16]\ttrain-rmse:0.182500 \n[17]\ttrain-rmse:0.173310 \n[18]\ttrain-rmse:0.154747 \n[19]\ttrain-rmse:0.144045 \n[20]\ttrain-rmse:0.139083 \n[21]\ttrain-rmse:0.129605 \n[22]\ttrain-rmse:0.118541 \n[23]\ttrain-rmse:0.110689 \n[24]\ttrain-rmse:0.097798 \n```\n:::\n\n```{.r .cell-code}\npred = round(predict(brt, newdata = data_xg)) # Only integers are allowed.\ntable(pred, data$quality)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    \npred   3   4   5   6   7   8\n   3   2   0   0   0   0   0\n   4   0  10   0   0   0   0\n   5   0   0 136   0   0   0\n   6   0   0   0 113   1   0\n   7   0   0   0   0  34   0\n   8   0   0   0   0   0   3\n```\n:::\n\n```{.r .cell-code}\n(accuracy = mean(pred == data$quality)) # Fits very well (on the training data...)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9966555\n```\n:::\n\n```{.r .cell-code}\n# For submission:\n#write.csv(round(predict(rf, submission)), file = \"wine_RF.csv\")\n\n# Look at variable importance:\nxgboost::xgb.importance(model = brt)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 Feature       Gain      Cover  Frequency\n 1:              alcohol 0.28363854 0.13667721 0.07073509\n 2:            sulphates 0.11331809 0.07015405 0.06657420\n 3:        fixed.acidity 0.09844424 0.11359510 0.19278779\n 4:     volatile.acidity 0.09582787 0.07098397 0.12760055\n 5: total.sulfur.dioxide 0.09207959 0.09147259 0.07212205\n 6:              density 0.07374571 0.14910006 0.08321775\n 7:            chlorides 0.06025507 0.07972405 0.08876560\n 8:       residual.sugar 0.05307941 0.07202137 0.08044383\n 9:  free.sulfur.dioxide 0.04602735 0.04743503 0.06518724\n10:                   pH 0.04477571 0.12562892 0.07489598\n11:          citric.acid 0.03880842 0.04320764 0.07766990\n```\n:::\n:::\n\n\nEvery method yields slightly different results, but the main ingredient is alcohol (and sulphates).\n\n\n</div>\n\n:::\n\n::: {.callout-caution icon=\"false\"}\n#### Bonus Task\n\nIf you're done with the previous tasks and have still time and appetite, improve the submissions for our competition, in particular for the Wine data set. Possible ideas:\n\n-   Use MLR framework (section @sec-mlr).\n\n-   Try Transfer learning (section @sec-transfer). The winner from last years used transfer learning to win the flower competition\n\n-   Search on kaggle for more ideas / try to copy the ideas. This was the winner two years ago.\n\nA minimal example for the (unbalanced!) Wine data set:\n\n\n<div class='webex-solution'><button>Click here to see the solution</button>\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tensorflow)\nlibrary(keras)\nset_random_seed(123L, disable_gpu = FALSE)\t# Already sets R's random seed.\n\nreadin = function(percentageTest = 0.2, aggregate = 0){\n    # Parameter \"aggregate\" packs the classes with very low abundances into one.\n    # If \"aggregate\" equals to NA, NaN, Null, 0 or FALSE, no aggregation is performed.\n    # Else, the given number is the boundary.\n    # Every class with less elements than the boundary is aggregated into one.\n    \n    # WARNING: These classes cannot be distinguished from then on!\n    # Using the predictions for submission needs further processing!\n    \n    # Just for random selection of features, independent of the amount of function calls.\n    set.seed(12345)\n    \n    train = as.data.frame(EcoData::wine)\n    indicesTrain = which(!is.na(train$quality))\n    labelsTrain = train$quality[indicesTrain]\n    labelsTrain = labelsTrain - min(labelsTrain)  # Start at 0 (for softmax).\n    train = train[, -which(colnames(train) == \"quality\")]\n    \n    if(!is.na(aggregate) & aggregate){\n        indices = names(table(labelsTrain)[\n            table(labelsTrain) < aggregate & table(labelsTrain) > 0\n        ])\n        if(length(indices)){\n            labelsTrain[labelsTrain %in% indices] = -1\n            labelsTrain = as.factor(labelsTrain)\n            levels(labelsTrain) = 1:length(levels(labelsTrain)) - 1\n            labelsTrain = as.integer(labelsTrain)\n        }\n    }\n    \n    # Impute missing values (before any splitting, to get the highest power):\n    train = missRanger::missRanger(\n        data = train,\n        maxiter = 10L,\n        seed = 123,\n        num.trees = 200L\n    )\n    \n    # Separate submission data (mind scaling!):\n    submission = scale(train[-indicesTrain,])\n    train = scale(train[indicesTrain,])\n    \n    # Very asymmetric training data:\n    cat(paste0(\"Size of training set: \", length(labelsTrain), \"\\n\"))\n    print(table(labelsTrain))\n    \n    if(percentageTest == 0){\n      return(list(\n        \"labelsTrain\" = labelsTrain,\n        \"labelsTest\" = list(),\n        \"train\" = train,\n        \"test\" = list(),\n        \"submission\" = submission\n      ))\n    }\n    \n    # Split into training and test set:\n    len = nrow(train)\n    indicesTest = sample(x = 1:len, size = percentageTest * len, replace = FALSE)\n    test = as.data.frame(train[indicesTest,])\n    labelsTest = labelsTrain[indicesTest]\n    train = as.data.frame(train[-indicesTest,])\n    labelsTrain = labelsTrain[-indicesTest]\n    \n    return(list(\n        \"labelsTrain\" = labelsTrain,\n        \"labelsTest\" = labelsTest,\n        \"train\" = train,\n        \"test\" = test,\n        \"submission\" = submission\n    ))\n}\n\nretVal = readin(aggregate = 0)\nlabelsTrain = retVal[[\"labelsTrain\"]]\nlabelsTest = retVal[[\"labelsTest\"]]\ntrain = retVal[[\"train\"]]\ntest = retVal[[\"test\"]]\nsubmission = retVal[[\"submission\"]]\nrm(retVal)\n\nclassNumber = length(table(labelsTrain))\n\nmodel = keras_model_sequential()\nmodel %>%\n    layer_dense(units = 200L, activation = \"leaky_relu\",\n    kernel_regularizer = regularizer_l2(0.00035),\n    input_shape = ncol(train)) %>%\n    layer_dropout(0.45) %>%\n    layer_dense(units = 100L, activation = \"relu\",\n    bias_regularizer = regularizer_l1_l2(0.5)) %>%\n    layer_dropout(0.2) %>%\n    layer_dense(units = 100L, activation = \"leaky_relu\",\n    kernel_regularizer = regularizer_l2(0.00035),\n    bias_regularizer = regularizer_l1_l2(0.1)) %>%\n    layer_dropout(0.25) %>%\n    layer_dense(units = 50L, activation = \"gelu\") %>%\n    layer_dense(units = 25L, activation = \"elu\") %>%\n    layer_dropout(0.35) %>%\n    # We need probabilities. So we use the softmax function.\n    # Remember, the labels MUST start at 0!\n    layer_dense(units = classNumber, activation = \"softmax\")\n\nmodel %>%\n    keras::compile(loss = loss_binary_crossentropy,\n                   optimizer = optimizer_adamax(learning_rate = 0.015))\n\nmodel_history = \n    model %>% # Mind the matrix property (no data.frame)!\n        fit(x = as.matrix(train), y = k_one_hot(labelsTrain, classNumber),\n            epochs = 80L, batch = 12L, shuffle = TRUE)\n\nplot(model_history)\n\n# Accuracy on training set (!)\npred = predict(model, as.matrix(train)) %>% apply(1, which.max) - 1\nMetrics::accuracy(pred, labelsTrain)\ntable(pred, labelsTrain)\n\n# Accuracy on test set\npred = predict(model, as.matrix(test)) %>% apply(1, which.max) - 1\nMetrics::accuracy(pred, labelsTest)\ntable(pred, labelsTest)\n```\n:::\n\n\nRecognize overfitting of your model selection strategy by changing the seed few times (while keeping the model constant) and increase the percentage of test data. Furthermore, consider fitting a random forest for good quality as well.\n\nFor the final predictions, we use the whole data set without holdouts:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tensorflow)\nlibrary(keras)\nset_random_seed(321L, disable_gpu = FALSE)\t# Already sets R's random seed.\n\nretVal = readin(percentageTest = 0, aggregate = 0)\nlabelsTrain = retVal[[\"labelsTrain\"]]\nlabelsTest = retVal[[\"labelsTest\"]]\ntrain = retVal[[\"train\"]]\ntest = retVal[[\"test\"]]\nsubmission = retVal[[\"submission\"]]\nrm(retVal)\n\nclassNumber = length(table(labelsTrain))\n\nmodel = keras_model_sequential()\nmodel %>%\n    layer_dense(units = 200L, activation = \"leaky_relu\",\n    kernel_regularizer = regularizer_l2(0.00035),\n    input_shape = ncol(train)) %>%\n    layer_dropout(0.45) %>%\n    layer_dense(units = 100L, activation = \"relu\",\n    bias_regularizer = regularizer_l1_l2(0.5)) %>%\n    layer_dropout(0.2) %>%\n    layer_dense(units = 100L, activation = \"leaky_relu\",\n    kernel_regularizer = regularizer_l2(0.00035),\n    bias_regularizer = regularizer_l1_l2(0.1)) %>%\n    layer_dropout(0.25) %>%\n    layer_dense(units = 50L, activation = \"gelu\") %>%\n    layer_dense(units = 25L, activation = \"elu\") %>%\n    layer_dropout(0.35) %>%\n    # We need probabilities. So we use the softmax function.\n    # Remember, the labels MUST start at 0!\n    layer_dense(units = classNumber, activation = \"softmax\")\n\nmodel %>%\n    keras::compile(loss = loss_binary_crossentropy,\n                   optimizer = optimizer_adamax(learning_rate = 0.015))\n\nmodel_history = \n    model %>% # Mind the matrix property (no data.frame)!\n        fit(x = as.matrix(train), y = k_one_hot(labelsTrain, classNumber),\n            epochs = 80L, batch = 12L, shuffle = TRUE)\n\nplot(model_history)\n\n# Accuracy on training set (!)\npred = predict(model, as.matrix(train)) %>% apply(1, which.max) - 1\nMetrics::accuracy(pred, labelsTrain)\ntable(pred, labelsTrain)\n\n# Reverse subtraction (for start at 0) and create submission file.\nwrite.csv(pred + min(as.data.frame(EcoData::wine)$quality, na.rm = TRUE),\n          file = \"wine_NN.csv\")\n```\n:::\n\n\n\n</div>\n\n:::\n",
    "supporting": [
      "D2-explainableAI_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
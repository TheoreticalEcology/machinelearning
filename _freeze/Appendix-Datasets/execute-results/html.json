{
  "hash": "8db470e9f21165393f51b1ffef5d137f",
  "result": {
    "markdown": "---\noutput: html_document\neditor_options:\n  chunk_output_type: console\n---\n\n\n# Datasets {#sec-datasets}\n\n\n\n\n\nYou can download the data sets we use in the course <a href=\"http://rhsbio7.uni-regensburg.de:8500\" target=\"_blank\" rel=\"noopener\">here</a> (ignore browser warnings) or by installing the EcoData package:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndevtools::install_github(repo = \"florianhartig/EcoData\", subdir = \"EcoData\",\n                         dependencies = TRUE, build_vignettes = FALSE)\n```\n:::\n\n\n## Titanic\n\nThe data set is a collection of Titanic passengers with information about their age, class, sex, and their survival status. The competition is simple here: Train a machine learning model and predict the survival probability.\n\nThe Titanic data set is very well explored and serves as a stepping stone in many machine learning careers. For inspiration and data exploration notebooks, check out this <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\" rel=\"noopener\">kaggle competition</a>.\n\n**Response variable:** \"survived\"\n\nA minimal working example:\n\n1.  Load data set:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(EcoData)\n\ndata(titanic_ml)\ntitanic = titanic_ml\nsummary(titanic)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     pclass         survived          name               sex     \n Min.   :1.000   Min.   :0.0000   Length:1309        female:466  \n 1st Qu.:2.000   1st Qu.:0.0000   Class :character   male  :843  \n Median :3.000   Median :0.0000   Mode  :character               \n Mean   :2.295   Mean   :0.3853                                  \n 3rd Qu.:3.000   3rd Qu.:1.0000                                  \n Max.   :3.000   Max.   :1.0000                                  \n                 NA's   :655                                     \n      age              sibsp            parch            ticket    \n Min.   : 0.1667   Min.   :0.0000   Min.   :0.000   CA. 2343:  11  \n 1st Qu.:21.0000   1st Qu.:0.0000   1st Qu.:0.000   1601    :   8  \n Median :28.0000   Median :0.0000   Median :0.000   CA 2144 :   8  \n Mean   :29.8811   Mean   :0.4989   Mean   :0.385   3101295 :   7  \n 3rd Qu.:39.0000   3rd Qu.:1.0000   3rd Qu.:0.000   347077  :   7  \n Max.   :80.0000   Max.   :8.0000   Max.   :9.000   347082  :   7  \n NA's   :263                                        (Other) :1261  \n      fare                     cabin      embarked      boat    \n Min.   :  0.000                  :1014    :  2           :823  \n 1st Qu.:  7.896   C23 C25 C27    :   6   C:270    13     : 39  \n Median : 14.454   B57 B59 B63 B66:   5   Q:123    C      : 38  \n Mean   : 33.295   G6             :   5   S:914    15     : 37  \n 3rd Qu.: 31.275   B96 B98        :   4            14     : 33  \n Max.   :512.329   C22 C26        :   4            4      : 31  \n NA's   :1         (Other)        : 271            (Other):308  \n      body                      home.dest  \n Min.   :  1.0                       :564  \n 1st Qu.: 72.0   New York, NY        : 64  \n Median :155.0   London              : 14  \n Mean   :160.8   Montreal, PQ        : 10  \n 3rd Qu.:256.0   Cornwall / Akron, OH:  9  \n Max.   :328.0   Paris, France       :  9  \n NA's   :1188    (Other)             :639  \n```\n:::\n:::\n\n\n2.  Impute missing values (not our response variable!):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(missRanger)\nlibrary(dplyr)\nset.seed(123)\n\ntitanic_imputed = titanic %>% select(-name, -ticket, -cabin, -boat, -home.dest)\ntitanic_imputed = missRanger::missRanger(data = titanic_imputed %>%\n                                           select(-survived))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nMissing value imputation by random forests\n\n  Variables to impute:\t\tage, fare, body\n  Variables used to impute:\tpclass, sex, age, sibsp, parch, fare, embarked, body\n\niter 1\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |======================================================================| 100%\niter 2\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |======================================================================| 100%\niter 3\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\ntitanic_imputed$survived = titanic$survived\n```\n:::\n\n\n3.  Split into training and test set:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain = titanic_imputed[!is.na(titanic$survived), ]\ntest = titanic_imputed[is.na(titanic$survived), ]\n```\n:::\n\n\n4.  Train model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel = glm(survived~., data = train, family = binomial())\n```\n:::\n\n\n5.  Predictions:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreds = predict(model, data = test, type = \"response\")\nhead(preds)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       561        321       1177       1098       1252       1170 \n0.79095923 0.30597519 0.01400693 0.12310859 0.14099292 0.11768284 \n```\n:::\n:::\n\n\n6.  Create submission csv:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite.csv(data.frame(y = preds), file = \"glm.csv\")\n```\n:::\n\n\nAnd submit the csv on <a href=\"http://rhsbio7.uni-regensburg.de:8500\" target=\"_blank\" rel=\"noopener\">http://rhsbio7.uni-regensburg.de:8500</a>.\n\n## Plant-pollinator Database\n\nThe plant-pollinator database is a collection of plant-pollinator interactions with traits for plants and pollinators. The idea is pollinators interact with plants when their traits fit (e.g. the tongue of a bee needs to match the shape of a flower). We explored the advantage of machine learning algorithms over traditional statistical models in predicting species interactions in our paper. If you are interested you can have a look <a href=\"https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.13329\" target=\"_blank\" rel=\"noopener\">here</a>.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](./images/TM.png){width=699}\n:::\n:::\n\n\n**Response variable:** \"interaction\"\n\nA minimal working example:\n\n1.  Load data set:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(EcoData)\n\ndata(plantPollinator_df)\nplant_poll = plantPollinator_df\nsummary(plant_poll)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                   crop                       insect          type          \n Vaccinium_corymbosum:  256   Andrena_wilkella   :   80   Length:20480      \n Brassica_napus      :  256   Andrena_barbilabris:   80   Class :character  \n Carum_carvi         :  256   Andrena_cineraria  :   80   Mode  :character  \n Coriandrum_sativum  :  256   Andrena_flavipes   :   80                     \n Daucus_carota       :  256   Andrena_gravida    :   80                     \n Malus_domestica     :  256   Andrena_haemorrhoa :   80                     \n (Other)             :18944   (Other)            :20000                     \n    season             diameter        corolla             colour         \n Length:20480       Min.   :  2.00   Length:20480       Length:20480      \n Class :character   1st Qu.:  5.00   Class :character   Class :character  \n Mode  :character   Median : 19.00   Mode  :character   Mode  :character  \n                    Mean   : 27.03                                        \n                    3rd Qu.: 25.00                                        \n                    Max.   :150.00                                        \n                    NA's   :9472                                          \n    nectar            b.system         s.pollination      inflorescence     \n Length:20480       Length:20480       Length:20480       Length:20480      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n  composite            guild               tongue            body      \n Length:20480       Length:20480       Min.   : 2.000   Min.   : 2.00  \n Class :character   Class :character   1st Qu.: 4.800   1st Qu.: 8.00  \n Mode  :character   Mode  :character   Median : 6.600   Median :10.50  \n                                       Mean   : 8.104   Mean   :10.66  \n                                       3rd Qu.:10.500   3rd Qu.:13.00  \n                                       Max.   :26.400   Max.   :25.00  \n                                       NA's   :17040    NA's   :6160   \n  sociality           feeding          interaction \n Length:20480       Length:20480       0   :14095  \n Class :character   Class :character   1   :  595  \n Mode  :character   Mode  :character   NA's: 5790  \n                                                   \n                                                   \n                                                   \n                                                   \n```\n:::\n:::\n\n\n2.  Impute missing values (not our response variable!) We will select only a few predictors here (you can work with all predictors of course).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(missRanger)\nlibrary(dplyr)\nset.seed(123)\n\nplant_poll_imputed = plant_poll %>% select(diameter,\n                                           corolla,\n                                           tongue,\n                                           body,\n                                           interaction)\nplant_poll_imputed = missRanger::missRanger(data = plant_poll_imputed %>%\n                                              select(-interaction))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nMissing value imputation by random forests\n\n  Variables to impute:\t\tdiameter, corolla, tongue, body\n  Variables used to impute:\tdiameter, corolla, tongue, body\n\niter 1\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |======================================================================| 100%\niter 2\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |======================================================================| 100%\niter 3\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\nplant_poll_imputed$interaction = plant_poll$interaction\n```\n:::\n\n\n3.  Split into training and test set:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain = plant_poll_imputed[!is.na(plant_poll_imputed$interaction), ]\ntest = plant_poll_imputed[is.na(plant_poll_imputed$interaction), ]\n```\n:::\n\n\n4.  Train model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel = glm(interaction~., data = train, family = binomial())\n```\n:::\n\n\n5.  Predictions:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreds = predict(model, newdata = test, type = \"response\")\nhead(preds)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         1          2          3          4          5          6 \n0.02942746 0.05063489 0.03780247 0.03780247 0.02651142 0.04130643 \n```\n:::\n:::\n\n\n6.  Create submission csv:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite.csv(data.frame(y = preds), file = \"glm.csv\")\n```\n:::\n\n\n## Wine\n\nThe data set is a collection of wines of different quality. The aim is to predict the quality of the wine based on physiochemical predictors.\n\nFor inspiration and data exploration notebooks, check out this <a href=\"https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009\" target=\"_blank\" rel=\"noopener\">kaggle competition</a>. For instance, check out this very nice <a href=\"https://www.kaggle.com/aditimulye/red-wine-quality-assesment-starter-pack\" target=\"_blank\" rel=\"noopener\">notebook</a> which removes a few problems from the data.\n\n**Response variable:** \"quality\"\n\nWe could theoretically use a regression model for this task but we will stick with a classification model.\n\nA minimal working example:\n\n1.  Load data set:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(EcoData)\n\ndata(wine)\nsummary(wine)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n fixed.acidity    volatile.acidity  citric.acid     residual.sugar  \n Min.   : 4.600   Min.   :0.1200   Min.   :0.0000   Min.   : 0.900  \n 1st Qu.: 7.100   1st Qu.:0.3900   1st Qu.:0.0900   1st Qu.: 1.900  \n Median : 7.900   Median :0.5200   Median :0.2600   Median : 2.200  \n Mean   : 8.335   Mean   :0.5284   Mean   :0.2705   Mean   : 2.533  \n 3rd Qu.: 9.300   3rd Qu.:0.6400   3rd Qu.:0.4200   3rd Qu.: 2.600  \n Max.   :15.900   Max.   :1.5800   Max.   :1.0000   Max.   :15.500  \n NA's   :70       NA's   :48       NA's   :41       NA's   :60      \n   chlorides       free.sulfur.dioxide total.sulfur.dioxide    density      \n Min.   :0.01200   Min.   : 1.00       Min.   :  6.00       Min.   :0.9901  \n 1st Qu.:0.07000   1st Qu.: 7.00       1st Qu.: 22.00       1st Qu.:0.9956  \n Median :0.07900   Median :14.00       Median : 38.00       Median :0.9968  \n Mean   :0.08747   Mean   :15.83       Mean   : 46.23       Mean   :0.9968  \n 3rd Qu.:0.09000   3rd Qu.:21.00       3rd Qu.: 62.00       3rd Qu.:0.9979  \n Max.   :0.61100   Max.   :72.00       Max.   :289.00       Max.   :1.0037  \n NA's   :37        NA's   :78          NA's   :78           NA's   :78      \n       pH          sulphates         alcohol         quality     \n Min.   :2.740   Min.   :0.3300   Min.   : 8.40   Min.   :3.000  \n 1st Qu.:3.210   1st Qu.:0.5500   1st Qu.: 9.50   1st Qu.:5.000  \n Median :3.310   Median :0.6200   Median :10.20   Median :6.000  \n Mean   :3.311   Mean   :0.6572   Mean   :10.42   Mean   :5.596  \n 3rd Qu.:3.400   3rd Qu.:0.7300   3rd Qu.:11.10   3rd Qu.:6.000  \n Max.   :4.010   Max.   :2.0000   Max.   :14.90   Max.   :8.000  \n NA's   :25      NA's   :51                       NA's   :905    \n```\n:::\n:::\n\n\n2.  Impute missing values (not our response variable!).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(missRanger)\nlibrary(dplyr)\nset.seed(123)\n\nwine_imputed = missRanger::missRanger(data = wine %>% select(-quality))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nMissing value imputation by random forests\n\n  Variables to impute:\t\tfixed.acidity, volatile.acidity, citric.acid, residual.sugar, chlorides, free.sulfur.dioxide, total.sulfur.dioxide, density, pH, sulphates\n  Variables used to impute:\tfixed.acidity, volatile.acidity, citric.acid, residual.sugar, chlorides, free.sulfur.dioxide, total.sulfur.dioxide, density, pH, sulphates, alcohol\n\niter 1\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |======================================================================| 100%\niter 2\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |======================================================================| 100%\niter 3\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |======================================================================| 100%\niter 4\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |======================================================================| 100%\niter 5\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\nwine_imputed$quality = wine$quality\n```\n:::\n\n\n3.  Split into training and test set:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain = wine_imputed[!is.na(wine$quality), ]\ntest = wine_imputed[is.na(wine$quality), ]\n```\n:::\n\n\n4.  Train model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ranger)\nset.seed(123)\n\nrf = ranger(quality~., data = train, classification = TRUE)\n```\n:::\n\n\n5.  Predictions:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreds = predict(rf, data = test)$predictions\nhead(preds)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 6 5 5 7 6 6\n```\n:::\n:::\n\n\n6.  Create submission csv:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite.csv(data.frame(y = preds), file = \"rf.csv\")\n```\n:::\n\n\n## Nasa\n\nA collection about asteroids and their characteristics from kaggle. The aim is to predict whether the asteroids are hazardous or not. For inspiration and data exploration notebooks, check out this <a href=\"https://www.kaggle.com/shrutimehta/nasa-asteroids-classification\" target=\"_blank\" rel=\"noopener\">kaggle competition</a>.\n\n**Response variable:** \"Hazardous\"\n\n1.  Load data set:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(EcoData)\n\ndata(nasa)\nsummary(nasa)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Neo.Reference.ID       Name         Absolute.Magnitude Est.Dia.in.KM.min.\n Min.   :2000433   Min.   :2000433   Min.   :11.16      Min.   : 0.00101  \n 1st Qu.:3102682   1st Qu.:3102683   1st Qu.:20.10      1st Qu.: 0.03346  \n Median :3514800   Median :3514800   Median :21.90      Median : 0.11080  \n Mean   :3272675   Mean   :3273113   Mean   :22.27      Mean   : 0.20523  \n 3rd Qu.:3690987   3rd Qu.:3690385   3rd Qu.:24.50      3rd Qu.: 0.25384  \n Max.   :3781897   Max.   :3781897   Max.   :32.10      Max.   :15.57955  \n NA's   :53        NA's   :57        NA's   :36         NA's   :60        \n Est.Dia.in.KM.max. Est.Dia.in.M.min.   Est.Dia.in.M.max. \n Min.   : 0.00226   Min.   :    1.011   Min.   :    2.26  \n 1st Qu.: 0.07482   1st Qu.:   33.462   1st Qu.:   74.82  \n Median : 0.24777   Median :  110.804   Median :  247.77  \n Mean   : 0.45754   Mean   :  204.649   Mean   :  458.45  \n 3rd Qu.: 0.56760   3rd Qu.:  253.837   3rd Qu.:  567.60  \n Max.   :34.83694   Max.   :15579.552   Max.   :34836.94  \n NA's   :23         NA's   :29          NA's   :46        \n Est.Dia.in.Miles.min. Est.Dia.in.Miles.max. Est.Dia.in.Feet.min.\n Min.   :0.00063       Min.   : 0.00140      Min.   :    3.32    \n 1st Qu.:0.02079       1st Qu.: 0.04649      1st Qu.:  109.78    \n Median :0.06885       Median : 0.15395      Median :  363.53    \n Mean   :0.12734       Mean   : 0.28486      Mean   :  670.44    \n 3rd Qu.:0.15773       3rd Qu.: 0.35269      3rd Qu.:  832.80    \n Max.   :9.68068       Max.   :21.64666      Max.   :51114.02    \n NA's   :42            NA's   :50            NA's   :21          \n Est.Dia.in.Feet.max. Close.Approach.Date Epoch.Date.Close.Approach\n Min.   :     7.41    2016-07-22:  18     Min.   :7.889e+11        \n 1st Qu.:   245.49    2015-01-15:  17     1st Qu.:1.016e+12        \n Median :   812.88    2015-02-15:  16     Median :1.203e+12        \n Mean   :  1500.77    2007-11-08:  15     Mean   :1.180e+12        \n 3rd Qu.:  1862.19    2012-01-15:  15     3rd Qu.:1.356e+12        \n Max.   :114294.42    (Other)   :4577     Max.   :1.473e+12        \n NA's   :46           NA's      :  29     NA's   :43               \n Relative.Velocity.km.per.sec Relative.Velocity.km.per.hr Miles.per.hour   \n Min.   : 0.3355              Min.   :  1208              Min.   :  750.5  \n 1st Qu.: 8.4497              1st Qu.: 30399              1st Qu.:18846.7  \n Median :12.9370              Median : 46532              Median :28893.7  \n Mean   :13.9848              Mean   : 50298              Mean   :31228.0  \n 3rd Qu.:18.0774              3rd Qu.: 65068              3rd Qu.:40436.9  \n Max.   :44.6337              Max.   :160681              Max.   :99841.2  \n NA's   :27                   NA's   :28                  NA's   :38       \n Miss.Dist..Astronomical. Miss.Dist..lunar.   Miss.Dist..kilometers.\n Min.   :0.00018          Min.   :  0.06919   Min.   :   26610      \n 1st Qu.:0.13341          1st Qu.: 51.89874   1st Qu.:19964907      \n Median :0.26497          Median :103.19415   Median :39685408      \n Mean   :0.25690          Mean   : 99.91366   Mean   :38436154      \n 3rd Qu.:0.38506          3rd Qu.:149.59244   3rd Qu.:57540318      \n Max.   :0.49988          Max.   :194.45491   Max.   :74781600      \n NA's   :60               NA's   :30          NA's   :56            \n Miss.Dist..miles.  Orbiting.Body    Orbit.ID     \n Min.   :   16535   Earth:4665    Min.   :  1.00  \n 1st Qu.:12454813   NA's :  22    1st Qu.:  9.00  \n Median :24662435                 Median : 16.00  \n Mean   :23885560                 Mean   : 28.34  \n 3rd Qu.:35714721                 3rd Qu.: 31.00  \n Max.   :46467132                 Max.   :611.00  \n NA's   :27                       NA's   :33      \n        Orbit.Determination.Date Orbit.Uncertainity Minimum.Orbit.Intersection\n 2017-06-21 06:17:20:   9        Min.   :0.000      Min.   :0.00000           \n 2017-04-06 08:57:13:   8        1st Qu.:0.000      1st Qu.:0.01435           \n 2017-04-06 09:24:24:   8        Median :3.000      Median :0.04653           \n 2017-04-06 08:24:13:   7        Mean   :3.521      Mean   :0.08191           \n 2017-04-06 08:26:19:   7        3rd Qu.:6.000      3rd Qu.:0.12150           \n (Other)            :4622        Max.   :9.000      Max.   :0.47789           \n NA's               :  26        NA's   :49         NA's   :137               \n Jupiter.Tisserand.Invariant Epoch.Osculation   Eccentricity    \n Min.   :2.196               Min.   :2450164   Min.   :0.00752  \n 1st Qu.:4.047               1st Qu.:2458000   1st Qu.:0.24086  \n Median :5.071               Median :2458000   Median :0.37251  \n Mean   :5.056               Mean   :2457723   Mean   :0.38267  \n 3rd Qu.:6.017               3rd Qu.:2458000   3rd Qu.:0.51256  \n Max.   :9.025               Max.   :2458020   Max.   :0.96026  \n NA's   :56                  NA's   :60        NA's   :39       \n Semi.Major.Axis   Inclination       Asc.Node.Longitude Orbital.Period  \n Min.   :0.6159   Min.   : 0.01451   Min.   :  0.0019   Min.   : 176.6  \n 1st Qu.:1.0012   1st Qu.: 4.93290   1st Qu.: 83.1849   1st Qu.: 365.9  \n Median :1.2422   Median :10.27694   Median :172.6347   Median : 504.9  \n Mean   :1.4009   Mean   :13.36159   Mean   :172.1717   Mean   : 635.5  \n 3rd Qu.:1.6782   3rd Qu.:19.47848   3rd Qu.:254.8804   3rd Qu.: 793.1  \n Max.   :5.0720   Max.   :75.40667   Max.   :359.9059   Max.   :4172.2  \n NA's   :53       NA's   :42         NA's   :60         NA's   :46      \n Perihelion.Distance Perihelion.Arg     Aphelion.Dist    Perihelion.Time  \n Min.   :0.08074     Min.   :  0.0069   Min.   :0.8038   Min.   :2450100  \n 1st Qu.:0.63038     1st Qu.: 95.6430   1st Qu.:1.2661   1st Qu.:2457815  \n Median :0.83288     Median :189.7729   Median :1.6182   Median :2457972  \n Mean   :0.81316     Mean   :184.0185   Mean   :1.9864   Mean   :2457726  \n 3rd Qu.:0.99718     3rd Qu.:271.9535   3rd Qu.:2.4497   3rd Qu.:2458108  \n Max.   :1.29983     Max.   :359.9931   Max.   :8.9839   Max.   :2458839  \n NA's   :22          NA's   :48         NA's   :38       NA's   :59       \n  Mean.Anomaly       Mean.Motion       Equinox       Hazardous    \n Min.   :  0.0032   Min.   :0.08628   J2000:4663   Min.   :0.000  \n 1st Qu.: 87.0069   1st Qu.:0.45147   NA's :  24   1st Qu.:0.000  \n Median :186.0219   Median :0.71137                Median :0.000  \n Mean   :181.2882   Mean   :0.73732                Mean   :0.176  \n 3rd Qu.:276.6418   3rd Qu.:0.98379                3rd Qu.:0.000  \n Max.   :359.9180   Max.   :2.03900                Max.   :1.000  \n NA's   :40         NA's   :48                     NA's   :4187   \n```\n:::\n:::\n\n\n2.  Impute missing values (not our response variable!):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(missRanger)\nlibrary(dplyr)\nset.seed(123)\n\nnasa_imputed = missRanger::missRanger(data = nasa %>% select(-Hazardous),\n                                      maxiter = 1, num.trees = 5L)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nMissing value imputation by random forests\n\n  Variables to impute:\t\tNeo.Reference.ID, Name, Absolute.Magnitude, Est.Dia.in.KM.min., Est.Dia.in.KM.max., Est.Dia.in.M.min., Est.Dia.in.M.max., Est.Dia.in.Miles.min., Est.Dia.in.Miles.max., Est.Dia.in.Feet.min., Est.Dia.in.Feet.max., Close.Approach.Date, Epoch.Date.Close.Approach, Relative.Velocity.km.per.sec, Relative.Velocity.km.per.hr, Miles.per.hour, Miss.Dist..Astronomical., Miss.Dist..lunar., Miss.Dist..kilometers., Miss.Dist..miles., Orbiting.Body, Orbit.ID, Orbit.Determination.Date, Orbit.Uncertainity, Minimum.Orbit.Intersection, Jupiter.Tisserand.Invariant, Epoch.Osculation, Eccentricity, Semi.Major.Axis, Inclination, Asc.Node.Longitude, Orbital.Period, Perihelion.Distance, Perihelion.Arg, Aphelion.Dist, Perihelion.Time, Mean.Anomaly, Mean.Motion, Equinox\n  Variables used to impute:\tNeo.Reference.ID, Name, Absolute.Magnitude, Est.Dia.in.KM.min., Est.Dia.in.KM.max., Est.Dia.in.M.min., Est.Dia.in.M.max., Est.Dia.in.Miles.min., Est.Dia.in.Miles.max., Est.Dia.in.Feet.min., Est.Dia.in.Feet.max., Close.Approach.Date, Epoch.Date.Close.Approach, Relative.Velocity.km.per.sec, Relative.Velocity.km.per.hr, Miles.per.hour, Miss.Dist..Astronomical., Miss.Dist..lunar., Miss.Dist..kilometers., Miss.Dist..miles., Orbiting.Body, Orbit.ID, Orbit.Determination.Date, Orbit.Uncertainity, Minimum.Orbit.Intersection, Jupiter.Tisserand.Invariant, Epoch.Osculation, Eccentricity, Semi.Major.Axis, Inclination, Asc.Node.Longitude, Orbital.Period, Perihelion.Distance, Perihelion.Arg, Aphelion.Dist, Perihelion.Time, Mean.Anomaly, Mean.Motion, Equinox\n\niter 1\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |=====                                                                 |   8%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |===========                                                           |  15%\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |==============                                                        |  21%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |====================                                                  |  28%\n  |                                                                            \n  |======================                                                |  31%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |===========================                                           |  38%\n  |                                                                            \n  |=============================                                         |  41%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |================================                                      |  46%\n  |                                                                            \n  |==================================                                    |  49%\n  |                                                                            \n  |====================================                                  |  51%\n  |                                                                            \n  |======================================                                |  54%\n  |                                                                            \n  |=======================================                               |  56%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |===========================================                           |  62%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |================================================                      |  69%\n  |                                                                            \n  |==================================================                    |  72%\n  |                                                                            \n  |====================================================                  |  74%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |========================================================              |  79%\n  |                                                                            \n  |=========================================================             |  82%\n  |                                                                            \n  |===========================================================           |  85%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |=================================================================     |  92%\n  |                                                                            \n  |==================================================================    |  95%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\nnasa_imputed$Hazardous = nasa$Hazardous\n```\n:::\n\n\n3.  Split into training and test set:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain = nasa_imputed[!is.na(nasa$Hazardous), ]\ntest = nasa_imputed[is.na(nasa$Hazardous), ]\n```\n:::\n\n\n4.  Train model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ranger)\nset.seed(123)\n\nrf = ranger(Hazardous~., data = train, classification = TRUE,\n            probability = TRUE)\n```\n:::\n\n\n5.  Predictions:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreds = predict(rf, data = test)$predictions[,2]\nhead(preds)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6348055556 0.7525960317 0.0008444444 0.7733373016 0.1404333333\n[6] 0.1509190476\n```\n:::\n:::\n\n\n6.  Create submission csv:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite.csv(data.frame(y = preds), file = \"rf.csv\")\n```\n:::\n\n\n## Flower\n\nA collection of over 4000 flower images of 5 plant species. The data set is from <a href=\"https://www.kaggle.com/alxmamaev/flowers-recognition\" target=\"_blank\" rel=\"noopener\">kaggle</a> but we downsampled the images from $320*240$ to $80*80$ pixels. You can a) download the data set <a href=\"http://rhsbio7.uni-regensburg.de:8500\" target=\"_blank\" rel=\"noopener\">here</a> or b) get it via the EcoData package.\n\n**Notes:**\n\n-   Check out convolutional neural network notebooks on kaggle (they are often written in Python but you can still copy the architectures), e.g. <a href=\"https://www.kaggle.com/alirazaaliqadri/flower-recognition-tensorflow-keras-sequential\" target=\"_blank\" rel=\"noopener\">this one</a>.\n-   Last year's winners have used a transfer learning approach (they achieved around 70% accuracy), check out this <a href=\"https://www.kaggle.com/stpeteishii/flower-name-classify-densenet201\" target=\"_blank\" rel=\"noopener\">notebook</a>, see also the section about transfer learning \\@ref(transfer).\n\n**Response variable:** \"Plant species\"\n\n1.  Load data set:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tensorflow)\nlibrary(keras)\n\ntrain = EcoData::dataset_flower()$train/255\ntest = EcoData::dataset_flower()$test/255\nlabels = EcoData::dataset_flower()$labels\n```\n:::\n\n\nLet's visualize a flower:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain[100,,,] %>%\n  image_to_array() %>%\n  as.raster() %>%\n  plot()\n```\n\n::: {.cell-output-display}\n![](Appendix-Datasets_files/figure-html/chunk_chapter8_27-1.png){width=672}\n:::\n:::\n\n\n2.  Build and train model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel = keras_model_sequential()\nmodel %>% \n  layer_conv_2d(filters = 4L, kernel_size = 2L,\n                input_shape = list(80L, 80L, 3L)) %>% \n  layer_max_pooling_2d() %>% \n  layer_flatten() %>% \n  layer_dense(units = 5L, activation = \"softmax\")\n\n### Model fitting ###\n\nmodel %>% \n  compile(loss = loss_categorical_crossentropy, \n          optimizer = optimizer_adamax(learning_rate = 0.01))\n\nmodel %>% \n  fit(x = train, y = keras::k_one_hot(labels, 5L))\n```\n:::\n\n\n3.  Predictions:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Prediction on training data:\npred = apply(model %>% predict(train), 1, which.max)\nMetrics::accuracy(pred - 1L, labels)\ntable(pred)\n\n# Prediction for the submission server:\npred = model %>% predict(test) %>% apply(1, which.max) - 1L\ntable(pred)\n```\n:::\n\n\n4.  Create submission csv:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite.csv(data.frame(y = pred), file = \"cnn.csv\")\n```\n:::\n",
    "supporting": [
      "Appendix-Datasets_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
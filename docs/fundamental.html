<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 Fundamental Principles and Techniques | Machine Learning and AI in TensorFlow and R</title>
  <meta name="description" content="4 Fundamental Principles and Techniques | Machine Learning and AI in TensorFlow and R" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="4 Fundamental Principles and Techniques | Machine Learning and AI in TensorFlow and R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="4 Fundamental Principles and Techniques | Machine Learning and AI in TensorFlow and R" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Fundamental Principles and Techniques | Machine Learning and AI in TensorFlow and R" />
  
  <meta name="twitter:description" content="4 Fundamental Principles and Techniques | Machine Learning and AI in TensorFlow and R" />
  

<meta name="author" content="Maximilian Pichler and Florian Hartig" />


<meta name="date" content="2021-11-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introduction.html"/>
<link rel="next" href="deep.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/viz-1.8.2/viz.js"></script>
<link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="libs/grViz-binding-1.0.6.1/grViz.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #ffffff;
    color: #a0a0a0;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
div.sourceCode
  { color: #1f1c1b; background-color: #ffffff; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span { color: #1f1c1b; } /* Normal */
code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
code span.an { color: #ca60ca; } /* Annotation */
code span.at { color: #0057ae; } /* Attribute */
code span.bn { color: #b08000; } /* BaseN */
code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #924c9d; } /* Char */
code span.cn { color: #aa5500; } /* Constant */
code span.co { color: #898887; } /* Comment */
code span.cv { color: #0095ff; } /* CommentVar */
code span.do { color: #607880; } /* Documentation */
code span.dt { color: #0057ae; } /* DataType */
code span.dv { color: #b08000; } /* DecVal */
code span.er { color: #bf0303; text-decoration: underline; } /* Error */
code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
code span.fl { color: #b08000; } /* Float */
code span.fu { color: #644a9b; } /* Function */
code span.im { color: #ff5500; } /* Import */
code span.in { color: #b08000; } /* Information */
code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
code span.op { color: #1f1c1b; } /* Operator */
code span.ot { color: #006e28; } /* Other */
code span.pp { color: #006e28; } /* Preprocessor */
code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #ff5500; } /* SpecialString */
code span.st { color: #bf0303; } /* String */
code span.va { color: #0057ae; } /* Variable */
code span.vs { color: #bf0303; } /* VerbatimString */
code span.wa { color: #bf0303; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#r-system"><i class="fa fa-check"></i><b>1.1</b> R System</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#tensorflow-and-keras"><i class="fa fa-check"></i><b>1.2</b> TensorFlow and Keras</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#torch-for-r"><i class="fa fa-check"></i><b>1.3</b> Torch for R</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#ecodata"><i class="fa fa-check"></i><b>1.4</b> EcoData</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#further-used-libraries"><i class="fa fa-check"></i><b>1.5</b> Further Used Libraries</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#linuxunix-systems-have-to-fulfill-some-durther-dependencies"><i class="fa fa-check"></i><b>1.6</b> Linux/UNIX systems have to fulfill some durther dependencies</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="reminder.html"><a href="reminder.html"><i class="fa fa-check"></i><b>2</b> Reminders About Basic Operations in R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="reminder.html"><a href="reminder.html#your-r-system"><i class="fa fa-check"></i><b>2.1</b> Your R System</a></li>
<li class="chapter" data-level="2.2" data-path="reminder.html"><a href="reminder.html#data-types-in-r"><i class="fa fa-check"></i><b>2.2</b> Data types in R</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="reminder.html"><a href="reminder.html#test-your-knowledge"><i class="fa fa-check"></i><b>2.2.1</b> Test Your Knowledge</a></li>
<li class="chapter" data-level="2.2.2" data-path="reminder.html"><a href="reminder.html#iris-data"><i class="fa fa-check"></i><b>2.2.2</b> Iris Data</a></li>
<li class="chapter" data-level="2.2.3" data-path="reminder.html"><a href="reminder.html#dynamic-typing"><i class="fa fa-check"></i><b>2.2.3</b> Dynamic typing</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="reminder.html"><a href="reminder.html#data-selection-slicing-and-subsetting"><i class="fa fa-check"></i><b>2.3</b> Data selection, Slicing and Subsetting</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="reminder.html"><a href="reminder.html#subsetting-and-slicing-for-single-data-types"><i class="fa fa-check"></i><b>2.3.1</b> Subsetting and Slicing for Single Data Types</a></li>
<li class="chapter" data-level="2.3.2" data-path="reminder.html"><a href="reminder.html#logic-and-slicing"><i class="fa fa-check"></i><b>2.3.2</b> Logic and Slicing</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="reminder.html"><a href="reminder.html#applying-functions-and-aggregates-across-a-data-set"><i class="fa fa-check"></i><b>2.4</b> Applying Functions and Aggregates Across a Data set</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="reminder.html"><a href="reminder.html#functions"><i class="fa fa-check"></i><b>2.4.1</b> Functions</a></li>
<li class="chapter" data-level="2.4.2" data-path="reminder.html"><a href="reminder.html#the-apply-function"><i class="fa fa-check"></i><b>2.4.2</b> The apply() Function</a></li>
<li class="chapter" data-level="2.4.3" data-path="reminder.html"><a href="reminder.html#the-aggregate-function"><i class="fa fa-check"></i><b>2.4.3</b> The aggregate() Function</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="reminder.html"><a href="reminder.html#plotting"><i class="fa fa-check"></i><b>2.5</b> Plotting</a></li>
<li class="chapter" data-level="2.6" data-path="reminder.html"><a href="reminder.html#additional-resources"><i class="fa fa-check"></i><b>2.6</b> Additional Resources</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="reminder.html"><a href="reminder.html#books"><i class="fa fa-check"></i><b>2.6.1</b> Books</a></li>
<li class="chapter" data-level="2.6.2" data-path="reminder.html"><a href="reminder.html#instructional-videos"><i class="fa fa-check"></i><b>2.6.2</b> Instructional videos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>3</b> Introduction to Machine Learning</a>
<ul>
<li class="chapter" data-level="3.1" data-path="introduction.html"><a href="introduction.html#unsupervised-learning"><i class="fa fa-check"></i><b>3.1</b> Unsupervised Learning</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="introduction.html"><a href="introduction.html#hierarchical-clustering"><i class="fa fa-check"></i><b>3.1.1</b> Hierarchical Clustering</a></li>
<li class="chapter" data-level="3.1.2" data-path="introduction.html"><a href="introduction.html#k-means-clustering"><i class="fa fa-check"></i><b>3.1.2</b> K-means Clustering</a></li>
<li class="chapter" data-level="3.1.3" data-path="introduction.html"><a href="introduction.html#density-based-clustering"><i class="fa fa-check"></i><b>3.1.3</b> Density-based Clustering</a></li>
<li class="chapter" data-level="3.1.4" data-path="introduction.html"><a href="introduction.html#model-based-clustering"><i class="fa fa-check"></i><b>3.1.4</b> Model-based Clustering</a></li>
<li class="chapter" data-level="3.1.5" data-path="introduction.html"><a href="introduction.html#ordination"><i class="fa fa-check"></i><b>3.1.5</b> Ordination</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="introduction.html"><a href="introduction.html#supervised-learning-regression-and-classification"><i class="fa fa-check"></i><b>3.2</b> Supervised Learning: Regression and Classification</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="introduction.html"><a href="introduction.html#supervised-regression-using-random-forest"><i class="fa fa-check"></i><b>3.2.1</b> Supervised Regression Using Random Forest</a></li>
<li class="chapter" data-level="3.2.2" data-path="introduction.html"><a href="introduction.html#supervised-classification-using-random-forest"><i class="fa fa-check"></i><b>3.2.2</b> Supervised Classification Using Random Forest</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="introduction.html"><a href="introduction.html#basicMath"><i class="fa fa-check"></i><b>3.3</b> Small Introduction Into the Underlying Mathematical Concepts of all Following Lessons - Optional</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="introduction.html"><a href="introduction.html#caveat-about-learning-rates-and-activation-functions"><i class="fa fa-check"></i><b>3.3.1</b> Caveat About Learning Rates and Activation Functions</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="introduction.html"><a href="introduction.html#introduction-to-tensorflow"><i class="fa fa-check"></i><b>3.4</b> Introduction to TensorFlow</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="introduction.html"><a href="introduction.html#tensorflow-data-containers"><i class="fa fa-check"></i><b>3.4.1</b> TensorFlow Data Containers</a></li>
<li class="chapter" data-level="3.4.2" data-path="introduction.html"><a href="introduction.html#basic-operations"><i class="fa fa-check"></i><b>3.4.2</b> Basic Operations</a></li>
<li class="chapter" data-level="3.4.3" data-path="introduction.html"><a href="introduction.html#tensorflow-data-types---good-practice-with-r-tensorflow"><i class="fa fa-check"></i><b>3.4.3</b> TensorFlow Data Types - Good Practice With R-TensorFlow</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="introduction.html"><a href="introduction.html#introduction-to-pytorch"><i class="fa fa-check"></i><b>3.5</b> Introduction to PyTorch</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="introduction.html"><a href="introduction.html#pytorch-data-containers"><i class="fa fa-check"></i><b>3.5.1</b> PyTorch Data Containers</a></li>
<li class="chapter" data-level="3.5.2" data-path="introduction.html"><a href="introduction.html#basic-operations-1"><i class="fa fa-check"></i><b>3.5.2</b> Basic Operations</a></li>
<li class="chapter" data-level="3.5.3" data-path="introduction.html"><a href="introduction.html#torch-data-types---good-practice-with-r-torch"><i class="fa fa-check"></i><b>3.5.3</b> Torch Data Types - Good Practice With R-Torch</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="introduction.html"><a href="introduction.html#first-steps-with-the-keras-framework"><i class="fa fa-check"></i><b>3.6</b> First Steps With the Keras Framework</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="introduction.html"><a href="introduction.html#example-workflow-in-keras"><i class="fa fa-check"></i><b>3.6.1</b> Example Workflow in Keras</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="fundamental.html"><a href="fundamental.html"><i class="fa fa-check"></i><b>4</b> Fundamental Principles and Techniques</a>
<ul>
<li class="chapter" data-level="4.1" data-path="fundamental.html"><a href="fundamental.html#machine-learning-principles"><i class="fa fa-check"></i><b>4.1</b> Machine Learning Principles</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="fundamental.html"><a href="fundamental.html#optimization"><i class="fa fa-check"></i><b>4.1.1</b> Optimization</a></li>
<li class="chapter" data-level="4.1.2" data-path="fundamental.html"><a href="fundamental.html#advanced-optimization-example"><i class="fa fa-check"></i><b>4.1.2</b> Advanced Optimization Example</a></li>
<li class="chapter" data-level="4.1.3" data-path="fundamental.html"><a href="fundamental.html#regularization"><i class="fa fa-check"></i><b>4.1.3</b> Regularization</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="fundamental.html"><a href="fundamental.html#artificial-neural-networks"><i class="fa fa-check"></i><b>4.2</b> Artificial Neural Networks</a></li>
<li class="chapter" data-level="4.3" data-path="fundamental.html"><a href="fundamental.html#tree-based-machine-learning-algorithms"><i class="fa fa-check"></i><b>4.3</b> Tree-based Machine Learning Algorithms</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="fundamental.html"><a href="fundamental.html#classification-and-regression-trees"><i class="fa fa-check"></i><b>4.3.1</b> Classification and Regression Trees</a></li>
<li class="chapter" data-level="4.3.2" data-path="fundamental.html"><a href="fundamental.html#random-forest"><i class="fa fa-check"></i><b>4.3.2</b> Random Forest</a></li>
<li class="chapter" data-level="4.3.3" data-path="fundamental.html"><a href="fundamental.html#boosted-regression-trees"><i class="fa fa-check"></i><b>4.3.3</b> Boosted Regression Trees</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="fundamental.html"><a href="fundamental.html#distance-based-algorithms"><i class="fa fa-check"></i><b>4.4</b> Distance-based Algorithms</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="fundamental.html"><a href="fundamental.html#k-nearest-neighbor"><i class="fa fa-check"></i><b>4.4.1</b> K-Nearest-Neighbor</a></li>
<li class="chapter" data-level="4.4.2" data-path="fundamental.html"><a href="fundamental.html#support-vector-machines-svms"><i class="fa fa-check"></i><b>4.4.2</b> Support Vector Machines (SVMs)</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="fundamental.html"><a href="fundamental.html#the-standard-machine-learning-pipeline-at-the-eexample-of-the-titanic-data-set"><i class="fa fa-check"></i><b>4.5</b> The Standard Machine Learning Pipeline at the Eexample of the Titanic Data set</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="fundamental.html"><a href="fundamental.html#data-cleaning"><i class="fa fa-check"></i><b>4.5.1</b> Data Cleaning</a></li>
<li class="chapter" data-level="4.5.2" data-path="fundamental.html"><a href="fundamental.html#preprocessing-and-feature-selection"><i class="fa fa-check"></i><b>4.5.2</b> Preprocessing and Feature Selection</a></li>
<li class="chapter" data-level="4.5.3" data-path="fundamental.html"><a href="fundamental.html#split-data-for-training-and-testing"><i class="fa fa-check"></i><b>4.5.3</b> Split Data for Training and Testing</a></li>
<li class="chapter" data-level="4.5.4" data-path="fundamental.html"><a href="fundamental.html#model-fitting"><i class="fa fa-check"></i><b>4.5.4</b> Model Fitting</a></li>
<li class="chapter" data-level="4.5.5" data-path="fundamental.html"><a href="fundamental.html#model-evaluation"><i class="fa fa-check"></i><b>4.5.5</b> Model Evaluation</a></li>
<li class="chapter" data-level="4.5.6" data-path="fundamental.html"><a href="fundamental.html#predictions-and-submission"><i class="fa fa-check"></i><b>4.5.6</b> Predictions and Submission</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="fundamental.html"><a href="fundamental.html#mlr"><i class="fa fa-check"></i><b>4.6</b> Bonus - Machine Learning Pipelines with mlr3</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="fundamental.html"><a href="fundamental.html#mlr3---the-basic-workflow"><i class="fa fa-check"></i><b>4.6.1</b> mlr3 - The Basic Workflow</a></li>
<li class="chapter" data-level="4.6.2" data-path="fundamental.html"><a href="fundamental.html#mlr3---hyperparameter-tuning"><i class="fa fa-check"></i><b>4.6.2</b> mlr3 - Hyperparameter Tuning</a></li>
<li class="chapter" data-level="4.6.3" data-path="fundamental.html"><a href="fundamental.html#mlr3---hyperparameter-tuning-with-oversampling"><i class="fa fa-check"></i><b>4.6.3</b> mlr3 - Hyperparameter Tuning with Oversampling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="deep.html"><a href="deep.html"><i class="fa fa-check"></i><b>5</b> Deep Learning</a>
<ul>
<li class="chapter" data-level="5.1" data-path="deep.html"><a href="deep.html#network-architectures"><i class="fa fa-check"></i><b>5.1</b> Network Architectures</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="deep.html"><a href="deep.html#deep-neural-networks-dnns"><i class="fa fa-check"></i><b>5.1.1</b> Deep Neural Networks (DNNs)</a></li>
<li class="chapter" data-level="5.1.2" data-path="deep.html"><a href="deep.html#convolutional-neural-networks-cnns"><i class="fa fa-check"></i><b>5.1.2</b> Convolutional Neural Networks (CNNs)</a></li>
<li class="chapter" data-level="5.1.3" data-path="deep.html"><a href="deep.html#recurrent-neural-networks-rnns"><i class="fa fa-check"></i><b>5.1.3</b> Recurrent Neural Networks (RNNs)</a></li>
<li class="chapter" data-level="5.1.4" data-path="deep.html"><a href="deep.html#natural-language-processing-nlp"><i class="fa fa-check"></i><b>5.1.4</b> Natural Language Processing (NLP)</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="deep.html"><a href="deep.html#case-study-dropout-and-early-stopping-in-a-deep-neural-network"><i class="fa fa-check"></i><b>5.2</b> Case Study: Dropout and Early Stopping in a Deep Neural Network</a></li>
<li class="chapter" data-level="5.3" data-path="deep.html"><a href="deep.html#case-study-fitting-a-convolutional-neural-network-on-mnist"><i class="fa fa-check"></i><b>5.3</b> Case Study: Fitting a Convolutional Neural Network on MNIST</a></li>
<li class="chapter" data-level="5.4" data-path="deep.html"><a href="deep.html#advanced-training-techniques"><i class="fa fa-check"></i><b>5.4</b> Advanced Training Techniques</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="deep.html"><a href="deep.html#data-augmentation"><i class="fa fa-check"></i><b>5.4.1</b> Data Augmentation</a></li>
<li class="chapter" data-level="5.4.2" data-path="deep.html"><a href="deep.html#transfer"><i class="fa fa-check"></i><b>5.4.2</b> Transfer Learning</a></li>
<li class="chapter" data-level="5.4.3" data-path="deep.html"><a href="deep.html#influence-of-batch-size-and-learning-rate"><i class="fa fa-check"></i><b>5.4.3</b> Influence of Batch Size and Learning Rate</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="interpretation.html"><a href="interpretation.html"><i class="fa fa-check"></i><b>6</b> Interpretation and Causality With Machine Learning</a>
<ul>
<li class="chapter" data-level="6.1" data-path="interpretation.html"><a href="interpretation.html#explainable-ai"><i class="fa fa-check"></i><b>6.1</b> Explainable AI</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="interpretation.html"><a href="interpretation.html#a-practical-example"><i class="fa fa-check"></i><b>6.1.1</b> A Practical Example</a></li>
<li class="chapter" data-level="6.1.2" data-path="interpretation.html"><a href="interpretation.html#feature-importance"><i class="fa fa-check"></i><b>6.1.2</b> Feature Importance</a></li>
<li class="chapter" data-level="6.1.3" data-path="interpretation.html"><a href="interpretation.html#partial-dependencies"><i class="fa fa-check"></i><b>6.1.3</b> Partial Dependencies</a></li>
<li class="chapter" data-level="6.1.4" data-path="interpretation.html"><a href="interpretation.html#accumulated-local-effects"><i class="fa fa-check"></i><b>6.1.4</b> Accumulated Local Effects</a></li>
<li class="chapter" data-level="6.1.5" data-path="interpretation.html"><a href="interpretation.html#friedmans-h-statistic"><i class="fa fa-check"></i><b>6.1.5</b> Friedman’s H-statistic</a></li>
<li class="chapter" data-level="6.1.6" data-path="interpretation.html"><a href="interpretation.html#global-explainer---simplifying-the-machine-learning-model"><i class="fa fa-check"></i><b>6.1.6</b> Global Explainer - Simplifying the Machine Learning Model</a></li>
<li class="chapter" data-level="6.1.7" data-path="interpretation.html"><a href="interpretation.html#local-explainer---lime-explaining-single-instances-observations"><i class="fa fa-check"></i><b>6.1.7</b> Local Explainer - LIME Explaining Single Instances (observations)</a></li>
<li class="chapter" data-level="6.1.8" data-path="interpretation.html"><a href="interpretation.html#local-explainer---shapley"><i class="fa fa-check"></i><b>6.1.8</b> Local Explainer - Shapley</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="interpretation.html"><a href="interpretation.html#causal-inference-and-machine-learning"><i class="fa fa-check"></i><b>6.2</b> Causal Inference and Machine Learning</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="interpretation.html"><a href="interpretation.html#causalInference"><i class="fa fa-check"></i><b>6.2.1</b> Causal Inference on Static Data</a></li>
<li class="chapter" data-level="6.2.2" data-path="interpretation.html"><a href="interpretation.html#structural-equation-models"><i class="fa fa-check"></i><b>6.2.2</b> Structural Equation Models</a></li>
<li class="chapter" data-level="6.2.3" data-path="interpretation.html"><a href="interpretation.html#automatic-causal-discovery"><i class="fa fa-check"></i><b>6.2.3</b> Automatic Causal Discovery</a></li>
<li class="chapter" data-level="6.2.4" data-path="interpretation.html"><a href="interpretation.html#causal-inference-on-dynamic-data"><i class="fa fa-check"></i><b>6.2.4</b> Causal Inference on Dynamic Data</a></li>
<li class="chapter" data-level="6.2.5" data-path="interpretation.html"><a href="interpretation.html#outlook-for-machine-learning"><i class="fa fa-check"></i><b>6.2.5</b> Outlook for Machine Learning</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="gan.html"><a href="gan.html"><i class="fa fa-check"></i><b>7</b> Generative Modeling and Reinforcement Learning</a>
<ul>
<li class="chapter" data-level="7.1" data-path="gan.html"><a href="gan.html#autoencoder"><i class="fa fa-check"></i><b>7.1</b> Autoencoder</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="gan.html"><a href="gan.html#autoencoder---deep-neural-network-mnist"><i class="fa fa-check"></i><b>7.1.1</b> Autoencoder - Deep Neural Network MNIST</a></li>
<li class="chapter" data-level="7.1.2" data-path="gan.html"><a href="gan.html#autoencoder---mnist-convolutional-neural-networks"><i class="fa fa-check"></i><b>7.1.2</b> Autoencoder - MNIST Convolutional Neural Networks</a></li>
<li class="chapter" data-level="7.1.3" data-path="gan.html"><a href="gan.html#VAE"><i class="fa fa-check"></i><b>7.1.3</b> Variational Autoencoder (VAE)</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="gan.html"><a href="gan.html#GANS"><i class="fa fa-check"></i><b>7.2</b> Generative Adversarial Networks (GANs)</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="gan.html"><a href="gan.html#mnist---generative-adversarial-networks-based-on-deep-neural-networks"><i class="fa fa-check"></i><b>7.2.1</b> MNIST - Generative Adversarial Networks Based on Deep Neural Networks</a></li>
<li class="chapter" data-level="7.2.2" data-path="gan.html"><a href="gan.html#flower---gan"><i class="fa fa-check"></i><b>7.2.2</b> Flower - GAN</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="gan.html"><a href="gan.html#reinforcement-learning"><i class="fa fa-check"></i><b>7.3</b> Reinforcement learning</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="datasets.html"><a href="datasets.html"><i class="fa fa-check"></i><b>8</b> Data sets</a>
<ul>
<li class="chapter" data-level="8.1" data-path="datasets.html"><a href="datasets.html#titanic"><i class="fa fa-check"></i><b>8.1</b> Titanic</a></li>
<li class="chapter" data-level="8.2" data-path="datasets.html"><a href="datasets.html#plant-pollinator-database"><i class="fa fa-check"></i><b>8.2</b> Plant-pollinator Database</a></li>
<li class="chapter" data-level="8.3" data-path="datasets.html"><a href="datasets.html#wine"><i class="fa fa-check"></i><b>8.3</b> Wine</a></li>
<li class="chapter" data-level="8.4" data-path="datasets.html"><a href="datasets.html#nasa"><i class="fa fa-check"></i><b>8.4</b> Nasa</a></li>
<li class="chapter" data-level="8.5" data-path="datasets.html"><a href="datasets.html#flower"><i class="fa fa-check"></i><b>8.5</b> Flower</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning and AI in TensorFlow and R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="fundamental" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Fundamental Principles and Techniques</h1>
<!-- Put this here (right after the first markdown headline) and only here for each document! -->
<script src="./scripts/multipleChoice.js"></script>
<div id="machine-learning-principles" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Machine Learning Principles</h2>
<div id="optimization" class="section level3" number="4.1.1">
<h3><span class="header-section-number">4.1.1</span> Optimization</h3>
<p>Out of Wikipedia: “An optimization problem is the problem of finding the best solution from all feasible solutions.”</p>
<p>Why do we need this “optimization?”</p>
<p>Somehow, we need to tell the algorithm what it should learn. To do so we have the so called <strong>loss function</strong>, which expresses what our goal is. But we also need to find the configurations where the loss function attains its minimum. This is the job of the optimizer. Thus, an optimization consists of:</p>
<ul>
<li><p>A <strong>loss function</strong> (e.g. we tell the algorithm in each training step how many observations were misclassified) guides the training of machine learning algorithms.</p></li>
<li><p>The <strong>optimizer</strong>, which tries to update the weights of the machine learning algorithms in a way that the loss function is minimized.</p></li>
</ul>
<p>Calculating the global optimum analytically is a non-trivial problem and thus a bunch of diverse optimization algorithms evolved.</p>
<p>Some optimization algorithms are inspired by biological systems e.g. ants, bees or even slimes. These optimizers are explained in the following video, have a look:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/X-iSQQgOd1A" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
</iframe>
  <hr/>
  <details>
    <summary>
        <strong><span style="color: #0011AA; font-size:25px;">Questions</span></strong>
    </summary>
    <p>
      <script>
        makeMultipleChoiceForm(
                'In the lecture, it was said that, during training, machine learning parameters are optimised to get a good fit (loss function) to training data. Which of the following statements about loss functions is correct?',
                'checkbox',
                [
                    {
                        'answer':'A loss function measures the difference between the (current) machine learning model prediction and the data.',
                        'correct':true,
                        'explanationIfSelected':'',
                        'explanationIfNotSelected':'',
                        'explanationGeneral':''
                    },
                    {
                        'answer':'When we specify a simple line as our machine learning model, all loss functions will lead to the same line.',
                        'correct':false,
                        'explanationIfSelected':'',
                        'explanationIfNotSelected':'',
                        'explanationGeneral':''
                    },
                    {
                        'answer':'Cross-Entropy and Kullback–Leibler divergence are common loss functions.',
                        'correct':true,
                        'explanationIfSelected':'',
                        'explanationIfNotSelected':'',
                        'explanationGeneral':''
                    },
                    {
                        'answer':'For regression, there is only one sensible loss function, and this is the mean squared error.',
                        'correct':false,
                        'explanationIfSelected':'',
                        'explanationIfNotSelected':'',
                        'explanationGeneral':''
            }
          ],
          ''
        );
      </script>
    </p>
  </details>
  <hr/>
<div id="small-optimization-example" class="section level4" number="4.1.1.1">
<h4><span class="header-section-number">4.1.1.1</span> Small Optimization Example</h4>
<p>As an easy example for an optimization we can think of a quadratic function:</p>
<div class="sourceCode" id="cb353"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb353-1"><a href="fundamental.html#cb353-1" aria-hidden="true" tabindex="-1"></a>func <span class="ot">=</span> <span class="cf">function</span>(x){ <span class="fu">return</span>(x<span class="sc">^</span><span class="dv">2</span>) }</span></code></pre></div>
<p>This function is so easy, we can randomly probe it and identify the optimum by plotting.</p>
<div class="sourceCode" id="cb354"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb354-1"><a href="fundamental.html#cb354-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb354-2"><a href="fundamental.html#cb354-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb354-3"><a href="fundamental.html#cb354-3" aria-hidden="true" tabindex="-1"></a>a <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="dv">100</span>)</span>
<span id="cb354-4"><a href="fundamental.html#cb354-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(a, <span class="fu">func</span>(a))</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_2-1.png" width="672" /></p>
<p>The minimal value is at <span class="math inline">\(x = 0\)</span> (to be honest, we can calculate this analytically in this simple case).</p>
<p>We can also use an optimizer with the optim-function (the first argument is the starting value):</p>
<div class="sourceCode" id="cb355"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb355-1"><a href="fundamental.html#cb355-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb355-2"><a href="fundamental.html#cb355-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb355-3"><a href="fundamental.html#cb355-3" aria-hidden="true" tabindex="-1"></a>opt <span class="ot">=</span> <span class="fu">optim</span>(<span class="fl">1.0</span>, func, <span class="at">method =</span> <span class="st">&quot;Brent&quot;</span>, <span class="at">lower =</span> <span class="sc">-</span><span class="dv">100</span>, <span class="at">upper =</span> <span class="dv">100</span>)</span>
<span id="cb355-4"><a href="fundamental.html#cb355-4" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(opt<span class="sc">$</span>par)</span></code></pre></div>
<pre><code>## [1] -3.552714e-15</code></pre>
<p>opt$par will return the best values found by the optimizer, which is really close to zero :)</p>
</div>
</div>
<div id="advanced-optimization-example" class="section level3" number="4.1.2">
<h3><span class="header-section-number">4.1.2</span> Advanced Optimization Example</h3>
<p>Optimization is also done when fitting a linear regression model. Thereby, we optimize the weights (intercept and slope). Just using lm(y~x) is too simple. We want to do this by hand to also better understand what optimization is and how it works.</p>
<p>As an example we take the airquality data set. First, we have to be sure to have no NAs in there. Then we split into response (Ozone) and predictors (Month, Day, Solar.R, Wind, Temp). Additionally it is beneficial for the optimizer, when the different predictors have the same support, and thus we scale them.</p>
<div class="sourceCode" id="cb357"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb357-1"><a href="fundamental.html#cb357-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality[<span class="fu">complete.cases</span>(airquality<span class="sc">$</span>Ozone) <span class="sc">&amp;</span> <span class="fu">complete.cases</span>(airquality<span class="sc">$</span>Solar.R),]</span>
<span id="cb357-2"><a href="fundamental.html#cb357-2" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb357-3"><a href="fundamental.html#cb357-3" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span> data<span class="sc">$</span>Ozone</span></code></pre></div>
<p>The model we want to optimize: <span class="math inline">\(Ozone = Solar.R \cdot X1 + Wind \cdot X2 + Temp \cdot X3 + Month \cdot X4 + Day \cdot X5 + X6\)</span></p>
<p>We assume that the residuals are normally distributed, and our loss function to be the mean squared error: <span class="math inline">\(\mathrm{mean}(predicted~ozone - true~ozone)^{2}\)</span></p>
<p>Our task is now to find the parameters <span class="math inline">\(X1,\dots,X6\)</span> for which this loss function is minimal. Therefore, we implement a function, that takes parameters and returns the loss.</p>
<div class="sourceCode" id="cb358"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb358-1"><a href="fundamental.html#cb358-1" aria-hidden="true" tabindex="-1"></a>linear_regression <span class="ot">=</span> <span class="cf">function</span>(w){</span>
<span id="cb358-2"><a href="fundamental.html#cb358-2" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">=</span> w[<span class="dv">1</span>]<span class="sc">*</span>X[,<span class="dv">1</span>] <span class="sc">+</span> <span class="co"># Solar.R</span></span>
<span id="cb358-3"><a href="fundamental.html#cb358-3" aria-hidden="true" tabindex="-1"></a>         w[<span class="dv">2</span>]<span class="sc">*</span>X[,<span class="dv">2</span>] <span class="sc">+</span> <span class="co"># Wind</span></span>
<span id="cb358-4"><a href="fundamental.html#cb358-4" aria-hidden="true" tabindex="-1"></a>         w[<span class="dv">3</span>]<span class="sc">*</span>X[,<span class="dv">3</span>] <span class="sc">+</span> <span class="co"># Temp</span></span>
<span id="cb358-5"><a href="fundamental.html#cb358-5" aria-hidden="true" tabindex="-1"></a>         w[<span class="dv">4</span>]<span class="sc">*</span>X[,<span class="dv">4</span>] <span class="sc">+</span> <span class="co"># Month</span></span>
<span id="cb358-6"><a href="fundamental.html#cb358-6" aria-hidden="true" tabindex="-1"></a>         w[<span class="dv">5</span>]<span class="sc">*</span>X[,<span class="dv">5</span>] <span class="sc">+</span></span>
<span id="cb358-7"><a href="fundamental.html#cb358-7" aria-hidden="true" tabindex="-1"></a>         w[<span class="dv">6</span>]         <span class="co"># or X * w[1:5]^T + w[6]</span></span>
<span id="cb358-8"><a href="fundamental.html#cb358-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># loss  = MSE, we want to find the optimal weights </span></span>
<span id="cb358-9"><a href="fundamental.html#cb358-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># to minimize the sum of squared residuals.</span></span>
<span id="cb358-10"><a href="fundamental.html#cb358-10" aria-hidden="true" tabindex="-1"></a>  loss <span class="ot">=</span> <span class="fu">mean</span>((pred <span class="sc">-</span> Y)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb358-11"><a href="fundamental.html#cb358-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(loss)</span>
<span id="cb358-12"><a href="fundamental.html#cb358-12" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>For example we can sample some weights and see how the loss changes with this weights.</p>
<div class="sourceCode" id="cb359"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb359-1"><a href="fundamental.html#cb359-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb359-2"><a href="fundamental.html#cb359-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb359-3"><a href="fundamental.html#cb359-3" aria-hidden="true" tabindex="-1"></a><span class="fu">linear_regression</span>(<span class="fu">runif</span>(<span class="dv">6</span>))</span></code></pre></div>
<pre><code>## [1] 2866.355</code></pre>
<p>We can try to find the optimum by bruteforce (what means we will use a random set of weights and see for which the loss function is minimal):</p>
<div class="sourceCode" id="cb361"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb361-1"><a href="fundamental.html#cb361-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb361-2"><a href="fundamental.html#cb361-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb361-3"><a href="fundamental.html#cb361-3" aria-hidden="true" tabindex="-1"></a>random_search <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(<span class="dv">6</span><span class="sc">*</span><span class="dv">5000</span>, <span class="sc">-</span><span class="dv">10</span>, <span class="dv">10</span>), <span class="dv">5000</span>, <span class="dv">6</span>)</span>
<span id="cb361-4"><a href="fundamental.html#cb361-4" aria-hidden="true" tabindex="-1"></a>losses <span class="ot">=</span> <span class="fu">apply</span>(random_search, <span class="dv">1</span>, linear_regression)</span>
<span id="cb361-5"><a href="fundamental.html#cb361-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(losses, <span class="at">type =</span> <span class="st">&quot;l&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_7-1.png" width="672" /></p>
<div class="sourceCode" id="cb362"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb362-1"><a href="fundamental.html#cb362-1" aria-hidden="true" tabindex="-1"></a>random_search[<span class="fu">which.min</span>(losses),]</span></code></pre></div>
<pre><code>## [1]  7.411631 -7.018960  9.376949  6.490659  5.432706  9.460573</code></pre>
<p>In most cases, bruteforce isn’t a good approach. It might work well with only a few parameters, but with increasing complexity and more parameters it will take a long time. Furthermore it is not guaranteed that it finds a stable solution on continuous data.</p>
<p>In R the optim function helps computing the optimum faster.</p>
<div class="sourceCode" id="cb364"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb364-1"><a href="fundamental.html#cb364-1" aria-hidden="true" tabindex="-1"></a>opt <span class="ot">=</span> <span class="fu">optim</span>(<span class="fu">runif</span>(<span class="dv">6</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>), linear_regression)</span>
<span id="cb364-2"><a href="fundamental.html#cb364-2" aria-hidden="true" tabindex="-1"></a>opt<span class="sc">$</span>par</span></code></pre></div>
<pre><code>## [1]   1.631666 -17.272902  11.645608  -7.371417   1.754860  42.577956</code></pre>
<p>In the background, mostly some <em>gradient descent</em> methods are used.</p>
<p>By comparing the weights from the optimizer to the estimated weights of the lm() function, we see that our self-written code obtains the same weights as the lm. Keep in mind, that our simple method uses random numbers thus the results might differ each run (without setting the seed).</p>
<div class="sourceCode" id="cb366"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb366-1"><a href="fundamental.html#cb366-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">lm</span>(Y<span class="sc">~</span>X))</span></code></pre></div>
<pre><code>## (Intercept)    XSolar.R       XWind       XTemp      XMonth        XDay 
##   42.099099    4.582620  -11.806072   18.066786   -4.479175    2.384705</code></pre>
</div>
<div id="regularization" class="section level3" number="4.1.3">
<h3><span class="header-section-number">4.1.3</span> Regularization</h3>
<p>Regularization means adding information or structure to a system in order to solve an ill-posed optimization problem or to prevent overfitting. There are many ways of regularizing a machine learning model. The most important distinction is between <em>shrinkage estimators</em> and estimators based on <em>model averaging</em>.</p>
<p><strong>Shrikage estimators</strong> are based on the idea of adding a penalty to the loss function that penalizes deviations of the model parameters from a particular value (typically 0). In this way, estimates are <em>“shrunk”</em> to the specified default value. In practice, the most important penalties are the least absolute shrinkage and selection operator; also <em>Lasso</em> or <em>LASSO</em>, where the penalty is proportional to the sum of absolute deviations (<span class="math inline">\(L1\)</span> penalty), and the <em>Tikhonov regularization</em> aka <em>Ridge regression</em>, where the penalty is proportional to the sum of squared distances from the reference (<span class="math inline">\(L2\)</span> penalty). Thus, the loss function that we optimize is given by</p>
<p><span class="math display">\[
loss = fit - \lambda \cdot d
\]</span></p>
<p>where fit refers to the standard loss function, <span class="math inline">\(\lambda\)</span> is the strength of the regularization, and <span class="math inline">\(d\)</span> is the chosen metric, e.g. <span class="math inline">\(L1\)</span> or<span class="math inline">\(L2\)</span>:</p>
<p><span class="math display">\[
loss_{L1} = fit - \lambda \cdot \Vert weights \Vert_1
\]</span>
<span class="math display">\[
loss_{L2} = fit - \lambda \cdot \Vert weights \Vert_2
\]</span></p>
<p><span class="math inline">\(\lambda\)</span> and possibly d are typically optimized under cross-validation. <span class="math inline">\(L1\)</span> and <span class="math inline">\(L2\)</span> can be also combined what is then called <em>elastic net</em> (see <span class="citation"><a href="#ref-zou2005" role="doc-biblioref">Zou and Hastie</a> (<a href="#ref-zou2005" role="doc-biblioref">2005</a>)</span>).</p>
<p><strong>Model averaging</strong> refers to an entire set of techniques, including <em>boosting</em>, <em>bagging</em> and other averaging techniques. The general principle is that predictions are made by combining (= averaging) several models. This is based on on the insight that it is often more efficient having many simpler models and average them, than one “super model.” The reasons are complicated, and explained in more detail in <span class="citation"><a href="#ref-dormann2018" role="doc-biblioref">Dormann et al.</a> (<a href="#ref-dormann2018" role="doc-biblioref">2018</a>)</span>.</p>
<p>A particular important application of averaging is <em>boosting</em>, where the idea is that many weak learners are combined to a model average, resulting in a strong learner. Another related method is <em>bootstrap aggregating</em>, also called <em>bagging</em>. Idea here is to <em>boostrap</em> (use random sampling with replacement ) the data, and average the bootstrapped predictions.</p>
<p>To see how these techniques work in practice, let’s first focus on LASSO and Ridge regularization for weights in neural networks. We can imagine that the LASSO and Ridge act similar to a rubber band on the weights that pulls them to zero if the data does not strongly push them away from zero. This leads to important weights, which are supported by the data, being estimated as different from zero, whereas unimportant model structures are reduced (shrunken) to zero.</p>
<p>LASSO <span class="math inline">\(\left(penalty \propto \sum_{}^{} \mathrm{abs}(weights) \right)\)</span> and Ridge <span class="math inline">\(\left(penalty \propto \sum_{}^{} weights^{2} \right)\)</span> have slightly different properties. They are best understood if we express those as the effective prior preference they create on the parameters:</p>
<p><img src="_main_files/figure-html/chunk_chapter4_10-1.png" width="672" /></p>
<p>As you can see, the LASSO creates a very strong preference towards exactly zero, but falls off less strongly towards the tails. This means that parameters tend to be estimated either to exactly zero, or, if not, they are more free than the Ridge. For this reason, LASSO is often more interpreted as a model selection method.</p>
<p>The Ridge, on the other hand, has a certain area around zero where it is relatively indifferent about deviations from zero, thus rarely leading to exactly zero values. However, it will create a stronger shrinkage for values that deviate significantly from zero.</p>
<p>We can implement the linear regression also in Keras, when we do not specify any hidden layers:</p>
<div class="sourceCode" id="cb368"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb368-1"><a href="fundamental.html#cb368-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb368-2"><a href="fundamental.html#cb368-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb368-3"><a href="fundamental.html#cb368-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb368-4"><a href="fundamental.html#cb368-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb368-5"><a href="fundamental.html#cb368-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality[<span class="fu">complete.cases</span>(airquality),]</span>
<span id="cb368-6"><a href="fundamental.html#cb368-6" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb368-7"><a href="fundamental.html#cb368-7" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span> data<span class="sc">$</span>Ozone</span>
<span id="cb368-8"><a href="fundamental.html#cb368-8" aria-hidden="true" tabindex="-1"></a><span class="co"># L1/L2 on linear model.</span></span>
<span id="cb368-9"><a href="fundamental.html#cb368-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb368-10"><a href="fundamental.html#cb368-10" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb368-11"><a href="fundamental.html#cb368-11" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb368-12"><a href="fundamental.html#cb368-12" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;linear&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(<span class="fu">dim</span>(X)[<span class="dv">2</span>]))</span>
<span id="cb368-13"><a href="fundamental.html#cb368-13" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## Model: &quot;sequential_7&quot;
## ______________________________________________________________________________________________________________________________
##  Layer (type)                                           Output Shape                                       Param #            
## ==============================================================================================================================
##  dense_31 (Dense)                                       (None, 1)                                          6                  
##                                                                                                                               
## ==============================================================================================================================
## Total params: 6
## Trainable params: 6
## Non-trainable params: 0
## ______________________________________________________________________________________________________________________________</code></pre>
<div class="sourceCode" id="cb370"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb370-1"><a href="fundamental.html#cb370-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb370-2"><a href="fundamental.html#cb370-2" aria-hidden="true" tabindex="-1"></a> <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.5</span>),</span>
<span id="cb370-3"><a href="fundamental.html#cb370-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">metrics =</span> <span class="fu">c</span>(metric_mean_squared_error))</span>
<span id="cb370-4"><a href="fundamental.html#cb370-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb370-5"><a href="fundamental.html#cb370-5" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb370-6"><a href="fundamental.html#cb370-6" aria-hidden="true" tabindex="-1"></a> model <span class="sc">%&gt;%</span></span>
<span id="cb370-7"><a href="fundamental.html#cb370-7" aria-hidden="true" tabindex="-1"></a> <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, <span class="at">epochs =</span> 100L, <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb370-8"><a href="fundamental.html#cb370-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb370-9"><a href="fundamental.html#cb370-9" aria-hidden="true" tabindex="-1"></a>unconstrained <span class="ot">=</span> model<span class="sc">$</span><span class="fu">get_weights</span>()</span>
<span id="cb370-10"><a href="fundamental.html#cb370-10" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(Y<span class="sc">~</span>X))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Y ~ X)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -37.014 -12.284  -3.302   8.454  95.348 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   42.099      1.980  21.264  &lt; 2e-16 ***
## XSolar.R       4.583      2.135   2.147   0.0341 *  
## XWind        -11.806      2.293  -5.149 1.23e-06 ***
## XTemp         18.067      2.610   6.922 3.66e-10 ***
## XMonth        -4.479      2.230  -2.009   0.0471 *  
## XDay           2.385      2.000   1.192   0.2358    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 20.86 on 105 degrees of freedom
## Multiple R-squared:  0.6249, Adjusted R-squared:  0.6071 
## F-statistic: 34.99 on 5 and 105 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb372"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb372-1"><a href="fundamental.html#cb372-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">lm</span>(Y<span class="sc">~</span>X))</span></code></pre></div>
<pre><code>## (Intercept)    XSolar.R       XWind       XTemp      XMonth        XDay 
##   42.099099    4.582620  -11.806072   18.066786   -4.479175    2.384705</code></pre>
<details>
<summary>
<strong><span style="color: #CC2FAA;">Torch</span></strong>
</summary>
<p>
<div class="sourceCode" id="cb374"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb374-1"><a href="fundamental.html#cb374-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb374-2"><a href="fundamental.html#cb374-2" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_manual_seed</span>(321L)</span>
<span id="cb374-3"><a href="fundamental.html#cb374-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb374-4"><a href="fundamental.html#cb374-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb374-5"><a href="fundamental.html#cb374-5" aria-hidden="true" tabindex="-1"></a>model_torch <span class="ot">=</span> <span class="fu">nn_sequential</span>(</span>
<span id="cb374-6"><a href="fundamental.html#cb374-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_linear</span>(<span class="at">in_features =</span> <span class="fu">dim</span>(X)[<span class="dv">2</span>], <span class="at">out_features =</span> 1L)</span>
<span id="cb374-7"><a href="fundamental.html#cb374-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb374-8"><a href="fundamental.html#cb374-8" aria-hidden="true" tabindex="-1"></a>opt <span class="ot">=</span> <span class="fu">optim_adam</span>(<span class="at">params =</span> model_torch<span class="sc">$</span>parameters, <span class="at">lr =</span> <span class="fl">0.5</span>)</span>
<span id="cb374-9"><a href="fundamental.html#cb374-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb374-10"><a href="fundamental.html#cb374-10" aria-hidden="true" tabindex="-1"></a>X_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(X)</span>
<span id="cb374-11"><a href="fundamental.html#cb374-11" aria-hidden="true" tabindex="-1"></a>Y_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fu">matrix</span>(Y, <span class="at">ncol =</span> 1L), <span class="at">dtype =</span> <span class="fu">torch_float32</span>())</span>
<span id="cb374-12"><a href="fundamental.html#cb374-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">500</span>){</span>
<span id="cb374-13"><a href="fundamental.html#cb374-13" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(X), 20L)</span>
<span id="cb374-14"><a href="fundamental.html#cb374-14" aria-hidden="true" tabindex="-1"></a>  opt<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb374-15"><a href="fundamental.html#cb374-15" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">=</span> <span class="fu">model_torch</span>(X_torch[indices, ])</span>
<span id="cb374-16"><a href="fundamental.html#cb374-16" aria-hidden="true" tabindex="-1"></a>  loss <span class="ot">=</span> <span class="fu">nnf_mse_loss</span>(pred, Y_torch[indices,,<span class="at">drop =</span> <span class="cn">FALSE</span>])</span>
<span id="cb374-17"><a href="fundamental.html#cb374-17" aria-hidden="true" tabindex="-1"></a>  loss<span class="sc">$</span><span class="fu">sum</span>()<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb374-18"><a href="fundamental.html#cb374-18" aria-hidden="true" tabindex="-1"></a>  opt<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb374-19"><a href="fundamental.html#cb374-19" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb374-20"><a href="fundamental.html#cb374-20" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">lm</span>(Y<span class="sc">~</span>X))</span></code></pre></div>
<pre><code>## (Intercept)    XSolar.R       XWind       XTemp      XMonth        XDay 
##   42.099099    4.582620  -11.806072   18.066786   -4.479175    2.384705</code></pre>
<div class="sourceCode" id="cb376"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb376-1"><a href="fundamental.html#cb376-1" aria-hidden="true" tabindex="-1"></a>model_torch<span class="sc">$</span>parameters</span></code></pre></div>
<pre><code>## $`0.weight`
## torch_tensor
##   4.1083 -10.1831  18.2815  -4.3478   1.2937
## [ CPUFloatType{1,5} ][ requires_grad = TRUE ]
## 
## $`0.bias`
## torch_tensor
##  42.0958
## [ CPUFloatType{1} ][ requires_grad = TRUE ]</code></pre>
</p>
</details>
<p><br/></p>
<p>TensorFlow and thus Keras also allow use using LASSO and Ridge on the weights.
Lets see what happens when we put an <span class="math inline">\(L1\)</span> (LASSO) regularization on the weights:</p>
<div class="sourceCode" id="cb378"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb378-1"><a href="fundamental.html#cb378-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb378-2"><a href="fundamental.html#cb378-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb378-3"><a href="fundamental.html#cb378-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb378-4"><a href="fundamental.html#cb378-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb378-5"><a href="fundamental.html#cb378-5" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb378-6"><a href="fundamental.html#cb378-6" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="co"># Remind the penalty lambda that is set to 10 here.</span></span>
<span id="cb378-7"><a href="fundamental.html#cb378-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;linear&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(<span class="fu">dim</span>(X)[<span class="dv">2</span>]), </span>
<span id="cb378-8"><a href="fundamental.html#cb378-8" aria-hidden="true" tabindex="-1"></a>              <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1</span>(<span class="dv">10</span>),</span>
<span id="cb378-9"><a href="fundamental.html#cb378-9" aria-hidden="true" tabindex="-1"></a>              <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l1</span>(<span class="dv">10</span>))</span>
<span id="cb378-10"><a href="fundamental.html#cb378-10" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## Model: &quot;sequential_8&quot;
## ______________________________________________________________________________________________________________________________
##  Layer (type)                                           Output Shape                                       Param #            
## ==============================================================================================================================
##  dense_32 (Dense)                                       (None, 1)                                          6                  
##                                                                                                                               
## ==============================================================================================================================
## Total params: 6
## Trainable params: 6
## Non-trainable params: 0
## ______________________________________________________________________________________________________________________________</code></pre>
<div class="sourceCode" id="cb380"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb380-1"><a href="fundamental.html#cb380-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb380-2"><a href="fundamental.html#cb380-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.5</span>),</span>
<span id="cb380-3"><a href="fundamental.html#cb380-3" aria-hidden="true" tabindex="-1"></a>          <span class="at">metrics =</span> <span class="fu">c</span>(metric_mean_squared_error))</span>
<span id="cb380-4"><a href="fundamental.html#cb380-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb380-5"><a href="fundamental.html#cb380-5" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb380-6"><a href="fundamental.html#cb380-6" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb380-7"><a href="fundamental.html#cb380-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, <span class="at">epochs =</span> 30L, <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb380-8"><a href="fundamental.html#cb380-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb380-9"><a href="fundamental.html#cb380-9" aria-hidden="true" tabindex="-1"></a>l1 <span class="ot">=</span> model<span class="sc">$</span><span class="fu">get_weights</span>()</span>
<span id="cb380-10"><a href="fundamental.html#cb380-10" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(Y<span class="sc">~</span>X))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Y ~ X)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -37.014 -12.284  -3.302   8.454  95.348 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   42.099      1.980  21.264  &lt; 2e-16 ***
## XSolar.R       4.583      2.135   2.147   0.0341 *  
## XWind        -11.806      2.293  -5.149 1.23e-06 ***
## XTemp         18.067      2.610   6.922 3.66e-10 ***
## XMonth        -4.479      2.230  -2.009   0.0471 *  
## XDay           2.385      2.000   1.192   0.2358    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 20.86 on 105 degrees of freedom
## Multiple R-squared:  0.6249, Adjusted R-squared:  0.6071 
## F-statistic: 34.99 on 5 and 105 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb382"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb382-1"><a href="fundamental.html#cb382-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">lm</span>(Y<span class="sc">~</span>X))</span></code></pre></div>
<pre><code>## (Intercept)    XSolar.R       XWind       XTemp      XMonth        XDay 
##   42.099099    4.582620  -11.806072   18.066786   -4.479175    2.384705</code></pre>
<div class="sourceCode" id="cb384"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb384-1"><a href="fundamental.html#cb384-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(<span class="fu">unlist</span>(l1), <span class="fu">unlist</span>(unconstrained))</span></code></pre></div>
<pre><code>##             [,1]       [,2]
## [1,]  1.69559026   4.576884
## [2,] -8.43734646 -11.771938
## [3,] 12.91758442  18.096060
## [4,]  0.01775982  -4.407187
## [5,]  0.01594419   2.432310
## [6,] 33.05084229  42.205029</code></pre>
<p>One can clearly see that parameters are pulled towards zero because of the regularization.</p>
<details>
<summary>
<strong><span style="color: #CC2FAA;">Torch</span></strong>
</summary>
<p>
<p>In Torch, we have to specify the regularization on our own when calculating the loss.</p>
<div class="sourceCode" id="cb386"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb386-1"><a href="fundamental.html#cb386-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb386-2"><a href="fundamental.html#cb386-2" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_manual_seed</span>(321L)</span>
<span id="cb386-3"><a href="fundamental.html#cb386-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb386-4"><a href="fundamental.html#cb386-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb386-5"><a href="fundamental.html#cb386-5" aria-hidden="true" tabindex="-1"></a>model_torch <span class="ot">=</span> <span class="fu">nn_sequential</span>(</span>
<span id="cb386-6"><a href="fundamental.html#cb386-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_linear</span>(<span class="at">in_features =</span> <span class="fu">dim</span>(X)[<span class="dv">2</span>], <span class="at">out_features =</span> 1L)</span>
<span id="cb386-7"><a href="fundamental.html#cb386-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb386-8"><a href="fundamental.html#cb386-8" aria-hidden="true" tabindex="-1"></a>opt <span class="ot">=</span> <span class="fu">optim_adam</span>(<span class="at">params =</span> model_torch<span class="sc">$</span>parameters, <span class="at">lr =</span> <span class="fl">0.5</span>)</span>
<span id="cb386-9"><a href="fundamental.html#cb386-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb386-10"><a href="fundamental.html#cb386-10" aria-hidden="true" tabindex="-1"></a>X_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(X)</span>
<span id="cb386-11"><a href="fundamental.html#cb386-11" aria-hidden="true" tabindex="-1"></a>Y_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fu">matrix</span>(Y, <span class="at">ncol =</span> 1L), <span class="at">dtype =</span> <span class="fu">torch_float32</span>())</span>
<span id="cb386-12"><a href="fundamental.html#cb386-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">500</span>){</span>
<span id="cb386-13"><a href="fundamental.html#cb386-13" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(X), 20L)</span>
<span id="cb386-14"><a href="fundamental.html#cb386-14" aria-hidden="true" tabindex="-1"></a>  opt<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb386-15"><a href="fundamental.html#cb386-15" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">=</span> <span class="fu">model_torch</span>(X_torch[indices, ])</span>
<span id="cb386-16"><a href="fundamental.html#cb386-16" aria-hidden="true" tabindex="-1"></a>  loss <span class="ot">=</span> <span class="fu">nnf_mse_loss</span>(pred, Y_torch[indices,,<span class="at">drop =</span> <span class="cn">FALSE</span>])</span>
<span id="cb386-17"><a href="fundamental.html#cb386-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb386-18"><a href="fundamental.html#cb386-18" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Add L1:</span></span>
<span id="cb386-19"><a href="fundamental.html#cb386-19" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(model_torch<span class="sc">$</span>parameters)){</span>
<span id="cb386-20"><a href="fundamental.html#cb386-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Remind the penalty lambda that is set to 10 here.</span></span>
<span id="cb386-21"><a href="fundamental.html#cb386-21" aria-hidden="true" tabindex="-1"></a>    loss <span class="ot">=</span> loss <span class="sc">+</span> model_torch<span class="sc">$</span>parameters[[i]]<span class="sc">$</span><span class="fu">abs</span>()<span class="sc">$</span><span class="fu">sum</span>()<span class="sc">*</span><span class="fl">10.0</span></span>
<span id="cb386-22"><a href="fundamental.html#cb386-22" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb386-23"><a href="fundamental.html#cb386-23" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb386-24"><a href="fundamental.html#cb386-24" aria-hidden="true" tabindex="-1"></a>  loss<span class="sc">$</span><span class="fu">sum</span>()<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb386-25"><a href="fundamental.html#cb386-25" aria-hidden="true" tabindex="-1"></a>  opt<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb386-26"><a href="fundamental.html#cb386-26" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb386-27"><a href="fundamental.html#cb386-27" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">lm</span>(Y<span class="sc">~</span>X))</span></code></pre></div>
<pre><code>## (Intercept)    XSolar.R       XWind       XTemp      XMonth        XDay 
##   42.099099    4.582620  -11.806072   18.066786   -4.479175    2.384705</code></pre>
<div class="sourceCode" id="cb388"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb388-1"><a href="fundamental.html#cb388-1" aria-hidden="true" tabindex="-1"></a>model_torch<span class="sc">$</span>parameters</span></code></pre></div>
<pre><code>## $`0.weight`
## torch_tensor
##   0.7787  -6.5937  14.6648  -0.0670   0.0475
## [ CPUFloatType{1,5} ][ requires_grad = TRUE ]
## 
## $`0.bias`
## torch_tensor
##  37.2661
## [ CPUFloatType{1} ][ requires_grad = TRUE ]</code></pre>
</p>
</details>
<p><br/></p>
  <hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Tasks</span></strong><br/>
  In our linear regression model for the airquality dataset we only had to optimize 6 parameters/weights...
... in neural networks, we have to optimize thousands, up to billions of weights.
You can surlely imagine that the surface of the loss function is very complex, with many local optima. 
Finding a global optimum is almost impossible, most of the times we are only searching for good local optima.

The learning rate of the optimizers defines the step size in which the weights of the neural network are updated:

<ul>
  <li>Too high learning rates and optima might be jumped over.</li>
  <li>Too low learning rates and we might be land in local optima or it might take too long.</li>
</ul> 

Below, there is the code for the iris dataset.

Try out different learning rates, very high and very low learning rates, can you see a difference?
<div class="sourceCode" id="cb390"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb390-1"><a href="fundamental.html#cb390-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb390-2"><a href="fundamental.html#cb390-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb390-3"><a href="fundamental.html#cb390-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb390-4"><a href="fundamental.html#cb390-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb390-5"><a href="fundamental.html#cb390-5" aria-hidden="true" tabindex="-1"></a>iris <span class="ot">=</span> datasets<span class="sc">::</span>iris</span>
<span id="cb390-6"><a href="fundamental.html#cb390-6" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">scale</span>(iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span>
<span id="cb390-7"><a href="fundamental.html#cb390-7" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span> iris[,<span class="dv">5</span>]</span>
<span id="cb390-8"><a href="fundamental.html#cb390-8" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span> keras<span class="sc">::</span><span class="fu">k_one_hot</span>(<span class="fu">as.integer</span>(Y)<span class="sc">-</span>1L, <span class="dv">3</span>)</span>
<span id="cb390-9"><a href="fundamental.html#cb390-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb390-10"><a href="fundamental.html#cb390-10" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb390-11"><a href="fundamental.html#cb390-11" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb390-12"><a href="fundamental.html#cb390-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(4L)) <span class="sc">%&gt;%</span></span>
<span id="cb390-13"><a href="fundamental.html#cb390-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L) <span class="sc">%&gt;%</span></span>
<span id="cb390-14"><a href="fundamental.html#cb390-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L) <span class="sc">%&gt;%</span></span>
<span id="cb390-15"><a href="fundamental.html#cb390-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 3L, <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>)</span>
<span id="cb390-16"><a href="fundamental.html#cb390-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Softmax scales to (0, 1]; 3 output nodes for 3 response classes/labels.</span></span>
<span id="cb390-17"><a href="fundamental.html#cb390-17" aria-hidden="true" tabindex="-1"></a><span class="co"># The labels MUST start at 0!</span></span>
<span id="cb390-18"><a href="fundamental.html#cb390-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb390-19"><a href="fundamental.html#cb390-19" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb390-20"><a href="fundamental.html#cb390-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb390-21"><a href="fundamental.html#cb390-21" aria-hidden="true" tabindex="-1"></a>          <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.5</span>),</span>
<span id="cb390-22"><a href="fundamental.html#cb390-22" aria-hidden="true" tabindex="-1"></a>          <span class="at">metrics =</span> <span class="fu">c</span>(metric_categorical_accuracy)</span>
<span id="cb390-23"><a href="fundamental.html#cb390-23" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb390-24"><a href="fundamental.html#cb390-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb390-25"><a href="fundamental.html#cb390-25" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb390-26"><a href="fundamental.html#cb390-26" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb390-27"><a href="fundamental.html#cb390-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, <span class="at">epochs =</span> 30L, <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb390-28"><a href="fundamental.html#cb390-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb390-29"><a href="fundamental.html#cb390-29" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb390-30"><a href="fundamental.html#cb390-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">evaluate</span>(X, Y)</span></code></pre></div>
<pre><code>##                 loss categorical_accuracy 
##           0.04896358           0.98000002</code></pre>
<div class="sourceCode" id="cb392"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb392-1"><a href="fundamental.html#cb392-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="_main_files/figure-html/chunk_chapter4_task_0-1.png" width="672" /></p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<div class="sourceCode" id="cb394"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb394-1"><a href="fundamental.html#cb394-1" aria-hidden="true" tabindex="-1"></a>keras<span class="sc">::</span><span class="fu">reset_states</span>(model)</span>
<span id="cb394-2"><a href="fundamental.html#cb394-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb394-3"><a href="fundamental.html#cb394-3" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb394-4"><a href="fundamental.html#cb394-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb394-5"><a href="fundamental.html#cb394-5" aria-hidden="true" tabindex="-1"></a>          <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.005</span>),</span>
<span id="cb394-6"><a href="fundamental.html#cb394-6" aria-hidden="true" tabindex="-1"></a>          <span class="at">metrics =</span> <span class="fu">c</span>(metric_categorical_accuracy)</span>
<span id="cb394-7"><a href="fundamental.html#cb394-7" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb394-8"><a href="fundamental.html#cb394-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb394-9"><a href="fundamental.html#cb394-9" aria-hidden="true" tabindex="-1"></a>model_history2 <span class="ot">=</span></span>
<span id="cb394-10"><a href="fundamental.html#cb394-10" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb394-11"><a href="fundamental.html#cb394-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, <span class="at">epochs =</span> 30L, <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb394-12"><a href="fundamental.html#cb394-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb394-13"><a href="fundamental.html#cb394-13" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb394-14"><a href="fundamental.html#cb394-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">evaluate</span>(X, Y)</span></code></pre></div>
<pre><code>##                 loss categorical_accuracy 
##           0.04000899           0.98666668</code></pre>
<div class="sourceCode" id="cb396"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb396-1"><a href="fundamental.html#cb396-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history2)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_1-1.png" width="672" /></p>
<div class="sourceCode" id="cb397"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb397-1"><a href="fundamental.html#cb397-1" aria-hidden="true" tabindex="-1"></a><span class="do">##########  -&gt; (very) Low learning rate: May take (very) long </span></span>
<span id="cb397-2"><a href="fundamental.html#cb397-2" aria-hidden="true" tabindex="-1"></a><span class="co">#           (and may need very many epochs) and get stuck in local optima.</span></span>
<span id="cb397-3"><a href="fundamental.html#cb397-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb397-4"><a href="fundamental.html#cb397-4" aria-hidden="true" tabindex="-1"></a>keras<span class="sc">::</span><span class="fu">reset_states</span>(model)</span>
<span id="cb397-5"><a href="fundamental.html#cb397-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb397-6"><a href="fundamental.html#cb397-6" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb397-7"><a href="fundamental.html#cb397-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb397-8"><a href="fundamental.html#cb397-8" aria-hidden="true" tabindex="-1"></a>          <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.00001</span>),</span>
<span id="cb397-9"><a href="fundamental.html#cb397-9" aria-hidden="true" tabindex="-1"></a>          <span class="at">metrics =</span> <span class="fu">c</span>(metric_categorical_accuracy)</span>
<span id="cb397-10"><a href="fundamental.html#cb397-10" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb397-11"><a href="fundamental.html#cb397-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb397-12"><a href="fundamental.html#cb397-12" aria-hidden="true" tabindex="-1"></a>model_history3 <span class="ot">=</span></span>
<span id="cb397-13"><a href="fundamental.html#cb397-13" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb397-14"><a href="fundamental.html#cb397-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, <span class="at">epochs =</span> 30L, <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb397-15"><a href="fundamental.html#cb397-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb397-16"><a href="fundamental.html#cb397-16" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb397-17"><a href="fundamental.html#cb397-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">evaluate</span>(X, Y)</span></code></pre></div>
<pre><code>##                 loss categorical_accuracy 
##           0.03999748           0.98666668</code></pre>
<div class="sourceCode" id="cb399"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb399-1"><a href="fundamental.html#cb399-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history3)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_1-2.png" width="672" /></p>
<div class="sourceCode" id="cb400"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb400-1"><a href="fundamental.html#cb400-1" aria-hidden="true" tabindex="-1"></a>keras<span class="sc">::</span><span class="fu">reset_states</span>(model)</span>
<span id="cb400-2"><a href="fundamental.html#cb400-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb400-3"><a href="fundamental.html#cb400-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Try higher epoch number</span></span>
<span id="cb400-4"><a href="fundamental.html#cb400-4" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb400-5"><a href="fundamental.html#cb400-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb400-6"><a href="fundamental.html#cb400-6" aria-hidden="true" tabindex="-1"></a>          <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.00001</span>),</span>
<span id="cb400-7"><a href="fundamental.html#cb400-7" aria-hidden="true" tabindex="-1"></a>          <span class="at">metrics =</span> <span class="fu">c</span>(metric_categorical_accuracy)</span>
<span id="cb400-8"><a href="fundamental.html#cb400-8" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb400-9"><a href="fundamental.html#cb400-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb400-10"><a href="fundamental.html#cb400-10" aria-hidden="true" tabindex="-1"></a>model_history4 <span class="ot">=</span></span>
<span id="cb400-11"><a href="fundamental.html#cb400-11" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb400-12"><a href="fundamental.html#cb400-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, <span class="at">epochs =</span> 200L, <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb400-13"><a href="fundamental.html#cb400-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb400-14"><a href="fundamental.html#cb400-14" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb400-15"><a href="fundamental.html#cb400-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">evaluate</span>(X, Y)</span></code></pre></div>
<pre><code>##                 loss categorical_accuracy 
##           0.03996202           0.98666668</code></pre>
<div class="sourceCode" id="cb402"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb402-1"><a href="fundamental.html#cb402-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history4)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_1-3.png" width="672" /></p>
<div class="sourceCode" id="cb403"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb403-1"><a href="fundamental.html#cb403-1" aria-hidden="true" tabindex="-1"></a><span class="do">##########  -&gt; (very) High learning rate (may skip optimum).</span></span>
<span id="cb403-2"><a href="fundamental.html#cb403-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb403-3"><a href="fundamental.html#cb403-3" aria-hidden="true" tabindex="-1"></a>keras<span class="sc">::</span><span class="fu">reset_states</span>(model)</span>
<span id="cb403-4"><a href="fundamental.html#cb403-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb403-5"><a href="fundamental.html#cb403-5" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb403-6"><a href="fundamental.html#cb403-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb403-7"><a href="fundamental.html#cb403-7" aria-hidden="true" tabindex="-1"></a>          <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="dv">3</span>),</span>
<span id="cb403-8"><a href="fundamental.html#cb403-8" aria-hidden="true" tabindex="-1"></a>          <span class="at">metrics =</span> <span class="fu">c</span>(metric_categorical_accuracy)</span>
<span id="cb403-9"><a href="fundamental.html#cb403-9" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb403-10"><a href="fundamental.html#cb403-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb403-11"><a href="fundamental.html#cb403-11" aria-hidden="true" tabindex="-1"></a>model_history5 <span class="ot">=</span></span>
<span id="cb403-12"><a href="fundamental.html#cb403-12" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb403-13"><a href="fundamental.html#cb403-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, <span class="at">epochs =</span> 30L, <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb403-14"><a href="fundamental.html#cb403-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb403-15"><a href="fundamental.html#cb403-15" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb403-16"><a href="fundamental.html#cb403-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">evaluate</span>(X, Y)</span></code></pre></div>
<pre><code>##                 loss categorical_accuracy 
##            3.2687612            0.9666666</code></pre>
<div class="sourceCode" id="cb405"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb405-1"><a href="fundamental.html#cb405-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history5)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_1-4.png" width="672" /></p>
<div class="sourceCode" id="cb406"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb406-1"><a href="fundamental.html#cb406-1" aria-hidden="true" tabindex="-1"></a><span class="do">##########  -&gt; Higher epoch number (possibly better fitting, maybe overfitting).</span></span>
<span id="cb406-2"><a href="fundamental.html#cb406-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb406-3"><a href="fundamental.html#cb406-3" aria-hidden="true" tabindex="-1"></a>keras<span class="sc">::</span><span class="fu">reset_states</span>(model)</span>
<span id="cb406-4"><a href="fundamental.html#cb406-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb406-5"><a href="fundamental.html#cb406-5" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb406-6"><a href="fundamental.html#cb406-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb406-7"><a href="fundamental.html#cb406-7" aria-hidden="true" tabindex="-1"></a>          <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="dv">3</span>),</span>
<span id="cb406-8"><a href="fundamental.html#cb406-8" aria-hidden="true" tabindex="-1"></a>          <span class="at">metrics =</span> <span class="fu">c</span>(metric_categorical_accuracy)</span>
<span id="cb406-9"><a href="fundamental.html#cb406-9" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb406-10"><a href="fundamental.html#cb406-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb406-11"><a href="fundamental.html#cb406-11" aria-hidden="true" tabindex="-1"></a>model_history6 <span class="ot">=</span></span>
<span id="cb406-12"><a href="fundamental.html#cb406-12" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb406-13"><a href="fundamental.html#cb406-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, <span class="at">epochs =</span> 100L, <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb406-14"><a href="fundamental.html#cb406-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb406-15"><a href="fundamental.html#cb406-15" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb406-16"><a href="fundamental.html#cb406-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">evaluate</span>(X, Y)</span></code></pre></div>
<pre><code>##                 loss categorical_accuracy 
##            5.2018671            0.9066667</code></pre>
<div class="sourceCode" id="cb408"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb408-1"><a href="fundamental.html#cb408-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history6)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_1-5.png" width="672" /></p>
<div class="sourceCode" id="cb409"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb409-1"><a href="fundamental.html#cb409-1" aria-hidden="true" tabindex="-1"></a><span class="do">##########</span></span>
<span id="cb409-2"><a href="fundamental.html#cb409-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb409-3"><a href="fundamental.html#cb409-3" aria-hidden="true" tabindex="-1"></a>keras<span class="sc">::</span><span class="fu">reset_states</span>(model)</span>
<span id="cb409-4"><a href="fundamental.html#cb409-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb409-5"><a href="fundamental.html#cb409-5" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb409-6"><a href="fundamental.html#cb409-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb409-7"><a href="fundamental.html#cb409-7" aria-hidden="true" tabindex="-1"></a>          <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.5</span>),</span>
<span id="cb409-8"><a href="fundamental.html#cb409-8" aria-hidden="true" tabindex="-1"></a>          <span class="at">metrics =</span> <span class="fu">c</span>(metric_categorical_accuracy)</span>
<span id="cb409-9"><a href="fundamental.html#cb409-9" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb409-10"><a href="fundamental.html#cb409-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb409-11"><a href="fundamental.html#cb409-11" aria-hidden="true" tabindex="-1"></a>model_history7 <span class="ot">=</span></span>
<span id="cb409-12"><a href="fundamental.html#cb409-12" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb409-13"><a href="fundamental.html#cb409-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, <span class="at">epochs =</span> 100L, <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb409-14"><a href="fundamental.html#cb409-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb409-15"><a href="fundamental.html#cb409-15" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb409-16"><a href="fundamental.html#cb409-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">evaluate</span>(X, Y)</span></code></pre></div>
<pre><code>##                 loss categorical_accuracy 
##           23.2035313            0.7733333</code></pre>
<div class="sourceCode" id="cb411"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb411-1"><a href="fundamental.html#cb411-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history7)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_1-6.png" width="672" /></p>
<div class="sourceCode" id="cb412"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb412-1"><a href="fundamental.html#cb412-1" aria-hidden="true" tabindex="-1"></a><span class="do">##########</span></span>
<span id="cb412-2"><a href="fundamental.html#cb412-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb412-3"><a href="fundamental.html#cb412-3" aria-hidden="true" tabindex="-1"></a>keras<span class="sc">::</span><span class="fu">reset_states</span>(model)</span>
<span id="cb412-4"><a href="fundamental.html#cb412-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb412-5"><a href="fundamental.html#cb412-5" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb412-6"><a href="fundamental.html#cb412-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb412-7"><a href="fundamental.html#cb412-7" aria-hidden="true" tabindex="-1"></a>          <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.00001</span>),</span>
<span id="cb412-8"><a href="fundamental.html#cb412-8" aria-hidden="true" tabindex="-1"></a>          <span class="at">metrics =</span> <span class="fu">c</span>(metric_categorical_accuracy)</span>
<span id="cb412-9"><a href="fundamental.html#cb412-9" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb412-10"><a href="fundamental.html#cb412-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb412-11"><a href="fundamental.html#cb412-11" aria-hidden="true" tabindex="-1"></a>model_history8 <span class="ot">=</span></span>
<span id="cb412-12"><a href="fundamental.html#cb412-12" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb412-13"><a href="fundamental.html#cb412-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, <span class="at">epochs =</span> 100L, <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb412-14"><a href="fundamental.html#cb412-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb412-15"><a href="fundamental.html#cb412-15" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb412-16"><a href="fundamental.html#cb412-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">evaluate</span>(X, Y)</span></code></pre></div>
<pre><code>##                 loss categorical_accuracy 
##           20.6392994            0.7733333</code></pre>
<div class="sourceCode" id="cb414"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb414-1"><a href="fundamental.html#cb414-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history8)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_1-7.png" width="672" /></p>
<div class="sourceCode" id="cb415"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb415-1"><a href="fundamental.html#cb415-1" aria-hidden="true" tabindex="-1"></a><span class="do">##########  -&gt; Lower batch size.</span></span>
<span id="cb415-2"><a href="fundamental.html#cb415-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb415-3"><a href="fundamental.html#cb415-3" aria-hidden="true" tabindex="-1"></a>keras<span class="sc">::</span><span class="fu">reset_states</span>(model)</span>
<span id="cb415-4"><a href="fundamental.html#cb415-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb415-5"><a href="fundamental.html#cb415-5" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb415-6"><a href="fundamental.html#cb415-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb415-7"><a href="fundamental.html#cb415-7" aria-hidden="true" tabindex="-1"></a>          <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="dv">3</span>),</span>
<span id="cb415-8"><a href="fundamental.html#cb415-8" aria-hidden="true" tabindex="-1"></a>          <span class="at">metrics =</span> <span class="fu">c</span>(metric_categorical_accuracy)</span>
<span id="cb415-9"><a href="fundamental.html#cb415-9" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb415-10"><a href="fundamental.html#cb415-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb415-11"><a href="fundamental.html#cb415-11" aria-hidden="true" tabindex="-1"></a>model_history9 <span class="ot">=</span></span>
<span id="cb415-12"><a href="fundamental.html#cb415-12" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb415-13"><a href="fundamental.html#cb415-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, <span class="at">epochs =</span> 100L, <span class="at">batch_size =</span> 5L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb415-14"><a href="fundamental.html#cb415-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb415-15"><a href="fundamental.html#cb415-15" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb415-16"><a href="fundamental.html#cb415-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">evaluate</span>(X, Y)</span></code></pre></div>
<pre><code>##                 loss categorical_accuracy 
##            0.5272142            0.6666667</code></pre>
<div class="sourceCode" id="cb417"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb417-1"><a href="fundamental.html#cb417-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history9)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_1-8.png" width="672" /></p>
<div class="sourceCode" id="cb418"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb418-1"><a href="fundamental.html#cb418-1" aria-hidden="true" tabindex="-1"></a><span class="do">##########</span></span>
<span id="cb418-2"><a href="fundamental.html#cb418-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb418-3"><a href="fundamental.html#cb418-3" aria-hidden="true" tabindex="-1"></a>keras<span class="sc">::</span><span class="fu">reset_states</span>(model)</span>
<span id="cb418-4"><a href="fundamental.html#cb418-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb418-5"><a href="fundamental.html#cb418-5" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb418-6"><a href="fundamental.html#cb418-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb418-7"><a href="fundamental.html#cb418-7" aria-hidden="true" tabindex="-1"></a>          <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.5</span>),</span>
<span id="cb418-8"><a href="fundamental.html#cb418-8" aria-hidden="true" tabindex="-1"></a>          <span class="at">metrics =</span> <span class="fu">c</span>(metric_categorical_accuracy)</span>
<span id="cb418-9"><a href="fundamental.html#cb418-9" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb418-10"><a href="fundamental.html#cb418-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb418-11"><a href="fundamental.html#cb418-11" aria-hidden="true" tabindex="-1"></a>model_history10 <span class="ot">=</span></span>
<span id="cb418-12"><a href="fundamental.html#cb418-12" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb418-13"><a href="fundamental.html#cb418-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, <span class="at">epochs =</span> 100L, <span class="at">batch_size =</span> 5L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb418-14"><a href="fundamental.html#cb418-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb418-15"><a href="fundamental.html#cb418-15" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb418-16"><a href="fundamental.html#cb418-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">evaluate</span>(X, Y)</span></code></pre></div>
<pre><code>##                 loss categorical_accuracy 
##            0.5486130            0.6666667</code></pre>
<div class="sourceCode" id="cb420"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb420-1"><a href="fundamental.html#cb420-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history10)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_1-9.png" width="672" /></p>
<div class="sourceCode" id="cb421"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb421-1"><a href="fundamental.html#cb421-1" aria-hidden="true" tabindex="-1"></a><span class="do">##########</span></span>
<span id="cb421-2"><a href="fundamental.html#cb421-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb421-3"><a href="fundamental.html#cb421-3" aria-hidden="true" tabindex="-1"></a>keras<span class="sc">::</span><span class="fu">reset_states</span>(model)</span>
<span id="cb421-4"><a href="fundamental.html#cb421-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb421-5"><a href="fundamental.html#cb421-5" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb421-6"><a href="fundamental.html#cb421-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb421-7"><a href="fundamental.html#cb421-7" aria-hidden="true" tabindex="-1"></a>          <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.00001</span>),</span>
<span id="cb421-8"><a href="fundamental.html#cb421-8" aria-hidden="true" tabindex="-1"></a>          <span class="at">metrics =</span> <span class="fu">c</span>(metric_categorical_accuracy)</span>
<span id="cb421-9"><a href="fundamental.html#cb421-9" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb421-10"><a href="fundamental.html#cb421-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb421-11"><a href="fundamental.html#cb421-11" aria-hidden="true" tabindex="-1"></a>model_history11 <span class="ot">=</span></span>
<span id="cb421-12"><a href="fundamental.html#cb421-12" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb421-13"><a href="fundamental.html#cb421-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, <span class="at">epochs =</span> 100L, <span class="at">batch_size =</span> 5L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb421-14"><a href="fundamental.html#cb421-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb421-15"><a href="fundamental.html#cb421-15" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb421-16"><a href="fundamental.html#cb421-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">evaluate</span>(X, Y)</span></code></pre></div>
<pre><code>##                 loss categorical_accuracy 
##            0.5061002            0.6666667</code></pre>
<div class="sourceCode" id="cb423"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb423-1"><a href="fundamental.html#cb423-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history11)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_1-10.png" width="672" /></p>
<div class="sourceCode" id="cb424"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb424-1"><a href="fundamental.html#cb424-1" aria-hidden="true" tabindex="-1"></a><span class="do">##########  -&gt; Higher batch size (faster but less accurate).</span></span>
<span id="cb424-2"><a href="fundamental.html#cb424-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb424-3"><a href="fundamental.html#cb424-3" aria-hidden="true" tabindex="-1"></a>keras<span class="sc">::</span><span class="fu">reset_states</span>(model)</span>
<span id="cb424-4"><a href="fundamental.html#cb424-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb424-5"><a href="fundamental.html#cb424-5" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb424-6"><a href="fundamental.html#cb424-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb424-7"><a href="fundamental.html#cb424-7" aria-hidden="true" tabindex="-1"></a>          <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="dv">3</span>),</span>
<span id="cb424-8"><a href="fundamental.html#cb424-8" aria-hidden="true" tabindex="-1"></a>          <span class="at">metrics =</span> <span class="fu">c</span>(metric_categorical_accuracy)</span>
<span id="cb424-9"><a href="fundamental.html#cb424-9" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb424-10"><a href="fundamental.html#cb424-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb424-11"><a href="fundamental.html#cb424-11" aria-hidden="true" tabindex="-1"></a>model_history12 <span class="ot">=</span></span>
<span id="cb424-12"><a href="fundamental.html#cb424-12" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb424-13"><a href="fundamental.html#cb424-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, <span class="at">epochs =</span> 100L, <span class="at">batch_size =</span> 50L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb424-14"><a href="fundamental.html#cb424-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb424-15"><a href="fundamental.html#cb424-15" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb424-16"><a href="fundamental.html#cb424-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">evaluate</span>(X, Y)</span></code></pre></div>
<pre><code>##                 loss categorical_accuracy 
##            0.4643030            0.6666667</code></pre>
<div class="sourceCode" id="cb426"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb426-1"><a href="fundamental.html#cb426-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history12)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_1-11.png" width="672" /></p>
<div class="sourceCode" id="cb427"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb427-1"><a href="fundamental.html#cb427-1" aria-hidden="true" tabindex="-1"></a><span class="do">##########</span></span>
<span id="cb427-2"><a href="fundamental.html#cb427-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb427-3"><a href="fundamental.html#cb427-3" aria-hidden="true" tabindex="-1"></a>keras<span class="sc">::</span><span class="fu">reset_states</span>(model)</span>
<span id="cb427-4"><a href="fundamental.html#cb427-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb427-5"><a href="fundamental.html#cb427-5" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb427-6"><a href="fundamental.html#cb427-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb427-7"><a href="fundamental.html#cb427-7" aria-hidden="true" tabindex="-1"></a>          <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.5</span>),</span>
<span id="cb427-8"><a href="fundamental.html#cb427-8" aria-hidden="true" tabindex="-1"></a>          <span class="at">metrics =</span> <span class="fu">c</span>(metric_categorical_accuracy)</span>
<span id="cb427-9"><a href="fundamental.html#cb427-9" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb427-10"><a href="fundamental.html#cb427-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb427-11"><a href="fundamental.html#cb427-11" aria-hidden="true" tabindex="-1"></a>model_history13 <span class="ot">=</span></span>
<span id="cb427-12"><a href="fundamental.html#cb427-12" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb427-13"><a href="fundamental.html#cb427-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, <span class="at">epochs =</span> 100L, <span class="at">batch_size =</span> 50L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb427-14"><a href="fundamental.html#cb427-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb427-15"><a href="fundamental.html#cb427-15" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb427-16"><a href="fundamental.html#cb427-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">evaluate</span>(X, Y)</span></code></pre></div>
<pre><code>##                 loss categorical_accuracy 
##            0.4621144            0.6666667</code></pre>
<div class="sourceCode" id="cb429"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb429-1"><a href="fundamental.html#cb429-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history13)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_1-12.png" width="672" /></p>
<div class="sourceCode" id="cb430"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb430-1"><a href="fundamental.html#cb430-1" aria-hidden="true" tabindex="-1"></a><span class="do">##########</span></span>
<span id="cb430-2"><a href="fundamental.html#cb430-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb430-3"><a href="fundamental.html#cb430-3" aria-hidden="true" tabindex="-1"></a>keras<span class="sc">::</span><span class="fu">reset_states</span>(model)</span>
<span id="cb430-4"><a href="fundamental.html#cb430-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb430-5"><a href="fundamental.html#cb430-5" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb430-6"><a href="fundamental.html#cb430-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb430-7"><a href="fundamental.html#cb430-7" aria-hidden="true" tabindex="-1"></a>          <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.00001</span>),</span>
<span id="cb430-8"><a href="fundamental.html#cb430-8" aria-hidden="true" tabindex="-1"></a>          <span class="at">metrics =</span> <span class="fu">c</span>(metric_categorical_accuracy)</span>
<span id="cb430-9"><a href="fundamental.html#cb430-9" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb430-10"><a href="fundamental.html#cb430-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb430-11"><a href="fundamental.html#cb430-11" aria-hidden="true" tabindex="-1"></a>model_history14 <span class="ot">=</span></span>
<span id="cb430-12"><a href="fundamental.html#cb430-12" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb430-13"><a href="fundamental.html#cb430-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, <span class="at">epochs =</span> 100L, <span class="at">batch_size =</span> 50L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb430-14"><a href="fundamental.html#cb430-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb430-15"><a href="fundamental.html#cb430-15" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb430-16"><a href="fundamental.html#cb430-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">evaluate</span>(X, Y)</span></code></pre></div>
<pre><code>##                 loss categorical_accuracy 
##            0.4621110            0.6666667</code></pre>
<div class="sourceCode" id="cb432"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb432-1"><a href="fundamental.html#cb432-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history14)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_1-13.png" width="672" /></p>
<div class="sourceCode" id="cb433"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb433-1"><a href="fundamental.html#cb433-1" aria-hidden="true" tabindex="-1"></a><span class="do">####################</span></span>
<span id="cb433-2"><a href="fundamental.html#cb433-2" aria-hidden="true" tabindex="-1"></a><span class="do">####################</span></span>
<span id="cb433-3"><a href="fundamental.html#cb433-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb433-4"><a href="fundamental.html#cb433-4" aria-hidden="true" tabindex="-1"></a>keras<span class="sc">::</span><span class="fu">reset_states</span>(model)</span>
<span id="cb433-5"><a href="fundamental.html#cb433-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb433-6"><a href="fundamental.html#cb433-6" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb433-7"><a href="fundamental.html#cb433-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb433-8"><a href="fundamental.html#cb433-8" aria-hidden="true" tabindex="-1"></a>          <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.05</span>),</span>
<span id="cb433-9"><a href="fundamental.html#cb433-9" aria-hidden="true" tabindex="-1"></a>          <span class="at">metrics =</span> <span class="fu">c</span>(metric_categorical_accuracy)</span>
<span id="cb433-10"><a href="fundamental.html#cb433-10" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb433-11"><a href="fundamental.html#cb433-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb433-12"><a href="fundamental.html#cb433-12" aria-hidden="true" tabindex="-1"></a>model_history15 <span class="ot">=</span></span>
<span id="cb433-13"><a href="fundamental.html#cb433-13" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb433-14"><a href="fundamental.html#cb433-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, <span class="at">epochs =</span> 150L, <span class="at">batch_size =</span> 50L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb433-15"><a href="fundamental.html#cb433-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb433-16"><a href="fundamental.html#cb433-16" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history15)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_1-14.png" width="672" /></p>
<div class="sourceCode" id="cb434"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb434-1"><a href="fundamental.html#cb434-1" aria-hidden="true" tabindex="-1"></a><span class="do">##########  -&gt; shuffle = FALSE (some kind of overfitting)</span></span>
<span id="cb434-2"><a href="fundamental.html#cb434-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb434-3"><a href="fundamental.html#cb434-3" aria-hidden="true" tabindex="-1"></a>keras<span class="sc">::</span><span class="fu">reset_states</span>(model)</span>
<span id="cb434-4"><a href="fundamental.html#cb434-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb434-5"><a href="fundamental.html#cb434-5" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb434-6"><a href="fundamental.html#cb434-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb434-7"><a href="fundamental.html#cb434-7" aria-hidden="true" tabindex="-1"></a>          <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.05</span>),</span>
<span id="cb434-8"><a href="fundamental.html#cb434-8" aria-hidden="true" tabindex="-1"></a>          <span class="at">metrics =</span> <span class="fu">c</span>(metric_categorical_accuracy)</span>
<span id="cb434-9"><a href="fundamental.html#cb434-9" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb434-10"><a href="fundamental.html#cb434-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb434-11"><a href="fundamental.html#cb434-11" aria-hidden="true" tabindex="-1"></a>model_history16 <span class="ot">=</span></span>
<span id="cb434-12"><a href="fundamental.html#cb434-12" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb434-13"><a href="fundamental.html#cb434-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, <span class="at">epochs =</span> 150L, <span class="at">batch_size =</span> 50L, <span class="at">shuffle =</span> <span class="cn">FALSE</span>)</span>
<span id="cb434-14"><a href="fundamental.html#cb434-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb434-15"><a href="fundamental.html#cb434-15" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history16)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_1-15.png" width="672" /></p>
<div class="sourceCode" id="cb435"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb435-1"><a href="fundamental.html#cb435-1" aria-hidden="true" tabindex="-1"></a><span class="do">##########  -&gt; shuffle = FALSE + lower batch size</span></span>
<span id="cb435-2"><a href="fundamental.html#cb435-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb435-3"><a href="fundamental.html#cb435-3" aria-hidden="true" tabindex="-1"></a>keras<span class="sc">::</span><span class="fu">reset_states</span>(model)</span>
<span id="cb435-4"><a href="fundamental.html#cb435-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb435-5"><a href="fundamental.html#cb435-5" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb435-6"><a href="fundamental.html#cb435-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb435-7"><a href="fundamental.html#cb435-7" aria-hidden="true" tabindex="-1"></a>          <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.05</span>),</span>
<span id="cb435-8"><a href="fundamental.html#cb435-8" aria-hidden="true" tabindex="-1"></a>          <span class="at">metrics =</span> <span class="fu">c</span>(metric_categorical_accuracy)</span>
<span id="cb435-9"><a href="fundamental.html#cb435-9" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb435-10"><a href="fundamental.html#cb435-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb435-11"><a href="fundamental.html#cb435-11" aria-hidden="true" tabindex="-1"></a>model_history17 <span class="ot">=</span></span>
<span id="cb435-12"><a href="fundamental.html#cb435-12" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb435-13"><a href="fundamental.html#cb435-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, <span class="at">epochs =</span> 150L, <span class="at">batch_size =</span> 5L, <span class="at">shuffle =</span> <span class="cn">FALSE</span>)</span>
<span id="cb435-14"><a href="fundamental.html#cb435-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb435-15"><a href="fundamental.html#cb435-15" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history17)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_1-16.png" width="672" /></p>
<div class="sourceCode" id="cb436"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb436-1"><a href="fundamental.html#cb436-1" aria-hidden="true" tabindex="-1"></a><span class="do">##########  -&gt; shuffle = FALSE + higher batch size</span></span>
<span id="cb436-2"><a href="fundamental.html#cb436-2" aria-hidden="true" tabindex="-1"></a><span class="co">#           (Many samples are taken at once, so no &quot;hopping&quot; any longer.)</span></span>
<span id="cb436-3"><a href="fundamental.html#cb436-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb436-4"><a href="fundamental.html#cb436-4" aria-hidden="true" tabindex="-1"></a>keras<span class="sc">::</span><span class="fu">reset_states</span>(model)</span>
<span id="cb436-5"><a href="fundamental.html#cb436-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb436-6"><a href="fundamental.html#cb436-6" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb436-7"><a href="fundamental.html#cb436-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb436-8"><a href="fundamental.html#cb436-8" aria-hidden="true" tabindex="-1"></a>          <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.05</span>),</span>
<span id="cb436-9"><a href="fundamental.html#cb436-9" aria-hidden="true" tabindex="-1"></a>          <span class="at">metrics =</span> <span class="fu">c</span>(metric_categorical_accuracy)</span>
<span id="cb436-10"><a href="fundamental.html#cb436-10" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb436-11"><a href="fundamental.html#cb436-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb436-12"><a href="fundamental.html#cb436-12" aria-hidden="true" tabindex="-1"></a>model_history18 <span class="ot">=</span></span>
<span id="cb436-13"><a href="fundamental.html#cb436-13" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb436-14"><a href="fundamental.html#cb436-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, <span class="at">epochs =</span> 150L, <span class="at">batch_size =</span> 75L, <span class="at">shuffle =</span> <span class="cn">FALSE</span>)</span>
<span id="cb436-15"><a href="fundamental.html#cb436-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb436-16"><a href="fundamental.html#cb436-16" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history18)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_1-17.png" width="672" /></p>
<p>Play around with the parameters on your own!</p>
    </p>
  </details>
  <br/><hr/>
</div>
</div>
<div id="artificial-neural-networks" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Artificial Neural Networks</h2>
<p>Now, we will come to artificial neural networks (ANNs), for which the topic of regularization is very important. We can specify the regularization in each layer via the kernel_regularization (and/or the bias_regularization) argument.</p>
<div class="sourceCode" id="cb437"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb437-1"><a href="fundamental.html#cb437-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb437-2"><a href="fundamental.html#cb437-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb437-3"><a href="fundamental.html#cb437-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb437-4"><a href="fundamental.html#cb437-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb437-5"><a href="fundamental.html#cb437-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality</span>
<span id="cb437-6"><a href="fundamental.html#cb437-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(data)</span></code></pre></div>
<pre><code>##      Ozone           Solar.R           Wind             Temp           Month            Day      
##  Min.   :  1.00   Min.   :  7.0   Min.   : 1.700   Min.   :56.00   Min.   :5.000   Min.   : 1.0  
##  1st Qu.: 18.00   1st Qu.:115.8   1st Qu.: 7.400   1st Qu.:72.00   1st Qu.:6.000   1st Qu.: 8.0  
##  Median : 31.50   Median :205.0   Median : 9.700   Median :79.00   Median :7.000   Median :16.0  
##  Mean   : 42.13   Mean   :185.9   Mean   : 9.958   Mean   :77.88   Mean   :6.993   Mean   :15.8  
##  3rd Qu.: 63.25   3rd Qu.:258.8   3rd Qu.:11.500   3rd Qu.:85.00   3rd Qu.:8.000   3rd Qu.:23.0  
##  Max.   :168.00   Max.   :334.0   Max.   :20.700   Max.   :97.00   Max.   :9.000   Max.   :31.0  
##  NA&#39;s   :37       NA&#39;s   :7</code></pre>
<div class="sourceCode" id="cb439"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb439-1"><a href="fundamental.html#cb439-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> data[<span class="fu">complete.cases</span>(data),] <span class="co"># Remove NAs.</span></span>
<span id="cb439-2"><a href="fundamental.html#cb439-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(data)</span></code></pre></div>
<pre><code>##      Ozone          Solar.R           Wind            Temp           Month            Day       
##  Min.   :  1.0   Min.   :  7.0   Min.   : 2.30   Min.   :57.00   Min.   :5.000   Min.   : 1.00  
##  1st Qu.: 18.0   1st Qu.:113.5   1st Qu.: 7.40   1st Qu.:71.00   1st Qu.:6.000   1st Qu.: 9.00  
##  Median : 31.0   Median :207.0   Median : 9.70   Median :79.00   Median :7.000   Median :16.00  
##  Mean   : 42.1   Mean   :184.8   Mean   : 9.94   Mean   :77.79   Mean   :7.216   Mean   :15.95  
##  3rd Qu.: 62.0   3rd Qu.:255.5   3rd Qu.:11.50   3rd Qu.:84.50   3rd Qu.:9.000   3rd Qu.:22.50  
##  Max.   :168.0   Max.   :334.0   Max.   :20.70   Max.   :97.00   Max.   :9.000   Max.   :31.00</code></pre>
<div class="sourceCode" id="cb441"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb441-1"><a href="fundamental.html#cb441-1" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="dv">2</span><span class="sc">:</span><span class="dv">6</span>])</span>
<span id="cb441-2"><a href="fundamental.html#cb441-2" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span> data[,<span class="dv">1</span>]</span>
<span id="cb441-3"><a href="fundamental.html#cb441-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb441-4"><a href="fundamental.html#cb441-4" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb441-5"><a href="fundamental.html#cb441-5" aria-hidden="true" tabindex="-1"></a>penalty <span class="ot">=</span> <span class="fl">0.1</span></span>
<span id="cb441-6"><a href="fundamental.html#cb441-6" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb441-7"><a href="fundamental.html#cb441-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>,</span>
<span id="cb441-8"><a href="fundamental.html#cb441-8" aria-hidden="true" tabindex="-1"></a>             <span class="at">input_shape =</span> <span class="fu">list</span>(5L),</span>
<span id="cb441-9"><a href="fundamental.html#cb441-9" aria-hidden="true" tabindex="-1"></a>             <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1</span>(penalty)) <span class="sc">%&gt;%</span></span>
<span id="cb441-10"><a href="fundamental.html#cb441-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>,</span>
<span id="cb441-11"><a href="fundamental.html#cb441-11" aria-hidden="true" tabindex="-1"></a>             <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1</span>(penalty) ) <span class="sc">%&gt;%</span></span>
<span id="cb441-12"><a href="fundamental.html#cb441-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>,</span>
<span id="cb441-13"><a href="fundamental.html#cb441-13" aria-hidden="true" tabindex="-1"></a>             <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1</span>(penalty)) <span class="sc">%&gt;%</span></span>
<span id="cb441-14"><a href="fundamental.html#cb441-14" aria-hidden="true" tabindex="-1"></a> <span class="co"># One output dimension with a linear activation function.</span></span>
<span id="cb441-15"><a href="fundamental.html#cb441-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;linear&quot;</span>,</span>
<span id="cb441-16"><a href="fundamental.html#cb441-16" aria-hidden="true" tabindex="-1"></a>             <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1</span>(penalty))</span>
<span id="cb441-17"><a href="fundamental.html#cb441-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb441-18"><a href="fundamental.html#cb441-18" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb441-19"><a href="fundamental.html#cb441-19" aria-hidden="true" tabindex="-1"></a> <span class="fu">compile</span>(</span>
<span id="cb441-20"><a href="fundamental.html#cb441-20" aria-hidden="true" tabindex="-1"></a>   <span class="at">loss =</span> loss_mean_squared_error,</span>
<span id="cb441-21"><a href="fundamental.html#cb441-21" aria-hidden="true" tabindex="-1"></a>   keras<span class="sc">::</span><span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.1</span>)</span>
<span id="cb441-22"><a href="fundamental.html#cb441-22" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb441-23"><a href="fundamental.html#cb441-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb441-24"><a href="fundamental.html#cb441-24" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb441-25"><a href="fundamental.html#cb441-25" aria-hidden="true" tabindex="-1"></a> model <span class="sc">%&gt;%</span></span>
<span id="cb441-26"><a href="fundamental.html#cb441-26" aria-hidden="true" tabindex="-1"></a> <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> <span class="fu">matrix</span>(Y, <span class="at">ncol =</span> 1L), <span class="at">epochs =</span> 100L,</span>
<span id="cb441-27"><a href="fundamental.html#cb441-27" aria-hidden="true" tabindex="-1"></a>     <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>, <span class="at">validation_split =</span> <span class="fl">0.2</span>)</span>
<span id="cb441-28"><a href="fundamental.html#cb441-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb441-29"><a href="fundamental.html#cb441-29" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_15-1.png" width="672" /></p>
<div class="sourceCode" id="cb442"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb442-1"><a href="fundamental.html#cb442-1" aria-hidden="true" tabindex="-1"></a>weights <span class="ot">=</span> <span class="fu">lapply</span>(model<span class="sc">$</span>weights, <span class="cf">function</span>(w) w<span class="sc">$</span><span class="fu">numpy</span>() )</span>
<span id="cb442-2"><a href="fundamental.html#cb442-2" aria-hidden="true" tabindex="-1"></a>fields<span class="sc">::</span><span class="fu">image.plot</span>(weights[[<span class="dv">1</span>]])</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_15-2.png" width="672" /></p>
<details>
<summary>
<strong><span style="color: #CC2FAA;">Torch</span></strong>
</summary>
<p>
<p>Again, we have to do the regularization on our own:</p>
<div class="sourceCode" id="cb443"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb443-1"><a href="fundamental.html#cb443-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb443-2"><a href="fundamental.html#cb443-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb443-3"><a href="fundamental.html#cb443-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb443-4"><a href="fundamental.html#cb443-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb443-5"><a href="fundamental.html#cb443-5" aria-hidden="true" tabindex="-1"></a>model_torch <span class="ot">=</span> <span class="fu">nn_sequential</span>(</span>
<span id="cb443-6"><a href="fundamental.html#cb443-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_linear</span>(<span class="at">in_features =</span> <span class="fu">dim</span>(X)[<span class="dv">2</span>], <span class="at">out_features =</span> 100L),</span>
<span id="cb443-7"><a href="fundamental.html#cb443-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_relu</span>(),</span>
<span id="cb443-8"><a href="fundamental.html#cb443-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_linear</span>(100L, 100L),</span>
<span id="cb443-9"><a href="fundamental.html#cb443-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_relu</span>(),</span>
<span id="cb443-10"><a href="fundamental.html#cb443-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_linear</span>(100L, 100L),</span>
<span id="cb443-11"><a href="fundamental.html#cb443-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_relu</span>(),</span>
<span id="cb443-12"><a href="fundamental.html#cb443-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_linear</span>(100L, 1L),</span>
<span id="cb443-13"><a href="fundamental.html#cb443-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb443-14"><a href="fundamental.html#cb443-14" aria-hidden="true" tabindex="-1"></a>opt <span class="ot">=</span> <span class="fu">optim_adam</span>(<span class="at">params =</span> model_torch<span class="sc">$</span>parameters, <span class="at">lr =</span> <span class="fl">0.1</span>)</span>
<span id="cb443-15"><a href="fundamental.html#cb443-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb443-16"><a href="fundamental.html#cb443-16" aria-hidden="true" tabindex="-1"></a>X_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(X)</span>
<span id="cb443-17"><a href="fundamental.html#cb443-17" aria-hidden="true" tabindex="-1"></a>Y_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fu">matrix</span>(Y, <span class="at">ncol =</span> 1L), <span class="at">dtype =</span> <span class="fu">torch_float32</span>())</span>
<span id="cb443-18"><a href="fundamental.html#cb443-18" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">500</span>){</span>
<span id="cb443-19"><a href="fundamental.html#cb443-19" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(X), 20L)</span>
<span id="cb443-20"><a href="fundamental.html#cb443-20" aria-hidden="true" tabindex="-1"></a>  opt<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb443-21"><a href="fundamental.html#cb443-21" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">=</span> <span class="fu">model_torch</span>(X_torch[indices, ])</span>
<span id="cb443-22"><a href="fundamental.html#cb443-22" aria-hidden="true" tabindex="-1"></a>  loss <span class="ot">=</span> <span class="fu">nnf_mse_loss</span>(pred, Y_torch[indices,,<span class="at">drop =</span> <span class="cn">FALSE</span>])</span>
<span id="cb443-23"><a href="fundamental.html#cb443-23" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb443-24"><a href="fundamental.html#cb443-24" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Add L1 (only on the &#39;kernel weights&#39;):</span></span>
<span id="cb443-25"><a href="fundamental.html#cb443-25" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="fu">seq</span>(<span class="dv">1</span>, <span class="dv">8</span>, <span class="at">by =</span> <span class="dv">2</span>)){</span>
<span id="cb443-26"><a href="fundamental.html#cb443-26" aria-hidden="true" tabindex="-1"></a>    loss <span class="ot">=</span> loss <span class="sc">+</span> model_torch<span class="sc">$</span>parameters[[i]]<span class="sc">$</span><span class="fu">abs</span>()<span class="sc">$</span><span class="fu">sum</span>()<span class="sc">*</span><span class="fl">0.1</span></span>
<span id="cb443-27"><a href="fundamental.html#cb443-27" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb443-28"><a href="fundamental.html#cb443-28" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb443-29"><a href="fundamental.html#cb443-29" aria-hidden="true" tabindex="-1"></a>  loss<span class="sc">$</span><span class="fu">sum</span>()<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb443-30"><a href="fundamental.html#cb443-30" aria-hidden="true" tabindex="-1"></a>  opt<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb443-31"><a href="fundamental.html#cb443-31" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Let’s visualize the first (input) layer:</p>
<div class="sourceCode" id="cb444"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb444-1"><a href="fundamental.html#cb444-1" aria-hidden="true" tabindex="-1"></a>fields<span class="sc">::</span><span class="fu">image.plot</span>(<span class="fu">as.matrix</span>(model_torch<span class="sc">$</span>parameters<span class="sc">$</span><span class="st">`</span><span class="at">0.weight</span><span class="st">`</span>))</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_17-1.png" width="672" /></p>
</p>
</details>
<p><br/></p>
<p>Additionally to the usual <span class="math inline">\(L1\)</span> and <span class="math inline">\(L2\)</span> regularization there is another regularization: the so called <strong>dropout-layer</strong> (we will learn about this in more detail later).</p>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<p>The following code is our working example for the next exercises:</p>
<div class="sourceCode" id="cb445"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb445-1"><a href="fundamental.html#cb445-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb445-2"><a href="fundamental.html#cb445-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb445-3"><a href="fundamental.html#cb445-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb445-4"><a href="fundamental.html#cb445-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb445-5"><a href="fundamental.html#cb445-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality[<span class="fu">complete.cases</span>(airquality),]</span>
<span id="cb445-6"><a href="fundamental.html#cb445-6" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb445-7"><a href="fundamental.html#cb445-7" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> data<span class="sc">$</span>Ozone</span>
<span id="cb445-8"><a href="fundamental.html#cb445-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb445-9"><a href="fundamental.html#cb445-9" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb445-10"><a href="fundamental.html#cb445-10" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb445-11"><a href="fundamental.html#cb445-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;linear&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(<span class="fu">dim</span>(x)[<span class="dv">2</span>]), </span>
<span id="cb445-12"><a href="fundamental.html#cb445-12" aria-hidden="true" tabindex="-1"></a>             <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1</span>(<span class="dv">10</span>),</span>
<span id="cb445-13"><a href="fundamental.html#cb445-13" aria-hidden="true" tabindex="-1"></a>             <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l1</span>(<span class="dv">10</span>))</span>
<span id="cb445-14"><a href="fundamental.html#cb445-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb445-15"><a href="fundamental.html#cb445-15" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb445-16"><a href="fundamental.html#cb445-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.5</span>))</span>
<span id="cb445-17"><a href="fundamental.html#cb445-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb445-18"><a href="fundamental.html#cb445-18" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb445-19"><a href="fundamental.html#cb445-19" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb445-20"><a href="fundamental.html#cb445-20" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(<span class="at">x =</span> x, <span class="at">y =</span> y, <span class="at">epochs =</span> 60L, <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb445-21"><a href="fundamental.html#cb445-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb445-22"><a href="fundamental.html#cb445-22" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_2-1.png" width="672" /></p>
<div class="sourceCode" id="cb446"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb446-1"><a href="fundamental.html#cb446-1" aria-hidden="true" tabindex="-1"></a>l1 <span class="ot">=</span> model<span class="sc">$</span><span class="fu">get_weights</span>()</span>
<span id="cb446-2"><a href="fundamental.html#cb446-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb446-3"><a href="fundamental.html#cb446-3" aria-hidden="true" tabindex="-1"></a>linear <span class="ot">=</span> <span class="fu">lm</span>(y<span class="sc">~</span>x)</span>
<span id="cb446-4"><a href="fundamental.html#cb446-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(linear)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -37.014 -12.284  -3.302   8.454  95.348 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   42.099      1.980  21.264  &lt; 2e-16 ***
## xSolar.R       4.583      2.135   2.147   0.0341 *  
## xWind        -11.806      2.293  -5.149 1.23e-06 ***
## xTemp         18.067      2.610   6.922 3.66e-10 ***
## xMonth        -4.479      2.230  -2.009   0.0471 *  
## xDay           2.385      2.000   1.192   0.2358    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 20.86 on 105 degrees of freedom
## Multiple R-squared:  0.6249, Adjusted R-squared:  0.6071 
## F-statistic: 34.99 on 5 and 105 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb448"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb448-1"><a href="fundamental.html#cb448-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;Linear:     &quot;</span>, <span class="fu">round</span>(<span class="fu">coef</span>(linear), <span class="dv">3</span>))</span></code></pre></div>
<pre><code>## Linear:      42.099 4.583 -11.806 18.067 -4.479 2.385</code></pre>
<div class="sourceCode" id="cb450"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb450-1"><a href="fundamental.html#cb450-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The last parameter is the intercept (first parameter in lm).</span></span>
<span id="cb450-2"><a href="fundamental.html#cb450-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;L1:         &quot;</span>, <span class="fu">round</span>(<span class="fu">c</span>(<span class="fu">unlist</span>(l1)[<span class="fu">length</span>(<span class="fu">unlist</span>(l1))],</span>
<span id="cb450-3"><a href="fundamental.html#cb450-3" aria-hidden="true" tabindex="-1"></a>                            <span class="fu">unlist</span>(l1)[<span class="dv">1</span><span class="sc">:</span>(<span class="fu">length</span>(<span class="fu">unlist</span>(l1)) <span class="sc">-</span> <span class="dv">1</span> )]), <span class="dv">3</span>))</span></code></pre></div>
<pre><code>## L1:          36.766 1.193 -8.446 13.394 -0.108 0.034</code></pre>
<p>What happens if you change the regularization from <span class="math inline">\(L1\)</span> to <span class="math inline">\(L2\)</span>?</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<div class="sourceCode" id="cb452"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb452-1"><a href="fundamental.html#cb452-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb452-2"><a href="fundamental.html#cb452-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb452-3"><a href="fundamental.html#cb452-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb452-4"><a href="fundamental.html#cb452-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb452-5"><a href="fundamental.html#cb452-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality[<span class="fu">complete.cases</span>(airquality),]</span>
<span id="cb452-6"><a href="fundamental.html#cb452-6" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb452-7"><a href="fundamental.html#cb452-7" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> data<span class="sc">$</span>Ozone</span>
<span id="cb452-8"><a href="fundamental.html#cb452-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb452-9"><a href="fundamental.html#cb452-9" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb452-10"><a href="fundamental.html#cb452-10" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb452-11"><a href="fundamental.html#cb452-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;linear&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(<span class="fu">dim</span>(x)[<span class="dv">2</span>]), </span>
<span id="cb452-12"><a href="fundamental.html#cb452-12" aria-hidden="true" tabindex="-1"></a>             <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l2</span>(<span class="dv">10</span>),</span>
<span id="cb452-13"><a href="fundamental.html#cb452-13" aria-hidden="true" tabindex="-1"></a>             <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l2</span>(<span class="dv">10</span>))</span>
<span id="cb452-14"><a href="fundamental.html#cb452-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb452-15"><a href="fundamental.html#cb452-15" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb452-16"><a href="fundamental.html#cb452-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.5</span>))</span>
<span id="cb452-17"><a href="fundamental.html#cb452-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb452-18"><a href="fundamental.html#cb452-18" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb452-19"><a href="fundamental.html#cb452-19" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb452-20"><a href="fundamental.html#cb452-20" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(<span class="at">x =</span> x, <span class="at">y =</span> y, <span class="at">epochs =</span> 60L, <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb452-21"><a href="fundamental.html#cb452-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb452-22"><a href="fundamental.html#cb452-22" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_3-1.png" width="672" /></p>
<div class="sourceCode" id="cb453"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb453-1"><a href="fundamental.html#cb453-1" aria-hidden="true" tabindex="-1"></a>l2 <span class="ot">=</span> model<span class="sc">$</span><span class="fu">get_weights</span>()</span></code></pre></div>
<pre><code>## Linear:      42.099 4.583 -11.806 18.067 -4.479 2.385</code></pre>
<pre><code>## L1:          36.766 1.193 -8.446 13.394 -0.108 0.034</code></pre>
<pre><code>## L2:          3.756 0.976 -1.721 1.956 0.402 -0.112</code></pre>
<p>Weights 4 and 5 are strongly pushed towards zero with <span class="math inline">\(L1\)</span> regularization, but <span class="math inline">\(L2\)</span> regularization shrinks more in general.
<em>Note</em>: The weights are not similar to the linear model! (But often, they keep their sign.)</p>
    </p>
  </details>
  <br/><hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<p>Try different regularization strengths, try to push the weights to zero. What is the strategy to push the parameters to zero?</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<p><strong>Now with less regularization:</strong></p>
<div class="sourceCode" id="cb457"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb457-1"><a href="fundamental.html#cb457-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb457-2"><a href="fundamental.html#cb457-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb457-3"><a href="fundamental.html#cb457-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb457-4"><a href="fundamental.html#cb457-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb457-5"><a href="fundamental.html#cb457-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality[<span class="fu">complete.cases</span>(airquality),]</span>
<span id="cb457-6"><a href="fundamental.html#cb457-6" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb457-7"><a href="fundamental.html#cb457-7" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> data<span class="sc">$</span>Ozone</span>
<span id="cb457-8"><a href="fundamental.html#cb457-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb457-9"><a href="fundamental.html#cb457-9" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb457-10"><a href="fundamental.html#cb457-10" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb457-11"><a href="fundamental.html#cb457-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;linear&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(<span class="fu">dim</span>(x)[<span class="dv">2</span>]), </span>
<span id="cb457-12"><a href="fundamental.html#cb457-12" aria-hidden="true" tabindex="-1"></a>             <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1</span>(<span class="dv">1</span>),</span>
<span id="cb457-13"><a href="fundamental.html#cb457-13" aria-hidden="true" tabindex="-1"></a>             <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l1</span>(<span class="dv">1</span>))</span>
<span id="cb457-14"><a href="fundamental.html#cb457-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb457-15"><a href="fundamental.html#cb457-15" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb457-16"><a href="fundamental.html#cb457-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.5</span>))</span>
<span id="cb457-17"><a href="fundamental.html#cb457-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb457-18"><a href="fundamental.html#cb457-18" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb457-19"><a href="fundamental.html#cb457-19" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb457-20"><a href="fundamental.html#cb457-20" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(<span class="at">x =</span> x, <span class="at">y =</span> y, <span class="at">epochs =</span> 60L, <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb457-21"><a href="fundamental.html#cb457-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb457-22"><a href="fundamental.html#cb457-22" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_5-1.png" width="672" /></p>
<div class="sourceCode" id="cb458"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb458-1"><a href="fundamental.html#cb458-1" aria-hidden="true" tabindex="-1"></a>l1_lesser <span class="ot">=</span> model<span class="sc">$</span><span class="fu">get_weights</span>()</span></code></pre></div>
<pre><code>## Linear:      42.099 4.583 -11.806 18.067 -4.479 2.385</code></pre>
<pre><code>## L1:          36.766 1.193 -8.446 13.394 -0.108 0.034</code></pre>
<pre><code>## L1, lesser:  41.087 4.164 -11.617 17.043 -3.571 1.986</code></pre>
<div class="sourceCode" id="cb462"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb462-1"><a href="fundamental.html#cb462-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb462-2"><a href="fundamental.html#cb462-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb462-3"><a href="fundamental.html#cb462-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb462-4"><a href="fundamental.html#cb462-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb462-5"><a href="fundamental.html#cb462-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality[<span class="fu">complete.cases</span>(airquality),]</span>
<span id="cb462-6"><a href="fundamental.html#cb462-6" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb462-7"><a href="fundamental.html#cb462-7" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> data<span class="sc">$</span>Ozone</span>
<span id="cb462-8"><a href="fundamental.html#cb462-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb462-9"><a href="fundamental.html#cb462-9" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb462-10"><a href="fundamental.html#cb462-10" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb462-11"><a href="fundamental.html#cb462-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;linear&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(<span class="fu">dim</span>(x)[<span class="dv">2</span>]), </span>
<span id="cb462-12"><a href="fundamental.html#cb462-12" aria-hidden="true" tabindex="-1"></a>             <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l2</span>(<span class="dv">1</span>),</span>
<span id="cb462-13"><a href="fundamental.html#cb462-13" aria-hidden="true" tabindex="-1"></a>             <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l2</span>(<span class="dv">1</span>))</span>
<span id="cb462-14"><a href="fundamental.html#cb462-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb462-15"><a href="fundamental.html#cb462-15" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb462-16"><a href="fundamental.html#cb462-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.5</span>))</span>
<span id="cb462-17"><a href="fundamental.html#cb462-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb462-18"><a href="fundamental.html#cb462-18" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb462-19"><a href="fundamental.html#cb462-19" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb462-20"><a href="fundamental.html#cb462-20" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(<span class="at">x =</span> x, <span class="at">y =</span> y, <span class="at">epochs =</span> 60L, <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb462-21"><a href="fundamental.html#cb462-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb462-22"><a href="fundamental.html#cb462-22" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_7-1.png" width="672" /></p>
<div class="sourceCode" id="cb463"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb463-1"><a href="fundamental.html#cb463-1" aria-hidden="true" tabindex="-1"></a>l2_lesser <span class="ot">=</span> model<span class="sc">$</span><span class="fu">get_weights</span>()</span></code></pre></div>
<pre><code>## Linear:      42.099 4.583 -11.806 18.067 -4.479 2.385</code></pre>
<pre><code>## L2:          3.756 0.976 -1.721 1.956 0.402 -0.112</code></pre>
<pre><code>## L2, lesser:  20.999 3.726 -7.585 9.065 -0.065 0.669</code></pre>
<p><strong>And with more regularization:</strong></p>
<div class="sourceCode" id="cb467"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb467-1"><a href="fundamental.html#cb467-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb467-2"><a href="fundamental.html#cb467-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb467-3"><a href="fundamental.html#cb467-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb467-4"><a href="fundamental.html#cb467-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb467-5"><a href="fundamental.html#cb467-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality[<span class="fu">complete.cases</span>(airquality),]</span>
<span id="cb467-6"><a href="fundamental.html#cb467-6" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb467-7"><a href="fundamental.html#cb467-7" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> data<span class="sc">$</span>Ozone</span>
<span id="cb467-8"><a href="fundamental.html#cb467-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb467-9"><a href="fundamental.html#cb467-9" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb467-10"><a href="fundamental.html#cb467-10" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb467-11"><a href="fundamental.html#cb467-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;linear&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(<span class="fu">dim</span>(x)[<span class="dv">2</span>]), </span>
<span id="cb467-12"><a href="fundamental.html#cb467-12" aria-hidden="true" tabindex="-1"></a>             <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1</span>(<span class="dv">25</span>),</span>
<span id="cb467-13"><a href="fundamental.html#cb467-13" aria-hidden="true" tabindex="-1"></a>             <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l1</span>(<span class="dv">25</span>))</span>
<span id="cb467-14"><a href="fundamental.html#cb467-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb467-15"><a href="fundamental.html#cb467-15" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb467-16"><a href="fundamental.html#cb467-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.5</span>))</span>
<span id="cb467-17"><a href="fundamental.html#cb467-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb467-18"><a href="fundamental.html#cb467-18" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb467-19"><a href="fundamental.html#cb467-19" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb467-20"><a href="fundamental.html#cb467-20" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(<span class="at">x =</span> x, <span class="at">y =</span> y, <span class="at">epochs =</span> 60L, <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb467-21"><a href="fundamental.html#cb467-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb467-22"><a href="fundamental.html#cb467-22" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_9-1.png" width="672" /></p>
<div class="sourceCode" id="cb468"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb468-1"><a href="fundamental.html#cb468-1" aria-hidden="true" tabindex="-1"></a>l1_higher <span class="ot">=</span> model<span class="sc">$</span><span class="fu">get_weights</span>()</span></code></pre></div>
<pre><code>## Linear:      42.099 4.583 -11.806 18.067 -4.479 2.385</code></pre>
<pre><code>## L1:          36.766 1.193 -8.446 13.394 -0.108 0.034</code></pre>
<pre><code>## L1, lesser:  41.087 4.164 -11.617 17.043 -3.571 1.986</code></pre>
<pre><code>## L1, higher:  29.367 0.112 -3.354 8.732 0.058 0.03</code></pre>
<div class="sourceCode" id="cb473"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb473-1"><a href="fundamental.html#cb473-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb473-2"><a href="fundamental.html#cb473-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb473-3"><a href="fundamental.html#cb473-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb473-4"><a href="fundamental.html#cb473-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb473-5"><a href="fundamental.html#cb473-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality[<span class="fu">complete.cases</span>(airquality),]</span>
<span id="cb473-6"><a href="fundamental.html#cb473-6" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb473-7"><a href="fundamental.html#cb473-7" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> data<span class="sc">$</span>Ozone</span>
<span id="cb473-8"><a href="fundamental.html#cb473-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb473-9"><a href="fundamental.html#cb473-9" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb473-10"><a href="fundamental.html#cb473-10" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb473-11"><a href="fundamental.html#cb473-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;linear&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(<span class="fu">dim</span>(x)[<span class="dv">2</span>]), </span>
<span id="cb473-12"><a href="fundamental.html#cb473-12" aria-hidden="true" tabindex="-1"></a>             <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l2</span>(<span class="dv">25</span>),</span>
<span id="cb473-13"><a href="fundamental.html#cb473-13" aria-hidden="true" tabindex="-1"></a>             <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l2</span>(<span class="dv">25</span>))</span>
<span id="cb473-14"><a href="fundamental.html#cb473-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb473-15"><a href="fundamental.html#cb473-15" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb473-16"><a href="fundamental.html#cb473-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.5</span>))</span>
<span id="cb473-17"><a href="fundamental.html#cb473-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb473-18"><a href="fundamental.html#cb473-18" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb473-19"><a href="fundamental.html#cb473-19" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb473-20"><a href="fundamental.html#cb473-20" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(<span class="at">x =</span> x, <span class="at">y =</span> y, <span class="at">epochs =</span> 60L, <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb473-21"><a href="fundamental.html#cb473-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb473-22"><a href="fundamental.html#cb473-22" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_11-1.png" width="672" /></p>
<div class="sourceCode" id="cb474"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb474-1"><a href="fundamental.html#cb474-1" aria-hidden="true" tabindex="-1"></a>l2_higher <span class="ot">=</span> model<span class="sc">$</span><span class="fu">get_weights</span>()</span></code></pre></div>
<pre><code>## Linear:      42.099 4.583 -11.806 18.067 -4.479 2.385</code></pre>
<pre><code>## L2:          3.756 0.976 -1.721 1.956 0.402 -0.112</code></pre>
<pre><code>## L2, lesser:  20.999 3.726 -7.585 9.065 -0.065 0.669</code></pre>
<pre><code>## L2, higher:  1.564 0.414 -0.797 0.83 0.165 0.048</code></pre>
<p>For pushing weights towards zero, <span class="math inline">\(L1\)</span> regularization is used rather than <span class="math inline">\(L2\)</span>.
Higher regularization leads to smaller parameters (maybe in combination with smaller learning rates).</p>
<p>Play around on your own! Ask questions if you have any.</p>
    </p>
  </details>
  <br/><hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<p>Use a combination of <span class="math inline">\(L1\)</span> and a <span class="math inline">\(L2\)</span> regularization (there is a Keras function for this). How is this kind of regularization called and what is the advantage of this approach?</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<div class="sourceCode" id="cb479"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb479-1"><a href="fundamental.html#cb479-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb479-2"><a href="fundamental.html#cb479-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb479-3"><a href="fundamental.html#cb479-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb479-4"><a href="fundamental.html#cb479-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb479-5"><a href="fundamental.html#cb479-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality[<span class="fu">complete.cases</span>(airquality),]</span>
<span id="cb479-6"><a href="fundamental.html#cb479-6" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb479-7"><a href="fundamental.html#cb479-7" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> data<span class="sc">$</span>Ozone</span>
<span id="cb479-8"><a href="fundamental.html#cb479-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb479-9"><a href="fundamental.html#cb479-9" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb479-10"><a href="fundamental.html#cb479-10" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb479-11"><a href="fundamental.html#cb479-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;linear&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(<span class="fu">dim</span>(x)[<span class="dv">2</span>]), </span>
<span id="cb479-12"><a href="fundamental.html#cb479-12" aria-hidden="true" tabindex="-1"></a>             <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1_l2</span>(<span class="dv">10</span>),</span>
<span id="cb479-13"><a href="fundamental.html#cb479-13" aria-hidden="true" tabindex="-1"></a>             <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l1_l2</span>(<span class="dv">10</span>))</span>
<span id="cb479-14"><a href="fundamental.html#cb479-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb479-15"><a href="fundamental.html#cb479-15" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb479-16"><a href="fundamental.html#cb479-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.5</span>))</span>
<span id="cb479-17"><a href="fundamental.html#cb479-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb479-18"><a href="fundamental.html#cb479-18" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb479-19"><a href="fundamental.html#cb479-19" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb479-20"><a href="fundamental.html#cb479-20" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(<span class="at">x =</span> x, <span class="at">y =</span> y, <span class="at">epochs =</span> 60L, <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb479-21"><a href="fundamental.html#cb479-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb479-22"><a href="fundamental.html#cb479-22" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_13-1.png" width="672" /></p>
<p>This kind of regularization is called <strong>Elastic net</strong>. It is a combination of LASSO (<span class="math inline">\(L1\)</span>) and Ridge. It is more flexible than <span class="math inline">\(L1\)</span> and less flexible than <span class="math inline">\(L2\)</span> and higher computational cost. Elastic net does shrinkage as well, but does not separate highly correlated parameters out that much.</p>
    </p>
  </details>
  <br/><hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<p>In Keras you can tell the model to keep a specific percentage of the data as holdout (validation_split argument in the fit function):</p>
<div class="sourceCode" id="cb480"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb480-1"><a href="fundamental.html#cb480-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb480-2"><a href="fundamental.html#cb480-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb480-3"><a href="fundamental.html#cb480-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb480-4"><a href="fundamental.html#cb480-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb480-5"><a href="fundamental.html#cb480-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality</span>
<span id="cb480-6"><a href="fundamental.html#cb480-6" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> data[<span class="fu">complete.cases</span>(data),]</span>
<span id="cb480-7"><a href="fundamental.html#cb480-7" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="dv">2</span><span class="sc">:</span><span class="dv">6</span>])</span>
<span id="cb480-8"><a href="fundamental.html#cb480-8" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> data[,<span class="dv">1</span>]</span>
<span id="cb480-9"><a href="fundamental.html#cb480-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb480-10"><a href="fundamental.html#cb480-10" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb480-11"><a href="fundamental.html#cb480-11" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb480-12"><a href="fundamental.html#cb480-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(5L)) <span class="sc">%&gt;%</span></span>
<span id="cb480-13"><a href="fundamental.html#cb480-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L) <span class="sc">%&gt;%</span></span>
<span id="cb480-14"><a href="fundamental.html#cb480-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L) <span class="sc">%&gt;%</span></span>
<span id="cb480-15"><a href="fundamental.html#cb480-15" aria-hidden="true" tabindex="-1"></a>  <span class="co"># One output dimension with a linear activation function.</span></span>
<span id="cb480-16"><a href="fundamental.html#cb480-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;linear&quot;</span>)</span>
<span id="cb480-17"><a href="fundamental.html#cb480-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb480-18"><a href="fundamental.html#cb480-18" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb480-19"><a href="fundamental.html#cb480-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.1</span>))</span>
<span id="cb480-20"><a href="fundamental.html#cb480-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb480-21"><a href="fundamental.html#cb480-21" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb480-22"><a href="fundamental.html#cb480-22" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb480-23"><a href="fundamental.html#cb480-23" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(<span class="at">x =</span> x, <span class="at">y =</span> <span class="fu">matrix</span>(y, <span class="at">ncol =</span> 1L), <span class="at">epochs =</span> 50L, <span class="at">batch_size =</span> 20L,</span>
<span id="cb480-24"><a href="fundamental.html#cb480-24" aria-hidden="true" tabindex="-1"></a>        <span class="at">shuffle =</span> <span class="cn">TRUE</span>, <span class="at">validation_split =</span> <span class="fl">0.2</span>)</span>
<span id="cb480-25"><a href="fundamental.html#cb480-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb480-26"><a href="fundamental.html#cb480-26" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_14-1.png" width="672" /></p>
<p>Run the code and view the loss for the train and the validation (test) set in the viewer panel. What happens with the validation loss? Why?</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<p>The training loss keeps decreasing, but the validation loss increases after a time. This increase in validation loss is due to overfitting.</p>
    </p>
  </details>
  <br/><hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<p>Add <span class="math inline">\(L1\)</span> / <span class="math inline">\(L2\)</span> regularization to the neural network above and try to keep the test loss close to the training loss. Try a little higher epoch number!</p>
<p>Explain the strategy that helps to achieve this.</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<p><strong>Adding regularization (</strong><span class="math inline">\(L1\)</span> <strong>and</strong> <span class="math inline">\(L2\)</span><strong>):</strong></p>
<div class="sourceCode" id="cb481"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb481-1"><a href="fundamental.html#cb481-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb481-2"><a href="fundamental.html#cb481-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb481-3"><a href="fundamental.html#cb481-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb481-4"><a href="fundamental.html#cb481-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb481-5"><a href="fundamental.html#cb481-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality</span>
<span id="cb481-6"><a href="fundamental.html#cb481-6" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> data[<span class="fu">complete.cases</span>(data),]</span>
<span id="cb481-7"><a href="fundamental.html#cb481-7" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="dv">2</span><span class="sc">:</span><span class="dv">6</span>])</span>
<span id="cb481-8"><a href="fundamental.html#cb481-8" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> data[,<span class="dv">1</span>]</span>
<span id="cb481-9"><a href="fundamental.html#cb481-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb481-10"><a href="fundamental.html#cb481-10" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb481-11"><a href="fundamental.html#cb481-11" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb481-12"><a href="fundamental.html#cb481-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(5L)) <span class="sc">%&gt;%</span></span>
<span id="cb481-13"><a href="fundamental.html#cb481-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1_l2</span>(<span class="dv">5</span>),</span>
<span id="cb481-14"><a href="fundamental.html#cb481-14" aria-hidden="true" tabindex="-1"></a>              <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l1</span>(<span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb481-15"><a href="fundamental.html#cb481-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1_l2</span>(<span class="dv">5</span>),</span>
<span id="cb481-16"><a href="fundamental.html#cb481-16" aria-hidden="true" tabindex="-1"></a>              <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l1</span>(<span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb481-17"><a href="fundamental.html#cb481-17" aria-hidden="true" tabindex="-1"></a>  <span class="co"># One output dimension with a linear activation function.</span></span>
<span id="cb481-18"><a href="fundamental.html#cb481-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;linear&quot;</span>)</span>
<span id="cb481-19"><a href="fundamental.html#cb481-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb481-20"><a href="fundamental.html#cb481-20" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb481-21"><a href="fundamental.html#cb481-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.1</span>))</span>
<span id="cb481-22"><a href="fundamental.html#cb481-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb481-23"><a href="fundamental.html#cb481-23" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb481-24"><a href="fundamental.html#cb481-24" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb481-25"><a href="fundamental.html#cb481-25" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(<span class="at">x =</span> x, <span class="at">y =</span> <span class="fu">matrix</span>(y, <span class="at">ncol =</span> 1L), <span class="at">epochs =</span> 150L, <span class="at">batch_size =</span> 20L,</span>
<span id="cb481-26"><a href="fundamental.html#cb481-26" aria-hidden="true" tabindex="-1"></a>        <span class="at">shuffle =</span> <span class="cn">TRUE</span>, <span class="at">validation_split =</span> <span class="fl">0.2</span>)</span>
<span id="cb481-27"><a href="fundamental.html#cb481-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb481-28"><a href="fundamental.html#cb481-28" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_15-1.png" width="672" /></p>
<p><strong>Adding higher regularization (</strong><span class="math inline">\(L1\)</span> <strong>and</strong> <span class="math inline">\(L2\)</span><strong>):</strong></p>
<div class="sourceCode" id="cb482"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb482-1"><a href="fundamental.html#cb482-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb482-2"><a href="fundamental.html#cb482-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb482-3"><a href="fundamental.html#cb482-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb482-4"><a href="fundamental.html#cb482-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb482-5"><a href="fundamental.html#cb482-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality</span>
<span id="cb482-6"><a href="fundamental.html#cb482-6" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> data[<span class="fu">complete.cases</span>(data),]</span>
<span id="cb482-7"><a href="fundamental.html#cb482-7" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="dv">2</span><span class="sc">:</span><span class="dv">6</span>])</span>
<span id="cb482-8"><a href="fundamental.html#cb482-8" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> data[,<span class="dv">1</span>]</span>
<span id="cb482-9"><a href="fundamental.html#cb482-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb482-10"><a href="fundamental.html#cb482-10" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb482-11"><a href="fundamental.html#cb482-11" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb482-12"><a href="fundamental.html#cb482-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(5L)) <span class="sc">%&gt;%</span></span>
<span id="cb482-13"><a href="fundamental.html#cb482-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1_l2</span>(<span class="dv">15</span>),</span>
<span id="cb482-14"><a href="fundamental.html#cb482-14" aria-hidden="true" tabindex="-1"></a>              <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l1</span>(<span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb482-15"><a href="fundamental.html#cb482-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1_l2</span>(<span class="dv">15</span>),</span>
<span id="cb482-16"><a href="fundamental.html#cb482-16" aria-hidden="true" tabindex="-1"></a>              <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l1</span>(<span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb482-17"><a href="fundamental.html#cb482-17" aria-hidden="true" tabindex="-1"></a>  <span class="co"># One output dimension with a linear activation function.</span></span>
<span id="cb482-18"><a href="fundamental.html#cb482-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;linear&quot;</span>)</span>
<span id="cb482-19"><a href="fundamental.html#cb482-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb482-20"><a href="fundamental.html#cb482-20" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb482-21"><a href="fundamental.html#cb482-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.1</span>))</span>
<span id="cb482-22"><a href="fundamental.html#cb482-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb482-23"><a href="fundamental.html#cb482-23" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb482-24"><a href="fundamental.html#cb482-24" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb482-25"><a href="fundamental.html#cb482-25" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(<span class="at">x =</span> x, <span class="at">y =</span> <span class="fu">matrix</span>(y, <span class="at">ncol =</span> 1L), <span class="at">epochs =</span> 150L, <span class="at">batch_size =</span> 20L,</span>
<span id="cb482-26"><a href="fundamental.html#cb482-26" aria-hidden="true" tabindex="-1"></a>        <span class="at">shuffle =</span> <span class="cn">TRUE</span>, <span class="at">validation_split =</span> <span class="fl">0.2</span>)</span>
<span id="cb482-27"><a href="fundamental.html#cb482-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb482-28"><a href="fundamental.html#cb482-28" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_16-1.png" width="672" /></p>
<p><em>Keep in mind: With higher regularization, both the training and the validation loss keep relatively high!</em></p>
<p><strong>Adding normal regularization (</strong><span class="math inline">\(L1\)</span> <strong>and</strong> <span class="math inline">\(L2\)</span><strong>) and use a larger learning rate:</strong></p>
<div class="sourceCode" id="cb483"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb483-1"><a href="fundamental.html#cb483-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb483-2"><a href="fundamental.html#cb483-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb483-3"><a href="fundamental.html#cb483-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb483-4"><a href="fundamental.html#cb483-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb483-5"><a href="fundamental.html#cb483-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality</span>
<span id="cb483-6"><a href="fundamental.html#cb483-6" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> data[<span class="fu">complete.cases</span>(data),]</span>
<span id="cb483-7"><a href="fundamental.html#cb483-7" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="dv">2</span><span class="sc">:</span><span class="dv">6</span>])</span>
<span id="cb483-8"><a href="fundamental.html#cb483-8" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> data[,<span class="dv">1</span>]</span>
<span id="cb483-9"><a href="fundamental.html#cb483-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb483-10"><a href="fundamental.html#cb483-10" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb483-11"><a href="fundamental.html#cb483-11" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb483-12"><a href="fundamental.html#cb483-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(5L)) <span class="sc">%&gt;%</span></span>
<span id="cb483-13"><a href="fundamental.html#cb483-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1_l2</span>(<span class="dv">5</span>),</span>
<span id="cb483-14"><a href="fundamental.html#cb483-14" aria-hidden="true" tabindex="-1"></a>              <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l1</span>(<span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb483-15"><a href="fundamental.html#cb483-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1_l2</span>(<span class="dv">5</span>),</span>
<span id="cb483-16"><a href="fundamental.html#cb483-16" aria-hidden="true" tabindex="-1"></a>              <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l1</span>(<span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb483-17"><a href="fundamental.html#cb483-17" aria-hidden="true" tabindex="-1"></a>  <span class="co"># One output dimension with a linear activation function.</span></span>
<span id="cb483-18"><a href="fundamental.html#cb483-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;linear&quot;</span>)</span>
<span id="cb483-19"><a href="fundamental.html#cb483-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb483-20"><a href="fundamental.html#cb483-20" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb483-21"><a href="fundamental.html#cb483-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.2</span>))</span>
<span id="cb483-22"><a href="fundamental.html#cb483-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb483-23"><a href="fundamental.html#cb483-23" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb483-24"><a href="fundamental.html#cb483-24" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb483-25"><a href="fundamental.html#cb483-25" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(<span class="at">x =</span> x, <span class="at">y =</span> <span class="fu">matrix</span>(y, <span class="at">ncol =</span> 1L), <span class="at">epochs =</span> 150L, <span class="at">batch_size =</span> 20L,</span>
<span id="cb483-26"><a href="fundamental.html#cb483-26" aria-hidden="true" tabindex="-1"></a>        <span class="at">shuffle =</span> <span class="cn">TRUE</span>, <span class="at">validation_split =</span> <span class="fl">0.2</span>)</span>
<span id="cb483-27"><a href="fundamental.html#cb483-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb483-28"><a href="fundamental.html#cb483-28" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_17-1.png" width="672" /></p>
<p><strong>Adding normal regularization (</strong><span class="math inline">\(L1\)</span> <strong>and</strong> <span class="math inline">\(L2\)</span><strong>) and use a very low learning rate:</strong></p>
<div class="sourceCode" id="cb484"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb484-1"><a href="fundamental.html#cb484-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb484-2"><a href="fundamental.html#cb484-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb484-3"><a href="fundamental.html#cb484-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb484-4"><a href="fundamental.html#cb484-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb484-5"><a href="fundamental.html#cb484-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality</span>
<span id="cb484-6"><a href="fundamental.html#cb484-6" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> data[<span class="fu">complete.cases</span>(data),]</span>
<span id="cb484-7"><a href="fundamental.html#cb484-7" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="dv">2</span><span class="sc">:</span><span class="dv">6</span>])</span>
<span id="cb484-8"><a href="fundamental.html#cb484-8" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> data[,<span class="dv">1</span>]</span>
<span id="cb484-9"><a href="fundamental.html#cb484-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb484-10"><a href="fundamental.html#cb484-10" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb484-11"><a href="fundamental.html#cb484-11" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb484-12"><a href="fundamental.html#cb484-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(5L)) <span class="sc">%&gt;%</span></span>
<span id="cb484-13"><a href="fundamental.html#cb484-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1_l2</span>(<span class="dv">5</span>),</span>
<span id="cb484-14"><a href="fundamental.html#cb484-14" aria-hidden="true" tabindex="-1"></a>              <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l1</span>(<span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb484-15"><a href="fundamental.html#cb484-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1_l2</span>(<span class="dv">5</span>),</span>
<span id="cb484-16"><a href="fundamental.html#cb484-16" aria-hidden="true" tabindex="-1"></a>              <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l1</span>(<span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb484-17"><a href="fundamental.html#cb484-17" aria-hidden="true" tabindex="-1"></a>  <span class="co"># One output dimension with a linear activation function.</span></span>
<span id="cb484-18"><a href="fundamental.html#cb484-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;linear&quot;</span>)</span>
<span id="cb484-19"><a href="fundamental.html#cb484-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb484-20"><a href="fundamental.html#cb484-20" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb484-21"><a href="fundamental.html#cb484-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.001</span>))</span>
<span id="cb484-22"><a href="fundamental.html#cb484-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb484-23"><a href="fundamental.html#cb484-23" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb484-24"><a href="fundamental.html#cb484-24" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb484-25"><a href="fundamental.html#cb484-25" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(<span class="at">x =</span> x, <span class="at">y =</span> <span class="fu">matrix</span>(y, <span class="at">ncol =</span> 1L), <span class="at">epochs =</span> 150L, <span class="at">batch_size =</span> 20L,</span>
<span id="cb484-26"><a href="fundamental.html#cb484-26" aria-hidden="true" tabindex="-1"></a>        <span class="at">shuffle =</span> <span class="cn">TRUE</span>, <span class="at">validation_split =</span> <span class="fl">0.2</span>)</span>
<span id="cb484-27"><a href="fundamental.html#cb484-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb484-28"><a href="fundamental.html#cb484-28" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_18-1.png" width="672" /></p>
<p>Look at the constantly lower validation loss.</p>
<p><strong>Adding low regularization (</strong><span class="math inline">\(L1\)</span> <strong>and</strong> <span class="math inline">\(L2\)</span><strong>) and use a very low learning rate:</strong></p>
<div class="sourceCode" id="cb485"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb485-1"><a href="fundamental.html#cb485-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb485-2"><a href="fundamental.html#cb485-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb485-3"><a href="fundamental.html#cb485-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb485-4"><a href="fundamental.html#cb485-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb485-5"><a href="fundamental.html#cb485-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality</span>
<span id="cb485-6"><a href="fundamental.html#cb485-6" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> data[<span class="fu">complete.cases</span>(data),]</span>
<span id="cb485-7"><a href="fundamental.html#cb485-7" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="dv">2</span><span class="sc">:</span><span class="dv">6</span>])</span>
<span id="cb485-8"><a href="fundamental.html#cb485-8" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> data[,<span class="dv">1</span>]</span>
<span id="cb485-9"><a href="fundamental.html#cb485-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb485-10"><a href="fundamental.html#cb485-10" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb485-11"><a href="fundamental.html#cb485-11" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb485-12"><a href="fundamental.html#cb485-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(5L)) <span class="sc">%&gt;%</span></span>
<span id="cb485-13"><a href="fundamental.html#cb485-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1_l2</span>(.<span class="dv">5</span>),</span>
<span id="cb485-14"><a href="fundamental.html#cb485-14" aria-hidden="true" tabindex="-1"></a>              <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l1</span>(<span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb485-15"><a href="fundamental.html#cb485-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1_l2</span>(.<span class="dv">5</span>),</span>
<span id="cb485-16"><a href="fundamental.html#cb485-16" aria-hidden="true" tabindex="-1"></a>              <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l1</span>(<span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb485-17"><a href="fundamental.html#cb485-17" aria-hidden="true" tabindex="-1"></a>  <span class="co"># One output dimension with a linear activation function.</span></span>
<span id="cb485-18"><a href="fundamental.html#cb485-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;linear&quot;</span>)</span>
<span id="cb485-19"><a href="fundamental.html#cb485-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb485-20"><a href="fundamental.html#cb485-20" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb485-21"><a href="fundamental.html#cb485-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.001</span>))</span>
<span id="cb485-22"><a href="fundamental.html#cb485-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb485-23"><a href="fundamental.html#cb485-23" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb485-24"><a href="fundamental.html#cb485-24" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb485-25"><a href="fundamental.html#cb485-25" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(<span class="at">x =</span> x, <span class="at">y =</span> <span class="fu">matrix</span>(y, <span class="at">ncol =</span> 1L), <span class="at">epochs =</span> 150L, <span class="at">batch_size =</span> 20L,</span>
<span id="cb485-26"><a href="fundamental.html#cb485-26" aria-hidden="true" tabindex="-1"></a>        <span class="at">shuffle =</span> <span class="cn">TRUE</span>, <span class="at">validation_split =</span> <span class="fl">0.2</span>)</span>
<span id="cb485-27"><a href="fundamental.html#cb485-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb485-28"><a href="fundamental.html#cb485-28" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_19-1.png" width="672" /></p>
<p>This was a good example for <strong>early stopping</strong>.</p>
<p><strong>Taking the example from above, but without shuffling:</strong></p>
<div class="sourceCode" id="cb486"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb486-1"><a href="fundamental.html#cb486-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb486-2"><a href="fundamental.html#cb486-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb486-3"><a href="fundamental.html#cb486-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb486-4"><a href="fundamental.html#cb486-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb486-5"><a href="fundamental.html#cb486-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality</span>
<span id="cb486-6"><a href="fundamental.html#cb486-6" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> data[<span class="fu">complete.cases</span>(data),]</span>
<span id="cb486-7"><a href="fundamental.html#cb486-7" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="dv">2</span><span class="sc">:</span><span class="dv">6</span>])</span>
<span id="cb486-8"><a href="fundamental.html#cb486-8" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> data[,<span class="dv">1</span>]</span>
<span id="cb486-9"><a href="fundamental.html#cb486-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb486-10"><a href="fundamental.html#cb486-10" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb486-11"><a href="fundamental.html#cb486-11" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb486-12"><a href="fundamental.html#cb486-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(5L)) <span class="sc">%&gt;%</span></span>
<span id="cb486-13"><a href="fundamental.html#cb486-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1_l2</span>(.<span class="dv">5</span>),</span>
<span id="cb486-14"><a href="fundamental.html#cb486-14" aria-hidden="true" tabindex="-1"></a>              <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l1</span>(<span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb486-15"><a href="fundamental.html#cb486-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1_l2</span>(.<span class="dv">5</span>),</span>
<span id="cb486-16"><a href="fundamental.html#cb486-16" aria-hidden="true" tabindex="-1"></a>              <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l1</span>(<span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb486-17"><a href="fundamental.html#cb486-17" aria-hidden="true" tabindex="-1"></a>  <span class="co"># One output dimension with a linear activation function.</span></span>
<span id="cb486-18"><a href="fundamental.html#cb486-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;linear&quot;</span>)</span>
<span id="cb486-19"><a href="fundamental.html#cb486-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb486-20"><a href="fundamental.html#cb486-20" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb486-21"><a href="fundamental.html#cb486-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.001</span>))</span>
<span id="cb486-22"><a href="fundamental.html#cb486-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb486-23"><a href="fundamental.html#cb486-23" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb486-24"><a href="fundamental.html#cb486-24" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb486-25"><a href="fundamental.html#cb486-25" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(<span class="at">x =</span> x, <span class="at">y =</span> <span class="fu">matrix</span>(y, <span class="at">ncol =</span> 1L), <span class="at">epochs =</span> 150L, <span class="at">batch_size =</span> 20L,</span>
<span id="cb486-26"><a href="fundamental.html#cb486-26" aria-hidden="true" tabindex="-1"></a>        <span class="at">shuffle =</span> <span class="cn">FALSE</span>, <span class="at">validation_split =</span> <span class="fl">0.2</span>)</span>
<span id="cb486-27"><a href="fundamental.html#cb486-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb486-28"><a href="fundamental.html#cb486-28" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_20-1.png" width="672" /></p>
<p>Play around with regularization kind (<span class="math inline">\(L1\)</span>, <span class="math inline">\(L2\)</span>, <span class="math inline">\(L1,L2\)</span>) strength and the learning rate also on your own!</p>
    </p>
  </details>
  <br/><hr/>
</div>
<div id="tree-based-machine-learning-algorithms" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> Tree-based Machine Learning Algorithms</h2>
<p>Famous machine learning algorithms such as <em>Random Forest</em> and <em>Gradient Boosted trees</em> are based on classification and regression trees.
<strong>Hint</strong>: Tree-based algorithms are not distance based and thus do not need scaling.</p>
<p>If you want to know a little bit more about the concepts described in the following - like decision, classification and regression trees as well as random forests - you might watch the following videos:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=7VeUPuFGJHk" target="_blank" rel="noopener">Decision trees</a></li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/7VeUPuFGJHk" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<ul>
<li><p><a href="https://www.youtube.com/watch?v=g9c66TUylZ4" target="_blank" rel="noopener">Regression trees</a>
<iframe width="560" height="315" 
src="https://www.youtube.com/embed/g9c66TUylZ4"
frameborder="0" allow="accelerometer; autoplay; encrypted-media;
gyroscope; picture-in-picture" allowfullscreen>
</iframe></p></li>
<li><p><a href="https://www.youtube.com/watch?v=J4Wdy0Wc_xQ" target="_blank" rel="noopener">Random forests</a>
<iframe width="560" height="315" 
src="https://www.youtube.com/embed/J4Wdy0Wc_xQ"
frameborder="0" allow="accelerometer; autoplay; encrypted-media;
gyroscope; picture-in-picture" allowfullscreen>
</iframe></p></li>
<li><p><a href="https://www.youtube.com/watch?v=D0efHEJsfHo" target="_blank" rel="noopener">Pruning trees</a>
<iframe width="560" height="315" 
src="https://www.youtube.com/embed/D0efHEJsfHo"
frameborder="0" allow="accelerometer; autoplay; encrypted-media;
gyroscope; picture-in-picture" allowfullscreen>
</iframe></p></li>
</ul>
<p>After watching these videos, you should know what the different hyperparameters are doing and how to prevent trees / forests from doing something you don’t want.</p>
<div id="classification-and-regression-trees" class="section level3" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> Classification and Regression Trees</h3>
<p>Tree-based models in general use a series of if-then rules to generate predictions from one or more decision trees.
In this lecture, we will explore regression and classification trees by the example of the airquality data set. There is one important hyperparameter for regression trees: “minsplit.”</p>
<ul>
<li>It controls the depth of tree (see the help of rpart for a description).</li>
<li>It controls the complexity of the tree and can thus also be seen as a regularization parameter.</li>
</ul>
<p>We first prepare and visualize the data and afterwards fit a decision tree.</p>
<div class="sourceCode" id="cb487"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb487-1"><a href="fundamental.html#cb487-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb487-2"><a href="fundamental.html#cb487-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart.plot)</span>
<span id="cb487-3"><a href="fundamental.html#cb487-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb487-4"><a href="fundamental.html#cb487-4" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality[<span class="fu">complete.cases</span>(airquality),]</span></code></pre></div>
<p>Fit and visualize one(!) regression tree:</p>
<div class="sourceCode" id="cb488"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb488-1"><a href="fundamental.html#cb488-1" aria-hidden="true" tabindex="-1"></a>rt <span class="ot">=</span> <span class="fu">rpart</span>(Ozone<span class="sc">~</span>., <span class="at">data =</span> data, <span class="at">control =</span> <span class="fu">rpart.control</span>(<span class="at">minsplit =</span> <span class="dv">10</span>))</span>
<span id="cb488-2"><a href="fundamental.html#cb488-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(rt)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_23-1.png" width="672" /></p>
<p>Visualize the predictions:</p>
<div class="sourceCode" id="cb489"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb489-1"><a href="fundamental.html#cb489-1" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">predict</span>(rt, data)</span>
<span id="cb489-2"><a href="fundamental.html#cb489-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(data<span class="sc">$</span>Temp, data<span class="sc">$</span>Ozone)</span>
<span id="cb489-3"><a href="fundamental.html#cb489-3" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(data<span class="sc">$</span>Temp[<span class="fu">order</span>(data<span class="sc">$</span>Temp)], pred[<span class="fu">order</span>(data<span class="sc">$</span>Temp)], <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_24-1.png" width="672" /></p>
<p>The angular form of the prediction line is typical for regression trees and is a weakness of it.</p>
</div>
<div id="random-forest" class="section level3" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> Random Forest</h3>
<p>To overcome this weakness, a random forest uses an ensemble of regression/classification trees. Thus, the random forest is in principle nothing else than a normal regression/classification tree, but it uses the idea of the <em>“wisdom of the crowd”</em> : By asking many people (regression/classification trees) one can make a more informed decision (prediction/classification). When you want to buy a new phone for example you also wouldn’t go directly into the shop, but search in the internet and ask your friends and family.</p>
<p>There are two randomization steps with the random forest that are responsible for their success:</p>
<ul>
<li>Bootstrap samples for each tree (we will sample observations with replacement from the data set. For the phone this is like not everyone has experience about each phone).</li>
<li>At each split, we will sample a subset of predictors that is then considered as potential splitting criterion (for the phone this is like that not everyone has the same decision criteria).
Annotation: While building a decision tree (random forests consist of many decision trees), one splits the data at some point according to their features. For example if you have females and males, big and small people in a crowd, you con split this crowd by gender and then by size or by size and then by gender to build a decision tree.</li>
</ul>
<p>Applying the random forest follows the same principle as for the methods before: We visualize the data (we have already done this so often for the airquality data set, thus we skip it here), fit the algorithm and then plot the outcomes.</p>
<p>Fit a random forest and visualize the predictions:</p>
<div class="sourceCode" id="cb490"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb490-1"><a href="fundamental.html#cb490-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span>
<span id="cb490-2"><a href="fundamental.html#cb490-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb490-3"><a href="fundamental.html#cb490-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb490-4"><a href="fundamental.html#cb490-4" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality[<span class="fu">complete.cases</span>(airquality),]</span>
<span id="cb490-5"><a href="fundamental.html#cb490-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb490-6"><a href="fundamental.html#cb490-6" aria-hidden="true" tabindex="-1"></a>rf <span class="ot">=</span> <span class="fu">randomForest</span>(Ozone<span class="sc">~</span>., <span class="at">data =</span> data)</span>
<span id="cb490-7"><a href="fundamental.html#cb490-7" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">predict</span>(rf, data)</span>
<span id="cb490-8"><a href="fundamental.html#cb490-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(Ozone<span class="sc">~</span>Temp, <span class="at">data =</span> data)</span>
<span id="cb490-9"><a href="fundamental.html#cb490-9" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(data<span class="sc">$</span>Temp[<span class="fu">order</span>(data<span class="sc">$</span>Temp)], pred[<span class="fu">order</span>(data<span class="sc">$</span>Temp)], <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_25-1.png" width="672" /></p>
<p>One advantage of random forests is that we will get an importance of variables. At each split in each tree, the improvement in the split-criterion is the importance measure attributed to the splitting variable, and is accumulated over all the trees in the forest separately for each variable. Thus the variable importance shows us how important a variable is averaged over all trees.</p>
<div class="sourceCode" id="cb491"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb491-1"><a href="fundamental.html#cb491-1" aria-hidden="true" tabindex="-1"></a>rf<span class="sc">$</span>importance</span></code></pre></div>
<pre><code>##         IncNodePurity
## Solar.R      17969.59
## Wind         31978.36
## Temp         34176.71
## Month        10753.73
## Day          15436.47</code></pre>
<p>There are several important hyperparameters in a random forest that we can tune to get better results:</p>
<ul>
<li>Similar to the minsplit parameter in regression and classification trees, the hyperparameter “nodesize” controls for complexity <span class="math inline">\(\rightarrow\)</span> Minimum size of terminal nodes in the tree. Setting this number larger causes smaller trees to be grown (and thus take less time). Note that the default values are different for classification (1) and regression (5).</li>
<li>mtry: Number of features randomly sampled as candidates at each split.</li>
</ul>
</div>
<div id="boosted-regression-trees" class="section level3" number="4.3.3">
<h3><span class="header-section-number">4.3.3</span> Boosted Regression Trees</h3>
<p>Random forests fit hundreds of trees independent of each other. Here, the idea of a boosted regression tree comes in. Maybe we could learn from the errors the previous weak learners made and thus enhance the performance of the algorithm.</p>
<p>A boosted regression tree (BRT) starts with a simple regression tree (weak learner) and then sequentially fits additional trees to improve the results.
There are two different strategies to do so:</p>
<ul>
<li><em>AdaBoost</em>: Wrong classified observations (by the previous tree) will get a higher weight and therefore the next trees will focus on difficult/missclassified observations.</li>
<li><em>Gradient boosting</em> (state of the art): Each sequential model will be fit on the residual errors of the previous model.</li>
</ul>
<p>We can fit a boosted regression tree using xgboost, but before we have to transform the data into a xgb.Dmatrix.</p>
<div class="sourceCode" id="cb493"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb493-1"><a href="fundamental.html#cb493-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(xgboost)</span>
<span id="cb493-2"><a href="fundamental.html#cb493-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb493-3"><a href="fundamental.html#cb493-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb493-4"><a href="fundamental.html#cb493-4" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality[<span class="fu">complete.cases</span>(airquality),]</span></code></pre></div>
<div class="sourceCode" id="cb494"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb494-1"><a href="fundamental.html#cb494-1" aria-hidden="true" tabindex="-1"></a>data_xg <span class="ot">=</span> <span class="fu">xgb.DMatrix</span>(<span class="at">data =</span> <span class="fu">as.matrix</span>(<span class="fu">scale</span>(data[,<span class="sc">-</span><span class="dv">1</span>])), <span class="at">label =</span> data<span class="sc">$</span>Ozone)</span>
<span id="cb494-2"><a href="fundamental.html#cb494-2" aria-hidden="true" tabindex="-1"></a>brt <span class="ot">=</span> <span class="fu">xgboost</span>(data_xg, <span class="at">nrounds =</span> 16L)</span></code></pre></div>
<pre><code>## [1]  train-rmse:39.724628 
## [2]  train-rmse:30.225760 
## [3]  train-rmse:23.134838 
## [4]  train-rmse:17.899178 
## [5]  train-rmse:14.097786 
## [6]  train-rmse:11.375458 
## [7]  train-rmse:9.391275 
## [8]  train-rmse:7.889689 
## [9]  train-rmse:6.646585 
## [10] train-rmse:5.804860 
## [11] train-rmse:5.128437 
## [12] train-rmse:4.456416 
## [13] train-rmse:4.069464 
## [14] train-rmse:3.674615 
## [15] train-rmse:3.424578 
## [16] train-rmse:3.191302</code></pre>
<p>The parameter “nrounds” controls how many sequential trees we fit, in our example this was 16. When we predict on new data, we can limit the number of trees used to prevent overfitting (remember: each new tree tries to improve the predictions of the previous trees).</p>
<p>Let us visualize the predictions for different numbers of trees:</p>
<div class="sourceCode" id="cb496"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb496-1"><a href="fundamental.html#cb496-1" aria-hidden="true" tabindex="-1"></a>oldpar <span class="ot">=</span> <span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb496-2"><a href="fundamental.html#cb496-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>){</span>
<span id="cb496-3"><a href="fundamental.html#cb496-3" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">=</span> <span class="fu">predict</span>(brt, <span class="at">newdata =</span> data_xg, <span class="at">ntreelimit =</span> i)</span>
<span id="cb496-4"><a href="fundamental.html#cb496-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(data<span class="sc">$</span>Temp, data<span class="sc">$</span>Ozone, <span class="at">main =</span> i)</span>
<span id="cb496-5"><a href="fundamental.html#cb496-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(data<span class="sc">$</span>Temp[<span class="fu">order</span>(data<span class="sc">$</span>Temp)], pred[<span class="fu">order</span>(data<span class="sc">$</span>Temp)], <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb496-6"><a href="fundamental.html#cb496-6" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<pre><code>## [11:10:48] WARNING: amalgamation/../src/c_api/c_api.cc:718: `ntree_limit` is deprecated, use `iteration_range` instead.</code></pre>
<pre><code>## [11:10:48] WARNING: amalgamation/../src/c_api/c_api.cc:718: `ntree_limit` is deprecated, use `iteration_range` instead.</code></pre>
<pre><code>## [11:10:48] WARNING: amalgamation/../src/c_api/c_api.cc:718: `ntree_limit` is deprecated, use `iteration_range` instead.</code></pre>
<pre><code>## [11:10:48] WARNING: amalgamation/../src/c_api/c_api.cc:718: `ntree_limit` is deprecated, use `iteration_range` instead.</code></pre>
<p><img src="_main_files/figure-html/chunk_chapter4_29__BRT2-1.png" width="672" /></p>
<div class="sourceCode" id="cb501"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb501-1"><a href="fundamental.html#cb501-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(oldpar)</span></code></pre></div>
<p>There are also other ways to control for complexity of the boosted regression tree algorithm:</p>
<ul>
<li>max_depth: Maximum depth of each tree.</li>
<li>shrinkage (each tree will get a weight and the weight will decrease with the number of trees).</li>
</ul>
<p>When having specified the final model, we can obtain the importance of the variables like for random forests:</p>
<div class="sourceCode" id="cb502"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb502-1"><a href="fundamental.html#cb502-1" aria-hidden="true" tabindex="-1"></a>xgboost<span class="sc">::</span><span class="fu">xgb.importance</span>(<span class="at">model =</span> brt)</span></code></pre></div>
<pre><code>##    Feature        Gain     Cover  Frequency
## 1:    Temp 0.570071903 0.2958229 0.24836601
## 2:    Wind 0.348230710 0.3419576 0.24183007
## 3: Solar.R 0.058795542 0.1571072 0.30718954
## 4:     Day 0.019529993 0.1779925 0.16993464
## 5:   Month 0.003371853 0.0271197 0.03267974</code></pre>
<div class="sourceCode" id="cb504"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb504-1"><a href="fundamental.html#cb504-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">mean</span>((data<span class="sc">$</span>Ozone <span class="sc">-</span> pred)<span class="sc">^</span><span class="dv">2</span>)) <span class="co"># RMSE</span></span></code></pre></div>
<pre><code>## [1] 17.89918</code></pre>
<div class="sourceCode" id="cb506"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb506-1"><a href="fundamental.html#cb506-1" aria-hidden="true" tabindex="-1"></a>data_xg <span class="ot">=</span> <span class="fu">xgb.DMatrix</span>(<span class="at">data =</span> <span class="fu">as.matrix</span>(<span class="fu">scale</span>(data[,<span class="sc">-</span><span class="dv">1</span>])), <span class="at">label =</span> data<span class="sc">$</span>Ozone)</span></code></pre></div>
<p>One important strength of xgboost is that we can directly do a cross-validation (which is independent of the boosted regression tree itself!) and specify its properties with the parameter “n-fold”:</p>
<div class="sourceCode" id="cb507"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb507-1"><a href="fundamental.html#cb507-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb507-2"><a href="fundamental.html#cb507-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb507-3"><a href="fundamental.html#cb507-3" aria-hidden="true" tabindex="-1"></a>brt <span class="ot">=</span> <span class="fu">xgboost</span>(data_xg, <span class="at">nrounds =</span> 5L)</span></code></pre></div>
<pre><code>## [1]  train-rmse:39.724625 
## [2]  train-rmse:30.225765 
## [3]  train-rmse:23.134838 
## [4]  train-rmse:17.899179 
## [5]  train-rmse:14.097784</code></pre>
<div class="sourceCode" id="cb509"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb509-1"><a href="fundamental.html#cb509-1" aria-hidden="true" tabindex="-1"></a>brt_cv <span class="ot">=</span> xgboost<span class="sc">::</span><span class="fu">xgb.cv</span>(<span class="at">data =</span> data_xg, <span class="at">nfold =</span> 3L,</span>
<span id="cb509-2"><a href="fundamental.html#cb509-2" aria-hidden="true" tabindex="-1"></a>                         <span class="at">nrounds =</span> 3L, <span class="at">nthreads =</span> 4L)</span></code></pre></div>
<pre><code>## [1]  train-rmse:39.895106+2.127352   test-rmse:40.685477+5.745326 
## [2]  train-rmse:30.367660+1.728788   test-rmse:32.255812+5.572961 
## [3]  train-rmse:23.446236+1.366759   test-rmse:27.282436+5.746244</code></pre>
<div class="sourceCode" id="cb511"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb511-1"><a href="fundamental.html#cb511-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(brt_cv)</span></code></pre></div>
<pre><code>## ##### xgb.cv 3-folds
##  iter train_rmse_mean train_rmse_std test_rmse_mean test_rmse_std
##     1        39.89511       2.127352       40.68548      5.745326
##     2        30.36766       1.728788       32.25581      5.572961
##     3        23.44624       1.366759       27.28244      5.746244</code></pre>
<p>Annotation: The original data set is randomly partitioned into <span class="math inline">\(n\)</span> equal sized subsamples. Each time, the model is trained on <span class="math inline">\(n - 1\)</span> subsets (training set) and tested on the left out set (test set) to judge the performance.</p>
<p>If we do three-folded cross-validation, we actually fit three different boosted regression tree models (xgboost models) on <span class="math inline">\(\approx 67\%\)</span> of the data points. Afterwards, we judge the performance on the respective holdout. This now tells us how well the model performed.</p>
  <hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<p>We will use the following code snippet to see the influence of mincut on trees.</p>
<div class="sourceCode" id="cb513"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb513-1"><a href="fundamental.html#cb513-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tree)</span>
<span id="cb513-2"><a href="fundamental.html#cb513-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb513-3"><a href="fundamental.html#cb513-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb513-4"><a href="fundamental.html#cb513-4" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality</span>
<span id="cb513-5"><a href="fundamental.html#cb513-5" aria-hidden="true" tabindex="-1"></a>rt <span class="ot">=</span> <span class="fu">tree</span>(Ozone<span class="sc">~</span>., <span class="at">data =</span> data,</span>
<span id="cb513-6"><a href="fundamental.html#cb513-6" aria-hidden="true" tabindex="-1"></a>          <span class="at">control =</span> <span class="fu">tree.control</span>(<span class="at">mincut =</span> 1L, <span class="at">nobs =</span> <span class="fu">nrow</span>(data)))</span>
<span id="cb513-7"><a href="fundamental.html#cb513-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb513-8"><a href="fundamental.html#cb513-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(rt)</span>
<span id="cb513-9"><a href="fundamental.html#cb513-9" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(rt)</span>
<span id="cb513-10"><a href="fundamental.html#cb513-10" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">predict</span>(rt, data)</span>
<span id="cb513-11"><a href="fundamental.html#cb513-11" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(data<span class="sc">$</span>Temp, data<span class="sc">$</span>Ozone)</span>
<span id="cb513-12"><a href="fundamental.html#cb513-12" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(data<span class="sc">$</span>Temp[<span class="fu">order</span>(data<span class="sc">$</span>Temp)], pred[<span class="fu">order</span>(data<span class="sc">$</span>Temp)], <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb513-13"><a href="fundamental.html#cb513-13" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">mean</span>((data<span class="sc">$</span>Ozone <span class="sc">-</span> pred)<span class="sc">^</span><span class="dv">2</span>)) <span class="co"># RMSE</span></span></code></pre></div>
<p>Try different mincut parameters and see what happens.
(Compare the root mean squared error for different mincut parameters and explain what you see.
Compare predictions for different mincut parameters and explain what happens.)
What was wrong in the snippet above?</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<div class="sourceCode" id="cb514"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb514-1"><a href="fundamental.html#cb514-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tree)</span>
<span id="cb514-2"><a href="fundamental.html#cb514-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb514-3"><a href="fundamental.html#cb514-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb514-4"><a href="fundamental.html#cb514-4" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality[<span class="fu">complete.cases</span>(airquality),]</span>
<span id="cb514-5"><a href="fundamental.html#cb514-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb514-6"><a href="fundamental.html#cb514-6" aria-hidden="true" tabindex="-1"></a>doTask <span class="ot">=</span> <span class="cf">function</span>(mincut){</span>
<span id="cb514-7"><a href="fundamental.html#cb514-7" aria-hidden="true" tabindex="-1"></a>  rt <span class="ot">=</span> <span class="fu">tree</span>(Ozone<span class="sc">~</span>., <span class="at">data =</span> data,</span>
<span id="cb514-8"><a href="fundamental.html#cb514-8" aria-hidden="true" tabindex="-1"></a>            <span class="at">control =</span> <span class="fu">tree.control</span>(<span class="at">mincut =</span> mincut, <span class="at">nobs =</span> <span class="fu">nrow</span>(data)))</span>
<span id="cb514-9"><a href="fundamental.html#cb514-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb514-10"><a href="fundamental.html#cb514-10" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">=</span> <span class="fu">predict</span>(rt, data)</span>
<span id="cb514-11"><a href="fundamental.html#cb514-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(data<span class="sc">$</span>Temp, data<span class="sc">$</span>Ozone,</span>
<span id="cb514-12"><a href="fundamental.html#cb514-12" aria-hidden="true" tabindex="-1"></a>       <span class="at">main =</span> <span class="fu">paste0</span>(</span>
<span id="cb514-13"><a href="fundamental.html#cb514-13" aria-hidden="true" tabindex="-1"></a>         <span class="st">&quot;mincut: &quot;</span>, mincut,</span>
<span id="cb514-14"><a href="fundamental.html#cb514-14" aria-hidden="true" tabindex="-1"></a>         <span class="st">&quot;</span><span class="sc">\n</span><span class="st">RMSE: &quot;</span>, <span class="fu">round</span>(<span class="fu">sqrt</span>(<span class="fu">mean</span>((data<span class="sc">$</span>Ozone <span class="sc">-</span> pred)<span class="sc">^</span><span class="dv">2</span>)), <span class="dv">2</span>)</span>
<span id="cb514-15"><a href="fundamental.html#cb514-15" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb514-16"><a href="fundamental.html#cb514-16" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb514-17"><a href="fundamental.html#cb514-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(data<span class="sc">$</span>Temp[<span class="fu">order</span>(data<span class="sc">$</span>Temp)], pred[<span class="fu">order</span>(data<span class="sc">$</span>Temp)], <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb514-18"><a href="fundamental.html#cb514-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb514-19"><a href="fundamental.html#cb514-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb514-20"><a href="fundamental.html#cb514-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">25</span>, <span class="dv">50</span>, <span class="dv">54</span>, <span class="dv">55</span>, <span class="dv">56</span>, <span class="dv">57</span>, <span class="dv">75</span>, <span class="dv">100</span>)){ <span class="fu">doTask</span>(i) }</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_22-1.png" width="672" /><img src="_main_files/figure-html/chunk_chapter4_task_22-2.png" width="672" /><img src="_main_files/figure-html/chunk_chapter4_task_22-3.png" width="672" /><img src="_main_files/figure-html/chunk_chapter4_task_22-4.png" width="672" /><img src="_main_files/figure-html/chunk_chapter4_task_22-5.png" width="672" /><img src="_main_files/figure-html/chunk_chapter4_task_22-6.png" width="672" /><img src="_main_files/figure-html/chunk_chapter4_task_22-7.png" width="672" /><img src="_main_files/figure-html/chunk_chapter4_task_22-8.png" width="672" /><img src="_main_files/figure-html/chunk_chapter4_task_22-9.png" width="672" /><img src="_main_files/figure-html/chunk_chapter4_task_22-10.png" width="672" /><img src="_main_files/figure-html/chunk_chapter4_task_22-11.png" width="672" /><img src="_main_files/figure-html/chunk_chapter4_task_22-12.png" width="672" /><img src="_main_files/figure-html/chunk_chapter4_task_22-13.png" width="672" /><img src="_main_files/figure-html/chunk_chapter4_task_22-14.png" width="672" />
Approximately at mincut = 15, prediction is the best (mind overfitting). After mincut = 56, the prediction has no information at all and the RMSE stays constant.</p>
<p>Mind the complete cases of the airquality data set, that was the error.</p>
    </p>
  </details>
  <br/><hr/>
  <hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<p>We will use the following code snippet to explore a random forest:</p>
<div class="sourceCode" id="cb515"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb515-1"><a href="fundamental.html#cb515-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span>
<span id="cb515-2"><a href="fundamental.html#cb515-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb515-3"><a href="fundamental.html#cb515-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb515-4"><a href="fundamental.html#cb515-4" aria-hidden="true" tabindex="-1"></a>airquality[<span class="fu">complete.cases</span>(airquality),]</span></code></pre></div>
<pre><code>##     Ozone Solar.R Wind Temp Month Day
## 1      41     190  7.4   67     5   1
## 2      36     118  8.0   72     5   2
## 3      12     149 12.6   74     5   3
## 4      18     313 11.5   62     5   4
## 7      23     299  8.6   65     5   7
## 8      19      99 13.8   59     5   8
## 9       8      19 20.1   61     5   9
## 12     16     256  9.7   69     5  12
## 13     11     290  9.2   66     5  13
## 14     14     274 10.9   68     5  14
## 15     18      65 13.2   58     5  15
## 16     14     334 11.5   64     5  16
## 17     34     307 12.0   66     5  17
## 18      6      78 18.4   57     5  18
## 19     30     322 11.5   68     5  19
## 20     11      44  9.7   62     5  20
## 21      1       8  9.7   59     5  21
## 22     11     320 16.6   73     5  22
## 23      4      25  9.7   61     5  23
## 24     32      92 12.0   61     5  24
## 28     23      13 12.0   67     5  28
## 29     45     252 14.9   81     5  29
## 30    115     223  5.7   79     5  30
## 31     37     279  7.4   76     5  31
## 38     29     127  9.7   82     6   7
## 40     71     291 13.8   90     6   9
## 41     39     323 11.5   87     6  10
## 44     23     148  8.0   82     6  13
## 47     21     191 14.9   77     6  16
## 48     37     284 20.7   72     6  17
## 49     20      37  9.2   65     6  18
## 50     12     120 11.5   73     6  19
## 51     13     137 10.3   76     6  20
## 62    135     269  4.1   84     7   1
## 63     49     248  9.2   85     7   2
## 64     32     236  9.2   81     7   3
## 66     64     175  4.6   83     7   5
## 67     40     314 10.9   83     7   6
## 68     77     276  5.1   88     7   7
## 69     97     267  6.3   92     7   8
## 70     97     272  5.7   92     7   9
## 71     85     175  7.4   89     7  10
## 73     10     264 14.3   73     7  12
## 74     27     175 14.9   81     7  13
## 76      7      48 14.3   80     7  15
## 77     48     260  6.9   81     7  16
## 78     35     274 10.3   82     7  17
## 79     61     285  6.3   84     7  18
## 80     79     187  5.1   87     7  19
## 81     63     220 11.5   85     7  20
## 82     16       7  6.9   74     7  21
## 85     80     294  8.6   86     7  24
## 86    108     223  8.0   85     7  25
## 87     20      81  8.6   82     7  26
## 88     52      82 12.0   86     7  27
## 89     82     213  7.4   88     7  28
## 90     50     275  7.4   86     7  29
## 91     64     253  7.4   83     7  30
## 92     59     254  9.2   81     7  31
## 93     39      83  6.9   81     8   1
## 94      9      24 13.8   81     8   2
## 95     16      77  7.4   82     8   3
## 99    122     255  4.0   89     8   7
## 100    89     229 10.3   90     8   8
## 101   110     207  8.0   90     8   9
## 104    44     192 11.5   86     8  12
## 105    28     273 11.5   82     8  13
## 106    65     157  9.7   80     8  14
## 108    22      71 10.3   77     8  16
## 109    59      51  6.3   79     8  17
## 110    23     115  7.4   76     8  18
## 111    31     244 10.9   78     8  19
## 112    44     190 10.3   78     8  20
## 113    21     259 15.5   77     8  21
## 114     9      36 14.3   72     8  22
## 116    45     212  9.7   79     8  24
## 117   168     238  3.4   81     8  25
## 118    73     215  8.0   86     8  26
## 120    76     203  9.7   97     8  28
## 121   118     225  2.3   94     8  29
## 122    84     237  6.3   96     8  30
## 123    85     188  6.3   94     8  31
## 124    96     167  6.9   91     9   1
## 125    78     197  5.1   92     9   2
## 126    73     183  2.8   93     9   3
## 127    91     189  4.6   93     9   4
## 128    47      95  7.4   87     9   5
## 129    32      92 15.5   84     9   6
## 130    20     252 10.9   80     9   7
## 131    23     220 10.3   78     9   8
## 132    21     230 10.9   75     9   9
## 133    24     259  9.7   73     9  10
## 134    44     236 14.9   81     9  11
## 135    21     259 15.5   76     9  12
## 136    28     238  6.3   77     9  13
## 137     9      24 10.9   71     9  14
## 138    13     112 11.5   71     9  15
## 139    46     237  6.9   78     9  16
## 140    18     224 13.8   67     9  17
## 141    13      27 10.3   76     9  18
## 142    24     238 10.3   68     9  19
## 143    16     201  8.0   82     9  20
## 144    13     238 12.6   64     9  21
## 145    23      14  9.2   71     9  22
## 146    36     139 10.3   81     9  23
## 147     7      49 10.3   69     9  24
## 148    14      20 16.6   63     9  25
## 149    30     193  6.9   70     9  26
## 151    14     191 14.3   75     9  28
## 152    18     131  8.0   76     9  29
## 153    20     223 11.5   68     9  30</code></pre>
<div class="sourceCode" id="cb517"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb517-1"><a href="fundamental.html#cb517-1" aria-hidden="true" tabindex="-1"></a>rf <span class="ot">=</span> <span class="fu">randomForest</span>(Ozone<span class="sc">~</span>., <span class="at">data =</span> data)</span>
<span id="cb517-2"><a href="fundamental.html#cb517-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb517-3"><a href="fundamental.html#cb517-3" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">predict</span>(rf, data)</span>
<span id="cb517-4"><a href="fundamental.html#cb517-4" aria-hidden="true" tabindex="-1"></a><span class="fu">importance</span>(rf)</span></code></pre></div>
<pre><code>##         IncNodePurity
## Solar.R      17969.59
## Wind         31978.36
## Temp         34176.71
## Month        10753.73
## Day          15436.47</code></pre>
<div class="sourceCode" id="cb519"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb519-1"><a href="fundamental.html#cb519-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;RMSE: &quot;</span>, <span class="fu">sqrt</span>(<span class="fu">mean</span>((data<span class="sc">$</span>Ozone <span class="sc">-</span> pred)<span class="sc">^</span><span class="dv">2</span>)), <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<pre><code>## RMSE:  9.507848</code></pre>
<div class="sourceCode" id="cb521"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb521-1"><a href="fundamental.html#cb521-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(data<span class="sc">$</span>Temp, data<span class="sc">$</span>Ozone)</span>
<span id="cb521-2"><a href="fundamental.html#cb521-2" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(data<span class="sc">$</span>Temp[<span class="fu">order</span>(data<span class="sc">$</span>Temp)], pred[<span class="fu">order</span>(data<span class="sc">$</span>Temp)], <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_23-1.png" width="672" /></p>
<p>Try different values for the nodesize and mtry and describe how the predictions depend on these parameters.</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<div class="sourceCode" id="cb522"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb522-1"><a href="fundamental.html#cb522-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span>
<span id="cb522-2"><a href="fundamental.html#cb522-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb522-3"><a href="fundamental.html#cb522-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb522-4"><a href="fundamental.html#cb522-4" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality[<span class="fu">complete.cases</span>(airquality),]</span>
<span id="cb522-5"><a href="fundamental.html#cb522-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb522-6"><a href="fundamental.html#cb522-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb522-7"><a href="fundamental.html#cb522-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(nodesize <span class="cf">in</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">15</span>, <span class="dv">50</span>, <span class="dv">100</span>)){</span>
<span id="cb522-8"><a href="fundamental.html#cb522-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(mtry <span class="cf">in</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5</span>)){</span>
<span id="cb522-9"><a href="fundamental.html#cb522-9" aria-hidden="true" tabindex="-1"></a>    rf <span class="ot">=</span> <span class="fu">randomForest</span>(Ozone<span class="sc">~</span>., <span class="at">data =</span> data, <span class="at">mtry =</span> mtry, <span class="at">nodesize =</span> nodesize)</span>
<span id="cb522-10"><a href="fundamental.html#cb522-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb522-11"><a href="fundamental.html#cb522-11" aria-hidden="true" tabindex="-1"></a>    pred <span class="ot">=</span> <span class="fu">predict</span>(rf, data)</span>
<span id="cb522-12"><a href="fundamental.html#cb522-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb522-13"><a href="fundamental.html#cb522-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">plot</span>(data<span class="sc">$</span>Temp, data<span class="sc">$</span>Ozone, <span class="at">main =</span> <span class="fu">paste0</span>(</span>
<span id="cb522-14"><a href="fundamental.html#cb522-14" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;mtry: &quot;</span>, mtry, <span class="st">&quot;    nodesize: &quot;</span>, nodesize,</span>
<span id="cb522-15"><a href="fundamental.html#cb522-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;</span><span class="sc">\n</span><span class="st">RMSE: &quot;</span>, <span class="fu">round</span>(<span class="fu">sqrt</span>(<span class="fu">mean</span>((data<span class="sc">$</span>Ozone <span class="sc">-</span> pred)<span class="sc">^</span><span class="dv">2</span>)), <span class="dv">2</span>)</span>
<span id="cb522-16"><a href="fundamental.html#cb522-16" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb522-17"><a href="fundamental.html#cb522-17" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb522-18"><a href="fundamental.html#cb522-18" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>(data<span class="sc">$</span>Temp[<span class="fu">order</span>(data<span class="sc">$</span>Temp)], pred[<span class="fu">order</span>(data<span class="sc">$</span>Temp)], <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb522-19"><a href="fundamental.html#cb522-19" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb522-20"><a href="fundamental.html#cb522-20" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_24-1.png" width="672" /><img src="_main_files/figure-html/chunk_chapter4_task_24-2.png" width="672" /><img src="_main_files/figure-html/chunk_chapter4_task_24-3.png" width="672" /><img src="_main_files/figure-html/chunk_chapter4_task_24-4.png" width="672" /><img src="_main_files/figure-html/chunk_chapter4_task_24-5.png" width="672" /><img src="_main_files/figure-html/chunk_chapter4_task_24-6.png" width="672" /><img src="_main_files/figure-html/chunk_chapter4_task_24-7.png" width="672" /><img src="_main_files/figure-html/chunk_chapter4_task_24-8.png" width="672" /><img src="_main_files/figure-html/chunk_chapter4_task_24-9.png" width="672" /><img src="_main_files/figure-html/chunk_chapter4_task_24-10.png" width="672" /><img src="_main_files/figure-html/chunk_chapter4_task_24-11.png" width="672" /><img src="_main_files/figure-html/chunk_chapter4_task_24-12.png" width="672" /><img src="_main_files/figure-html/chunk_chapter4_task_24-13.png" width="672" /><img src="_main_files/figure-html/chunk_chapter4_task_24-14.png" width="672" /><img src="_main_files/figure-html/chunk_chapter4_task_24-15.png" width="672" /></p>
<p>Higher numbers for mtry smooth the prediction curve and yield less overfitting. The same holds for the nodesize.
In other words: The bigger the nodesize, the smaller the trees and the more bias/less variance.</p>
    </p>
  </details>
  <br/><hr/>
  <hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<div class="sourceCode" id="cb523"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb523-1"><a href="fundamental.html#cb523-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(xgboost)</span>
<span id="cb523-2"><a href="fundamental.html#cb523-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(animation)</span>
<span id="cb523-3"><a href="fundamental.html#cb523-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb523-4"><a href="fundamental.html#cb523-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb523-5"><a href="fundamental.html#cb523-5" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb523-6"><a href="fundamental.html#cb523-6" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb523-7"><a href="fundamental.html#cb523-7" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">expand.grid</span>(x1, x2)</span>
<span id="cb523-8"><a href="fundamental.html#cb523-8" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">apply</span>(x, <span class="dv">1</span>, <span class="cf">function</span>(t) <span class="fu">exp</span>(<span class="sc">-</span>t[<span class="dv">1</span>]<span class="sc">^</span><span class="dv">2</span> <span class="sc">-</span> t[<span class="dv">2</span>]<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb523-9"><a href="fundamental.html#cb523-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb523-10"><a href="fundamental.html#cb523-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb523-11"><a href="fundamental.html#cb523-11" aria-hidden="true" tabindex="-1"></a><span class="fu">image</span>(<span class="fu">matrix</span>(y, <span class="dv">100</span>, <span class="dv">100</span>), <span class="at">main =</span> <span class="st">&quot;Original image&quot;</span>, <span class="at">axes =</span> <span class="cn">FALSE</span>, <span class="at">las =</span> <span class="dv">2</span>)</span>
<span id="cb523-12"><a href="fundamental.html#cb523-12" aria-hidden="true" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">1</span>, <span class="at">at =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">10</span>),</span>
<span id="cb523-13"><a href="fundamental.html#cb523-13" aria-hidden="true" tabindex="-1"></a>     <span class="at">labels =</span> <span class="fu">round</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">10</span>), <span class="dv">1</span>))</span>
<span id="cb523-14"><a href="fundamental.html#cb523-14" aria-hidden="true" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">2</span>, <span class="at">at =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">10</span>),</span>
<span id="cb523-15"><a href="fundamental.html#cb523-15" aria-hidden="true" tabindex="-1"></a>     <span class="at">labels =</span> <span class="fu">round</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">10</span>), <span class="dv">1</span>), <span class="at">las =</span> <span class="dv">2</span>)</span>
<span id="cb523-16"><a href="fundamental.html#cb523-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb523-17"><a href="fundamental.html#cb523-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb523-18"><a href="fundamental.html#cb523-18" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> xgboost<span class="sc">::</span><span class="fu">xgboost</span>(<span class="fu">xgb.DMatrix</span>(<span class="at">data =</span> <span class="fu">as.matrix</span>(x), <span class="at">label =</span> y),</span>
<span id="cb523-19"><a href="fundamental.html#cb523-19" aria-hidden="true" tabindex="-1"></a>                         <span class="at">nrounds =</span> 500L, <span class="at">verbose =</span> 0L)</span>
<span id="cb523-20"><a href="fundamental.html#cb523-20" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">predict</span>(model, <span class="at">newdata =</span> <span class="fu">xgb.DMatrix</span>(<span class="at">data =</span> <span class="fu">as.matrix</span>(x)),</span>
<span id="cb523-21"><a href="fundamental.html#cb523-21" aria-hidden="true" tabindex="-1"></a>               <span class="at">ntreelimit =</span> 10L)</span>
<span id="cb523-22"><a href="fundamental.html#cb523-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb523-23"><a href="fundamental.html#cb523-23" aria-hidden="true" tabindex="-1"></a><span class="fu">saveGIF</span>(</span>
<span id="cb523-24"><a href="fundamental.html#cb523-24" aria-hidden="true" tabindex="-1"></a>  {</span>
<span id="cb523-25"><a href="fundamental.html#cb523-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(i <span class="cf">in</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">8</span>, <span class="dv">12</span>, <span class="dv">20</span>, <span class="dv">40</span>, <span class="dv">80</span>, <span class="dv">200</span>)){</span>
<span id="cb523-26"><a href="fundamental.html#cb523-26" aria-hidden="true" tabindex="-1"></a>      pred <span class="ot">=</span> <span class="fu">predict</span>(model, <span class="at">newdata =</span> <span class="fu">xgb.DMatrix</span>(<span class="at">data =</span> <span class="fu">as.matrix</span>(x)),</span>
<span id="cb523-27"><a href="fundamental.html#cb523-27" aria-hidden="true" tabindex="-1"></a>                     <span class="at">ntreelimit =</span> i)</span>
<span id="cb523-28"><a href="fundamental.html#cb523-28" aria-hidden="true" tabindex="-1"></a>      <span class="fu">image</span>(<span class="fu">matrix</span>(pred, <span class="dv">100</span>, <span class="dv">100</span>), <span class="at">main =</span> <span class="fu">paste0</span>(<span class="st">&quot;Trees: &quot;</span>, i),</span>
<span id="cb523-29"><a href="fundamental.html#cb523-29" aria-hidden="true" tabindex="-1"></a>            <span class="at">axes =</span> <span class="cn">FALSE</span>, <span class="at">las =</span> <span class="dv">2</span>)</span>
<span id="cb523-30"><a href="fundamental.html#cb523-30" aria-hidden="true" tabindex="-1"></a>      <span class="fu">axis</span>(<span class="dv">1</span>, <span class="at">at =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">10</span>),</span>
<span id="cb523-31"><a href="fundamental.html#cb523-31" aria-hidden="true" tabindex="-1"></a>           <span class="at">labels =</span> <span class="fu">round</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">10</span>), <span class="dv">1</span>))</span>
<span id="cb523-32"><a href="fundamental.html#cb523-32" aria-hidden="true" tabindex="-1"></a>      <span class="fu">axis</span>(<span class="dv">2</span>, <span class="at">at =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">10</span>),</span>
<span id="cb523-33"><a href="fundamental.html#cb523-33" aria-hidden="true" tabindex="-1"></a>           <span class="at">labels =</span> <span class="fu">round</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">10</span>), <span class="dv">1</span>), <span class="at">las =</span> <span class="dv">2</span>)</span>
<span id="cb523-34"><a href="fundamental.html#cb523-34" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb523-35"><a href="fundamental.html#cb523-35" aria-hidden="true" tabindex="-1"></a>  },</span>
<span id="cb523-36"><a href="fundamental.html#cb523-36" aria-hidden="true" tabindex="-1"></a>  <span class="at">movie.name =</span> <span class="st">&quot;boosting.gif&quot;</span>, <span class="at">autobrowse =</span> <span class="cn">FALSE</span></span>
<span id="cb523-37"><a href="fundamental.html#cb523-37" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="images/boosting.gif" /><!-- --></p>
<p>Run the above code and play with different parameters for xgboost (especially with parameters that control the complexity) and describe what you see!</p>
<p>Tip: have a look at the boosting.gif.</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<div class="sourceCode" id="cb524"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb524-1"><a href="fundamental.html#cb524-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(xgboost)</span>
<span id="cb524-2"><a href="fundamental.html#cb524-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(animation)</span>
<span id="cb524-3"><a href="fundamental.html#cb524-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb524-4"><a href="fundamental.html#cb524-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb524-5"><a href="fundamental.html#cb524-5" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb524-6"><a href="fundamental.html#cb524-6" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb524-7"><a href="fundamental.html#cb524-7" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">expand.grid</span>(x1, x2)</span>
<span id="cb524-8"><a href="fundamental.html#cb524-8" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">apply</span>(x, <span class="dv">1</span>, <span class="cf">function</span>(t) <span class="fu">exp</span>(<span class="sc">-</span>t[<span class="dv">1</span>]<span class="sc">^</span><span class="dv">2</span> <span class="sc">-</span> t[<span class="dv">2</span>]<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb524-9"><a href="fundamental.html#cb524-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb524-10"><a href="fundamental.html#cb524-10" aria-hidden="true" tabindex="-1"></a><span class="fu">image</span>(<span class="fu">matrix</span>(y, <span class="dv">100</span>, <span class="dv">100</span>), <span class="at">main =</span> <span class="st">&quot;Original image&quot;</span>, <span class="at">axes =</span> <span class="cn">FALSE</span>, <span class="at">las =</span> <span class="dv">2</span>)</span>
<span id="cb524-11"><a href="fundamental.html#cb524-11" aria-hidden="true" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">1</span>, <span class="at">at =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">10</span>),</span>
<span id="cb524-12"><a href="fundamental.html#cb524-12" aria-hidden="true" tabindex="-1"></a>     <span class="at">labels =</span> <span class="fu">round</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">10</span>), <span class="dv">1</span>))</span>
<span id="cb524-13"><a href="fundamental.html#cb524-13" aria-hidden="true" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">2</span>, <span class="at">at =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">10</span>),</span>
<span id="cb524-14"><a href="fundamental.html#cb524-14" aria-hidden="true" tabindex="-1"></a>     <span class="at">labels =</span> <span class="fu">round</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">10</span>), <span class="dv">1</span>), <span class="at">las =</span> <span class="dv">2</span>)</span>
<span id="cb524-15"><a href="fundamental.html#cb524-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb524-16"><a href="fundamental.html#cb524-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(eta <span class="cf">in</span> <span class="fu">c</span>(.<span class="dv">1</span>, .<span class="dv">3</span>, .<span class="dv">5</span>, .<span class="dv">7</span>, .<span class="dv">9</span>)){</span>
<span id="cb524-17"><a href="fundamental.html#cb524-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(max_depth <span class="cf">in</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">6</span>, <span class="dv">10</span>, <span class="dv">20</span>)){</span>
<span id="cb524-18"><a href="fundamental.html#cb524-18" aria-hidden="true" tabindex="-1"></a>    model <span class="ot">=</span> xgboost<span class="sc">::</span><span class="fu">xgboost</span>(<span class="fu">xgb.DMatrix</span>(<span class="at">data =</span> <span class="fu">as.matrix</span>(x), <span class="at">label =</span> y),</span>
<span id="cb524-19"><a href="fundamental.html#cb524-19" aria-hidden="true" tabindex="-1"></a>                             <span class="at">max_depth =</span> max_depth, <span class="at">eta =</span> eta,</span>
<span id="cb524-20"><a href="fundamental.html#cb524-20" aria-hidden="true" tabindex="-1"></a>                             <span class="at">nrounds =</span> <span class="dv">500</span>, <span class="at">verbose =</span> 0L)</span>
<span id="cb524-21"><a href="fundamental.html#cb524-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb524-22"><a href="fundamental.html#cb524-22" aria-hidden="true" tabindex="-1"></a>    <span class="fu">saveGIF</span>(</span>
<span id="cb524-23"><a href="fundamental.html#cb524-23" aria-hidden="true" tabindex="-1"></a>      {</span>
<span id="cb524-24"><a href="fundamental.html#cb524-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span>(i <span class="cf">in</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">8</span>, <span class="dv">12</span>, <span class="dv">20</span>, <span class="dv">40</span>, <span class="dv">80</span>, <span class="dv">200</span>)){</span>
<span id="cb524-25"><a href="fundamental.html#cb524-25" aria-hidden="true" tabindex="-1"></a>          pred <span class="ot">=</span> <span class="fu">predict</span>(model, <span class="at">newdata =</span> <span class="fu">xgb.DMatrix</span>(<span class="at">data =</span> <span class="fu">as.matrix</span>(x)),</span>
<span id="cb524-26"><a href="fundamental.html#cb524-26" aria-hidden="true" tabindex="-1"></a>                         <span class="at">ntreelimit =</span> i)</span>
<span id="cb524-27"><a href="fundamental.html#cb524-27" aria-hidden="true" tabindex="-1"></a>          <span class="fu">image</span>(<span class="fu">matrix</span>(pred, <span class="dv">100</span>, <span class="dv">100</span>),</span>
<span id="cb524-28"><a href="fundamental.html#cb524-28" aria-hidden="true" tabindex="-1"></a>                <span class="at">main =</span> <span class="fu">paste0</span>(<span class="st">&quot;eta: &quot;</span>, eta,</span>
<span id="cb524-29"><a href="fundamental.html#cb524-29" aria-hidden="true" tabindex="-1"></a>                              <span class="st">&quot;    max_depth: &quot;</span>, max_depth,</span>
<span id="cb524-30"><a href="fundamental.html#cb524-30" aria-hidden="true" tabindex="-1"></a>                              <span class="st">&quot;    Trees: &quot;</span>, i),</span>
<span id="cb524-31"><a href="fundamental.html#cb524-31" aria-hidden="true" tabindex="-1"></a>                <span class="at">axes =</span> <span class="cn">FALSE</span>, <span class="at">las =</span> <span class="dv">2</span>)</span>
<span id="cb524-32"><a href="fundamental.html#cb524-32" aria-hidden="true" tabindex="-1"></a>          <span class="fu">axis</span>(<span class="dv">1</span>, <span class="at">at =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">10</span>),</span>
<span id="cb524-33"><a href="fundamental.html#cb524-33" aria-hidden="true" tabindex="-1"></a>               <span class="at">labels =</span> <span class="fu">round</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">10</span>), <span class="dv">1</span>))</span>
<span id="cb524-34"><a href="fundamental.html#cb524-34" aria-hidden="true" tabindex="-1"></a>          <span class="fu">axis</span>(<span class="dv">2</span>, <span class="at">at =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">10</span>),</span>
<span id="cb524-35"><a href="fundamental.html#cb524-35" aria-hidden="true" tabindex="-1"></a>               <span class="at">labels =</span> <span class="fu">round</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">10</span>), <span class="dv">1</span>), <span class="at">las =</span> <span class="dv">2</span>)</span>
<span id="cb524-36"><a href="fundamental.html#cb524-36" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb524-37"><a href="fundamental.html#cb524-37" aria-hidden="true" tabindex="-1"></a>      },</span>
<span id="cb524-38"><a href="fundamental.html#cb524-38" aria-hidden="true" tabindex="-1"></a>      <span class="at">movie.name =</span> <span class="fu">paste0</span>(<span class="st">&quot;boosting_&quot;</span>, max_depth, <span class="st">&quot;_&quot;</span>, eta, <span class="st">&quot;.gif&quot;</span>),</span>
<span id="cb524-39"><a href="fundamental.html#cb524-39" aria-hidden="true" tabindex="-1"></a>      <span class="at">autobrowse =</span> <span class="cn">FALSE</span></span>
<span id="cb524-40"><a href="fundamental.html#cb524-40" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb524-41"><a href="fundamental.html#cb524-41" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb524-42"><a href="fundamental.html#cb524-42" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>As the possibilities scale extremely, you must vary some parameters on yourself.
You may use for example the following parameters: “eta,” “gamma,” “max_depth,” “min_child_weight,” “subsample,” “colsample_bytree,” “num_parallel_tree,” “monotone_constraints” or “interaction_constraints.” Or you look into the documentation:</p>
<div class="sourceCode" id="cb525"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb525-1"><a href="fundamental.html#cb525-1" aria-hidden="true" tabindex="-1"></a>?xgboost<span class="sc">::</span>xgboost</span></code></pre></div>
<p>Just some examples:</p>
<p><img src="images/boosting_3_0.1.gif" /><!-- --><img src="images/boosting_6_0.7.gif" /><!-- --><img src="images/boosting_20_0.9.gif" /><!-- --></p>
    </p>
  </details>
  <br/><hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<p>We implemented a simple boosted regression tree using R just for fun.
Go through the code line by line and try to understand it. Ask, if you have any questions you cannot solve.</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">...</span></strong>
    </summary>
    <p>
<div class="sourceCode" id="cb526"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb526-1"><a href="fundamental.html#cb526-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tree)</span>
<span id="cb526-2"><a href="fundamental.html#cb526-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb526-3"><a href="fundamental.html#cb526-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb526-4"><a href="fundamental.html#cb526-4" aria-hidden="true" tabindex="-1"></a>depth <span class="ot">=</span> 1L</span>
<span id="cb526-5"><a href="fundamental.html#cb526-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb526-6"><a href="fundamental.html#cb526-6" aria-hidden="true" tabindex="-1"></a><span class="do">#### Simulate Data</span></span>
<span id="cb526-7"><a href="fundamental.html#cb526-7" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">runif</span>(<span class="dv">1000</span>, <span class="sc">-</span><span class="dv">5</span>, <span class="dv">5</span>)</span>
<span id="cb526-8"><a href="fundamental.html#cb526-8" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> x <span class="sc">*</span> <span class="fu">sin</span>(x) <span class="sc">*</span> <span class="dv">2</span> <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">1000</span>, <span class="dv">0</span>, <span class="fu">cos</span>(x) <span class="sc">+</span> <span class="fl">1.8</span>)</span>
<span id="cb526-9"><a href="fundamental.html#cb526-9" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)</span>
<span id="cb526-10"><a href="fundamental.html#cb526-10" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(y<span class="sc">~</span>x)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_30-1.png" width="672" /></p>
<div class="sourceCode" id="cb527"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb527-1"><a href="fundamental.html#cb527-1" aria-hidden="true" tabindex="-1"></a><span class="do">#### Helper function for single tree fit.</span></span>
<span id="cb527-2"><a href="fundamental.html#cb527-2" aria-hidden="true" tabindex="-1"></a>get_model <span class="ot">=</span> <span class="cf">function</span>(x, y){</span>
<span id="cb527-3"><a href="fundamental.html#cb527-3" aria-hidden="true" tabindex="-1"></a>  control <span class="ot">=</span> <span class="fu">tree.control</span>(<span class="at">nobs =</span> <span class="fu">length</span>(x), <span class="at">mincut =</span> 20L)</span>
<span id="cb527-4"><a href="fundamental.html#cb527-4" aria-hidden="true" tabindex="-1"></a>  model <span class="ot">=</span> <span class="fu">tree</span>(y<span class="sc">~</span>x, <span class="fu">data.frame</span>(<span class="at">x =</span> x, <span class="at">y =</span> y), <span class="at">control =</span> control)</span>
<span id="cb527-5"><a href="fundamental.html#cb527-5" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">=</span> <span class="fu">predict</span>(model, <span class="fu">data.frame</span>(<span class="at">x =</span> x, <span class="at">y =</span> y))</span>
<span id="cb527-6"><a href="fundamental.html#cb527-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">model =</span> model, <span class="at">pred =</span> pred))</span>
<span id="cb527-7"><a href="fundamental.html#cb527-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb527-8"><a href="fundamental.html#cb527-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb527-9"><a href="fundamental.html#cb527-9" aria-hidden="true" tabindex="-1"></a><span class="do">#### Boost function.</span></span>
<span id="cb527-10"><a href="fundamental.html#cb527-10" aria-hidden="true" tabindex="-1"></a>get_boosting_model <span class="ot">=</span> <span class="cf">function</span>(depth){</span>
<span id="cb527-11"><a href="fundamental.html#cb527-11" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">=</span> <span class="cn">NULL</span></span>
<span id="cb527-12"><a href="fundamental.html#cb527-12" aria-hidden="true" tabindex="-1"></a>  m_list <span class="ot">=</span> <span class="fu">list</span>()</span>
<span id="cb527-13"><a href="fundamental.html#cb527-13" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>depth){</span>
<span id="cb527-14"><a href="fundamental.html#cb527-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(i <span class="sc">==</span> <span class="dv">1</span>){</span>
<span id="cb527-15"><a href="fundamental.html#cb527-15" aria-hidden="true" tabindex="-1"></a>      m <span class="ot">=</span> <span class="fu">get_model</span>(x, y)</span>
<span id="cb527-16"><a href="fundamental.html#cb527-16" aria-hidden="true" tabindex="-1"></a>      pred <span class="ot">=</span> m<span class="sc">$</span>pred</span>
<span id="cb527-17"><a href="fundamental.html#cb527-17" aria-hidden="true" tabindex="-1"></a>    }<span class="cf">else</span>{</span>
<span id="cb527-18"><a href="fundamental.html#cb527-18" aria-hidden="true" tabindex="-1"></a>      y_res <span class="ot">=</span> y <span class="sc">-</span> pred</span>
<span id="cb527-19"><a href="fundamental.html#cb527-19" aria-hidden="true" tabindex="-1"></a>      m <span class="ot">=</span> <span class="fu">get_model</span>(x, y_res)</span>
<span id="cb527-20"><a href="fundamental.html#cb527-20" aria-hidden="true" tabindex="-1"></a>      pred <span class="ot">=</span> pred <span class="sc">+</span> m<span class="sc">$</span>pred</span>
<span id="cb527-21"><a href="fundamental.html#cb527-21" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb527-22"><a href="fundamental.html#cb527-22" aria-hidden="true" tabindex="-1"></a>    m_list[[i]] <span class="ot">=</span> m<span class="sc">$</span>model</span>
<span id="cb527-23"><a href="fundamental.html#cb527-23" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb527-24"><a href="fundamental.html#cb527-24" aria-hidden="true" tabindex="-1"></a>  model_list <span class="ot">&lt;&lt;-</span> m_list  <span class="co"># This writes outside function scope!</span></span>
<span id="cb527-25"><a href="fundamental.html#cb527-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(pred)</span>
<span id="cb527-26"><a href="fundamental.html#cb527-26" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb527-27"><a href="fundamental.html#cb527-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb527-28"><a href="fundamental.html#cb527-28" aria-hidden="true" tabindex="-1"></a><span class="do">### Main.</span></span>
<span id="cb527-29"><a href="fundamental.html#cb527-29" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">get_boosting_model</span>(10L)[<span class="fu">order</span>(data<span class="sc">$</span>x)]</span>
<span id="cb527-30"><a href="fundamental.html#cb527-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb527-31"><a href="fundamental.html#cb527-31" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(model_list)</span></code></pre></div>
<pre><code>## [1] 10</code></pre>
<div class="sourceCode" id="cb529"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb529-1"><a href="fundamental.html#cb529-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_list[[<span class="dv">1</span>]])</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_30-2.png" width="672" /></p>
<div class="sourceCode" id="cb530"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb530-1"><a href="fundamental.html#cb530-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(y<span class="sc">~</span>x)</span>
<span id="cb530-2"><a href="fundamental.html#cb530-2" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="at">x =</span> data<span class="sc">$</span>x[<span class="fu">order</span>(data<span class="sc">$</span>x)], <span class="fu">get_boosting_model</span>(1L)[<span class="fu">order</span>(data<span class="sc">$</span>x)],</span>
<span id="cb530-3"><a href="fundamental.html#cb530-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb530-4"><a href="fundamental.html#cb530-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="at">x =</span> data<span class="sc">$</span>x[<span class="fu">order</span>(data<span class="sc">$</span>x)], <span class="fu">get_boosting_model</span>(100L)[<span class="fu">order</span>(data<span class="sc">$</span>x)],</span>
<span id="cb530-5"><a href="fundamental.html#cb530-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&#39;green&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_30-3.png" width="672" /></p>
    </p>
  </details>
  <br/><hr/>
</div>
</div>
<div id="distance-based-algorithms" class="section level2" number="4.4">
<h2><span class="header-section-number">4.4</span> Distance-based Algorithms</h2>
<p>In this chapter, we introduce support-vector machines (SVMs) and other distance-based methods
<strong>Hint</strong>: Distance-based models need scaling!</p>
<div id="k-nearest-neighbor" class="section level3" number="4.4.1">
<h3><span class="header-section-number">4.4.1</span> K-Nearest-Neighbor</h3>
<p>K-nearest-neighbor (kNN) is a simple algorithm that stores all the available cases and classifies the new data based on a similarity measure. It is mostly used to classify a data point based on how its <span class="math inline">\(k\)</span> nearest neighbors are classified.</p>
<p>Let us first see an example:</p>
<div class="sourceCode" id="cb531"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb531-1"><a href="fundamental.html#cb531-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">scale</span>(iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span>
<span id="cb531-2"><a href="fundamental.html#cb531-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> iris[,<span class="dv">5</span>]</span>
<span id="cb531-3"><a href="fundamental.html#cb531-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x[<span class="sc">-</span><span class="dv">100</span>,<span class="dv">1</span>], x[<span class="sc">-</span><span class="dv">100</span>, <span class="dv">3</span>], <span class="at">col =</span> y)</span>
<span id="cb531-4"><a href="fundamental.html#cb531-4" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x[<span class="dv">100</span>,<span class="dv">1</span>], x[<span class="dv">100</span>, <span class="dv">3</span>], <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">pch =</span> <span class="dv">18</span>, <span class="at">cex =</span> <span class="fl">1.3</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_32-1.png" width="672" /></p>
<p>Which class would you decide for the blue point? What are the classes of the nearest points? Well, this procedure is used by the k-nearest-neighbors classifier and thus there is actually no “real” learning in a k-nearest-neighbors classification.</p>
<p>For applying a k-nearest-neighbors classification, we first have to scale the data set, because we deal with distances and want the same influence of all predictors. Imagine one variable has values from -10.000 to 10.000 and another from -1 to 1. Then the influence of the first variable on the distance to the other points is much stronger than the influence of the second variable.
On the iris data set, we have to split the data into training and test set on our own. Then we will follow the usual pipeline.</p>
<div class="sourceCode" id="cb532"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb532-1"><a href="fundamental.html#cb532-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> iris</span>
<span id="cb532-2"><a href="fundamental.html#cb532-2" aria-hidden="true" tabindex="-1"></a>data[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>] <span class="ot">=</span> <span class="fu">apply</span>(data[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>],<span class="dv">2</span>, scale)</span>
<span id="cb532-3"><a href="fundamental.html#cb532-3" aria-hidden="true" tabindex="-1"></a>indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(data), <span class="fl">0.7</span><span class="sc">*</span><span class="fu">nrow</span>(data))</span>
<span id="cb532-4"><a href="fundamental.html#cb532-4" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> data[indices,]</span>
<span id="cb532-5"><a href="fundamental.html#cb532-5" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> data[<span class="sc">-</span>indices,]</span></code></pre></div>
<p>Fit model and create predictions:</p>
<div class="sourceCode" id="cb533"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb533-1"><a href="fundamental.html#cb533-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(kknn)</span>
<span id="cb533-2"><a href="fundamental.html#cb533-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb533-3"><a href="fundamental.html#cb533-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb533-4"><a href="fundamental.html#cb533-4" aria-hidden="true" tabindex="-1"></a>knn <span class="ot">=</span> <span class="fu">kknn</span>(Species<span class="sc">~</span>., <span class="at">train =</span> train, <span class="at">test =</span> test)</span>
<span id="cb533-5"><a href="fundamental.html#cb533-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(knn)</span></code></pre></div>
<pre><code>## 
## Call:
## kknn(formula = Species ~ ., train = train, test = test)
## 
## Response: &quot;nominal&quot;
##           fit prob.setosa prob.versicolor prob.virginica
## 1      setosa           1      0.00000000      0.0000000
## 2      setosa           1      0.00000000      0.0000000
## 3      setosa           1      0.00000000      0.0000000
## 4      setosa           1      0.00000000      0.0000000
## 5      setosa           1      0.00000000      0.0000000
## 6      setosa           1      0.00000000      0.0000000
## 7      setosa           1      0.00000000      0.0000000
## 8      setosa           1      0.00000000      0.0000000
## 9      setosa           1      0.00000000      0.0000000
## 10     setosa           1      0.00000000      0.0000000
## 11     setosa           1      0.00000000      0.0000000
## 12     setosa           1      0.00000000      0.0000000
## 13     setosa           1      0.00000000      0.0000000
## 14 versicolor           0      0.86605852      0.1339415
## 15 versicolor           0      0.74027417      0.2597258
## 16 versicolor           0      0.91487300      0.0851270
## 17 versicolor           0      0.98430840      0.0156916
## 18 versicolor           0      0.91487300      0.0851270
## 19 versicolor           0      1.00000000      0.0000000
## 20 versicolor           0      1.00000000      0.0000000
## 21 versicolor           0      1.00000000      0.0000000
## 22 versicolor           0      1.00000000      0.0000000
## 23 versicolor           0      1.00000000      0.0000000
## 24 versicolor           0      1.00000000      0.0000000
## 25 versicolor           0      1.00000000      0.0000000
## 26 versicolor           0      1.00000000      0.0000000
## 27 versicolor           0      0.86605852      0.1339415
## 28 versicolor           0      1.00000000      0.0000000
## 29  virginica           0      0.00000000      1.0000000
## 30  virginica           0      0.00000000      1.0000000
## 31  virginica           0      0.00000000      1.0000000
## 32  virginica           0      0.00000000      1.0000000
## 33  virginica           0      0.08512700      0.9148730
## 34  virginica           0      0.22169561      0.7783044
## 35  virginica           0      0.00000000      1.0000000
## 36  virginica           0      0.23111986      0.7688801
## 37 versicolor           0      1.00000000      0.0000000
## 38  virginica           0      0.04881448      0.9511855
## 39 versicolor           0      0.64309579      0.3569042
## 40 versicolor           0      0.67748579      0.3225142
## 41  virginica           0      0.17288113      0.8271189
## 42  virginica           0      0.00000000      1.0000000
## 43  virginica           0      0.00000000      1.0000000
## 44  virginica           0      0.00000000      1.0000000
## 45  virginica           0      0.35690421      0.6430958</code></pre>
<div class="sourceCode" id="cb535"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb535-1"><a href="fundamental.html#cb535-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(test<span class="sc">$</span>Species, <span class="fu">fitted</span>(knn))</span></code></pre></div>
<pre><code>##             
##              setosa versicolor virginica
##   setosa         13          0         0
##   versicolor      0         15         0
##   virginica       0          3        14</code></pre>
</div>
<div id="support-vector-machines-svms" class="section level3" number="4.4.2">
<h3><span class="header-section-number">4.4.2</span> Support Vector Machines (SVMs)</h3>
<p>Support vectors machines have a different approach. They try to divide the predictor space into sectors for each class. To do so, a support-vector machine fits the parameters of a hyperplane (a <span class="math inline">\(n-1\)</span> dimensional subspace in a <span class="math inline">\(n\)</span>-dimensional space) in the predictor space by optimizing the distance between the hyperplane and the nearest point from each class.</p>
<p>Fitting a support-vector machine:</p>
<div class="sourceCode" id="cb537"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb537-1"><a href="fundamental.html#cb537-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(e1071)</span>
<span id="cb537-2"><a href="fundamental.html#cb537-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb537-3"><a href="fundamental.html#cb537-3" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> iris</span>
<span id="cb537-4"><a href="fundamental.html#cb537-4" aria-hidden="true" tabindex="-1"></a>data[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>] <span class="ot">=</span> <span class="fu">apply</span>(data[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>], <span class="dv">2</span>, scale)</span>
<span id="cb537-5"><a href="fundamental.html#cb537-5" aria-hidden="true" tabindex="-1"></a>indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(data), <span class="fl">0.7</span><span class="sc">*</span><span class="fu">nrow</span>(data))</span>
<span id="cb537-6"><a href="fundamental.html#cb537-6" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> data[indices,]</span>
<span id="cb537-7"><a href="fundamental.html#cb537-7" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> data[<span class="sc">-</span>indices,]</span>
<span id="cb537-8"><a href="fundamental.html#cb537-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb537-9"><a href="fundamental.html#cb537-9" aria-hidden="true" tabindex="-1"></a>sm <span class="ot">=</span> <span class="fu">svm</span>(Species<span class="sc">~</span>., <span class="at">data =</span> train, <span class="at">kernel =</span> <span class="st">&quot;linear&quot;</span>)</span>
<span id="cb537-10"><a href="fundamental.html#cb537-10" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">predict</span>(sm, <span class="at">newdata =</span> test)</span></code></pre></div>
<div class="sourceCode" id="cb538"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb538-1"><a href="fundamental.html#cb538-1" aria-hidden="true" tabindex="-1"></a>oldpar <span class="ot">=</span> <span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb538-2"><a href="fundamental.html#cb538-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(test<span class="sc">$</span>Sepal.Length, test<span class="sc">$</span>Petal.Length,</span>
<span id="cb538-3"><a href="fundamental.html#cb538-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span>  pred, <span class="at">main =</span> <span class="st">&quot;predicted&quot;</span>)</span>
<span id="cb538-4"><a href="fundamental.html#cb538-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(test<span class="sc">$</span>Sepal.Length, test<span class="sc">$</span>Petal.Length,</span>
<span id="cb538-5"><a href="fundamental.html#cb538-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span>  test<span class="sc">$</span>Species, <span class="at">main =</span> <span class="st">&quot;observed&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_36-1.png" width="672" /></p>
<div class="sourceCode" id="cb539"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb539-1"><a href="fundamental.html#cb539-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(oldpar)</span>
<span id="cb539-2"><a href="fundamental.html#cb539-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb539-3"><a href="fundamental.html#cb539-3" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(pred <span class="sc">==</span> test<span class="sc">$</span>Species) <span class="co"># Accuracy.</span></span></code></pre></div>
<pre><code>## [1] 0.9777778</code></pre>
<p>Support-vector machines can only work on linearly separable problems. (A problem is called linearly separable if there exists at least one line in the plane with all of the points of one class on one side of the hyperplane and all the points of the others classes on the other side).</p>
<p>If this is not possible, we however, can use the so called <em>kernel trick</em>, which maps the predictor space into a (higher dimensional) space in which the problem is linear separable. After having identified the boundaries in the higher-dimensional space, we can project them back into the original dimensions.</p>
<div class="sourceCode" id="cb541"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb541-1"><a href="fundamental.html#cb541-1" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb541-2"><a href="fundamental.html#cb541-2" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb541-3"><a href="fundamental.html#cb541-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">expand.grid</span>(x1, x2)</span>
<span id="cb541-4"><a href="fundamental.html#cb541-4" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">apply</span>(X, <span class="dv">1</span>, <span class="cf">function</span>(t) <span class="fu">exp</span>(<span class="sc">-</span>t[<span class="dv">1</span>]<span class="sc">^</span><span class="dv">2</span> <span class="sc">-</span> t[<span class="dv">2</span>]<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb541-5"><a href="fundamental.html#cb541-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">ifelse</span>(<span class="dv">1</span><span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(<span class="sc">-</span>y)) <span class="sc">&lt;</span> <span class="fl">0.62</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb541-6"><a href="fundamental.html#cb541-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb541-7"><a href="fundamental.html#cb541-7" aria-hidden="true" tabindex="-1"></a><span class="fu">image</span>(<span class="fu">matrix</span>(y, <span class="dv">100</span>, <span class="dv">100</span>))</span>
<span id="cb541-8"><a href="fundamental.html#cb541-8" aria-hidden="true" tabindex="-1"></a>animation<span class="sc">::</span><span class="fu">saveGIF</span>(</span>
<span id="cb541-9"><a href="fundamental.html#cb541-9" aria-hidden="true" tabindex="-1"></a>  {</span>
<span id="cb541-10"><a href="fundamental.html#cb541-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(i <span class="cf">in</span> <span class="fu">c</span>(<span class="st">&quot;truth&quot;</span>, <span class="st">&quot;linear&quot;</span>, <span class="st">&quot;radial&quot;</span>, <span class="st">&quot;sigmoid&quot;</span>)){</span>
<span id="cb541-11"><a href="fundamental.html#cb541-11" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span>(i <span class="sc">==</span> <span class="st">&quot;truth&quot;</span>){</span>
<span id="cb541-12"><a href="fundamental.html#cb541-12" aria-hidden="true" tabindex="-1"></a>        <span class="fu">image</span>(<span class="fu">matrix</span>(y, <span class="dv">100</span>,<span class="dv">100</span>),</span>
<span id="cb541-13"><a href="fundamental.html#cb541-13" aria-hidden="true" tabindex="-1"></a>        <span class="at">main =</span> <span class="st">&quot;Ground truth&quot;</span>, <span class="at">axes =</span> <span class="cn">FALSE</span>, <span class="at">las =</span> <span class="dv">2</span>)</span>
<span id="cb541-14"><a href="fundamental.html#cb541-14" aria-hidden="true" tabindex="-1"></a>      }<span class="cf">else</span>{</span>
<span id="cb541-15"><a href="fundamental.html#cb541-15" aria-hidden="true" tabindex="-1"></a>        sv <span class="ot">=</span> e1071<span class="sc">::</span><span class="fu">svm</span>(<span class="at">x =</span> x, <span class="at">y =</span> <span class="fu">factor</span>(y), <span class="at">kernel =</span> i)</span>
<span id="cb541-16"><a href="fundamental.html#cb541-16" aria-hidden="true" tabindex="-1"></a>        <span class="fu">image</span>(<span class="fu">matrix</span>(<span class="fu">as.numeric</span>(<span class="fu">as.character</span>(<span class="fu">predict</span>(sv, x))), <span class="dv">100</span>, <span class="dv">100</span>),</span>
<span id="cb541-17"><a href="fundamental.html#cb541-17" aria-hidden="true" tabindex="-1"></a>        <span class="at">main =</span> <span class="fu">paste0</span>(<span class="st">&quot;Kernel: &quot;</span>, i), <span class="at">axes =</span> <span class="cn">FALSE</span>, <span class="at">las =</span> <span class="dv">2</span>)</span>
<span id="cb541-18"><a href="fundamental.html#cb541-18" aria-hidden="true" tabindex="-1"></a>        <span class="fu">axis</span>(<span class="dv">1</span>, <span class="at">at =</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">10</span>),</span>
<span id="cb541-19"><a href="fundamental.html#cb541-19" aria-hidden="true" tabindex="-1"></a>        <span class="at">labels =</span> <span class="fu">round</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">10</span>), <span class="dv">1</span>))</span>
<span id="cb541-20"><a href="fundamental.html#cb541-20" aria-hidden="true" tabindex="-1"></a>        <span class="fu">axis</span>(<span class="dv">2</span>, <span class="at">at =</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">10</span>),</span>
<span id="cb541-21"><a href="fundamental.html#cb541-21" aria-hidden="true" tabindex="-1"></a>        <span class="at">labels =</span> <span class="fu">round</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">10</span>), <span class="dv">1</span>), <span class="at">las =</span> <span class="dv">2</span>)</span>
<span id="cb541-22"><a href="fundamental.html#cb541-22" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb541-23"><a href="fundamental.html#cb541-23" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb541-24"><a href="fundamental.html#cb541-24" aria-hidden="true" tabindex="-1"></a>  },</span>
<span id="cb541-25"><a href="fundamental.html#cb541-25" aria-hidden="true" tabindex="-1"></a>  <span class="at">movie.name =</span> <span class="st">&quot;svm.gif&quot;</span>, <span class="at">autobrowse =</span> <span class="cn">FALSE</span></span>
<span id="cb541-26"><a href="fundamental.html#cb541-26" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="images/svm.gif" /><!-- --></p>
<p>As you have seen, this does not work with every kernel. Hence, the problem is to find the actual correct kernel, which is again an optimization procedure and can thus be approximated.</p>
  <hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<p>We will use the Sonar data set to explore support-vector machines and k-neartest-neighbor classifier.</p>
<div class="sourceCode" id="cb542"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb542-1"><a href="fundamental.html#cb542-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlbench)</span>
<span id="cb542-2"><a href="fundamental.html#cb542-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb542-3"><a href="fundamental.html#cb542-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb542-4"><a href="fundamental.html#cb542-4" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Sonar)</span>
<span id="cb542-5"><a href="fundamental.html#cb542-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> Sonar</span>
<span id="cb542-6"><a href="fundamental.html#cb542-6" aria-hidden="true" tabindex="-1"></a>indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(Sonar), <span class="fl">0.5</span> <span class="sc">*</span> <span class="fu">nrow</span>(Sonar))</span></code></pre></div>
<p>Split the Sonar data set from the mlbench library into training- and testset with 50% in each group. Is this a useful split?
The response variable is “class.” So you are trying to classify the class.</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<div class="sourceCode" id="cb543"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb543-1"><a href="fundamental.html#cb543-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlbench)</span>
<span id="cb543-2"><a href="fundamental.html#cb543-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb543-3"><a href="fundamental.html#cb543-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb543-4"><a href="fundamental.html#cb543-4" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Sonar)</span>
<span id="cb543-5"><a href="fundamental.html#cb543-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> Sonar</span>
<span id="cb543-6"><a href="fundamental.html#cb543-6" aria-hidden="true" tabindex="-1"></a><span class="co">#str(data)</span></span>
<span id="cb543-7"><a href="fundamental.html#cb543-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb543-8"><a href="fundamental.html#cb543-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Do not forget scaling! This may be done implicitly by most functions.</span></span>
<span id="cb543-9"><a href="fundamental.html#cb543-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Here, it&#39;s done explicitly for teaching purposes.</span></span>
<span id="cb543-10"><a href="fundamental.html#cb543-10" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">cbind.data.frame</span>(</span>
<span id="cb543-11"><a href="fundamental.html#cb543-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale</span>(data[,<span class="sc">-</span><span class="fu">length</span>(data)]),</span>
<span id="cb543-12"><a href="fundamental.html#cb543-12" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;class&quot;</span> <span class="ot">=</span> data[,<span class="fu">length</span>(data)]</span>
<span id="cb543-13"><a href="fundamental.html#cb543-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb543-14"><a href="fundamental.html#cb543-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb543-15"><a href="fundamental.html#cb543-15" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="fu">length</span>(data[,<span class="dv">1</span>])</span>
<span id="cb543-16"><a href="fundamental.html#cb543-16" aria-hidden="true" tabindex="-1"></a>indicesTrain <span class="ot">=</span> <span class="fu">sample.int</span>(n, (n<span class="sc">+</span><span class="dv">1</span>) <span class="sc">%/%</span> <span class="dv">2</span>) <span class="co"># Take (at least) 50 % of the data.</span></span>
<span id="cb543-17"><a href="fundamental.html#cb543-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb543-18"><a href="fundamental.html#cb543-18" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> data[indicesTrain,]</span>
<span id="cb543-19"><a href="fundamental.html#cb543-19" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> data[<span class="sc">-</span>indicesTrain,]</span>
<span id="cb543-20"><a href="fundamental.html#cb543-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb543-21"><a href="fundamental.html#cb543-21" aria-hidden="true" tabindex="-1"></a>labelsTrain <span class="ot">=</span> train[,<span class="fu">length</span>(train)]</span>
<span id="cb543-22"><a href="fundamental.html#cb543-22" aria-hidden="true" tabindex="-1"></a>labelsTest <span class="ot">=</span> test[,<span class="fu">length</span>(test)]</span></code></pre></div>
<p>Until you have strong reasons for that, 50/50 is no really good decision. You waste data/power.
Do not forget scaling!</p>
    </p>
  </details>
  <br/><hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<p>Fit a standard k-nearest-neighbor classifier and a support vector machine with a linear kernel (check help), and report what fitted better.</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<div class="sourceCode" id="cb544"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb544-1"><a href="fundamental.html#cb544-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(e1071)</span>
<span id="cb544-2"><a href="fundamental.html#cb544-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(kknn)</span>
<span id="cb544-3"><a href="fundamental.html#cb544-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb544-4"><a href="fundamental.html#cb544-4" aria-hidden="true" tabindex="-1"></a>knn <span class="ot">=</span> <span class="fu">kknn</span>(class<span class="sc">~</span>., <span class="at">train =</span> train, <span class="at">test =</span> test, <span class="at">scale =</span> <span class="cn">FALSE</span>,</span>
<span id="cb544-5"><a href="fundamental.html#cb544-5" aria-hidden="true" tabindex="-1"></a>           <span class="at">kernel =</span> <span class="st">&quot;rectangular&quot;</span>)</span>
<span id="cb544-6"><a href="fundamental.html#cb544-6" aria-hidden="true" tabindex="-1"></a>predKNN <span class="ot">=</span> <span class="fu">predict</span>(knn, <span class="at">newdata =</span> test)</span>
<span id="cb544-7"><a href="fundamental.html#cb544-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb544-8"><a href="fundamental.html#cb544-8" aria-hidden="true" tabindex="-1"></a>sm <span class="ot">=</span> <span class="fu">svm</span>(class<span class="sc">~</span>., <span class="at">data =</span> train, <span class="at">scale =</span> <span class="cn">FALSE</span>, <span class="at">kernel =</span> <span class="st">&quot;linear&quot;</span>)</span>
<span id="cb544-9"><a href="fundamental.html#cb544-9" aria-hidden="true" tabindex="-1"></a>predSVM <span class="ot">=</span> <span class="fu">predict</span>(sm, <span class="at">newdata =</span> test)</span></code></pre></div>
<pre><code>## K-nearest-neighbor, standard (rectangular) kernel:</code></pre>
<pre><code>##        labelsTest
## predKNN  M  R
##       M 46 29
##       R  8 21</code></pre>
<pre><code>## Correctly classified:  67  /  104</code></pre>
<pre><code>## Support-vector machine, linear kernel:</code></pre>
<pre><code>##        labelsTest
## predSVM  M  R
##       M 41 15
##       R 13 35</code></pre>
<pre><code>## Correctly classified:  76  /  104</code></pre>
<p>K-nearest neighbor fitted (slightly) better.</p>
    </p>
  </details>
  <br/><hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<p>Calculate accuracies of both algorithms.</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<div class="sourceCode" id="cb551"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb551-1"><a href="fundamental.html#cb551-1" aria-hidden="true" tabindex="-1"></a>(<span class="at">accKNN =</span> <span class="fu">mean</span>(predKNN <span class="sc">==</span> labelsTest))</span></code></pre></div>
<pre><code>## [1] 0.6442308</code></pre>
<div class="sourceCode" id="cb553"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb553-1"><a href="fundamental.html#cb553-1" aria-hidden="true" tabindex="-1"></a>(<span class="at">accSVM =</span> <span class="fu">mean</span>(predSVM <span class="sc">==</span> labelsTest))</span></code></pre></div>
<pre><code>## [1] 0.7307692</code></pre>
    </p>
  </details>
  <br/><hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<p>Fit again with different kernels and compare accuracies.</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<div class="sourceCode" id="cb555"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb555-1"><a href="fundamental.html#cb555-1" aria-hidden="true" tabindex="-1"></a>knn <span class="ot">=</span> <span class="fu">kknn</span>(class<span class="sc">~</span>., <span class="at">train =</span> train, <span class="at">test =</span> test, <span class="at">scale =</span> <span class="cn">FALSE</span>,</span>
<span id="cb555-2"><a href="fundamental.html#cb555-2" aria-hidden="true" tabindex="-1"></a>           <span class="at">kernel =</span> <span class="st">&quot;optimal&quot;</span>)</span>
<span id="cb555-3"><a href="fundamental.html#cb555-3" aria-hidden="true" tabindex="-1"></a>predKNN <span class="ot">=</span> <span class="fu">predict</span>(knn, <span class="at">newdata =</span> test)</span>
<span id="cb555-4"><a href="fundamental.html#cb555-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb555-5"><a href="fundamental.html#cb555-5" aria-hidden="true" tabindex="-1"></a>sm <span class="ot">=</span> <span class="fu">svm</span>(class<span class="sc">~</span>., <span class="at">data =</span> train, <span class="at">scale =</span> <span class="cn">FALSE</span>, <span class="at">kernel =</span> <span class="st">&quot;radial&quot;</span>)</span>
<span id="cb555-6"><a href="fundamental.html#cb555-6" aria-hidden="true" tabindex="-1"></a>predSVM <span class="ot">=</span> <span class="fu">predict</span>(sm, <span class="at">newdata =</span> test)</span>
<span id="cb555-7"><a href="fundamental.html#cb555-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb555-8"><a href="fundamental.html#cb555-8" aria-hidden="true" tabindex="-1"></a>(<span class="at">accKNN =</span> <span class="fu">mean</span>(predKNN <span class="sc">==</span> labelsTest))</span></code></pre></div>
<pre><code>## [1] 0.75</code></pre>
<div class="sourceCode" id="cb557"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb557-1"><a href="fundamental.html#cb557-1" aria-hidden="true" tabindex="-1"></a>(<span class="at">accSVM =</span> <span class="fu">mean</span>(predSVM <span class="sc">==</span> labelsTest))</span></code></pre></div>
<pre><code>## [1] 0.8076923</code></pre>
    </p>
  </details>
  <br/><hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<p>Try the fit again with a different seed for training and test set generation.</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<div class="sourceCode" id="cb559"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb559-1"><a href="fundamental.html#cb559-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb559-2"><a href="fundamental.html#cb559-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb559-3"><a href="fundamental.html#cb559-3" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> Sonar</span>
<span id="cb559-4"><a href="fundamental.html#cb559-4" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">cbind.data.frame</span>(</span>
<span id="cb559-5"><a href="fundamental.html#cb559-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale</span>(data[,<span class="sc">-</span><span class="fu">length</span>(data)]),</span>
<span id="cb559-6"><a href="fundamental.html#cb559-6" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;class&quot;</span> <span class="ot">=</span> data[,<span class="fu">length</span>(data)]</span>
<span id="cb559-7"><a href="fundamental.html#cb559-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb559-8"><a href="fundamental.html#cb559-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb559-9"><a href="fundamental.html#cb559-9" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="fu">length</span>(data[,<span class="dv">1</span>])</span>
<span id="cb559-10"><a href="fundamental.html#cb559-10" aria-hidden="true" tabindex="-1"></a>indicesTrain <span class="ot">=</span> <span class="fu">sample.int</span>(n, (n<span class="sc">+</span><span class="dv">1</span>) <span class="sc">%/%</span> <span class="dv">2</span>)</span>
<span id="cb559-11"><a href="fundamental.html#cb559-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb559-12"><a href="fundamental.html#cb559-12" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> data[indicesTrain,]</span>
<span id="cb559-13"><a href="fundamental.html#cb559-13" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> data[<span class="sc">-</span>indicesTrain,]</span>
<span id="cb559-14"><a href="fundamental.html#cb559-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb559-15"><a href="fundamental.html#cb559-15" aria-hidden="true" tabindex="-1"></a>labelsTrain <span class="ot">=</span> train[,<span class="fu">length</span>(train)]</span>
<span id="cb559-16"><a href="fundamental.html#cb559-16" aria-hidden="true" tabindex="-1"></a>labelsTest <span class="ot">=</span> test[,<span class="fu">length</span>(test)]</span>
<span id="cb559-17"><a href="fundamental.html#cb559-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb559-18"><a href="fundamental.html#cb559-18" aria-hidden="true" tabindex="-1"></a><span class="do">#####</span></span>
<span id="cb559-19"><a href="fundamental.html#cb559-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb559-20"><a href="fundamental.html#cb559-20" aria-hidden="true" tabindex="-1"></a>knn <span class="ot">=</span> <span class="fu">kknn</span>(class<span class="sc">~</span>., <span class="at">train =</span> train, <span class="at">test =</span> test, <span class="at">scale =</span> <span class="cn">FALSE</span>,</span>
<span id="cb559-21"><a href="fundamental.html#cb559-21" aria-hidden="true" tabindex="-1"></a>           <span class="at">kernel =</span> <span class="st">&quot;rectangular&quot;</span>)</span>
<span id="cb559-22"><a href="fundamental.html#cb559-22" aria-hidden="true" tabindex="-1"></a>predKNN <span class="ot">=</span> <span class="fu">predict</span>(knn, <span class="at">newdata =</span> test)</span>
<span id="cb559-23"><a href="fundamental.html#cb559-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb559-24"><a href="fundamental.html#cb559-24" aria-hidden="true" tabindex="-1"></a>sm <span class="ot">=</span> <span class="fu">svm</span>(class<span class="sc">~</span>., <span class="at">data =</span> train, <span class="at">scale =</span> <span class="cn">FALSE</span>, <span class="at">kernel =</span> <span class="st">&quot;linear&quot;</span>)</span>
<span id="cb559-25"><a href="fundamental.html#cb559-25" aria-hidden="true" tabindex="-1"></a>predSVM <span class="ot">=</span> <span class="fu">predict</span>(sm, <span class="at">newdata =</span> test)</span>
<span id="cb559-26"><a href="fundamental.html#cb559-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb559-27"><a href="fundamental.html#cb559-27" aria-hidden="true" tabindex="-1"></a>(<span class="at">accKNN =</span> <span class="fu">mean</span>(predKNN <span class="sc">==</span> labelsTest))</span></code></pre></div>
<pre><code>## [1] 0.7115385</code></pre>
<div class="sourceCode" id="cb561"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb561-1"><a href="fundamental.html#cb561-1" aria-hidden="true" tabindex="-1"></a>(<span class="at">accSVM =</span> <span class="fu">mean</span>(predSVM <span class="sc">==</span> labelsTest))</span></code></pre></div>
<pre><code>## [1] 0.75</code></pre>
<div class="sourceCode" id="cb563"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb563-1"><a href="fundamental.html#cb563-1" aria-hidden="true" tabindex="-1"></a><span class="do">#####</span></span>
<span id="cb563-2"><a href="fundamental.html#cb563-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb563-3"><a href="fundamental.html#cb563-3" aria-hidden="true" tabindex="-1"></a>knn <span class="ot">=</span> <span class="fu">kknn</span>(class<span class="sc">~</span>., <span class="at">train =</span> train, <span class="at">test =</span> test, <span class="at">scale =</span> <span class="cn">FALSE</span>,</span>
<span id="cb563-4"><a href="fundamental.html#cb563-4" aria-hidden="true" tabindex="-1"></a>           <span class="at">kernel =</span> <span class="st">&quot;optimal&quot;</span>)</span>
<span id="cb563-5"><a href="fundamental.html#cb563-5" aria-hidden="true" tabindex="-1"></a>predKNN <span class="ot">=</span> <span class="fu">predict</span>(knn, <span class="at">newdata =</span> test)</span>
<span id="cb563-6"><a href="fundamental.html#cb563-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb563-7"><a href="fundamental.html#cb563-7" aria-hidden="true" tabindex="-1"></a>sm <span class="ot">=</span> <span class="fu">svm</span>(class<span class="sc">~</span>., <span class="at">data =</span> train, <span class="at">scale =</span> <span class="cn">FALSE</span>, <span class="at">kernel =</span> <span class="st">&quot;radial&quot;</span>)</span>
<span id="cb563-8"><a href="fundamental.html#cb563-8" aria-hidden="true" tabindex="-1"></a>predSVM <span class="ot">=</span> <span class="fu">predict</span>(sm, <span class="at">newdata =</span> test)</span>
<span id="cb563-9"><a href="fundamental.html#cb563-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb563-10"><a href="fundamental.html#cb563-10" aria-hidden="true" tabindex="-1"></a>(<span class="at">accKNN =</span> <span class="fu">mean</span>(predKNN <span class="sc">==</span> labelsTest))</span></code></pre></div>
<pre><code>## [1] 0.8557692</code></pre>
<div class="sourceCode" id="cb565"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb565-1"><a href="fundamental.html#cb565-1" aria-hidden="true" tabindex="-1"></a>(<span class="at">accSVM =</span> <span class="fu">mean</span>(predSVM <span class="sc">==</span> labelsTest))</span></code></pre></div>
<pre><code>## [1] 0.8365385</code></pre>
    </p>
  </details>
  <br/><hr/>
</div>
</div>
<div id="the-standard-machine-learning-pipeline-at-the-eexample-of-the-titanic-data-set" class="section level2" number="4.5">
<h2><span class="header-section-number">4.5</span> The Standard Machine Learning Pipeline at the Eexample of the Titanic Data set</h2>
<p>Before we specialize on any tuning, it is important to understand that machine learning always consists of a pipeline of actions.</p>
<p>The typical machine learning workflow consist of:</p>
<ul>
<li>Data cleaning and exploration (EDA = explorative data analysis) for example with tidyverse.</li>
<li>Preprocessing and feature selection.</li>
<li>Splitting data set into training and test set for evaluation.</li>
<li>Model fitting.</li>
<li>Model evaluation.</li>
<li>New predictions.</li>
</ul>
<p>Here is an (optional) video that explains the entire pipeline from a slightly different perspective:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/nKW8Ndu7Mjw" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<p>In the following example, we use tidyverse, a collection of R packages for data science / data manipulation mainly developed by Hadley Wickham. A video that explains the basics can be found here :</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/nRtp7wSEtJA" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<p>Another good reference is “<strong>R for data science</strong>” by Hadley Wickham: <a href="https://r4ds.had.co.nz/" target="_blank" rel="noopener"></a>.</p>
<p>For this lecture you need the Titanic data set provided by us. You can find it in GRIPS (datasets.RData in the data set and submission section) or at <a href="http://rhsbio6.uni-regensburg.de:8500" target="_blank" rel="noopener">http://rhsbio6.uni-regensburg.de:8500</a>.</p>
<p>We have split the data set already into training and test/prediction data sets (the test/prediction split has one column less than the train split, as the result is not known a priori).</p>
<div id="data-cleaning" class="section level3" number="4.5.1">
<h3><span class="header-section-number">4.5.1</span> Data Cleaning</h3>
<p>Load necessary libraries:</p>
<div class="sourceCode" id="cb567"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb567-1"><a href="fundamental.html#cb567-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb567-2"><a href="fundamental.html#cb567-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb567-3"><a href="fundamental.html#cb567-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb567-4"><a href="fundamental.html#cb567-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span></code></pre></div>
<p>Load data set:</p>
<div class="sourceCode" id="cb568"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb568-1"><a href="fundamental.html#cb568-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(EcoData)</span>
<span id="cb568-2"><a href="fundamental.html#cb568-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(titanic_ml)</span>
<span id="cb568-3"><a href="fundamental.html#cb568-3" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> titanic_ml</span></code></pre></div>
<p>Standard summaries:</p>
<div class="sourceCode" id="cb569"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb569-1"><a href="fundamental.html#cb569-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(data)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    1309 obs. of  14 variables:
##  $ pclass   : int  2 1 3 3 3 3 3 1 3 1 ...
##  $ survived : int  1 1 0 0 0 0 0 1 0 1 ...
##  $ name     : chr  &quot;Sinkkonen, Miss. Anna&quot; &quot;Woolner, Mr. Hugh&quot; &quot;Sage, Mr. Douglas Bullen&quot; &quot;Palsson, Master. Paul Folke&quot; ...
##  $ sex      : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 1 2 2 2 2 2 2 1 1 1 ...
##  $ age      : num  30 NA NA 6 30.5 38.5 20 53 NA 42 ...
##  $ sibsp    : int  0 0 8 3 0 0 0 0 0 0 ...
##  $ parch    : int  0 0 2 1 0 0 0 0 0 0 ...
##  $ ticket   : Factor w/ 929 levels &quot;110152&quot;,&quot;110413&quot;,..: 221 123 779 542 589 873 472 823 588 834 ...
##  $ fare     : num  13 35.5 69.55 21.07 8.05 ...
##  $ cabin    : Factor w/ 187 levels &quot;&quot;,&quot;A10&quot;,&quot;A11&quot;,..: 1 94 1 1 1 1 1 1 1 1 ...
##  $ embarked : Factor w/ 4 levels &quot;&quot;,&quot;C&quot;,&quot;Q&quot;,&quot;S&quot;: 4 4 4 4 4 4 4 2 4 2 ...
##  $ boat     : Factor w/ 28 levels &quot;&quot;,&quot;1&quot;,&quot;10&quot;,&quot;11&quot;,..: 3 28 1 1 1 1 1 19 1 15 ...
##  $ body     : int  NA NA NA NA 50 32 NA NA NA NA ...
##  $ home.dest: Factor w/ 370 levels &quot;&quot;,&quot;?Havana, Cuba&quot;,..: 121 213 1 1 1 1 322 350 1 1 ...</code></pre>
<div class="sourceCode" id="cb571"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb571-1"><a href="fundamental.html#cb571-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(data)</span></code></pre></div>
<pre><code>##      pclass         survived          name               sex           age              sibsp            parch      
##  Min.   :1.000   Min.   :0.0000   Length:1309        female:466   Min.   : 0.1667   Min.   :0.0000   Min.   :0.000  
##  1st Qu.:2.000   1st Qu.:0.0000   Class :character   male  :843   1st Qu.:21.0000   1st Qu.:0.0000   1st Qu.:0.000  
##  Median :3.000   Median :0.0000   Mode  :character                Median :28.0000   Median :0.0000   Median :0.000  
##  Mean   :2.295   Mean   :0.3853                                   Mean   :29.8811   Mean   :0.4989   Mean   :0.385  
##  3rd Qu.:3.000   3rd Qu.:1.0000                                   3rd Qu.:39.0000   3rd Qu.:1.0000   3rd Qu.:0.000  
##  Max.   :3.000   Max.   :1.0000                                   Max.   :80.0000   Max.   :8.0000   Max.   :9.000  
##                  NA&#39;s   :655                                      NA&#39;s   :263                                       
##       ticket          fare                     cabin      embarked      boat          body                      home.dest  
##  CA. 2343:  11   Min.   :  0.000                  :1014    :  2           :823   Min.   :  1.0                       :564  
##  1601    :   8   1st Qu.:  7.896   C23 C25 C27    :   6   C:270    13     : 39   1st Qu.: 72.0   New York, NY        : 64  
##  CA 2144 :   8   Median : 14.454   B57 B59 B63 B66:   5   Q:123    C      : 38   Median :155.0   London              : 14  
##  3101295 :   7   Mean   : 33.295   G6             :   5   S:914    15     : 37   Mean   :160.8   Montreal, PQ        : 10  
##  347077  :   7   3rd Qu.: 31.275   B96 B98        :   4            14     : 33   3rd Qu.:256.0   Cornwall / Akron, OH:  9  
##  347082  :   7   Max.   :512.329   C22 C26        :   4            4      : 31   Max.   :328.0   Paris, France       :  9  
##  (Other) :1261   NA&#39;s   :1         (Other)        : 271            (Other):308   NA&#39;s   :1188    (Other)             :639</code></pre>
<div class="sourceCode" id="cb573"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb573-1"><a href="fundamental.html#cb573-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(data)</span></code></pre></div>
<pre><code>##      pclass survived                         name    sex  age sibsp parch             ticket   fare cabin embarked boat body
## 561       2        1        Sinkkonen, Miss. Anna female 30.0     0     0             250648 13.000              S   10   NA
## 321       1        1            Woolner, Mr. Hugh   male   NA     0     0              19947 35.500   C52        S    D   NA
## 1177      3        0     Sage, Mr. Douglas Bullen   male   NA     8     2           CA. 2343 69.550              S        NA
## 1098      3        0  Palsson, Master. Paul Folke   male  6.0     3     1             349909 21.075              S        NA
## 1252      3        0   Tomlin, Mr. Ernest Portage   male 30.5     0     0             364499  8.050              S        50
## 1170      3        0 Saether, Mr. Simon Sivertsen   male 38.5     0     0 SOTON/O.Q. 3101262  7.250              S        32
##                     home.dest
## 561  Finland / Washington, DC
## 321           London, England
## 1177                         
## 1098                         
## 1252                         
## 1170</code></pre>
<p>The name variable consists of 1309 unique factors (there are 1309 observations…):</p>
<div class="sourceCode" id="cb575"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb575-1"><a href="fundamental.html#cb575-1" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(<span class="fu">unique</span>(data<span class="sc">$</span>name))</span></code></pre></div>
<pre><code>## [1] 1307</code></pre>
<p>However, there is a title in each name. Let’s extract the titles:</p>
<ol style="list-style-type: decimal">
<li>We will extract all names and split each name after each comma “,”</li>
<li>We will split the second split of the name after a point “.” and extract the titles.</li>
</ol>
<div class="sourceCode" id="cb577"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb577-1"><a href="fundamental.html#cb577-1" aria-hidden="true" tabindex="-1"></a>first_split <span class="ot">=</span> <span class="fu">sapply</span>(data<span class="sc">$</span>name,</span>
<span id="cb577-2"><a href="fundamental.html#cb577-2" aria-hidden="true" tabindex="-1"></a>                     <span class="cf">function</span>(x) stringr<span class="sc">::</span><span class="fu">str_split</span>(x, <span class="at">pattern =</span> <span class="st">&quot;,&quot;</span>)[[<span class="dv">1</span>]][<span class="dv">2</span>])</span>
<span id="cb577-3"><a href="fundamental.html#cb577-3" aria-hidden="true" tabindex="-1"></a>titles <span class="ot">=</span> <span class="fu">sapply</span>(first_split,</span>
<span id="cb577-4"><a href="fundamental.html#cb577-4" aria-hidden="true" tabindex="-1"></a>                <span class="cf">function</span>(x) <span class="fu">strsplit</span>(x, <span class="st">&quot;.&quot;</span>,<span class="at">fixed =</span> <span class="cn">TRUE</span>)[[<span class="dv">1</span>]][<span class="dv">1</span>])</span></code></pre></div>
<p>We get 18 unique titles:</p>
<div class="sourceCode" id="cb578"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb578-1"><a href="fundamental.html#cb578-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(titles)</span></code></pre></div>
<pre><code>## titles
##          Capt           Col           Don          Dona            Dr      Jonkheer          Lady         Major        Master 
##             1             4             1             1             8             1             1             2            61 
##          Miss          Mlle           Mme            Mr           Mrs            Ms           Rev           Sir  the Countess 
##           260             2             1           757           197             2             8             1             1</code></pre>
<p>A few titles have a very low occurrence rate:</p>
<div class="sourceCode" id="cb580"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb580-1"><a href="fundamental.html#cb580-1" aria-hidden="true" tabindex="-1"></a>titles <span class="ot">=</span> stringr<span class="sc">::</span><span class="fu">str_trim</span>((titles))</span>
<span id="cb580-2"><a href="fundamental.html#cb580-2" aria-hidden="true" tabindex="-1"></a>titles <span class="sc">%&gt;%</span></span>
<span id="cb580-3"><a href="fundamental.html#cb580-3" aria-hidden="true" tabindex="-1"></a> <span class="fu">fct_count</span>()</span></code></pre></div>
<pre><code>## # A tibble: 18 × 2
##    f                n
##    &lt;fct&gt;        &lt;int&gt;
##  1 Capt             1
##  2 Col              4
##  3 Don              1
##  4 Dona             1
##  5 Dr               8
##  6 Jonkheer         1
##  7 Lady             1
##  8 Major            2
##  9 Master          61
## 10 Miss           260
## 11 Mlle             2
## 12 Mme              1
## 13 Mr             757
## 14 Mrs            197
## 15 Ms               2
## 16 Rev              8
## 17 Sir              1
## 18 the Countess     1</code></pre>
<p>We will combine titles with low occurrences into one title, which we can easily do with the forcats package.</p>
<div class="sourceCode" id="cb582"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb582-1"><a href="fundamental.html#cb582-1" aria-hidden="true" tabindex="-1"></a>titles2 <span class="ot">=</span></span>
<span id="cb582-2"><a href="fundamental.html#cb582-2" aria-hidden="true" tabindex="-1"></a>  forcats<span class="sc">::</span><span class="fu">fct_collapse</span>(titles,</span>
<span id="cb582-3"><a href="fundamental.html#cb582-3" aria-hidden="true" tabindex="-1"></a>                        <span class="at">officer =</span> <span class="fu">c</span>(<span class="st">&quot;Capt&quot;</span>, <span class="st">&quot;Col&quot;</span>, <span class="st">&quot;Major&quot;</span>, <span class="st">&quot;Dr&quot;</span>, <span class="st">&quot;Rev&quot;</span>),</span>
<span id="cb582-4"><a href="fundamental.html#cb582-4" aria-hidden="true" tabindex="-1"></a>                        <span class="at">royal =</span> <span class="fu">c</span>(<span class="st">&quot;Jonkheer&quot;</span>, <span class="st">&quot;Don&quot;</span>, <span class="st">&quot;Sir&quot;</span>,</span>
<span id="cb582-5"><a href="fundamental.html#cb582-5" aria-hidden="true" tabindex="-1"></a>                                  <span class="st">&quot;the Countess&quot;</span>, <span class="st">&quot;Dona&quot;</span>, <span class="st">&quot;Lady&quot;</span>),</span>
<span id="cb582-6"><a href="fundamental.html#cb582-6" aria-hidden="true" tabindex="-1"></a>                        <span class="at">miss =</span> <span class="fu">c</span>(<span class="st">&quot;Miss&quot;</span>, <span class="st">&quot;Mlle&quot;</span>),</span>
<span id="cb582-7"><a href="fundamental.html#cb582-7" aria-hidden="true" tabindex="-1"></a>                        <span class="at">mrs =</span> <span class="fu">c</span>(<span class="st">&quot;Mrs&quot;</span>, <span class="st">&quot;Mme&quot;</span>, <span class="st">&quot;Ms&quot;</span>)</span>
<span id="cb582-8"><a href="fundamental.html#cb582-8" aria-hidden="true" tabindex="-1"></a>                        )</span></code></pre></div>
<p>We can count titles again to see the new number of titles:</p>
<div class="sourceCode" id="cb583"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb583-1"><a href="fundamental.html#cb583-1" aria-hidden="true" tabindex="-1"></a>titles2 <span class="sc">%&gt;%</span>  </span>
<span id="cb583-2"><a href="fundamental.html#cb583-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">fct_count</span>()</span></code></pre></div>
<pre><code>## # A tibble: 6 × 2
##   f           n
##   &lt;fct&gt;   &lt;int&gt;
## 1 officer    23
## 2 royal       6
## 3 Master     61
## 4 miss      262
## 5 mrs       200
## 6 Mr        757</code></pre>
<p>Add new title variable to data set:</p>
<div class="sourceCode" id="cb585"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb585-1"><a href="fundamental.html#cb585-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span></span>
<span id="cb585-2"><a href="fundamental.html#cb585-2" aria-hidden="true" tabindex="-1"></a>  data <span class="sc">%&gt;%</span></span>
<span id="cb585-3"><a href="fundamental.html#cb585-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">title =</span> titles2)</span></code></pre></div>
<p>As a second example, we will explore and clean the numeric “age” variable.</p>
<p>Explore the variable:</p>
<div class="sourceCode" id="cb586"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb586-1"><a href="fundamental.html#cb586-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(data)</span></code></pre></div>
<pre><code>##      pclass         survived          name               sex           age              sibsp            parch      
##  Min.   :1.000   Min.   :0.0000   Length:1309        female:466   Min.   : 0.1667   Min.   :0.0000   Min.   :0.000  
##  1st Qu.:2.000   1st Qu.:0.0000   Class :character   male  :843   1st Qu.:21.0000   1st Qu.:0.0000   1st Qu.:0.000  
##  Median :3.000   Median :0.0000   Mode  :character                Median :28.0000   Median :0.0000   Median :0.000  
##  Mean   :2.295   Mean   :0.3853                                   Mean   :29.8811   Mean   :0.4989   Mean   :0.385  
##  3rd Qu.:3.000   3rd Qu.:1.0000                                   3rd Qu.:39.0000   3rd Qu.:1.0000   3rd Qu.:0.000  
##  Max.   :3.000   Max.   :1.0000                                   Max.   :80.0000   Max.   :8.0000   Max.   :9.000  
##                  NA&#39;s   :655                                      NA&#39;s   :263                                       
##       ticket          fare                     cabin      embarked      boat          body                      home.dest  
##  CA. 2343:  11   Min.   :  0.000                  :1014    :  2           :823   Min.   :  1.0                       :564  
##  1601    :   8   1st Qu.:  7.896   C23 C25 C27    :   6   C:270    13     : 39   1st Qu.: 72.0   New York, NY        : 64  
##  CA 2144 :   8   Median : 14.454   B57 B59 B63 B66:   5   Q:123    C      : 38   Median :155.0   London              : 14  
##  3101295 :   7   Mean   : 33.295   G6             :   5   S:914    15     : 37   Mean   :160.8   Montreal, PQ        : 10  
##  347077  :   7   3rd Qu.: 31.275   B96 B98        :   4            14     : 33   3rd Qu.:256.0   Cornwall / Akron, OH:  9  
##  347082  :   7   Max.   :512.329   C22 C26        :   4            4      : 31   Max.   :328.0   Paris, France       :  9  
##  (Other) :1261   NA&#39;s   :1         (Other)        : 271            (Other):308   NA&#39;s   :1188    (Other)             :639  
##      title    
##  officer: 23  
##  royal  :  6  
##  Master : 61  
##  miss   :262  
##  mrs    :200  
##  Mr     :757  
## </code></pre>
<div class="sourceCode" id="cb588"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb588-1"><a href="fundamental.html#cb588-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">is.na</span>(data<span class="sc">$</span>age)) <span class="sc">/</span> <span class="fu">nrow</span>(data)</span></code></pre></div>
<pre><code>## [1] 0.2009167</code></pre>
<p>20% NAs!
Either we remove all observations with NAs, or we impute (fill) the missing values, e.g. with the median age. However, age itself might depend on other variables such as sex, class and title. We want to fill the NAs with the median age of these groups.
In tidyverse we can easily “group” the data, i.e. we will nest the observations (here: group_by after sex, pclass and title).
After grouping, all operations (such as our median(age….)) will be done within the specified groups.</p>
<div class="sourceCode" id="cb590"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb590-1"><a href="fundamental.html#cb590-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span></span>
<span id="cb590-2"><a href="fundamental.html#cb590-2" aria-hidden="true" tabindex="-1"></a>  data <span class="sc">%&gt;%</span></span>
<span id="cb590-3"><a href="fundamental.html#cb590-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(sex, pclass, title) <span class="sc">%&gt;%</span></span>
<span id="cb590-4"><a href="fundamental.html#cb590-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">age2 =</span> <span class="fu">ifelse</span>(<span class="fu">is.na</span>(age), <span class="fu">median</span>(age, <span class="at">na.rm =</span> <span class="cn">TRUE</span>), age)) <span class="sc">%&gt;%</span></span>
<span id="cb590-5"><a href="fundamental.html#cb590-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">fare2 =</span> <span class="fu">ifelse</span>(<span class="fu">is.na</span>(fare), <span class="fu">median</span>(fare, <span class="at">na.rm =</span> <span class="cn">TRUE</span>), fare)) <span class="sc">%&gt;%</span></span>
<span id="cb590-6"><a href="fundamental.html#cb590-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ungroup</span>()</span></code></pre></div>
</div>
<div id="preprocessing-and-feature-selection" class="section level3" number="4.5.2">
<h3><span class="header-section-number">4.5.2</span> Preprocessing and Feature Selection</h3>
<p>We want to use Keras in our example, but it cannot handle factors and requires the data to be scaled.</p>
<p>Normally, one would do this for all predictors, but as we only show the pipeline here, we have sub-selected a bunch of predictors and do this only for them.
We first scale the numeric predictors and change the factors with only two groups/levels into integers (this can be handled by Keras).</p>
<div class="sourceCode" id="cb591"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb591-1"><a href="fundamental.html#cb591-1" aria-hidden="true" tabindex="-1"></a>data_sub <span class="ot">=</span></span>
<span id="cb591-2"><a href="fundamental.html#cb591-2" aria-hidden="true" tabindex="-1"></a>  data <span class="sc">%&gt;%</span></span>
<span id="cb591-3"><a href="fundamental.html#cb591-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">select</span>(survived, sex, age2, fare2, title, pclass) <span class="sc">%&gt;%</span></span>
<span id="cb591-4"><a href="fundamental.html#cb591-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">age2 =</span> scales<span class="sc">::</span><span class="fu">rescale</span>(age2, <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)),</span>
<span id="cb591-5"><a href="fundamental.html#cb591-5" aria-hidden="true" tabindex="-1"></a>           <span class="at">fare2 =</span> scales<span class="sc">::</span><span class="fu">rescale</span>(fare2, <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>))) <span class="sc">%&gt;%</span></span>
<span id="cb591-6"><a href="fundamental.html#cb591-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">sex =</span> <span class="fu">as.integer</span>(sex) <span class="sc">-</span> 1L,</span>
<span id="cb591-7"><a href="fundamental.html#cb591-7" aria-hidden="true" tabindex="-1"></a>           <span class="at">title =</span> <span class="fu">as.integer</span>(title) <span class="sc">-</span> 1L, <span class="at">pclass =</span> <span class="fu">as.integer</span>(pclass <span class="sc">-</span> 1L))</span></code></pre></div>
<p>Factors with more than two levels should be <strong>one hot encoded</strong> (Make columns for every different factor level and write 1 in the respective column for every taken feature value and 0 else. For example: <span class="math inline">\(\{red, green, green, blue, red\} \rightarrow \{(0,0,1), (0,1,0), (0,1,0), (1,0,0), (0,0,1)\}\)</span>):</p>
<div class="sourceCode" id="cb592"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb592-1"><a href="fundamental.html#cb592-1" aria-hidden="true" tabindex="-1"></a>one_title <span class="ot">=</span> <span class="fu">k_one_hot</span>(data_sub<span class="sc">$</span>title, <span class="fu">length</span>(<span class="fu">unique</span>(data<span class="sc">$</span>title)))<span class="sc">$</span><span class="fu">numpy</span>()</span>
<span id="cb592-2"><a href="fundamental.html#cb592-2" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(one_title) <span class="ot">=</span> <span class="fu">levels</span>(data<span class="sc">$</span>title)</span>
<span id="cb592-3"><a href="fundamental.html#cb592-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb592-4"><a href="fundamental.html#cb592-4" aria-hidden="true" tabindex="-1"></a>one_sex <span class="ot">=</span> <span class="fu">k_one_hot</span>(data_sub<span class="sc">$</span>sex, <span class="fu">length</span>(<span class="fu">unique</span>(data<span class="sc">$</span>sex)))<span class="sc">$</span><span class="fu">numpy</span>()</span>
<span id="cb592-5"><a href="fundamental.html#cb592-5" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(one_sex) <span class="ot">=</span> <span class="fu">levels</span>(data<span class="sc">$</span>sex)</span>
<span id="cb592-6"><a href="fundamental.html#cb592-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb592-7"><a href="fundamental.html#cb592-7" aria-hidden="true" tabindex="-1"></a>one_pclass <span class="ot">=</span> <span class="fu">k_one_hot</span>(data_sub<span class="sc">$</span>pclass,  <span class="fu">length</span>(<span class="fu">unique</span>(data<span class="sc">$</span>pclass)))<span class="sc">$</span><span class="fu">numpy</span>()</span>
<span id="cb592-8"><a href="fundamental.html#cb592-8" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(one_pclass) <span class="ot">=</span> <span class="fu">paste0</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(<span class="fu">unique</span>(data<span class="sc">$</span>pclass)), <span class="st">&quot;pclass&quot;</span>)</span></code></pre></div>
<p>And we have to add the dummy encoded variables to the data set:</p>
<div class="sourceCode" id="cb593"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb593-1"><a href="fundamental.html#cb593-1" aria-hidden="true" tabindex="-1"></a>data_sub <span class="ot">=</span> <span class="fu">cbind</span>(<span class="fu">data.frame</span>(<span class="at">survived=</span> data_sub<span class="sc">$</span>survived),</span>
<span id="cb593-2"><a href="fundamental.html#cb593-2" aria-hidden="true" tabindex="-1"></a>                 one_title, one_sex, <span class="at">age =</span> data_sub<span class="sc">$</span>age2,</span>
<span id="cb593-3"><a href="fundamental.html#cb593-3" aria-hidden="true" tabindex="-1"></a>                 <span class="at">fare =</span> data_sub<span class="sc">$</span>fare2, one_pclass)</span>
<span id="cb593-4"><a href="fundamental.html#cb593-4" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(data_sub)</span></code></pre></div>
<pre><code>##   survived officer royal Master miss mrs Mr female male        age       fare 1pclass 2pclass 3pclass
## 1        1       0     0      0    1   0  0      1    0 0.37369494 0.02537431       0       1       0
## 2        1       0     0      0    0   0  1      0    1 0.51774510 0.06929139       1       0       0
## 3        0       0     0      0    0   0  1      0    1 0.32359053 0.13575256       0       0       1
## 4        0       0     0      1    0   0  0      0    1 0.07306851 0.04113566       0       0       1
## 5        0       0     0      0    0   0  1      0    1 0.37995799 0.01571255       0       0       1
## 6        0       0     0      0    0   0  1      0    1 0.48016680 0.01415106       0       0       1</code></pre>
</div>
<div id="split-data-for-training-and-testing" class="section level3" number="4.5.3">
<h3><span class="header-section-number">4.5.3</span> Split Data for Training and Testing</h3>
<p>The splitting consists of two splits:</p>
<ul>
<li>An outer split (the original split, remember we got a training and test split without the response “survived”).</li>
<li>An inner split (we will split the training data set further into another training and test split with known response).
The inner split is important to assess the model’s performance and potential overfitting.</li>
</ul>
<p>Outer split:</p>
<div class="sourceCode" id="cb595"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb595-1"><a href="fundamental.html#cb595-1" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> data_sub[<span class="sc">!</span><span class="fu">is.na</span>(data_sub<span class="sc">$</span>survived),]</span>
<span id="cb595-2"><a href="fundamental.html#cb595-2" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> data_sub[<span class="fu">is.na</span>(data_sub<span class="sc">$</span>survived),]</span></code></pre></div>
<p>Inner split:</p>
<div class="sourceCode" id="cb596"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb596-1"><a href="fundamental.html#cb596-1" aria-hidden="true" tabindex="-1"></a>indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(train), <span class="fl">0.7</span> <span class="sc">*</span> <span class="fu">nrow</span>(train))</span>
<span id="cb596-2"><a href="fundamental.html#cb596-2" aria-hidden="true" tabindex="-1"></a>sub_train <span class="ot">=</span> train[indices,]</span>
<span id="cb596-3"><a href="fundamental.html#cb596-3" aria-hidden="true" tabindex="-1"></a>sub_test <span class="ot">=</span> train[<span class="sc">-</span>indices,]</span></code></pre></div>
<p>What is the difference between the two splits? (Tip: have a look at the variable survived.)</p>
</div>
<div id="model-fitting" class="section level3" number="4.5.4">
<h3><span class="header-section-number">4.5.4</span> Model Fitting</h3>
<p>In the next step we will fit a Keras model on the training data of the inner split:</p>
<div class="sourceCode" id="cb597"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb597-1"><a href="fundamental.html#cb597-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb597-2"><a href="fundamental.html#cb597-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb597-3"><a href="fundamental.html#cb597-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb597-4"><a href="fundamental.html#cb597-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb597-5"><a href="fundamental.html#cb597-5" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb597-6"><a href="fundamental.html#cb597-6" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb597-7"><a href="fundamental.html#cb597-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">input_shape =</span> <span class="fu">ncol</span>(sub_train) <span class="sc">-</span> 1L,</span>
<span id="cb597-8"><a href="fundamental.html#cb597-8" aria-hidden="true" tabindex="-1"></a>              <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb597-9"><a href="fundamental.html#cb597-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb597-10"><a href="fundamental.html#cb597-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb597-11"><a href="fundamental.html#cb597-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Output layer consists of the 1-hot encoded variable &quot;survived&quot; -&gt; 2 units.</span></span>
<span id="cb597-12"><a href="fundamental.html#cb597-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 2L, <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>)</span>
<span id="cb597-13"><a href="fundamental.html#cb597-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb597-14"><a href="fundamental.html#cb597-14" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## Model: &quot;sequential_25&quot;
## ______________________________________________________________________________________________________________________________
##  Layer (type)                                           Output Shape                                       Param #            
## ==============================================================================================================================
##  dense_79 (Dense)                                       (None, 20)                                         280                
##                                                                                                                               
##  dense_78 (Dense)                                       (None, 20)                                         420                
##                                                                                                                               
##  dense_77 (Dense)                                       (None, 20)                                         420                
##                                                                                                                               
##  dense_76 (Dense)                                       (None, 2)                                          42                 
##                                                                                                                               
## ==============================================================================================================================
## Total params: 1,162
## Trainable params: 1,162
## Non-trainable params: 0
## ______________________________________________________________________________________________________________________________</code></pre>
<div class="sourceCode" id="cb599"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb599-1"><a href="fundamental.html#cb599-1" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb599-2"><a href="fundamental.html#cb599-2" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb599-3"><a href="fundamental.html#cb599-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb599-4"><a href="fundamental.html#cb599-4" aria-hidden="true" tabindex="-1"></a>          <span class="at">optimizer =</span> keras<span class="sc">::</span><span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.01</span>))</span>
<span id="cb599-5"><a href="fundamental.html#cb599-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb599-6"><a href="fundamental.html#cb599-6" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb599-7"><a href="fundamental.html#cb599-7" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb599-8"><a href="fundamental.html#cb599-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(<span class="at">x =</span> <span class="fu">as.matrix</span>(sub_train[,<span class="sc">-</span><span class="dv">1</span>]),</span>
<span id="cb599-9"><a href="fundamental.html#cb599-9" aria-hidden="true" tabindex="-1"></a>        <span class="at">y =</span> <span class="fu">to_categorical</span>(sub_train[,<span class="dv">1</span>], <span class="at">num_classes =</span> 2L),</span>
<span id="cb599-10"><a href="fundamental.html#cb599-10" aria-hidden="true" tabindex="-1"></a>        <span class="at">epochs =</span> 100L, <span class="at">batch_size =</span> 32L,</span>
<span id="cb599-11"><a href="fundamental.html#cb599-11" aria-hidden="true" tabindex="-1"></a>        <span class="at">validation_split =</span> <span class="fl">0.2</span>,   <span class="co">#Again a test set used by the algorithm.</span></span>
<span id="cb599-12"><a href="fundamental.html#cb599-12" aria-hidden="true" tabindex="-1"></a>        <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb599-13"><a href="fundamental.html#cb599-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb599-14"><a href="fundamental.html#cb599-14" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="_main_files/figure-html/chunk_chapter4_58-1.png" width="672" /></p>
<details>
<summary>
<strong><span style="color: #CC2FAA;">Torch</span></strong>
</summary>
<p>
<div class="sourceCode" id="cb601"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb601-1"><a href="fundamental.html#cb601-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb601-2"><a href="fundamental.html#cb601-2" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_manual_seed</span>(321L)</span>
<span id="cb601-3"><a href="fundamental.html#cb601-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb601-4"><a href="fundamental.html#cb601-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb601-5"><a href="fundamental.html#cb601-5" aria-hidden="true" tabindex="-1"></a>model_torch <span class="ot">=</span> <span class="fu">nn_sequential</span>(</span>
<span id="cb601-6"><a href="fundamental.html#cb601-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_linear</span>(<span class="at">in_features =</span> <span class="fu">dim</span>(sub_train[,<span class="sc">-</span><span class="dv">1</span>])[<span class="dv">2</span>], <span class="at">out_features =</span> 20L),</span>
<span id="cb601-7"><a href="fundamental.html#cb601-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_relu</span>(),</span>
<span id="cb601-8"><a href="fundamental.html#cb601-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_linear</span>(20L, 20L),</span>
<span id="cb601-9"><a href="fundamental.html#cb601-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_relu</span>(),</span>
<span id="cb601-10"><a href="fundamental.html#cb601-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_linear</span>(20L, 2L)</span>
<span id="cb601-11"><a href="fundamental.html#cb601-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb601-12"><a href="fundamental.html#cb601-12" aria-hidden="true" tabindex="-1"></a>opt <span class="ot">=</span> <span class="fu">optim_adam</span>(<span class="at">params =</span> model_torch<span class="sc">$</span>parameters, <span class="at">lr =</span> <span class="fl">0.01</span>)</span>
<span id="cb601-13"><a href="fundamental.html#cb601-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb601-14"><a href="fundamental.html#cb601-14" aria-hidden="true" tabindex="-1"></a>X_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fu">as.matrix</span>(sub_train[,<span class="sc">-</span><span class="dv">1</span>])) </span>
<span id="cb601-15"><a href="fundamental.html#cb601-15" aria-hidden="true" tabindex="-1"></a>Y_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(sub_train[,<span class="dv">1</span>]<span class="sc">+</span><span class="dv">1</span>, <span class="at">dtype =</span> <span class="fu">torch_long</span>())</span>
<span id="cb601-16"><a href="fundamental.html#cb601-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">500</span>){</span>
<span id="cb601-17"><a href="fundamental.html#cb601-17" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(sub_train), 20L)</span>
<span id="cb601-18"><a href="fundamental.html#cb601-18" aria-hidden="true" tabindex="-1"></a>  opt<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb601-19"><a href="fundamental.html#cb601-19" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">=</span> <span class="fu">model_torch</span>(X_torch[indices, ])</span>
<span id="cb601-20"><a href="fundamental.html#cb601-20" aria-hidden="true" tabindex="-1"></a>  loss <span class="ot">=</span> <span class="fu">nnf_cross_entropy</span>(pred, Y_torch[indices], <span class="at">reduction =</span> <span class="st">&quot;mean&quot;</span>)</span>
<span id="cb601-21"><a href="fundamental.html#cb601-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(loss)</span>
<span id="cb601-22"><a href="fundamental.html#cb601-22" aria-hidden="true" tabindex="-1"></a>  loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb601-23"><a href="fundamental.html#cb601-23" aria-hidden="true" tabindex="-1"></a>  opt<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb601-24"><a href="fundamental.html#cb601-24" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<pre><code>## torch_tensor
## 0.707869
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.686436
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.659611
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.654673
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.627494
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.68805
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.690998
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.652452
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.542723
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.553087
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.664908
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.708627
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.537437
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.43455
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.667144
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.496684
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.570908
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.597058
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.468032
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.649413
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.555161
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.657658
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.587866
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.5941
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.447766
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.604198
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.554323
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.643397
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.536915
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.674608
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.420315
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.32588
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.464963
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.596521
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.530618
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.234835
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.291255
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.929026
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.625346
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.278064
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.726598
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.62555
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.481452
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.673818
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.576145
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.475387
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.457026
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.50311
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.414785
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.385994
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.395334
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.676871
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.393855
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.710248
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.516789
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.530883
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.728959
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.470274
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.51207
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.453122
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.905312
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.4599
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.570826
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.445953
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.468076
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.565009
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.469997
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.600031
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.426152
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.700782
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.352638
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.400375
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.459513
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.568515
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.497609
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.600834
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.798421
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.327998
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.387632
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.63566
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.304985
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.526177
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.592815
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.346981
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.529488
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.623992
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.437405
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.471444
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.481523
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.595864
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.409776
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.408433
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.469692
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.652108
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.457667
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.535109
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.487944
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.588671
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.519266
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.4564
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.420434
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.564046
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.546535
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.655195
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.539748
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.451041
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.488228
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.443963
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.379549
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.592209
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.39709
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.403911
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.286926
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.746202
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.557143
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.343428
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.694007
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.418217
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.512508
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.605517
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.505859
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.57816
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.56861
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.371636
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.584577
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.542919
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.458773
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.673591
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.616572
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.54045
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.482451
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.413941
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.474845
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.419692
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.493641
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.499719
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.47251
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.759404
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.478613
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.446379
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.484713
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.532843
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.320036
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.546959
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.631938
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.367878
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.696314
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.858233
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.694158
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.68525
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.474375
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.547824
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.436111
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.538776
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.505266
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.47963
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.478373
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.517894
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.431919
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.558722
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.459529
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.465366
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.578217
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.603758
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.506026
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.383555
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.419734
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.515685
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.377787
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.251414
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.487529
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.595669
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.421177
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.35105
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.423871
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.474373
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.268141
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.518056
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.31674
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.46961
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.431192
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.329849
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.329375
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.609598
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.52314
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.402313
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.42145
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.634766
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.635958
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.46861
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.277993
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.482526
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.783625
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.481016
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.453809
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.532373
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.614476
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.429902
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.466269
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.52095
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.515713
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.594814
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.620781
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.496087
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.62666
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.574774
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.709346
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.696121
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.466134
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.390352
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.379508
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.518273
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.496471
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.409525
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.467409
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.58821
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.354203
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.54532
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.347564
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.399711
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.689771
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.68454
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.476687
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.44997
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.455688
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.403596
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.388859
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.532802
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.675519
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.496137
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.605388
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.465515
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.41161
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.349016
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.844552
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.45283
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.356554
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.324578
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.501251
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.740512
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.45971
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.4173
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.46211
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.505691
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.461158
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.457387
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.619157
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.540819
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.617918
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.46706
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.355819
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.883221
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.518348
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.44704
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.559336
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.297896
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.412469
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.502253
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.632805
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.374276
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.529211
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.361833
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.480561
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.390684
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.59659
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.2792
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.546276
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.366373
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.431727
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.511097
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.393672
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.510827
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.379485
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.236956
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.453161
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.576676
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.38702
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.511233
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.421102
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.671416
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.449251
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.421628
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.467304
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.471103
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.326304
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.330048
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.355706
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.37242
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.380477
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.445888
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.451437
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.44118
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.545506
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.454936
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.559109
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.554526
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.413272
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.433541
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.35778
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.640296
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.671153
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.271047
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.458804
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.298442
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.422499
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.379167
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.37151
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.29079
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.343601
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.309687
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.640103
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.374724
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.44974
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.349522
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.569582
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.55222
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.75569
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.382098
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.441822
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.608224
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.408617
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.399517
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.3563
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.582844
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.421269
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.458882
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.543267
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.497163
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.482459
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.561153
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.403645
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.417156
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.317258
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.543135
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.518725
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.43794
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.283879
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.341411
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.560607
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.700514
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.652319
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.370861
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.500019
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.701887
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.598595
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.446417
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.415801
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.555131
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.505287
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.663954
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.609121
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.438152
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.531093
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.558249
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.470651
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.476193
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.487094
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.398958
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.370758
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.474866
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.397224
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.429614
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.334949
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.71336
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.414789
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.332019
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.477892
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.317209
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.327091
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.419255
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.273266
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.573711
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.45249
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.346723
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.495111
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.381574
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.244849
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.424235
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.269414
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.607508
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.567444
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.606521
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.357238
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.60519
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.448005
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.650992
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.35432
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.724178
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.449799
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.421666
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.579403
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.945731
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.507651
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.624709
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.477855
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.297618
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.317562
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.578056
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.469425
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.694902
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.502019
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.633915
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.969901
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.416737
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.592856
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.394041
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.392264
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.353905
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.595177
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.359545
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.57412
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.364393
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.584685
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.583028
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.481971
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.383393
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.376592
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.586399
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.413973
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.342848
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.514671
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.406365
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.374424
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.290655
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.425498
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.420754
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.648903
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.859324
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.69948
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.432994
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.366822
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.50001
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.454298
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.475173
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.383777
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.445095
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.415456
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.461693
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.453002
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.519292
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.351406
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.608089
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.560487
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.416949
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.488941
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.562287
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.451058
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.501812
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.530042
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.382543
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.627286
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.569558
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.433292
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.392974
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.483538
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.493791
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.509549
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.519145
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.251333
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.35272
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.542718
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.506634
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.455043
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.526545
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.286775
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.445055
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.462968
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.420297
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.426609
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.22259
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.435372
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.484453
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.410166
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.297978
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.613961
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.479021
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.620836
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.625761
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.464297
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.276816
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.57245
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.380823
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.571787
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.349566
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.430171
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.569651
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.529671
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.428989
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.494857
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.603523
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.595237
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.60492
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.517747
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.492854
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.60878
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.534464
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.49266
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.463699
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.453637
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]
## torch_tensor
## 0.497914
## [ CPUFloatType{} ][ grad_fn = &lt;NllLossBackward&gt; ]</code></pre>
<p>Note: the “nnf_cross_entropy” expects predictions on the scale of the linear predictors (the loss function itself will apply the softmax!).</p>
</p>
</details>
<p><br/></p>
</div>
<div id="model-evaluation" class="section level3" number="4.5.5">
<h3><span class="header-section-number">4.5.5</span> Model Evaluation</h3>
<p>We will predict the variable “survived” for the test set of the inner split and calculate the accuracy:</p>
<div class="sourceCode" id="cb603"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb603-1"><a href="fundamental.html#cb603-1" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span></span>
<span id="cb603-2"><a href="fundamental.html#cb603-2" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb603-3"><a href="fundamental.html#cb603-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">predict</span>(<span class="at">x =</span> <span class="fu">as.matrix</span>(sub_test[,<span class="sc">-</span><span class="dv">1</span>]))</span>
<span id="cb603-4"><a href="fundamental.html#cb603-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb603-5"><a href="fundamental.html#cb603-5" aria-hidden="true" tabindex="-1"></a>predicted <span class="ot">=</span> <span class="fu">ifelse</span>(pred[,<span class="dv">2</span>] <span class="sc">&lt;</span> <span class="fl">0.5</span>, <span class="dv">0</span>, <span class="dv">1</span>) <span class="co"># Ternary operator.</span></span>
<span id="cb603-6"><a href="fundamental.html#cb603-6" aria-hidden="true" tabindex="-1"></a>observed <span class="ot">=</span> sub_test[,<span class="dv">1</span>]</span>
<span id="cb603-7"><a href="fundamental.html#cb603-7" aria-hidden="true" tabindex="-1"></a>(<span class="at">accuracy =</span> <span class="fu">mean</span>(predicted <span class="sc">==</span> observed))  <span class="co"># (...): Show output.</span></span></code></pre></div>
<pre><code>## [1] 0.8121827</code></pre>
<details>
<summary>
<strong><span style="color: #CC2FAA;">Torch</span></strong>
</summary>
<p>
<div class="sourceCode" id="cb605"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb605-1"><a href="fundamental.html#cb605-1" aria-hidden="true" tabindex="-1"></a>model_torch<span class="sc">$</span><span class="fu">eval</span>()</span>
<span id="cb605-2"><a href="fundamental.html#cb605-2" aria-hidden="true" tabindex="-1"></a>preds_torch <span class="ot">=</span> <span class="fu">nnf_softmax</span>(<span class="fu">model_torch</span>(<span class="fu">torch_tensor</span>(<span class="fu">as.matrix</span>(sub_test[,<span class="sc">-</span><span class="dv">1</span>]))),</span>
<span id="cb605-3"><a href="fundamental.html#cb605-3" aria-hidden="true" tabindex="-1"></a>                          <span class="at">dim =</span> 2L)</span>
<span id="cb605-4"><a href="fundamental.html#cb605-4" aria-hidden="true" tabindex="-1"></a>preds_torch <span class="ot">=</span> <span class="fu">as.matrix</span>(preds_torch)</span>
<span id="cb605-5"><a href="fundamental.html#cb605-5" aria-hidden="true" tabindex="-1"></a>preds_torch <span class="ot">=</span> <span class="fu">apply</span>(preds_torch, <span class="dv">1</span>, which.max)</span>
<span id="cb605-6"><a href="fundamental.html#cb605-6" aria-hidden="true" tabindex="-1"></a>(<span class="at">accuracy =</span> <span class="fu">mean</span>(preds_torch <span class="sc">-</span> <span class="dv">1</span> <span class="sc">==</span> observed))</span></code></pre></div>
<pre><code>## [1] 0.7817259</code></pre>
<pre><code>Now we have to use the softmax function.</code></pre>
</p>
</details>
<p><br/></p>
</div>
<div id="predictions-and-submission" class="section level3" number="4.5.6">
<h3><span class="header-section-number">4.5.6</span> Predictions and Submission</h3>
<p>When we are satisfied with the performance of our model in the inner split, we will create predictions for the test data of the outer split.
To do so, we take all observations that belong to the outer test split (use the filter function) and remove the survived (NAs) columns:</p>
<div class="sourceCode" id="cb608"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb608-1"><a href="fundamental.html#cb608-1" aria-hidden="true" tabindex="-1"></a>submit <span class="ot">=</span> </span>
<span id="cb608-2"><a href="fundamental.html#cb608-2" aria-hidden="true" tabindex="-1"></a>  test <span class="sc">%&gt;%</span> </span>
<span id="cb608-3"><a href="fundamental.html#cb608-3" aria-hidden="true" tabindex="-1"></a>      <span class="fu">select</span>(<span class="sc">-</span>survived)</span></code></pre></div>
<p>We cannot assess the performance on the test split because the true survival ratio is unknown, however, we can now submit our predictions to the submission server at <a href="http://rhsbio7.uni-regensburg.de:8500" target="_blank" rel="noopener">http://rhsbio7.uni-regensburg.de:8500</a>.
To do so, we have to transform our survived probabilities into actual 0/1 predictions (probabilities are not allowed) and create a .csv file:</p>
<div class="sourceCode" id="cb609"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb609-1"><a href="fundamental.html#cb609-1" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> model <span class="sc">%&gt;%</span> </span>
<span id="cb609-2"><a href="fundamental.html#cb609-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">predict</span>(<span class="fu">as.matrix</span>(submit))</span></code></pre></div>
<p>All values &gt; 0.5 will be set to 1 and values &lt; 0.5 to zero.
For the submission it is critical to change the predictions into a data.frame, select the second column (the probability to survive), and save it with the write.csv function:</p>
<div class="sourceCode" id="cb610"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb610-1"><a href="fundamental.html#cb610-1" aria-hidden="true" tabindex="-1"></a><span class="fu">write.csv</span>(<span class="fu">data.frame</span>(<span class="at">y =</span> <span class="fu">ifelse</span>(pred[,<span class="dv">2</span>] <span class="sc">&lt;</span> <span class="fl">0.5</span>, <span class="dv">0</span>, <span class="dv">1</span>)), <span class="at">file =</span> <span class="st">&quot;Max_1.csv&quot;</span>)</span></code></pre></div>
<p>The file name is used as the ID on the submission server, so change it to whatever you want as long as you can identify yourself.</p>
<p><strong>Annotation: The AUC is (always) higher for probabilities than for 0/1 data (depending on the implementation and definition of the AUC). We expect you to upload 0/1 data (usage scenarios, no theoretical ones)! Hint for cheaters (or if you just forget conversion): Your upload is converted to 0/1 data according to ifelse(… &lt; 0.5, 0, 1).</strong></p>
  <hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<p>The tasks below follow the above section about machine learning pipelines. We will use the titanic_ml data set from the EcoData package to see a pipeline. The goal is to predict if a passenger survives or not.</p>
<p>First, we should look at the data and do some feature engineering / selection. Give it a try! (Ideas can be found <a href="https://www.kaggle.com/c/titanic/notebooks?sortBy=hotness&group=everyone&pageSize=20&competitionId=3136&language=R" target="_blank" rel="noopener">here</a>.)</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<div class="sourceCode" id="cb611"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb611-1"><a href="fundamental.html#cb611-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb611-2"><a href="fundamental.html#cb611-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb611-3"><a href="fundamental.html#cb611-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb611-4"><a href="fundamental.html#cb611-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span>
<span id="cb611-5"><a href="fundamental.html#cb611-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb611-6"><a href="fundamental.html#cb611-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(EcoData)</span>
<span id="cb611-7"><a href="fundamental.html#cb611-7" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(54321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)    <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb611-8"><a href="fundamental.html#cb611-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb611-9"><a href="fundamental.html#cb611-9" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(titanic_ml)</span>
<span id="cb611-10"><a href="fundamental.html#cb611-10" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> titanic_ml</span></code></pre></div>
<div class="sourceCode" id="cb612"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb612-1"><a href="fundamental.html#cb612-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(data)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    1309 obs. of  14 variables:
##  $ pclass   : int  2 1 3 3 3 3 3 1 3 1 ...
##  $ survived : int  1 1 0 0 0 0 0 1 0 1 ...
##  $ name     : chr  &quot;Sinkkonen, Miss. Anna&quot; &quot;Woolner, Mr. Hugh&quot; &quot;Sage, Mr. Douglas Bullen&quot; &quot;Palsson, Master. Paul Folke&quot; ...
##  $ sex      : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 1 2 2 2 2 2 2 1 1 1 ...
##  $ age      : num  30 NA NA 6 30.5 38.5 20 53 NA 42 ...
##  $ sibsp    : int  0 0 8 3 0 0 0 0 0 0 ...
##  $ parch    : int  0 0 2 1 0 0 0 0 0 0 ...
##  $ ticket   : Factor w/ 929 levels &quot;110152&quot;,&quot;110413&quot;,..: 221 123 779 542 589 873 472 823 588 834 ...
##  $ fare     : num  13 35.5 69.55 21.07 8.05 ...
##  $ cabin    : Factor w/ 187 levels &quot;&quot;,&quot;A10&quot;,&quot;A11&quot;,..: 1 94 1 1 1 1 1 1 1 1 ...
##  $ embarked : Factor w/ 4 levels &quot;&quot;,&quot;C&quot;,&quot;Q&quot;,&quot;S&quot;: 4 4 4 4 4 4 4 2 4 2 ...
##  $ boat     : Factor w/ 28 levels &quot;&quot;,&quot;1&quot;,&quot;10&quot;,&quot;11&quot;,..: 3 28 1 1 1 1 1 19 1 15 ...
##  $ body     : int  NA NA NA NA 50 32 NA NA NA NA ...
##  $ home.dest: Factor w/ 370 levels &quot;&quot;,&quot;?Havana, Cuba&quot;,..: 121 213 1 1 1 1 322 350 1 1 ...</code></pre>
<div class="sourceCode" id="cb614"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb614-1"><a href="fundamental.html#cb614-1" aria-hidden="true" tabindex="-1"></a>indicesPredict <span class="ot">=</span> <span class="fu">which</span>(<span class="fu">is.na</span>(titanic_ml<span class="sc">$</span>survived))</span>
<span id="cb614-2"><a href="fundamental.html#cb614-2" aria-hidden="true" tabindex="-1"></a>indicesTrain <span class="ot">=</span> <span class="fu">which</span>(<span class="sc">!</span><span class="fu">is.na</span>(titanic_ml<span class="sc">$</span>survived))</span>
<span id="cb614-3"><a href="fundamental.html#cb614-3" aria-hidden="true" tabindex="-1"></a>subset <span class="ot">=</span> <span class="fu">sample</span>(<span class="fu">length</span>(indicesTrain), <span class="fu">length</span>(indicesTrain) <span class="sc">*</span> <span class="fl">0.7</span>, <span class="at">replace =</span> F)</span>
<span id="cb614-4"><a href="fundamental.html#cb614-4" aria-hidden="true" tabindex="-1"></a>indicesTest <span class="ot">=</span> <span class="fu">sort</span>(indicesTrain[<span class="sc">-</span>subset]) <span class="co"># Mind order of instructions!</span></span>
<span id="cb614-5"><a href="fundamental.html#cb614-5" aria-hidden="true" tabindex="-1"></a>indicesTrain <span class="ot">=</span> <span class="fu">sort</span>(indicesTrain[subset])</span>
<span id="cb614-6"><a href="fundamental.html#cb614-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb614-7"><a href="fundamental.html#cb614-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Determine labels. As they are fixed from now on, samples must not be left!</span></span>
<span id="cb614-8"><a href="fundamental.html#cb614-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Impute when necessary. </span></span>
<span id="cb614-9"><a href="fundamental.html#cb614-9" aria-hidden="true" tabindex="-1"></a>labelsTrain <span class="ot">=</span> data<span class="sc">$</span>survived[indicesTrain]</span>
<span id="cb614-10"><a href="fundamental.html#cb614-10" aria-hidden="true" tabindex="-1"></a>labelsTest <span class="ot">=</span> data<span class="sc">$</span>survived[indicesTest]</span>
<span id="cb614-11"><a href="fundamental.html#cb614-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb614-12"><a href="fundamental.html#cb614-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameter &quot;body&quot; has nearly no information).</span></span>
<span id="cb614-13"><a href="fundamental.html#cb614-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameter &quot;name&quot; was already processed above.</span></span>
<span id="cb614-14"><a href="fundamental.html#cb614-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameter &quot;ticket&quot; may include (other) information, but leave it out for now.</span></span>
<span id="cb614-15"><a href="fundamental.html#cb614-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameter &quot;survived&quot; is the target variable.</span></span>
<span id="cb614-16"><a href="fundamental.html#cb614-16" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> data <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>body, <span class="sc">-</span>name, <span class="sc">-</span>ticket, <span class="sc">-</span>survived)</span>
<span id="cb614-17"><a href="fundamental.html#cb614-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb614-18"><a href="fundamental.html#cb614-18" aria-hidden="true" tabindex="-1"></a>data<span class="sc">$</span>pclass <span class="ot">=</span> <span class="fu">as.factor</span>(data<span class="sc">$</span>pclass)  <span class="co"># &quot;pclass&quot; makes only sense as a factor.</span></span>
<span id="cb614-19"><a href="fundamental.html#cb614-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb614-20"><a href="fundamental.html#cb614-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>){</span>
<span id="cb614-21"><a href="fundamental.html#cb614-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(<span class="fu">sum</span>(data<span class="sc">$</span>cabin[data<span class="sc">$</span>pclass <span class="sc">==</span> i] <span class="sc">==</span> <span class="st">&quot;&quot;</span>) <span class="sc">/</span> <span class="fu">sum</span>(data<span class="sc">$</span>pclass <span class="sc">==</span> i))</span>
<span id="cb614-22"><a href="fundamental.html#cb614-22" aria-hidden="true" tabindex="-1"></a>  }</span></code></pre></div>
<pre><code>## [1] 0.2074303
## [1] 0.9169675
## [1] 0.977433</code></pre>
<div class="sourceCode" id="cb616"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb616-1"><a href="fundamental.html#cb616-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Most people have no cabin (21% in 1st, 92% in 2nd and 98% in 3rd class).</span></span>
<span id="cb616-2"><a href="fundamental.html#cb616-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Dummy code the availability of a cabin.</span></span>
<span id="cb616-3"><a href="fundamental.html#cb616-3" aria-hidden="true" tabindex="-1"></a><span class="co"># This is NOT one-hot encoding! Dummy coded variables use n-1 variables!</span></span>
<span id="cb616-4"><a href="fundamental.html#cb616-4" aria-hidden="true" tabindex="-1"></a>data<span class="sc">$</span>cabin <span class="ot">=</span> (data<span class="sc">$</span>cabin <span class="sc">!=</span> <span class="st">&quot;&quot;</span>) <span class="sc">*</span> <span class="dv">1</span></span>
<span id="cb616-5"><a href="fundamental.html#cb616-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb616-6"><a href="fundamental.html#cb616-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Impute values for parameter &quot;embarked&quot;:</span></span>
<span id="cb616-7"><a href="fundamental.html#cb616-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Leave parameters with too many levels or causal inverse ones (assumed).</span></span>
<span id="cb616-8"><a href="fundamental.html#cb616-8" aria-hidden="true" tabindex="-1"></a>  tmp <span class="ot">=</span> data <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>boat, <span class="sc">-</span>home.dest)</span>
<span id="cb616-9"><a href="fundamental.html#cb616-9" aria-hidden="true" tabindex="-1"></a>  tmp <span class="ot">=</span> <span class="fu">data.frame</span>(tmp[<span class="fu">complete.cases</span>(tmp),]) <span class="co"># Leave samples with missing values.</span></span>
<span id="cb616-10"><a href="fundamental.html#cb616-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb616-11"><a href="fundamental.html#cb616-11" aria-hidden="true" tabindex="-1"></a>  missingIndices <span class="ot">=</span> <span class="fu">which</span>(tmp<span class="sc">$</span>embarked <span class="sc">==</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb616-12"><a href="fundamental.html#cb616-12" aria-hidden="true" tabindex="-1"></a>  toPredict <span class="ot">=</span> tmp[missingIndices, <span class="sc">-</span><span class="dv">8</span>]</span>
<span id="cb616-13"><a href="fundamental.html#cb616-13" aria-hidden="true" tabindex="-1"></a>  tmp <span class="ot">=</span> tmp[<span class="sc">-</span>missingIndices,] <span class="co"># Leave samples that should be predicted.</span></span>
<span id="cb616-14"><a href="fundamental.html#cb616-14" aria-hidden="true" tabindex="-1"></a>  tmp<span class="sc">$</span>embarked <span class="ot">=</span> <span class="fu">droplevels</span>(tmp<span class="sc">$</span>embarked) <span class="co"># Remove unused levels (&quot;&quot;).</span></span>
<span id="cb616-15"><a href="fundamental.html#cb616-15" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb616-16"><a href="fundamental.html#cb616-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Random forests and simple regression trees don&#39;t need scaling.</span></span>
<span id="cb616-17"><a href="fundamental.html#cb616-17" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Use a simple regression tree instead of a random forest here,</span></span>
<span id="cb616-18"><a href="fundamental.html#cb616-18" aria-hidden="true" tabindex="-1"></a>  <span class="co"># we have only 2 missing values.</span></span>
<span id="cb616-19"><a href="fundamental.html#cb616-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># And a simple regression tree is easy to visualize.</span></span>
<span id="cb616-20"><a href="fundamental.html#cb616-20" aria-hidden="true" tabindex="-1"></a>  regressionTree <span class="ot">=</span> <span class="fu">rpart</span>(embarked <span class="sc">~</span> ., <span class="at">data =</span> tmp,</span>
<span id="cb616-21"><a href="fundamental.html#cb616-21" aria-hidden="true" tabindex="-1"></a>                         <span class="at">control =</span> <span class="fu">rpart.control</span>(<span class="at">minsplit =</span> <span class="dv">10</span>))</span>
<span id="cb616-22"><a href="fundamental.html#cb616-22" aria-hidden="true" tabindex="-1"></a>  rpart.plot<span class="sc">::</span><span class="fu">rpart.plot</span>(regressionTree)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_task_40-1.png" width="672" /></p>
<div class="sourceCode" id="cb617"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb617-1"><a href="fundamental.html#cb617-1" aria-hidden="true" tabindex="-1"></a>  prediction <span class="ot">=</span> <span class="fu">predict</span>(regressionTree, toPredict)</span>
<span id="cb617-2"><a href="fundamental.html#cb617-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb617-3"><a href="fundamental.html#cb617-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(prediction)){</span>
<span id="cb617-4"><a href="fundamental.html#cb617-4" aria-hidden="true" tabindex="-1"></a>    index <span class="ot">=</span> <span class="fu">which</span>(<span class="fu">rownames</span>(data) <span class="sc">==</span> <span class="fu">as.integer</span>(<span class="fu">rownames</span>(prediction))[i])</span>
<span id="cb617-5"><a href="fundamental.html#cb617-5" aria-hidden="true" tabindex="-1"></a>    data<span class="sc">$</span>embarked[index] <span class="ot">=</span> <span class="fu">colnames</span>(prediction)[<span class="fu">which.max</span>(prediction[i,])]</span>
<span id="cb617-6"><a href="fundamental.html#cb617-6" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb617-7"><a href="fundamental.html#cb617-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb617-8"><a href="fundamental.html#cb617-8" aria-hidden="true" tabindex="-1"></a>  data<span class="sc">$</span>embarked <span class="ot">=</span> <span class="fu">droplevels</span>(data<span class="sc">$</span>embarked) <span class="co"># Remove unused levels (&quot;&quot;).</span></span>
<span id="cb617-9"><a href="fundamental.html#cb617-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb617-10"><a href="fundamental.html#cb617-10" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(data<span class="sc">$</span>pclass)</span></code></pre></div>
<pre><code>## 
##   1   2   3 
## 323 277 709</code></pre>
<div class="sourceCode" id="cb619"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb619-1"><a href="fundamental.html#cb619-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">table</span>(data<span class="sc">$</span>pclass))</span></code></pre></div>
<pre><code>## [1] 1309</code></pre>
<div class="sourceCode" id="cb621"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb621-1"><a href="fundamental.html#cb621-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">table</span>(data<span class="sc">$</span>home.dest))</span></code></pre></div>
<pre><code>## [1] 1309</code></pre>
<div class="sourceCode" id="cb623"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb623-1"><a href="fundamental.html#cb623-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">is.na</span>(data<span class="sc">$</span>home.dest))</span></code></pre></div>
<pre><code>## [1] 0</code></pre>
<div class="sourceCode" id="cb625"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb625-1"><a href="fundamental.html#cb625-1" aria-hidden="true" tabindex="-1"></a><span class="co"># &quot;pclass&quot;, &quot;sex&quot;, &quot;sibsp&quot;, &quot;parch&quot;, &quot;boat&quot; and &quot;home.dest&quot; have no missing values.</span></span>
<span id="cb625-2"><a href="fundamental.html#cb625-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb625-3"><a href="fundamental.html#cb625-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(data<span class="sc">$</span>fare)</span></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   0.000   7.896  14.454  33.295  31.275 512.329       1</code></pre>
<div class="sourceCode" id="cb627"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb627-1"><a href="fundamental.html#cb627-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameter &quot;fare&quot; has 1 NA entry. Impute the mean.</span></span>
<span id="cb627-2"><a href="fundamental.html#cb627-2" aria-hidden="true" tabindex="-1"></a>data<span class="sc">$</span>fare[<span class="fu">is.na</span>(data<span class="sc">$</span>fare)] <span class="ot">=</span> <span class="fu">mean</span>(data<span class="sc">$</span>fare, <span class="at">na.rm =</span> <span class="cn">TRUE</span>)</span>
<span id="cb627-3"><a href="fundamental.html#cb627-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb627-4"><a href="fundamental.html#cb627-4" aria-hidden="true" tabindex="-1"></a><span class="fu">levels</span>(data<span class="sc">$</span>home.dest)[<span class="fu">levels</span>(data<span class="sc">$</span>home.dest) <span class="sc">==</span> <span class="st">&quot;&quot;</span>] <span class="ot">=</span> <span class="st">&quot;unknown&quot;</span></span>
<span id="cb627-5"><a href="fundamental.html#cb627-5" aria-hidden="true" tabindex="-1"></a><span class="fu">levels</span>(data<span class="sc">$</span>boat)[<span class="fu">levels</span>(data<span class="sc">$</span>boat) <span class="sc">==</span> <span class="st">&quot;&quot;</span>] <span class="ot">=</span> <span class="st">&quot;none&quot;</span></span>
<span id="cb627-6"><a href="fundamental.html#cb627-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb627-7"><a href="fundamental.html#cb627-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Impute values for &quot;age&quot;:</span></span>
<span id="cb627-8"><a href="fundamental.html#cb627-8" aria-hidden="true" tabindex="-1"></a>  tmp <span class="ot">=</span> data <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>home.dest) <span class="co"># Leave parameters with too many levels.</span></span>
<span id="cb627-9"><a href="fundamental.html#cb627-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb627-10"><a href="fundamental.html#cb627-10" aria-hidden="true" tabindex="-1"></a>  missingIndices <span class="ot">=</span> <span class="fu">which</span>(<span class="fu">is.na</span>(tmp<span class="sc">$</span>age))</span>
<span id="cb627-11"><a href="fundamental.html#cb627-11" aria-hidden="true" tabindex="-1"></a>  toPredict <span class="ot">=</span> tmp[missingIndices, <span class="sc">-</span><span class="dv">3</span>]</span>
<span id="cb627-12"><a href="fundamental.html#cb627-12" aria-hidden="true" tabindex="-1"></a>  tmp <span class="ot">=</span> tmp[<span class="sc">-</span>missingIndices,] <span class="co"># Leave samples that should be predicted.</span></span>
<span id="cb627-13"><a href="fundamental.html#cb627-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb627-14"><a href="fundamental.html#cb627-14" aria-hidden="true" tabindex="-1"></a>  forest <span class="ot">=</span> <span class="fu">randomForest</span>(<span class="at">x =</span> tmp[,<span class="sc">-</span><span class="dv">3</span>], <span class="at">y =</span> tmp<span class="sc">$</span>age)</span>
<span id="cb627-15"><a href="fundamental.html#cb627-15" aria-hidden="true" tabindex="-1"></a>  prediction <span class="ot">=</span> <span class="fu">predict</span>(forest, toPredict)</span>
<span id="cb627-16"><a href="fundamental.html#cb627-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb627-17"><a href="fundamental.html#cb627-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(prediction)){</span>
<span id="cb627-18"><a href="fundamental.html#cb627-18" aria-hidden="true" tabindex="-1"></a>    index <span class="ot">=</span> <span class="fu">which</span>(<span class="fu">rownames</span>(data) <span class="sc">==</span> <span class="fu">as.integer</span>(<span class="fu">names</span>(prediction))[i])</span>
<span id="cb627-19"><a href="fundamental.html#cb627-19" aria-hidden="true" tabindex="-1"></a>    data<span class="sc">$</span>age[index] <span class="ot">=</span> prediction[i]</span>
<span id="cb627-20"><a href="fundamental.html#cb627-20" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb627-21"><a href="fundamental.html#cb627-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb627-22"><a href="fundamental.html#cb627-22" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(data)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    1309 obs. of  10 variables:
##  $ pclass   : Factor w/ 3 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;: 2 1 3 3 3 3 3 1 3 1 ...
##  $ sex      : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 1 2 2 2 2 2 2 1 1 1 ...
##  $ age      : num  30 36.7 13.9 6 30.5 ...
##  $ sibsp    : int  0 0 8 3 0 0 0 0 0 0 ...
##  $ parch    : int  0 0 2 1 0 0 0 0 0 0 ...
##  $ fare     : num  13 35.5 69.55 21.07 8.05 ...
##  $ cabin    : num  0 1 0 0 0 0 0 0 0 0 ...
##  $ embarked : Factor w/ 3 levels &quot;C&quot;,&quot;Q&quot;,&quot;S&quot;: 3 3 3 3 3 3 3 1 3 1 ...
##  $ boat     : Factor w/ 28 levels &quot;none&quot;,&quot;1&quot;,&quot;10&quot;,..: 3 28 1 1 1 1 1 19 1 15 ...
##  $ home.dest: Factor w/ 370 levels &quot;unknown&quot;,&quot;?Havana, Cuba&quot;,..: 121 213 1 1 1 1 322 350 1 1 ...</code></pre>
<div class="sourceCode" id="cb629"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb629-1"><a href="fundamental.html#cb629-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">as.data.frame</span>(data)</span>
<span id="cb629-2"><a href="fundamental.html#cb629-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb629-3"><a href="fundamental.html#cb629-3" aria-hidden="true" tabindex="-1"></a><span class="co"># One-hot encoding of &quot;pclass&quot;, &quot;sex&quot;, &quot;cabin&quot;, &quot;embarked&quot;, &quot;boat&quot; and &quot;home.dest&quot;:</span></span>
<span id="cb629-4"><a href="fundamental.html#cb629-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(element <span class="cf">in</span> <span class="fu">c</span>(<span class="st">&quot;pclass&quot;</span>, <span class="st">&quot;sex&quot;</span>, <span class="st">&quot;cabin&quot;</span>, <span class="st">&quot;embarked&quot;</span>, <span class="st">&quot;boat&quot;</span>, <span class="st">&quot;home.dest&quot;</span>)){</span>
<span id="cb629-5"><a href="fundamental.html#cb629-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Build integer representation:</span></span>
<span id="cb629-6"><a href="fundamental.html#cb629-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># This MUST start at 0, otherwise, the encoding is wrong!!</span></span>
<span id="cb629-7"><a href="fundamental.html#cb629-7" aria-hidden="true" tabindex="-1"></a>      integers <span class="ot">=</span> <span class="fu">as.integer</span>(data[[element]])</span>
<span id="cb629-8"><a href="fundamental.html#cb629-8" aria-hidden="true" tabindex="-1"></a>      integers <span class="ot">=</span> integers <span class="sc">-</span> <span class="fu">min</span>(integers)</span>
<span id="cb629-9"><a href="fundamental.html#cb629-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb629-10"><a href="fundamental.html#cb629-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Determine number of classes:</span></span>
<span id="cb629-11"><a href="fundamental.html#cb629-11" aria-hidden="true" tabindex="-1"></a>    num_classes <span class="ot">=</span> <span class="fu">length</span>(<span class="fu">levels</span>(<span class="fu">as.factor</span>(data[[element]])))</span>
<span id="cb629-12"><a href="fundamental.html#cb629-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb629-13"><a href="fundamental.html#cb629-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Encode:</span></span>
<span id="cb629-14"><a href="fundamental.html#cb629-14" aria-hidden="true" tabindex="-1"></a>    encoded <span class="ot">=</span> <span class="fu">k_one_hot</span>(integers, num_classes)<span class="sc">$</span><span class="fu">numpy</span>()</span>
<span id="cb629-15"><a href="fundamental.html#cb629-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb629-16"><a href="fundamental.html#cb629-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Copy factor names.</span></span>
<span id="cb629-17"><a href="fundamental.html#cb629-17" aria-hidden="true" tabindex="-1"></a>    <span class="fu">colnames</span>(encoded) <span class="ot">=</span> <span class="fu">paste0</span>(element, <span class="st">&quot;_&quot;</span>, <span class="fu">levels</span>(<span class="fu">as.factor</span>(data[[element]])))</span>
<span id="cb629-18"><a href="fundamental.html#cb629-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb629-19"><a href="fundamental.html#cb629-19" aria-hidden="true" tabindex="-1"></a>    data <span class="ot">=</span> data <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span><span class="fu">all_of</span>(element))  <span class="co"># Remove original column.</span></span>
<span id="cb629-20"><a href="fundamental.html#cb629-20" aria-hidden="true" tabindex="-1"></a>    data <span class="ot">=</span> <span class="fu">cbind.data.frame</span>(data, encoded)  <span class="co"># Plug in new (encoded) columns.</span></span>
<span id="cb629-21"><a href="fundamental.html#cb629-21" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb629-22"><a href="fundamental.html#cb629-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb629-23"><a href="fundamental.html#cb629-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Scale parameters (including one-hot encoded):</span></span>
<span id="cb629-24"><a href="fundamental.html#cb629-24" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">scale</span>(<span class="fu">as.matrix</span>(data))</span>
<span id="cb629-25"><a href="fundamental.html#cb629-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb629-26"><a href="fundamental.html#cb629-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Split into training, test and prediction set:</span></span>
<span id="cb629-27"><a href="fundamental.html#cb629-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Be careful! You need matrices, no data.frames!</span></span>
<span id="cb629-28"><a href="fundamental.html#cb629-28" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> <span class="fu">as.matrix</span>(data[indicesTrain,])</span>
<span id="cb629-29"><a href="fundamental.html#cb629-29" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> <span class="fu">as.matrix</span>(data[indicesTest,])</span>
<span id="cb629-30"><a href="fundamental.html#cb629-30" aria-hidden="true" tabindex="-1"></a>predict <span class="ot">=</span> <span class="fu">as.matrix</span>(data[indicesPredict,])</span></code></pre></div>
    </p>
  </details>
  <br/><hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<p>Build a neural network to make predictions and check performance on the hold-out data.</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<p><img src="_main_files/figure-html/chunk_chapter4_task_41-1.png" width="672" /></p>
<pre><code>##           labelsTest
## prediction   0   1
##          0 106  14
##          1  15  62</code></pre>
<pre><code>## Accuracy:</code></pre>
<pre><code>## [1] 0.8527919</code></pre>
    </p>
  </details>
  <br/><hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<p>Play around with model parameters, optimizer(learning_rate = …), epochs = …, number of hidden nodes in layers: units = …, regularization: kernel_regularizer = …, bias_regularizer = … <strong>-</strong> Try to maximize the model’s accuracy for the hold-out data.</p>
<p><strong>Hint</strong>: There are a lot different activation functions like “linear,” “softmax,” “relu,” “leaky_relu,” “gelu,” “selu,” “elu,” “exponential,” “sigmoid,” “tanh,” “softplus,” “softsign,” etc. But be careful, this might be <em>very</em> computation-intensive (especially “gelu,” tanh" or “softmax”).
Every activation function has its own properties, requirements (!), advantages and disadvantages. Choose them wisely!</p>
<p>You should get an accuracy of at least 90%. (Before looking into the solution…) Try to be better than the solution.</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<p><img src="_main_files/figure-html/chunk_chapter4_task_42-1.png" width="672" /></p>
<pre><code>##           labelsTest
## prediction   0   1
##          0 120   7
##          1   1  69</code></pre>
<pre><code>## Accuracy:</code></pre>
<pre><code>## [1] 0.9593909</code></pre>
    </p>
  </details>
  <br/><hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<p>Now try your above solution (<strong>the exactly same one!</strong>) with another seed to check for overfitting (on the seed!) of your procedure.</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<p><img src="_main_files/figure-html/chunk_chapter4_task_43-1.png" width="672" /></p>
<pre><code>##           labelsTest
## prediction   0   1
##          0 113   6
##          1   8  70</code></pre>
<pre><code>## Accuracy:</code></pre>
<pre><code>## [1] 0.928934</code></pre>
    </p>
  </details>
  <br/><hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<p>Make predictions and submit them via our <a href="https://elearning.uni-regensburg.de/mod/page/view.php?id=1150717" target="_blank" rel="noopener">submission server</a>.</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<div class="sourceCode" id="cb639"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb639-1"><a href="fundamental.html#cb639-1" aria-hidden="true" tabindex="-1"></a>prediction <span class="ot">=</span></span>
<span id="cb639-2"><a href="fundamental.html#cb639-2" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb639-3"><a href="fundamental.html#cb639-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">predict</span>(<span class="at">x =</span> predict)</span>
<span id="cb639-4"><a href="fundamental.html#cb639-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb639-5"><a href="fundamental.html#cb639-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Take label with highest probability:</span></span>
<span id="cb639-6"><a href="fundamental.html#cb639-6" aria-hidden="true" tabindex="-1"></a>prediction <span class="ot">=</span> (prediction[,<span class="dv">1</span>] <span class="sc">&lt;</span> prediction[,<span class="dv">2</span>]) <span class="sc">*</span> <span class="dv">1</span></span>
<span id="cb639-7"><a href="fundamental.html#cb639-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb639-8"><a href="fundamental.html#cb639-8" aria-hidden="true" tabindex="-1"></a><span class="fu">write.csv</span>(<span class="fu">data.frame</span>(<span class="at">y =</span> prediction), <span class="at">file =</span> <span class="st">&quot;submission_NN.csv&quot;</span>)</span></code></pre></div>
    </p>
  </details>
  <br/><hr/>
</div>
</div>
<div id="mlr" class="section level2" number="4.6">
<h2><span class="header-section-number">4.6</span> Bonus - Machine Learning Pipelines with mlr3</h2>
<p>As we have seen today, many of the machine learning algorithms are distributed over several packages but the general machine learning pipeline is very similar for all models: feature engineering, feature selection, hyperparameter tuning and cross-validation.</p>
<p>The idea of the mlr3 framework is now to provide a general machine learning interface which you can use to build reproducible and automatic machine learning pipelines. The key features of mlr3 are:</p>
<ul>
<li>All common machine learning packages are integrated into mlr3, you can easily switch between different machine learning algorithms.</li>
<li>A common ‘language’/workflow to specify machine learning pipelines.</li>
<li>Support for different cross-validation strategies.</li>
<li>Hyperparameter tuning for all supported machine learning algorithms.</li>
<li>Ensemble models.</li>
</ul>
<p>Useful links:</p>
<ul>
<li><a href="https://mlr3book.mlr-org.com/" target="_blank" rel="noopener">mlr3-book</a> (still in work)</li>
<li><a href="https://mlr3.mlr-org.com/" target="_blank" rel="noopener">mlr3 website</a></li>
<li><a href="https://cheatsheets.mlr-org.com/mlr3.pdf" target="_blank" rel="noopener">mlr3 cheatsheet</a></li>
</ul>
<div id="mlr3---the-basic-workflow" class="section level3" number="4.6.1">
<h3><span class="header-section-number">4.6.1</span> mlr3 - The Basic Workflow</h3>
<p>The mlr3 package actually consists of several packages for different tasks (e.g. mlr3tuning for hyperparameter tuning, mlr3pipelines for data preparation pipes). But let’s start with the basic workflow:</p>
<div class="sourceCode" id="cb640"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb640-1"><a href="fundamental.html#cb640-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(EcoData)</span>
<span id="cb640-2"><a href="fundamental.html#cb640-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb640-3"><a href="fundamental.html#cb640-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3)</span>
<span id="cb640-4"><a href="fundamental.html#cb640-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3learners)</span>
<span id="cb640-5"><a href="fundamental.html#cb640-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3pipelines)</span>
<span id="cb640-6"><a href="fundamental.html#cb640-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3tuning)</span>
<span id="cb640-7"><a href="fundamental.html#cb640-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3measures)</span>
<span id="cb640-8"><a href="fundamental.html#cb640-8" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(nasa)</span>
<span id="cb640-9"><a href="fundamental.html#cb640-9" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(nasa)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    4687 obs. of  40 variables:
##  $ Neo.Reference.ID            : int  3449084 3702322 3406893 NA 2363305 3017307 2438430 3653917 3519490 2066391 ...
##  $ Name                        : int  NA 3702322 3406893 3082923 2363305 3017307 2438430 3653917 3519490 NA ...
##  $ Absolute.Magnitude          : num  18.7 22.1 24.8 21.6 21.4 18.2 20 21 20.9 16.5 ...
##  $ Est.Dia.in.KM.min.          : num  0.4837 0.1011 0.0291 0.1272 0.1395 ...
##  $ Est.Dia.in.KM.max.          : num  1.0815 0.226 0.0652 0.2845 0.3119 ...
##  $ Est.Dia.in.M.min.           : num  483.7 NA 29.1 127.2 139.5 ...
##  $ Est.Dia.in.M.max.           : num  1081.5 226 65.2 284.5 311.9 ...
##  $ Est.Dia.in.Miles.min.       : num  0.3005 0.0628 NA 0.0791 0.0867 ...
##  $ Est.Dia.in.Miles.max.       : num  0.672 0.1404 0.0405 0.1768 0.1938 ...
##  $ Est.Dia.in.Feet.min.        : num  1586.9 331.5 95.6 417.4 457.7 ...
##  $ Est.Dia.in.Feet.max.        : num  3548 741 214 933 1023 ...
##  $ Close.Approach.Date         : Factor w/ 777 levels &quot;1995-01-01&quot;,&quot;1995-01-08&quot;,..: 511 712 472 239 273 145 428 694 87 732 ...
##  $ Epoch.Date.Close.Approach   : num  NA 1.42e+12 1.21e+12 1.00e+12 1.03e+12 ...
##  $ Relative.Velocity.km.per.sec: num  11.22 13.57 5.75 13.84 4.61 ...
##  $ Relative.Velocity.km.per.hr : num  40404 48867 20718 49821 16583 ...
##  $ Miles.per.hour              : num  25105 30364 12873 30957 10304 ...
##  $ Miss.Dist..Astronomical.    : num  NA 0.0671 0.013 0.0583 0.0381 ...
##  $ Miss.Dist..lunar.           : num  112.7 26.1 NA 22.7 14.8 ...
##  $ Miss.Dist..kilometers.      : num  43348668 10030753 1949933 NA 5694558 ...
##  $ Miss.Dist..miles.           : num  26935614 6232821 1211632 5418692 3538434 ...
##  $ Orbiting.Body               : Factor w/ 1 level &quot;Earth&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ Orbit.ID                    : int  NA 8 12 12 91 NA 24 NA NA 212 ...
##  $ Orbit.Determination.Date    : Factor w/ 2680 levels &quot;2014-06-13 15:20:44&quot;,..: 69 NA 1377 1774 2275 2554 1919 731 1178 2520 ...
##  $ Orbit.Uncertainity          : int  0 8 6 0 0 0 1 1 1 0 ...
##  $ Minimum.Orbit.Intersection  : num  NA 0.05594 0.00553 NA 0.0281 ...
##  $ Jupiter.Tisserand.Invariant : num  5.58 3.61 4.44 5.5 NA ...
##  $ Epoch.Osculation            : num  2457800 2457010 NA 2458000 2458000 ...
##  $ Eccentricity                : num  0.276 0.57 0.344 0.255 0.22 ...
##  $ Semi.Major.Axis             : num  1.1 NA 1.52 1.11 1.24 ...
##  $ Inclination                 : num  20.06 4.39 5.44 23.9 3.5 ...
##  $ Asc.Node.Longitude          : num  29.85 1.42 170.68 356.18 183.34 ...
##  $ Orbital.Period              : num  419 1040 682 427 503 ...
##  $ Perihelion.Distance         : num  0.794 0.864 0.994 0.828 0.965 ...
##  $ Perihelion.Arg              : num  41.8 359.3 350 268.2 179.2 ...
##  $ Aphelion.Dist               : num  1.4 3.15 2.04 1.39 1.51 ...
##  $ Perihelion.Time             : num  2457736 2456941 2457937 NA 2458070 ...
##  $ Mean.Anomaly                : num  55.1 NA NA 297.4 310.5 ...
##  $ Mean.Motion                 : num  0.859 0.346 0.528 0.843 0.716 ...
##  $ Equinox                     : Factor w/ 1 level &quot;J2000&quot;: 1 1 NA 1 1 1 1 1 1 1 ...
##  $ Hazardous                   : int  0 0 0 1 1 0 0 0 1 1 ...</code></pre>
<p>Let’s drop time, name and ID variable and create a classification task:</p>
<div class="sourceCode" id="cb642"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb642-1"><a href="fundamental.html#cb642-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> nasa <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>Orbit.Determination.Date,</span>
<span id="cb642-2"><a href="fundamental.html#cb642-2" aria-hidden="true" tabindex="-1"></a>                       <span class="sc">-</span>Close.Approach.Date, <span class="sc">-</span>Name, <span class="sc">-</span>Neo.Reference.ID)</span>
<span id="cb642-3"><a href="fundamental.html#cb642-3" aria-hidden="true" tabindex="-1"></a>data<span class="sc">$</span>Hazardous <span class="ot">=</span> <span class="fu">as.factor</span>(data<span class="sc">$</span>Hazardous)</span>
<span id="cb642-4"><a href="fundamental.html#cb642-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb642-5"><a href="fundamental.html#cb642-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a classification task.</span></span>
<span id="cb642-6"><a href="fundamental.html#cb642-6" aria-hidden="true" tabindex="-1"></a>task <span class="ot">=</span> TaskClassif<span class="sc">$</span><span class="fu">new</span>(<span class="at">id =</span> <span class="st">&quot;nasa&quot;</span>, <span class="at">backend =</span> data,</span>
<span id="cb642-7"><a href="fundamental.html#cb642-7" aria-hidden="true" tabindex="-1"></a>                       <span class="at">target =</span> <span class="st">&quot;Hazardous&quot;</span>, <span class="at">positive =</span> <span class="st">&quot;1&quot;</span>)</span></code></pre></div>
<p>Create a generic pipeline of data transformation (imputation <span class="math inline">\(\rightarrow\)</span> scaling <span class="math inline">\(\rightarrow\)</span> encoding of categorical variables):</p>
<div class="sourceCode" id="cb643"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb643-1"><a href="fundamental.html#cb643-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb643-2"><a href="fundamental.html#cb643-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb643-3"><a href="fundamental.html#cb643-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Let&#39;s create the preprocessing graph.</span></span>
<span id="cb643-4"><a href="fundamental.html#cb643-4" aria-hidden="true" tabindex="-1"></a>preprocessing <span class="ot">=</span> <span class="fu">po</span>(<span class="st">&quot;imputeoor&quot;</span>) <span class="sc">%&gt;&gt;%</span> <span class="fu">po</span>(<span class="st">&quot;scale&quot;</span>) <span class="sc">%&gt;&gt;%</span> <span class="fu">po</span>(<span class="st">&quot;encode&quot;</span>) </span>
<span id="cb643-5"><a href="fundamental.html#cb643-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb643-6"><a href="fundamental.html#cb643-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the task.</span></span>
<span id="cb643-7"><a href="fundamental.html#cb643-7" aria-hidden="true" tabindex="-1"></a>transformed_task <span class="ot">=</span> preprocessing<span class="sc">$</span><span class="fu">train</span>(task)[[<span class="dv">1</span>]]</span>
<span id="cb643-8"><a href="fundamental.html#cb643-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb643-9"><a href="fundamental.html#cb643-9" aria-hidden="true" tabindex="-1"></a>transformed_task<span class="sc">$</span><span class="fu">missings</span>()</span></code></pre></div>
<pre><code>##                    Hazardous           Absolute.Magnitude                Aphelion.Dist           Asc.Node.Longitude 
##                         4187                            0                            0                            0 
##                 Eccentricity    Epoch.Date.Close.Approach             Epoch.Osculation         Est.Dia.in.Feet.max. 
##                            0                            0                            0                            0 
##         Est.Dia.in.Feet.min.           Est.Dia.in.KM.max.           Est.Dia.in.KM.min.            Est.Dia.in.M.max. 
##                            0                            0                            0                            0 
##            Est.Dia.in.M.min.        Est.Dia.in.Miles.max.        Est.Dia.in.Miles.min.                  Inclination 
##                            0                            0                            0                            0 
##  Jupiter.Tisserand.Invariant                 Mean.Anomaly                  Mean.Motion               Miles.per.hour 
##                            0                            0                            0                            0 
##   Minimum.Orbit.Intersection     Miss.Dist..Astronomical.       Miss.Dist..kilometers.            Miss.Dist..lunar. 
##                            0                            0                            0                            0 
##            Miss.Dist..miles.                     Orbit.ID           Orbit.Uncertainity               Orbital.Period 
##                            0                            0                            0                            0 
##               Perihelion.Arg          Perihelion.Distance              Perihelion.Time  Relative.Velocity.km.per.hr 
##                            0                            0                            0                            0 
## Relative.Velocity.km.per.sec              Semi.Major.Axis                Equinox.J2000             Equinox..MISSING 
##                            0                            0                            0                            0 
##          Orbiting.Body.Earth       Orbiting.Body..MISSING 
##                            0                            0</code></pre>
<p>We can even visualize the preprocessing graph:</p>
<div class="sourceCode" id="cb645"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb645-1"><a href="fundamental.html#cb645-1" aria-hidden="true" tabindex="-1"></a>preprocessing<span class="sc">$</span><span class="fu">plot</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter4_68-1.png" width="672" /></p>
<p>Now, to test our model (random forest) 10-fold cross-validated, we will do:</p>
<ul>
<li>Specify the missing target rows as validation so that they will be ignored.</li>
<li>Specify the cross-validation, the learner (the machine learning model we want to use), and the measurement (AUC).</li>
<li>Run (benchmark) our model.</li>
</ul>
<div class="sourceCode" id="cb646"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb646-1"><a href="fundamental.html#cb646-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb646-2"><a href="fundamental.html#cb646-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb646-3"><a href="fundamental.html#cb646-3" aria-hidden="true" tabindex="-1"></a>transformed_task<span class="sc">$</span><span class="fu">data</span>()</span></code></pre></div>
<pre><code>##       Hazardous Absolute.Magnitude Aphelion.Dist Asc.Node.Longitude Eccentricity Epoch.Date.Close.Approach Epoch.Osculation
##    1:         0        -0.81322649   -0.38042005       -1.140837452 -0.315605975                -4.7929881       0.14026773
##    2:         0         0.02110348    0.94306517       -1.380254611  0.744287645                 1.1058704      -0.26325244
##    3:         0         0.68365964    0.10199889        0.044905370 -0.068280074                 0.1591740      -7.76281014
##    4:         1        -0.10159210   -0.38415066        1.606769281 -0.392030729                -0.7630231       0.24229559
##    5:         1        -0.15067034   -0.29632490        0.151458877 -0.516897963                -0.6305034       0.24229559
##   ---                                                                                                                      
## 4683:      &lt;NA&gt;        -0.32244415    0.69173184       -0.171022906  1.043608082                 1.3635097       0.24229559
## 4684:      &lt;NA&gt;         0.46280759   -0.24203066       -0.009803808 -0.006429588                 1.3635097       0.05711503
## 4685:      &lt;NA&gt;         1.51798962   -0.56422744        1.514551982 -1.045386877                 1.3635097       0.24229559
## 4686:      &lt;NA&gt;         0.16833819    0.14193044       -1.080452287  0.017146757                 1.3635097       0.24229559
## 4687:      &lt;NA&gt;        -0.05251387   -0.08643345       -0.013006704 -0.579210554                 1.3635097       0.24229559
##       Est.Dia.in.Feet.max. Est.Dia.in.Feet.min. Est.Dia.in.KM.max. Est.Dia.in.KM.min. Est.Dia.in.M.max. Est.Dia.in.M.min.
##    1:          0.271417899          0.313407647        0.300713440        0.256568684       0.271095311       0.291624502
##    2:          0.032130074         -0.029173486       -0.020055639        0.057560696       0.031844946     -12.143577263
##    3:         -0.012841645         -0.093558135       -0.080340934        0.020159164      -0.013119734      -0.060269734
##    4:          0.048493723         -0.005746146        0.001880088        0.071169817       0.048206033       0.015659335
##    5:          0.056169717          0.005243343        0.012169879        0.077553695       0.055880826       0.025161701
##   ---                                                                                                                    
## 4683:          0.089353662          0.052751793        0.056653478        0.105151714       0.089059576       0.066241198
## 4684:         -0.003481174         -0.080157032       -0.067793075        0.027943967      -0.003760728      -0.048682099
## 4685:         -0.027260163         -0.114200690       -0.099669182        0.008167747      -0.027535994      -0.078118891
## 4686:          0.016872584         -0.051017172       -0.040508543        0.044871533       0.016589844      -0.023485512
## 4687:          0.041493133         -0.015768679       -0.007504312        0.065347651       0.041206539       0.006993074
##       Est.Dia.in.Miles.max. Est.Dia.in.Miles.min. Inclination Jupiter.Tisserand.Invariant Mean.Anomaly Mean.Motion
##    1:          2.620443e-01           0.258651038   0.5442288                   0.3840868  -1.02876096  0.31939530
##    2:          4.153888e-02           0.030928225  -0.5925952                  -0.7801632  -4.55056211 -0.71151122
##    3:          9.711407e-05         -10.258220292  -0.5164818                  -0.2872777  -4.55056211 -0.34600512
##    4:          5.661810e-02           0.046501003   0.8225188                   0.3403535   1.02239674  0.28551117
##    5:          6.369158e-02           0.053806009  -0.6568722                  -6.2415005   1.13265516  0.03164827
##   ---                                                                                                             
## 4683:          9.427082e-02           0.085386142   0.8222493                  -0.6412806   0.01560046 -0.51852041
## 4684:          8.722856e-03          -0.002961897   1.9818623                   0.1346891   1.08051799  0.17477591
## 4685:         -1.318965e-02          -0.025591624  -0.5220442                   0.4810091   0.89998250  0.36895738
## 4686:          2.747899e-02           0.016408144  -0.5912988                  -0.3061894   0.22720275 -0.35895074
## 4687:          5.016700e-02           0.039838758   0.6181969                  -0.2665930   0.22740438 -0.31462613
##       Miles.per.hour Minimum.Orbit.Intersection Miss.Dist..Astronomical. Miss.Dist..kilometers. Miss.Dist..lunar.
##    1:   -0.254130552                -5.45911858               -7.0769260             0.25122963         0.2398625
##    2:    0.009333354                 0.07077092               -0.6830928            -1.08492125        -1.1742128
##    3:   -0.866997591                -0.11099960               -0.9035573            -1.40898698        -4.7878719
##    4:    0.039031045                -5.45911858               -0.7188386            -4.48402327        -1.2298206
##    5:   -0.995720084                -0.02962490               -0.8013948            -1.25881601        -1.3582490
##   ---                                                                                                            
## 4683:    1.403775544                 0.30711241               -0.2728622            -0.48191427        -0.5360384
## 4684:    0.970963141                -0.05962478               -0.7879458            -1.23904708        -1.3373272
## 4685:   -1.150527134                -0.10766868               -0.9303542            -1.44837625        -1.5588644
## 4686:   -0.705980518                 0.08529226               -0.7077555            -1.12117355        -1.2125793
## 4687:   -0.239696213                 0.50904764                0.1075071             0.07719897         0.0556823
##       Miss.Dist..miles.   Orbit.ID Orbit.Uncertainity Orbital.Period Perihelion.Arg Perihelion.Distance Perihelion.Time
##    1:        0.23810770 -9.6514722         -1.0070872     -0.3013135   -1.170536399         -0.01831583      0.10526107
##    2:       -1.18860632 -0.2412680          1.3770116      0.7811097    1.549452700          0.20604472     -0.28203779
##    3:       -1.53463694 -0.1803606          0.7809869      0.1566040    1.470307933          0.61816146      0.20313227
##    4:       -1.24471124 -0.1803606         -1.0070872     -0.2866969    0.769006449          0.09005898     -7.86832915
##    5:       -1.37428752  1.0225620         -1.0070872     -0.1552813    0.006829799          0.52730977      0.26755741
##   ---                                                                                                                  
## 4683:       -0.54472804 -0.1194531         -0.7090748      0.3873214   -0.580282684         -0.65810123      0.03734532
## 4684:       -1.35317867 -0.3021755          1.3770116     -0.2345610    0.839430173         -0.18350549      0.09156633
## 4685:       -1.57669598 -0.3326292          0.7809869     -0.3216884   -1.168210857          0.62646993      0.27629790
## 4686:       -1.22731578 -0.1042262          0.7809869      0.1712806    0.824836889          0.52899080      0.37994517
## 4687:        0.05228143 -0.2717218          0.4829746      0.1224733    0.016358127          1.22720096      0.37399573
##       Relative.Velocity.km.per.hr Relative.Velocity.km.per.sec Semi.Major.Axis Equinox.J2000 Equinox..MISSING
##    1:                 -0.28167821                 -0.284140684      -0.2791037             1                0
##    2:                 -0.00604459                 -0.008343348      -7.3370940             1                0
##    3:                 -0.92285430                 -0.925697621       0.2204883             0                1
##    4:                  0.02502487                  0.022744569      -0.2617714             1                0
##    5:                 -1.05752264                 -1.060445948      -0.1106954             1                0
##   ---                                                                                                        
## 4683:                  1.45280854                  1.451376301       0.4468886             1                0
## 4684:                  1.00000402                  0.998302826      -0.2008499             1                0
## 4685:                 -1.21948041                 -1.222499918      -0.3034586             1                0
## 4686:                 -0.75439966                 -0.757142920       0.2353030             1                0
## 4687:                 -0.26657713                 -0.269030636       0.1857979             1                0
##       Orbiting.Body.Earth Orbiting.Body..MISSING
##    1:                   1                      0
##    2:                   1                      0
##    3:                   1                      0
##    4:                   1                      0
##    5:                   1                      0
##   ---                                           
## 4683:                   1                      0
## 4684:                   1                      0
## 4685:                   1                      0
## 4686:                   1                      0
## 4687:                   1                      0</code></pre>
<div class="sourceCode" id="cb648"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb648-1"><a href="fundamental.html#cb648-1" aria-hidden="true" tabindex="-1"></a>transformed_task<span class="sc">$</span><span class="fu">set_row_roles</span>((<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(data))[<span class="fu">is.na</span>(data<span class="sc">$</span>Hazardous)],</span>
<span id="cb648-2"><a href="fundamental.html#cb648-2" aria-hidden="true" tabindex="-1"></a>                               <span class="st">&quot;validation&quot;</span>)</span>
<span id="cb648-3"><a href="fundamental.html#cb648-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb648-4"><a href="fundamental.html#cb648-4" aria-hidden="true" tabindex="-1"></a>cv10 <span class="ot">=</span> mlr3<span class="sc">::</span><span class="fu">rsmp</span>(<span class="st">&quot;cv&quot;</span>, <span class="at">folds =</span> 10L)</span>
<span id="cb648-5"><a href="fundamental.html#cb648-5" aria-hidden="true" tabindex="-1"></a>rf <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">&quot;classif.ranger&quot;</span>, <span class="at">predict_type =</span> <span class="st">&quot;prob&quot;</span>)</span>
<span id="cb648-6"><a href="fundamental.html#cb648-6" aria-hidden="true" tabindex="-1"></a>measurement <span class="ot">=</span>  <span class="fu">msr</span>(<span class="st">&quot;classif.auc&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb649"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb649-1"><a href="fundamental.html#cb649-1" aria-hidden="true" tabindex="-1"></a>result <span class="ot">=</span> mlr3<span class="sc">::</span><span class="fu">resample</span>(transformed_task,</span>
<span id="cb649-2"><a href="fundamental.html#cb649-2" aria-hidden="true" tabindex="-1"></a>                        rf, <span class="at">resampling =</span> cv10, <span class="at">store_models =</span> <span class="cn">TRUE</span>)</span>
<span id="cb649-3"><a href="fundamental.html#cb649-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb649-4"><a href="fundamental.html#cb649-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the average AUC of the holdouts.</span></span>
<span id="cb649-5"><a href="fundamental.html#cb649-5" aria-hidden="true" tabindex="-1"></a>result<span class="sc">$</span><span class="fu">aggregate</span>(measurement)</span></code></pre></div>
<p>Very cool! Preprocessing + 10-fold cross-validation model evaluation in a few lines of code!</p>
<p>Let’s create the final predictions:</p>
<div class="sourceCode" id="cb650"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb650-1"><a href="fundamental.html#cb650-1" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>, <span class="cf">function</span>(i) result<span class="sc">$</span>learners[[i]]<span class="sc">$</span><span class="fu">predict</span>(transformed_task,</span>
<span id="cb650-2"><a href="fundamental.html#cb650-2" aria-hidden="true" tabindex="-1"></a><span class="at">row_ids =</span> (<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(data))[<span class="fu">is.na</span>(data<span class="sc">$</span>Hazardous)])<span class="sc">$</span>data<span class="sc">$</span>prob[, <span class="st">&quot;1&quot;</span>, <span class="at">drop =</span> <span class="cn">FALSE</span>])</span>
<span id="cb650-3"><a href="fundamental.html#cb650-3" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(pred)</span>
<span id="cb650-4"><a href="fundamental.html#cb650-4" aria-hidden="true" tabindex="-1"></a>predictions <span class="ot">=</span> <span class="fu">apply</span>(pred, <span class="dv">1</span>, mean)</span></code></pre></div>
<p>You could now submit the predictions <a href="http://rhsbio7.uni-regensburg.de:8500" target="_blank" rel="noopener">here</a>.</p>
<p>But we are still not happy with the results, let’s do some hyperparameter tuning!</p>
</div>
<div id="mlr3---hyperparameter-tuning" class="section level3" number="4.6.2">
<h3><span class="header-section-number">4.6.2</span> mlr3 - Hyperparameter Tuning</h3>
<p>Machine learning algorithms have a varying number of hyperparameters which can (!) have a high impact on the predictive performance. To list a few hyperparameters:</p>
<p><strong>Random Forest</strong></p>
<ul>
<li>mtry</li>
<li>Minimal node size</li>
</ul>
<p><strong>K-nearest-neighbors classification</strong></p>
<ul>
<li>Kernel</li>
<li>Number of neighbors</li>
<li>Distance metric</li>
</ul>
<p><strong>Boosted Regression Tree</strong></p>
<ul>
<li>nrounds</li>
<li>Maximum depth</li>
<li>alpha</li>
<li>booster</li>
<li>eta</li>
<li>gamma</li>
<li>lambda</li>
</ul>
<p>With mlr3, we can easily extend the above example to do hyperparameter tuning within nested cross-validation (the tuning has its own inner cross-validation).</p>
<p>Print the hyperparameter space of our random forest learner:</p>
<div class="sourceCode" id="cb651"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb651-1"><a href="fundamental.html#cb651-1" aria-hidden="true" tabindex="-1"></a>rf<span class="sc">$</span>param_set</span></code></pre></div>
<pre><code>## &lt;ParamSet&gt;
##                               id    class lower upper nlevels        default    parents value
##  1:                        alpha ParamDbl  -Inf   Inf     Inf            0.5                 
##  2:       always.split.variables ParamUty    NA    NA     Inf &lt;NoDefault[3]&gt;                 
##  3:                class.weights ParamDbl  -Inf   Inf     Inf                                
##  4:                      holdout ParamLgl    NA    NA       2          FALSE                 
##  5:                   importance ParamFct    NA    NA       4 &lt;NoDefault[3]&gt;                 
##  6:                   keep.inbag ParamLgl    NA    NA       2          FALSE                 
##  7:                    max.depth ParamInt     0   Inf     Inf                                
##  8:                min.node.size ParamInt     1   Inf     Inf              1                 
##  9:                     min.prop ParamDbl  -Inf   Inf     Inf            0.1                 
## 10:                      minprop ParamDbl  -Inf   Inf     Inf            0.1                 
## 11:                         mtry ParamInt     1   Inf     Inf &lt;NoDefault[3]&gt;                 
## 12:                   mtry.ratio ParamDbl     0     1     Inf &lt;NoDefault[3]&gt;                 
## 13:            num.random.splits ParamInt     1   Inf     Inf              1  splitrule      
## 14:                  num.threads ParamInt     1   Inf     Inf              1                1
## 15:                    num.trees ParamInt     1   Inf     Inf            500                 
## 16:                    oob.error ParamLgl    NA    NA       2           TRUE                 
## 17:        regularization.factor ParamUty    NA    NA     Inf              1                 
## 18:      regularization.usedepth ParamLgl    NA    NA       2          FALSE                 
## 19:                      replace ParamLgl    NA    NA       2           TRUE                 
## 20:    respect.unordered.factors ParamFct    NA    NA       3         ignore                 
## 21:              sample.fraction ParamDbl     0     1     Inf &lt;NoDefault[3]&gt;                 
## 22:                  save.memory ParamLgl    NA    NA       2          FALSE                 
## 23: scale.permutation.importance ParamLgl    NA    NA       2          FALSE importance      
## 24:                    se.method ParamFct    NA    NA       2        infjack                 
## 25:                         seed ParamInt  -Inf   Inf     Inf                                
## 26:         split.select.weights ParamDbl     0     1     Inf &lt;NoDefault[3]&gt;                 
## 27:                    splitrule ParamFct    NA    NA       2           gini                 
## 28:                      verbose ParamLgl    NA    NA       2           TRUE                 
## 29:                 write.forest ParamLgl    NA    NA       2           TRUE                 
##                               id    class lower upper nlevels        default    parents value</code></pre>
<p>Define the hyperparameter space of the random forest:</p>
<div class="sourceCode" id="cb653"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb653-1"><a href="fundamental.html#cb653-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(paradox)</span>
<span id="cb653-2"><a href="fundamental.html#cb653-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb653-3"><a href="fundamental.html#cb653-3" aria-hidden="true" tabindex="-1"></a>rf_pars <span class="ot">=</span> </span>
<span id="cb653-4"><a href="fundamental.html#cb653-4" aria-hidden="true" tabindex="-1"></a>    paradox<span class="sc">::</span>ParamSet<span class="sc">$</span><span class="fu">new</span>(</span>
<span id="cb653-5"><a href="fundamental.html#cb653-5" aria-hidden="true" tabindex="-1"></a>      <span class="fu">list</span>(paradox<span class="sc">::</span>ParamInt<span class="sc">$</span><span class="fu">new</span>(<span class="st">&quot;min.node.size&quot;</span>, <span class="at">lower =</span> <span class="dv">1</span>, <span class="at">upper =</span> 30L),</span>
<span id="cb653-6"><a href="fundamental.html#cb653-6" aria-hidden="true" tabindex="-1"></a>           paradox<span class="sc">::</span>ParamInt<span class="sc">$</span><span class="fu">new</span>(<span class="st">&quot;mtry&quot;</span>, <span class="at">lower =</span> <span class="dv">1</span>, <span class="at">upper =</span> 30L),</span>
<span id="cb653-7"><a href="fundamental.html#cb653-7" aria-hidden="true" tabindex="-1"></a>           paradox<span class="sc">::</span>ParamLgl<span class="sc">$</span><span class="fu">new</span>(<span class="st">&quot;regularization.usedepth&quot;</span>, <span class="at">default =</span> <span class="cn">TRUE</span>)))</span>
<span id="cb653-8"><a href="fundamental.html#cb653-8" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rf_pars)</span></code></pre></div>
<pre><code>## &lt;ParamSet&gt;
##                         id    class lower upper nlevels        default value
## 1:           min.node.size ParamInt     1    30      30 &lt;NoDefault[3]&gt;      
## 2:                    mtry ParamInt     1    30      30 &lt;NoDefault[3]&gt;      
## 3: regularization.usedepth ParamLgl    NA    NA       2           TRUE</code></pre>
<p>To set up the tuning pipeline we need:</p>
<ul>
<li>Inner cross-validation resampling object.</li>
<li>Tuning criterion (e.g. AUC).</li>
<li>Tuning method (e.g. random or block search).</li>
<li>Tuning terminator (When should we stop tuning? E.g. after <span class="math inline">\(n\)</span> iterations).</li>
</ul>
<div class="sourceCode" id="cb655"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb655-1"><a href="fundamental.html#cb655-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb655-2"><a href="fundamental.html#cb655-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb655-3"><a href="fundamental.html#cb655-3" aria-hidden="true" tabindex="-1"></a>inner3 <span class="ot">=</span> mlr3<span class="sc">::</span><span class="fu">rsmp</span>(<span class="st">&quot;cv&quot;</span>, <span class="at">folds =</span> 3L)</span>
<span id="cb655-4"><a href="fundamental.html#cb655-4" aria-hidden="true" tabindex="-1"></a>measurement <span class="ot">=</span>  <span class="fu">msr</span>(<span class="st">&quot;classif.auc&quot;</span>)</span>
<span id="cb655-5"><a href="fundamental.html#cb655-5" aria-hidden="true" tabindex="-1"></a>tuner <span class="ot">=</span>  mlr3tuning<span class="sc">::</span><span class="fu">tnr</span>(<span class="st">&quot;random_search&quot;</span>) </span>
<span id="cb655-6"><a href="fundamental.html#cb655-6" aria-hidden="true" tabindex="-1"></a>terminator <span class="ot">=</span> mlr3tuning<span class="sc">::</span><span class="fu">trm</span>(<span class="st">&quot;evals&quot;</span>, <span class="at">n_evals =</span> 5L)</span>
<span id="cb655-7"><a href="fundamental.html#cb655-7" aria-hidden="true" tabindex="-1"></a>rf <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">&quot;classif.ranger&quot;</span>, <span class="at">predict_type =</span> <span class="st">&quot;prob&quot;</span>)</span>
<span id="cb655-8"><a href="fundamental.html#cb655-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb655-9"><a href="fundamental.html#cb655-9" aria-hidden="true" tabindex="-1"></a>learner_tuner <span class="ot">=</span> AutoTuner<span class="sc">$</span><span class="fu">new</span>(<span class="at">learner =</span> rf, </span>
<span id="cb655-10"><a href="fundamental.html#cb655-10" aria-hidden="true" tabindex="-1"></a>                              <span class="at">measure =</span> measurement, </span>
<span id="cb655-11"><a href="fundamental.html#cb655-11" aria-hidden="true" tabindex="-1"></a>                              <span class="at">tuner =</span> tuner, </span>
<span id="cb655-12"><a href="fundamental.html#cb655-12" aria-hidden="true" tabindex="-1"></a>                              <span class="at">terminator =</span> terminator,</span>
<span id="cb655-13"><a href="fundamental.html#cb655-13" aria-hidden="true" tabindex="-1"></a>                              <span class="at">search_space =</span> rf_pars,</span>
<span id="cb655-14"><a href="fundamental.html#cb655-14" aria-hidden="true" tabindex="-1"></a>                              <span class="at">resampling =</span> inner3)</span>
<span id="cb655-15"><a href="fundamental.html#cb655-15" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(learner_tuner)</span></code></pre></div>
<pre><code>## &lt;AutoTuner:classif.ranger.tuned&gt;
## * Model: -
## * Search Space:
## &lt;ParamSet&gt;
##                         id    class lower upper nlevels        default value
## 1:           min.node.size ParamInt     1    30      30 &lt;NoDefault[3]&gt;      
## 2:                    mtry ParamInt     1    30      30 &lt;NoDefault[3]&gt;      
## 3: regularization.usedepth ParamLgl    NA    NA       2           TRUE      
## * Packages: mlr3, ranger
## * Predict Type: prob
## * Feature Types: logical, integer, numeric, character, factor, ordered
## * Properties: importance, multiclass, oob_error, twoclass, weights</code></pre>
<p>Now we can wrap it normally into the 10-fold cross-validated setup as done previously:</p>
<div class="sourceCode" id="cb657"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb657-1"><a href="fundamental.html#cb657-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb657-2"><a href="fundamental.html#cb657-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb657-3"><a href="fundamental.html#cb657-3" aria-hidden="true" tabindex="-1"></a>outer3 <span class="ot">=</span> mlr3<span class="sc">::</span><span class="fu">rsmp</span>(<span class="st">&quot;cv&quot;</span>, <span class="at">folds =</span> 3L)</span>
<span id="cb657-4"><a href="fundamental.html#cb657-4" aria-hidden="true" tabindex="-1"></a>result <span class="ot">=</span> mlr3<span class="sc">::</span><span class="fu">resample</span>(transformed_task, learner_tuner,</span>
<span id="cb657-5"><a href="fundamental.html#cb657-5" aria-hidden="true" tabindex="-1"></a>                        <span class="at">resampling =</span> outer3, <span class="at">store_models =</span> <span class="cn">TRUE</span>)</span>
<span id="cb657-6"><a href="fundamental.html#cb657-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb657-7"><a href="fundamental.html#cb657-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the average AUC of the holdouts.</span></span>
<span id="cb657-8"><a href="fundamental.html#cb657-8" aria-hidden="true" tabindex="-1"></a>result<span class="sc">$</span><span class="fu">aggregate</span>(measurement)</span></code></pre></div>
<p>Yeah, we were able to improve the performance!</p>
<p>Let’s create the final predictions:</p>
<div class="sourceCode" id="cb658"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb658-1"><a href="fundamental.html#cb658-1" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="cf">function</span>(i) result<span class="sc">$</span>learners[[i]]<span class="sc">$</span><span class="fu">predict</span>(transformed_task,</span>
<span id="cb658-2"><a href="fundamental.html#cb658-2" aria-hidden="true" tabindex="-1"></a><span class="at">row_ids =</span> (<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(data))[<span class="fu">is.na</span>(data<span class="sc">$</span>Hazardous)])<span class="sc">$</span>data<span class="sc">$</span>prob[, <span class="st">&quot;1&quot;</span>, <span class="at">drop =</span> <span class="cn">FALSE</span>])</span>
<span id="cb658-3"><a href="fundamental.html#cb658-3" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(pred)</span>
<span id="cb658-4"><a href="fundamental.html#cb658-4" aria-hidden="true" tabindex="-1"></a>predictions <span class="ot">=</span> <span class="fu">apply</span>(pred, <span class="dv">1</span>, mean)</span></code></pre></div>
</div>
<div id="mlr3---hyperparameter-tuning-with-oversampling" class="section level3" number="4.6.3">
<h3><span class="header-section-number">4.6.3</span> mlr3 - Hyperparameter Tuning with Oversampling</h3>
<p>Let’s go one step back, maybe you have noticed that our classes are unbalanced:</p>
<div class="sourceCode" id="cb659"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb659-1"><a href="fundamental.html#cb659-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(data<span class="sc">$</span>Hazardous)</span></code></pre></div>
<pre><code>## 
##   0   1 
## 412  88</code></pre>
<p>Many machine learning algorithms have problems with unbalanced data because if the imbalance is too strong it is cheaper for the algorithm to focus on only one class (e.g. by predicting only 0s or 1s). You need to keep in mind that machine learning algorithms are greedy and their main focus is to minimize the loss function.</p>
<p>There are few techniques to correct for imbalance:</p>
<ul>
<li>Oversampling (oversample the undersampled class).</li>
<li>Undersampling (undersample the oversampled class).</li>
<li>SMOTE <em>Synthetic Minority Over-sampling Technique</em> (very briefly, we will use a k-nearest-neighbors classification to create new samples around our undersampled class).</li>
</ul>
<p>Here, we will use oversampling which we can do by extending our random forest learner:</p>
<div class="sourceCode" id="cb661"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb661-1"><a href="fundamental.html#cb661-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb661-2"><a href="fundamental.html#cb661-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb661-3"><a href="fundamental.html#cb661-3" aria-hidden="true" tabindex="-1"></a>rf_over <span class="ot">=</span> <span class="fu">po</span>(<span class="st">&quot;classbalancing&quot;</span>, <span class="at">id =</span> <span class="st">&quot;over&quot;</span>, <span class="at">adjust =</span> <span class="st">&quot;minor&quot;</span>) <span class="sc">%&gt;&gt;%</span> rf</span>
<span id="cb661-4"><a href="fundamental.html#cb661-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb661-5"><a href="fundamental.html#cb661-5" aria-hidden="true" tabindex="-1"></a><span class="co"># However rf_over is now a &quot;graph&quot;,</span></span>
<span id="cb661-6"><a href="fundamental.html#cb661-6" aria-hidden="true" tabindex="-1"></a><span class="co"># but we can easily transform it back into a learner:</span></span>
<span id="cb661-7"><a href="fundamental.html#cb661-7" aria-hidden="true" tabindex="-1"></a>rf_over_learner <span class="ot">=</span> GraphLearner<span class="sc">$</span><span class="fu">new</span>(rf_over)</span>
<span id="cb661-8"><a href="fundamental.html#cb661-8" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rf_over_learner)</span></code></pre></div>
<pre><code>## &lt;GraphLearner:over.classif.ranger&gt;
## * Model: -
## * Parameters: over.ratio=1, over.reference=all, over.adjust=minor, over.shuffle=TRUE,
##   classif.ranger.num.threads=1
## * Packages: mlr3, mlr3pipelines
## * Predict Type: prob
## * Feature types: logical, integer, numeric, character, factor, ordered, POSIXct
## * Properties: featureless, hotstart_backward, hotstart_forward, importance, loglik, missings, multiclass,
##   oob_error, selected_features, twoclass, weights</code></pre>
<p>The learner has now a new feature space:</p>
<div class="sourceCode" id="cb663"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb663-1"><a href="fundamental.html#cb663-1" aria-hidden="true" tabindex="-1"></a>rf_over_learner<span class="sc">$</span>param_set</span></code></pre></div>
<pre><code>## &lt;ParamSetCollection&gt;
##                                              id    class lower upper nlevels        default                   parents value
##  1:                        classif.ranger.alpha ParamDbl  -Inf   Inf     Inf            0.5                                
##  2:       classif.ranger.always.split.variables ParamUty    NA    NA     Inf &lt;NoDefault[3]&gt;                                
##  3:                classif.ranger.class.weights ParamDbl  -Inf   Inf     Inf                                               
##  4:                      classif.ranger.holdout ParamLgl    NA    NA       2          FALSE                                
##  5:                   classif.ranger.importance ParamFct    NA    NA       4 &lt;NoDefault[3]&gt;                                
##  6:                   classif.ranger.keep.inbag ParamLgl    NA    NA       2          FALSE                                
##  7:                    classif.ranger.max.depth ParamInt     0   Inf     Inf                                               
##  8:                classif.ranger.min.node.size ParamInt     1   Inf     Inf              1                                
##  9:                     classif.ranger.min.prop ParamDbl  -Inf   Inf     Inf            0.1                                
## 10:                      classif.ranger.minprop ParamDbl  -Inf   Inf     Inf            0.1                                
## 11:                         classif.ranger.mtry ParamInt     1   Inf     Inf &lt;NoDefault[3]&gt;                                
## 12:                   classif.ranger.mtry.ratio ParamDbl     0     1     Inf &lt;NoDefault[3]&gt;                                
## 13:            classif.ranger.num.random.splits ParamInt     1   Inf     Inf              1  classif.ranger.splitrule      
## 14:                  classif.ranger.num.threads ParamInt     1   Inf     Inf              1                               1
## 15:                    classif.ranger.num.trees ParamInt     1   Inf     Inf            500                                
## 16:                    classif.ranger.oob.error ParamLgl    NA    NA       2           TRUE                                
## 17:        classif.ranger.regularization.factor ParamUty    NA    NA     Inf              1                                
## 18:      classif.ranger.regularization.usedepth ParamLgl    NA    NA       2          FALSE                                
## 19:                      classif.ranger.replace ParamLgl    NA    NA       2           TRUE                                
## 20:    classif.ranger.respect.unordered.factors ParamFct    NA    NA       3         ignore                                
## 21:              classif.ranger.sample.fraction ParamDbl     0     1     Inf &lt;NoDefault[3]&gt;                                
## 22:                  classif.ranger.save.memory ParamLgl    NA    NA       2          FALSE                                
## 23: classif.ranger.scale.permutation.importance ParamLgl    NA    NA       2          FALSE classif.ranger.importance      
## 24:                    classif.ranger.se.method ParamFct    NA    NA       2        infjack                                
## 25:                         classif.ranger.seed ParamInt  -Inf   Inf     Inf                                               
## 26:         classif.ranger.split.select.weights ParamDbl     0     1     Inf &lt;NoDefault[3]&gt;                                
## 27:                    classif.ranger.splitrule ParamFct    NA    NA       2           gini                                
## 28:                      classif.ranger.verbose ParamLgl    NA    NA       2           TRUE                                
## 29:                 classif.ranger.write.forest ParamLgl    NA    NA       2           TRUE                                
## 30:                                 over.adjust ParamFct    NA    NA       7 &lt;NoDefault[3]&gt;                           minor
## 31:                                  over.ratio ParamDbl     0   Inf     Inf &lt;NoDefault[3]&gt;                               1
## 32:                              over.reference ParamFct    NA    NA       6 &lt;NoDefault[3]&gt;                             all
## 33:                                over.shuffle ParamLgl    NA    NA       2 &lt;NoDefault[3]&gt;                            TRUE
##                                              id    class lower upper nlevels        default                   parents value</code></pre>
<p>We can also tune the oversampling rate!</p>
<div class="sourceCode" id="cb665"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb665-1"><a href="fundamental.html#cb665-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb665-2"><a href="fundamental.html#cb665-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb665-3"><a href="fundamental.html#cb665-3" aria-hidden="true" tabindex="-1"></a>rf_pars_over <span class="ot">=</span> </span>
<span id="cb665-4"><a href="fundamental.html#cb665-4" aria-hidden="true" tabindex="-1"></a>    paradox<span class="sc">::</span>ParamSet<span class="sc">$</span><span class="fu">new</span>(</span>
<span id="cb665-5"><a href="fundamental.html#cb665-5" aria-hidden="true" tabindex="-1"></a>      <span class="fu">list</span>(paradox<span class="sc">::</span>ParamInt<span class="sc">$</span><span class="fu">new</span>(<span class="st">&quot;over.ratio&quot;</span>, <span class="at">lower =</span> <span class="dv">1</span>, <span class="at">upper =</span> 7L),</span>
<span id="cb665-6"><a href="fundamental.html#cb665-6" aria-hidden="true" tabindex="-1"></a>           paradox<span class="sc">::</span>ParamInt<span class="sc">$</span><span class="fu">new</span>(<span class="st">&quot;classif.ranger.min.node.size&quot;</span>,</span>
<span id="cb665-7"><a href="fundamental.html#cb665-7" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">lower =</span> <span class="dv">1</span>, <span class="at">upper =</span> 30L),</span>
<span id="cb665-8"><a href="fundamental.html#cb665-8" aria-hidden="true" tabindex="-1"></a>           paradox<span class="sc">::</span>ParamInt<span class="sc">$</span><span class="fu">new</span>(<span class="st">&quot;classif.ranger.mtry&quot;</span>, <span class="at">lower =</span> <span class="dv">1</span>,</span>
<span id="cb665-9"><a href="fundamental.html#cb665-9" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">upper =</span> 30L),</span>
<span id="cb665-10"><a href="fundamental.html#cb665-10" aria-hidden="true" tabindex="-1"></a>           paradox<span class="sc">::</span>ParamLgl<span class="sc">$</span><span class="fu">new</span>(<span class="st">&quot;classif.ranger.regularization.usedepth&quot;</span>,</span>
<span id="cb665-11"><a href="fundamental.html#cb665-11" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">default =</span> <span class="cn">TRUE</span>)))</span>
<span id="cb665-12"><a href="fundamental.html#cb665-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb665-13"><a href="fundamental.html#cb665-13" aria-hidden="true" tabindex="-1"></a>inner3 <span class="ot">=</span> mlr3<span class="sc">::</span><span class="fu">rsmp</span>(<span class="st">&quot;cv&quot;</span>, <span class="at">folds =</span> 3L)</span>
<span id="cb665-14"><a href="fundamental.html#cb665-14" aria-hidden="true" tabindex="-1"></a>measurement <span class="ot">=</span>  <span class="fu">msr</span>(<span class="st">&quot;classif.auc&quot;</span>)</span>
<span id="cb665-15"><a href="fundamental.html#cb665-15" aria-hidden="true" tabindex="-1"></a>tuner <span class="ot">=</span>  mlr3tuning<span class="sc">::</span><span class="fu">tnr</span>(<span class="st">&quot;random_search&quot;</span>) </span>
<span id="cb665-16"><a href="fundamental.html#cb665-16" aria-hidden="true" tabindex="-1"></a>terminator <span class="ot">=</span> mlr3tuning<span class="sc">::</span><span class="fu">trm</span>(<span class="st">&quot;evals&quot;</span>, <span class="at">n_evals =</span> 5L)</span>
<span id="cb665-17"><a href="fundamental.html#cb665-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb665-18"><a href="fundamental.html#cb665-18" aria-hidden="true" tabindex="-1"></a>learner_tuner_over <span class="ot">=</span> AutoTuner<span class="sc">$</span><span class="fu">new</span>(<span class="at">learner =</span> rf_over_learner, </span>
<span id="cb665-19"><a href="fundamental.html#cb665-19" aria-hidden="true" tabindex="-1"></a>                                   <span class="at">measure =</span> measurement, </span>
<span id="cb665-20"><a href="fundamental.html#cb665-20" aria-hidden="true" tabindex="-1"></a>                                   <span class="at">tuner =</span> tuner, </span>
<span id="cb665-21"><a href="fundamental.html#cb665-21" aria-hidden="true" tabindex="-1"></a>                                   <span class="at">terminator =</span> terminator,</span>
<span id="cb665-22"><a href="fundamental.html#cb665-22" aria-hidden="true" tabindex="-1"></a>                                   <span class="at">search_space =</span> rf_pars_over,</span>
<span id="cb665-23"><a href="fundamental.html#cb665-23" aria-hidden="true" tabindex="-1"></a>                                   <span class="at">resampling =</span> inner3)</span>
<span id="cb665-24"><a href="fundamental.html#cb665-24" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(learner_tuner)</span></code></pre></div>
<pre><code>## &lt;AutoTuner:classif.ranger.tuned&gt;
## * Model: -
## * Search Space:
## &lt;ParamSet&gt;
##                         id    class lower upper nlevels        default value
## 1:           min.node.size ParamInt     1    30      30 &lt;NoDefault[3]&gt;      
## 2:                    mtry ParamInt     1    30      30 &lt;NoDefault[3]&gt;      
## 3: regularization.usedepth ParamLgl    NA    NA       2           TRUE      
## * Packages: mlr3, ranger
## * Predict Type: prob
## * Feature Types: logical, integer, numeric, character, factor, ordered
## * Properties: importance, multiclass, oob_error, twoclass, weights</code></pre>
<div class="sourceCode" id="cb667"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb667-1"><a href="fundamental.html#cb667-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb667-2"><a href="fundamental.html#cb667-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb667-3"><a href="fundamental.html#cb667-3" aria-hidden="true" tabindex="-1"></a>outer3 <span class="ot">=</span> mlr3<span class="sc">::</span><span class="fu">rsmp</span>(<span class="st">&quot;cv&quot;</span>, <span class="at">folds =</span> 3L)</span>
<span id="cb667-4"><a href="fundamental.html#cb667-4" aria-hidden="true" tabindex="-1"></a>result <span class="ot">=</span> mlr3<span class="sc">::</span><span class="fu">resample</span>(transformed_task, learner_tuner_over,</span>
<span id="cb667-5"><a href="fundamental.html#cb667-5" aria-hidden="true" tabindex="-1"></a>                        <span class="at">resampling =</span> outer3, <span class="at">store_models =</span> <span class="cn">TRUE</span>)</span>
<span id="cb667-6"><a href="fundamental.html#cb667-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb667-7"><a href="fundamental.html#cb667-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the average AUC of the holdouts.</span></span>
<span id="cb667-8"><a href="fundamental.html#cb667-8" aria-hidden="true" tabindex="-1"></a>result<span class="sc">$</span><span class="fu">aggregate</span>(measurement)</span></code></pre></div>
<p>5 iterations in the hyperspace is not very much…</p>
<p>Let’s create the final predictions:</p>
<div class="sourceCode" id="cb668"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb668-1"><a href="fundamental.html#cb668-1" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="cf">function</span>(i) result<span class="sc">$</span>learners[[i]]<span class="sc">$</span><span class="fu">predict</span>(transformed_task,</span>
<span id="cb668-2"><a href="fundamental.html#cb668-2" aria-hidden="true" tabindex="-1"></a><span class="at">row_ids =</span> (<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(data))[<span class="fu">is.na</span>(data<span class="sc">$</span>Hazardous)])<span class="sc">$</span>data<span class="sc">$</span>prob[, <span class="st">&quot;1&quot;</span>, <span class="at">drop =</span> <span class="cn">FALSE</span>])</span>
<span id="cb668-3"><a href="fundamental.html#cb668-3" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(pred)</span>
<span id="cb668-4"><a href="fundamental.html#cb668-4" aria-hidden="true" tabindex="-1"></a>predictions <span class="ot">=</span> <span class="fu">apply</span>(pred, <span class="dv">1</span>, mean)</span></code></pre></div>
  <hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Optional bonus task</span></strong><br/>
<p>After reading the above chapter about the mlr package, try to transfer it to the titanic data set (use the titanic_ml data set, this has already NAs for the values to predict).
Alternatively, you can also use other data sets from our challenge (e.g. the plant-pollinator data set, see the data set chapter <a href="datasets.html#datasets">8</a>).</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<div class="sourceCode" id="cb669"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb669-1"><a href="fundamental.html#cb669-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(EcoData)</span>
<span id="cb669-2"><a href="fundamental.html#cb669-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb669-3"><a href="fundamental.html#cb669-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3)</span>
<span id="cb669-4"><a href="fundamental.html#cb669-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3learners)</span>
<span id="cb669-5"><a href="fundamental.html#cb669-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3pipelines)</span>
<span id="cb669-6"><a href="fundamental.html#cb669-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3tuning)</span>
<span id="cb669-7"><a href="fundamental.html#cb669-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3measures)</span>
<span id="cb669-8"><a href="fundamental.html#cb669-8" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb669-9"><a href="fundamental.html#cb669-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb669-10"><a href="fundamental.html#cb669-10" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(titanic_ml)</span>
<span id="cb669-11"><a href="fundamental.html#cb669-11" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(titanic_ml)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    1309 obs. of  14 variables:
##  $ pclass   : int  2 1 3 3 3 3 3 1 3 1 ...
##  $ survived : int  1 1 0 0 0 0 0 1 0 1 ...
##  $ name     : chr  &quot;Sinkkonen, Miss. Anna&quot; &quot;Woolner, Mr. Hugh&quot; &quot;Sage, Mr. Douglas Bullen&quot; &quot;Palsson, Master. Paul Folke&quot; ...
##  $ sex      : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 1 2 2 2 2 2 2 1 1 1 ...
##  $ age      : num  30 NA NA 6 30.5 38.5 20 53 NA 42 ...
##  $ sibsp    : int  0 0 8 3 0 0 0 0 0 0 ...
##  $ parch    : int  0 0 2 1 0 0 0 0 0 0 ...
##  $ ticket   : Factor w/ 929 levels &quot;110152&quot;,&quot;110413&quot;,..: 221 123 779 542 589 873 472 823 588 834 ...
##  $ fare     : num  13 35.5 69.55 21.07 8.05 ...
##  $ cabin    : Factor w/ 187 levels &quot;&quot;,&quot;A10&quot;,&quot;A11&quot;,..: 1 94 1 1 1 1 1 1 1 1 ...
##  $ embarked : Factor w/ 4 levels &quot;&quot;,&quot;C&quot;,&quot;Q&quot;,&quot;S&quot;: 4 4 4 4 4 4 4 2 4 2 ...
##  $ boat     : Factor w/ 28 levels &quot;&quot;,&quot;1&quot;,&quot;10&quot;,&quot;11&quot;,..: 3 28 1 1 1 1 1 19 1 15 ...
##  $ body     : int  NA NA NA NA 50 32 NA NA NA NA ...
##  $ home.dest: Factor w/ 370 levels &quot;&quot;,&quot;?Havana, Cuba&quot;,..: 121 213 1 1 1 1 322 350 1 1 ...</code></pre>
<div class="sourceCode" id="cb671"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb671-1"><a href="fundamental.html#cb671-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> titanic_ml <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>name, <span class="sc">-</span>ticket, <span class="sc">-</span>name, <span class="sc">-</span>body)</span>
<span id="cb671-2"><a href="fundamental.html#cb671-2" aria-hidden="true" tabindex="-1"></a>data<span class="sc">$</span>pclass <span class="ot">=</span> <span class="fu">as.factor</span>(data<span class="sc">$</span>pclass)</span>
<span id="cb671-3"><a href="fundamental.html#cb671-3" aria-hidden="true" tabindex="-1"></a>data<span class="sc">$</span>sex <span class="ot">=</span> <span class="fu">as.factor</span>(data<span class="sc">$</span>sex)</span>
<span id="cb671-4"><a href="fundamental.html#cb671-4" aria-hidden="true" tabindex="-1"></a>data<span class="sc">$</span>survived <span class="ot">=</span> <span class="fu">as.factor</span>(data<span class="sc">$</span>survived)</span>
<span id="cb671-5"><a href="fundamental.html#cb671-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb671-6"><a href="fundamental.html#cb671-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Change easy things manually:</span></span>
<span id="cb671-7"><a href="fundamental.html#cb671-7" aria-hidden="true" tabindex="-1"></a>data<span class="sc">$</span>embarked[data<span class="sc">$</span>embarked <span class="sc">==</span> <span class="st">&quot;&quot;</span>] <span class="ot">=</span> <span class="st">&quot;S&quot;</span>  <span class="co"># Fill in &quot;empty&quot; values.</span></span>
<span id="cb671-8"><a href="fundamental.html#cb671-8" aria-hidden="true" tabindex="-1"></a>data<span class="sc">$</span>embarked <span class="ot">=</span> <span class="fu">droplevels</span>(<span class="fu">as.factor</span>(data<span class="sc">$</span>embarked)) <span class="co"># Remove unused levels (&quot;&quot;).</span></span>
<span id="cb671-9"><a href="fundamental.html#cb671-9" aria-hidden="true" tabindex="-1"></a>data<span class="sc">$</span>cabin <span class="ot">=</span> (data<span class="sc">$</span>cabin <span class="sc">!=</span> <span class="st">&quot;&quot;</span>) <span class="sc">*</span> <span class="dv">1</span> <span class="co"># Dummy code the availability of a cabin.</span></span>
<span id="cb671-10"><a href="fundamental.html#cb671-10" aria-hidden="true" tabindex="-1"></a>data<span class="sc">$</span>fare[<span class="fu">is.na</span>(data<span class="sc">$</span>fare)] <span class="ot">=</span> <span class="fu">mean</span>(data<span class="sc">$</span>fare, <span class="at">na.rm =</span> <span class="cn">TRUE</span>)</span>
<span id="cb671-11"><a href="fundamental.html#cb671-11" aria-hidden="true" tabindex="-1"></a><span class="fu">levels</span>(data<span class="sc">$</span>home.dest)[<span class="fu">levels</span>(data<span class="sc">$</span>home.dest) <span class="sc">==</span> <span class="st">&quot;&quot;</span>] <span class="ot">=</span> <span class="st">&quot;unknown&quot;</span></span>
<span id="cb671-12"><a href="fundamental.html#cb671-12" aria-hidden="true" tabindex="-1"></a><span class="fu">levels</span>(data<span class="sc">$</span>boat)[<span class="fu">levels</span>(data<span class="sc">$</span>boat) <span class="sc">==</span> <span class="st">&quot;&quot;</span>] <span class="ot">=</span> <span class="st">&quot;none&quot;</span></span>
<span id="cb671-13"><a href="fundamental.html#cb671-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb671-14"><a href="fundamental.html#cb671-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a classification task.</span></span>
<span id="cb671-15"><a href="fundamental.html#cb671-15" aria-hidden="true" tabindex="-1"></a>task <span class="ot">=</span> TaskClassif<span class="sc">$</span><span class="fu">new</span>(<span class="at">id =</span> <span class="st">&quot;titanic&quot;</span>, <span class="at">backend =</span> data,</span>
<span id="cb671-16"><a href="fundamental.html#cb671-16" aria-hidden="true" tabindex="-1"></a>                       <span class="at">target =</span> <span class="st">&quot;survived&quot;</span>, <span class="at">positive =</span> <span class="st">&quot;1&quot;</span>)</span>
<span id="cb671-17"><a href="fundamental.html#cb671-17" aria-hidden="true" tabindex="-1"></a>task<span class="sc">$</span><span class="fu">missings</span>()</span></code></pre></div>
<pre><code>##  survived       age      boat     cabin  embarked      fare home.dest     parch    pclass       sex     sibsp 
##       655       263         0         0         0         0         0         0         0         0         0</code></pre>
<div class="sourceCode" id="cb673"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb673-1"><a href="fundamental.html#cb673-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let&#39;s create the preprocessing graph.</span></span>
<span id="cb673-2"><a href="fundamental.html#cb673-2" aria-hidden="true" tabindex="-1"></a>preprocessing <span class="ot">=</span> <span class="fu">po</span>(<span class="st">&quot;imputeoor&quot;</span>) <span class="sc">%&gt;&gt;%</span> <span class="fu">po</span>(<span class="st">&quot;scale&quot;</span>) <span class="sc">%&gt;&gt;%</span> <span class="fu">po</span>(<span class="st">&quot;encode&quot;</span>) </span>
<span id="cb673-3"><a href="fundamental.html#cb673-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb673-4"><a href="fundamental.html#cb673-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the task.</span></span>
<span id="cb673-5"><a href="fundamental.html#cb673-5" aria-hidden="true" tabindex="-1"></a>transformed_task <span class="ot">=</span> preprocessing<span class="sc">$</span><span class="fu">train</span>(task)[[<span class="dv">1</span>]]</span>
<span id="cb673-6"><a href="fundamental.html#cb673-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb673-7"><a href="fundamental.html#cb673-7" aria-hidden="true" tabindex="-1"></a>transformed_task<span class="sc">$</span><span class="fu">set_row_roles</span>((<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(data))[<span class="fu">is.na</span>(data<span class="sc">$</span>survived)], <span class="st">&quot;validation&quot;</span>)</span>
<span id="cb673-8"><a href="fundamental.html#cb673-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb673-9"><a href="fundamental.html#cb673-9" aria-hidden="true" tabindex="-1"></a>cv10 <span class="ot">=</span> mlr3<span class="sc">::</span><span class="fu">rsmp</span>(<span class="st">&quot;cv&quot;</span>, <span class="at">folds =</span> 10L)</span>
<span id="cb673-10"><a href="fundamental.html#cb673-10" aria-hidden="true" tabindex="-1"></a>rf <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">&quot;classif.ranger&quot;</span>, <span class="at">predict_type =</span> <span class="st">&quot;prob&quot;</span>)</span>
<span id="cb673-11"><a href="fundamental.html#cb673-11" aria-hidden="true" tabindex="-1"></a>measurement <span class="ot">=</span>  <span class="fu">msr</span>(<span class="st">&quot;classif.auc&quot;</span>)</span>
<span id="cb673-12"><a href="fundamental.html#cb673-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb673-13"><a href="fundamental.html#cb673-13" aria-hidden="true" tabindex="-1"></a><span class="co"># result = mlr3::resample(transformed_task, rf,</span></span>
<span id="cb673-14"><a href="fundamental.html#cb673-14" aria-hidden="true" tabindex="-1"></a><span class="co">#                         resampling = cv10, store_models = TRUE)</span></span>
<span id="cb673-15"><a href="fundamental.html#cb673-15" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb673-16"><a href="fundamental.html#cb673-16" aria-hidden="true" tabindex="-1"></a><span class="co"># # Calculate the average AUC of the holdouts.</span></span>
<span id="cb673-17"><a href="fundamental.html#cb673-17" aria-hidden="true" tabindex="-1"></a><span class="co"># result$aggregate(measurement)</span></span>
<span id="cb673-18"><a href="fundamental.html#cb673-18" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb673-19"><a href="fundamental.html#cb673-19" aria-hidden="true" tabindex="-1"></a><span class="co"># pred = sapply(1:10, function(i) result$learners[[i]]$predict(transformed_task,</span></span>
<span id="cb673-20"><a href="fundamental.html#cb673-20" aria-hidden="true" tabindex="-1"></a><span class="co"># row_ids = (1:nrow(data))[is.na(data$survived)])$data$prob[, &quot;1&quot;, drop = FALSE])</span></span>
<span id="cb673-21"><a href="fundamental.html#cb673-21" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb673-22"><a href="fundamental.html#cb673-22" aria-hidden="true" tabindex="-1"></a><span class="co"># dim(pred)</span></span>
<span id="cb673-23"><a href="fundamental.html#cb673-23" aria-hidden="true" tabindex="-1"></a><span class="co"># predictions = round(apply(pred, 1, mean))</span></span>
<span id="cb673-24"><a href="fundamental.html#cb673-24" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb673-25"><a href="fundamental.html#cb673-25" aria-hidden="true" tabindex="-1"></a><span class="co"># write.csv(data.frame(y = predictions), file = &quot;submission_RF.csv&quot;)</span></span></code></pre></div>
    </p>
  </details>
  <br/><hr/>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-dormann2018" class="csl-entry">
Dormann, Carsten F, Justin M Calabrese, Gurutzeta Guillera-Arroita, Eleni Matechou, Volker Bahn, Kamil Bartoń, Colin M Beale, et al. 2018. <span>“Model Averaging in Ecology: A Review of Bayesian, Information-Theoretic, and Tactical Approaches for Predictive Inference.”</span> <em>Ecological Monographs</em> 88 (4): 485–504.
</div>
<div id="ref-zou2005" class="csl-entry">
Zou, Hui, and Trevor Hastie. 2005. <span>“Regularization and Variable Selection via the Elastic Net.”</span> <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 67 (2): 301–20.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="deep.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

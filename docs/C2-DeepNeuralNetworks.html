<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.427">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Machine Learning and Deep Learning with R - 9&nbsp; Deep Neural Networks</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./C3-ConvolutionalNeuralNetworks.html" rel="next">
<link href="./C1-TensorFlow.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="include/webex.css">
<meta name="citation_title" content="[9]{.chapter-number}&nbsp; [Deep Neural Networks]{.chapter-title}">
<meta name="citation_fulltext_html_url" content="https://TheoreticalEcology.github.io/machinelearning//C2-DeepNeuralNetworks.html">
<meta name="citation_language" content="en">
<meta name="citation_reference" content="citation_title=Regularization and variable selection via the elastic net;,citation_author=Hui Zou;,citation_author=Trevor Hastie;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_issue=2;,citation_volume=67;,citation_journal_title=Journal of the royal statistical society: series B (statistical methodology);,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Model averaging in ecology: A review of bayesian, information-theoretic, and tactical approaches for predictive inference;,citation_author=Carsten F Dormann;,citation_author=Justin M Calabrese;,citation_author=Gurutzeta Guillera-Arroita;,citation_author=Eleni Matechou;,citation_author=Volker Bahn;,citation_author=Kamil Bartoń;,citation_author=Colin M Beale;,citation_author=Simone Ciuti;,citation_author=Jane Elith;,citation_author=Katharina Gerstner;,citation_author=others;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=4;,citation_volume=88;,citation_journal_title=Ecological Monographs;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Dropout: A simple way to prevent neural networks from overfitting;,citation_author=Nitish Srivastava;,citation_author=Geoffrey Hinton;,citation_author=Alex Krizhevsky;,citation_author=Ilya Sutskever;,citation_author=Ruslan Salakhutdinov;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=1;,citation_volume=15;,citation_journal_title=The journal of machine learning research;,citation_publisher=JMLR. org;">
<meta name="citation_reference" content="citation_title=Machine learning and deep learning—a review for ecologists;,citation_author=Maximilian Pichler;,citation_author=Florian Hartig;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_issue=4;,citation_volume=14;,citation_journal_title=Methods in Ecology and Evolution;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Deep learning as a tool for ecology and evolution;,citation_author=Marek L Borowiec;,citation_author=Rebecca B Dikow;,citation_author=Paul B Frandsen;,citation_author=Alexander McKeeken;,citation_author=Gabriele Valentini;,citation_author=Alexander E White;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_issue=8;,citation_volume=13;,citation_journal_title=Methods in Ecology and Evolution;,citation_publisher=Wiley Online Library;">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./C1-TensorFlow.html">Deep Learning</a></li><li class="breadcrumb-item"><a href="./C2-DeepNeuralNetworks.html"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Deep Neural Networks</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Machine Learning and Deep Learning with R</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/TheoreticalEcology/machinelearning" rel="" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
              <i class="bi bi-bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A1-GettingStarted.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Getting Started</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Machine Learning Workflow</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A2-MachineLearningTasks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Typical Machine Learning Tasks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A3-BiasVarianceTradeOff.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Bias-variance trade-off</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A4-MLpipeline.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Machine learning pipeline</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Machine Learning Algorithms</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B1-Trees.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Tree-based Algorithms</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B2-Distance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Distance-based Algorithms</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B3-NeuralNetworks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Artificial Neural Networks</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Deep Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-TensorFlow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Introduction to TensorFlow and Keras</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-DeepNeuralNetworks.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Deep Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-ConvolutionalNeuralNetworks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Convolutional Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-RecurrentNeuralNetworks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Recurrent Neural Networks</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Appendix-Datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Datasets</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#kerastorch-framework" id="toc-kerastorch-framework" class="nav-link active" data-scroll-target="#kerastorch-framework"><span class="header-section-number">9.1</span> Keras/Torch Framework</a>
  <ul class="collapse">
  <li><a href="#example-workflow-in-keras-torch" id="toc-example-workflow-in-keras-torch" class="nav-link" data-scroll-target="#example-workflow-in-keras-torch"><span class="header-section-number">9.1.1</span> Example workflow in Keras / Torch</a></li>
  </ul></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="header-section-number">9.2</span> Exercises</a></li>
  <li><a href="#basicMath" id="toc-basicMath" class="nav-link" data-scroll-target="#basicMath"><span class="header-section-number">9.3</span> Underlying mathematical concepts - optional</a>
  <ul class="collapse">
  <li><a href="#caveats-of-neural-network-optimization" id="toc-caveats-of-neural-network-optimization" class="nav-link" data-scroll-target="#caveats-of-neural-network-optimization"><span class="header-section-number">9.3.1</span> Caveats of neural network optimization</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/TheoreticalEcology/machinelearning/edit/master/C2-DeepNeuralNetworks.qmd" class="toc-action">Edit this page</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Deep Neural Networks</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="kerastorch-framework" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="kerastorch-framework"><span class="header-section-number">9.1</span> Keras/Torch Framework</h2>
<p>We have seen that we can use TensorFlow directly out of R, and we could use this knowledge to implement a neural network in TensorFlow directly in R. However, this can be quite cumbersome. For simple problems, it is usually faster to use a higher-level API that helps us with implementing the machine learning models in TensorFlow. The most common of those is Keras.</p>
<p>Keras is a powerful framework for building and training neural networks with a few lines of codes. Since the end of 2018, Keras and TensorFlow are completely interoperable, allowing us to utilize the best of both.</p>
<p>The objective of this lesson is to familiarize yourself with Keras. If you have installed TensorFlow, Keras can be found within TensorFlow: tf.keras. However, the RStudio team has built an R package on top of tf.keras, and it is more convenient to use this. To load the Keras package, type</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># or library(torch)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="example-workflow-in-keras-torch" class="level3" data-number="9.1.1">
<h3 data-number="9.1.1" class="anchored" data-anchor-id="example-workflow-in-keras-torch"><span class="header-section-number">9.1.1</span> Example workflow in Keras / Torch</h3>
<p>To show how Keras works, we will now build a small classifier to predict the three species of the iris data set. Load the necessary packages and data sets:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R's random seed.</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(iris)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(iris)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  Sepal.Length Sepal.Width Petal.Length Petal.Width Species
1          5.1         3.5          1.4         0.2  setosa
2          4.9         3.0          1.4         0.2  setosa
3          4.7         3.2          1.3         0.2  setosa
4          4.6         3.1          1.5         0.2  setosa
5          5.0         3.6          1.4         0.2  setosa
6          5.4         3.9          1.7         0.4  setosa</code></pre>
</div>
</div>
<p>For neural networks, it is beneficial to scale the predictors (scaling = centering and standardization, see ?scale). We also split our data into predictors (X) and response (Y = the three species).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">scale</span>(iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span> iris[,<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Additionally, Keras/TensorFlow cannot handle factors and we have to create contrasts (one-hot encoding). To do so, we have to specify the number of categories. This can be tricky for a beginner, because in other programming languages like Python and C++, arrays start at zero. Thus, when we would specify 3 as number of classes for our three species, we would have the classes 0,1,2,3. Keep this in mind.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span> <span class="fu">to_categorical</span>(<span class="fu">as.integer</span>(Y) <span class="sc">-</span> 1L, <span class="dv">3</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(Y) <span class="co"># 3 columns, one for each level of the response.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2] [,3]
[1,]    1    0    0
[2,]    1    0    0
[3,]    1    0    0
[4,]    1    0    0
[5,]    1    0    0
[6,]    1    0    0</code></pre>
</div>
</div>
<p>After having prepared the data, we will now see a typical workflow to specify a model in Keras/Torch.</p>
<p><strong>1. Initialize a sequential model in Keras:</strong></p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true" aria-current="page">Keras</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">Torch</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<p>Torch users can skip this step.</p>
</div>
</div>
</div>
<p>A sequential Keras model is a higher order type of model within Keras and consists of one input and one output model.</p>
<p><strong>2. Add hidden layers to the model (we will learn more about hidden layers during the next days).</strong></p>
<p>When specifying the hidden layers, we also have to specify the shape and a so called <em>activation function</em>. You can think of the activation function as decision for what is forwarded to the next neuron (but we will learn more about it later). If you want to know this topic in even more depth, consider watching the videos presented in section @ref(basicMath).</p>
<p>The shape of the input is the number of predictors (here 4) and the shape of the output is the number of classes (here 3).</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true">Keras</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false">Torch</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">"relu"</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(4L)) <span class="sc">%&gt;%</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L) <span class="sc">%&gt;%</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L) <span class="sc">%&gt;%</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 3L, <span class="at">activation =</span> <span class="st">"softmax"</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<p>The Torch syntax is very similar, we will give a list of layers to the “nn_sequential” function. Here, we have to specify the softmax activation function as an extra layer:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>model_torch <span class="ot">=</span> </span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_sequential</span>(</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(4L, 20L),</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 20L),</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 20L),</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 3L),</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_softmax</span>(<span class="dv">2</span>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<ul>
<li>softmax scales a potential multidimensional vector to the interval <span class="math inline">\((0, 1]\)</span> for each component. The sum of all components equals 1. This might be very useful for example for handling probabilities. <strong>Ensure ther the labels start at 0! Otherwise the softmax function does not work well!</strong></li>
</ul>
<p><strong>3. Compile the model with a loss function (here: cross entropy) and an optimizer (here: Adamax).</strong></p>
<p>We will learn about other options later, so for now, do not worry about the “<strong>learning_rate</strong>” (“<strong>lr</strong>” in Torch or earlier in TensorFlow) argument, cross entropy or the optimizer.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true">Keras</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false">Torch</a></li></ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>          keras<span class="sc">::</span><span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.001</span>))</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential"
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_3 (Dense)                    (None, 20)                      100         
 dense_2 (Dense)                    (None, 20)                      420         
 dense_1 (Dense)                    (None, 20)                      420         
 dense (Dense)                      (None, 3)                       63          
================================================================================
Total params: 1,003
Trainable params: 1,003
Non-trainable params: 0
________________________________________________________________________________</code></pre>
</div>
</div>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<p>Specify optimizer and the parameters which will be trained (in our case the parameters of the network):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>optimizer_torch <span class="ot">=</span> <span class="fu">optim_adam</span>(<span class="at">params =</span> model_torch<span class="sc">$</span>parameters, <span class="at">lr =</span> <span class="fl">0.001</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<p><strong>4. Fit model in 30 iterations (epochs)</strong></p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-4-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-1" role="tab" aria-controls="tabset-4-1" aria-selected="true">Keras</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-2" role="tab" aria-controls="tabset-4-2" aria-selected="false">Torch</a></li></ul>
<div class="tab-content">
<div id="tabset-4-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-4-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R's random seed.</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> <span class="fu">apply</span>(Y, <span class="dv">2</span>, as.integer), <span class="at">epochs =</span> 30L,</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>        <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-4-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-2-tab">
<p>In Torch, we jump directly to the training loop, however, here we have to write our own training loop:</p>
<ol type="1">
<li>Get a batch of data.</li>
<li>Predict on batch.</li>
<li>Ccalculate loss between predictions and true labels.</li>
<li>Backpropagate error.</li>
<li>Update weights.</li>
<li>Go to step 1 and repeat.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_manual_seed</span>(321L)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate number of training steps.</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> <span class="dv">30</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>batch_size <span class="ot">=</span> <span class="dv">20</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>steps <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">nrow</span>(X)<span class="sc">/</span>batch_size <span class="sc">*</span> epochs)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>X_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(X)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>Y_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fu">apply</span>(Y, <span class="dv">1</span>, which.max)) </span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Set model into training status.</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>model_torch<span class="sc">$</span><span class="fu">train</span>()</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>log_losses <span class="ot">=</span> <span class="cn">NULL</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Training loop.</span></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>steps){</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Get batch.</span></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(X), batch_size)</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Reset backpropagation.</span></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>  optimizer_torch<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Predict and calculate loss.</span></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">=</span> <span class="fu">model_torch</span>(X_torch[indices, ])</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>  loss <span class="ot">=</span> <span class="fu">nnf_cross_entropy</span>(pred, Y_torch[indices])</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Backpropagation and weight update.</span></span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>  loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>  optimizer_torch<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>  log_losses[i] <span class="ot">=</span> <span class="fu">as.numeric</span>(loss)</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<p><strong>5. Plot training history:</strong></p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-5-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-1" role="tab" aria-controls="tabset-5-1" aria-selected="true">Keras</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-2" role="tab" aria-controls="tabset-5-2" aria-selected="false">Torch</a></li></ul>
<div class="tab-content">
<div id="tabset-5-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-5-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C2-DeepNeuralNetworks_files/figure-html/chunk_chapter3_72-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</div>
<div id="tabset-5-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(log_losses, <span class="at">xlab =</span> <span class="st">"steps"</span>, <span class="at">ylab =</span> <span class="st">"loss"</span>, <span class="at">las =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C2-DeepNeuralNetworks_files/figure-html/chunk_chapter3_73-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</div>
</div>
</div>
<p><strong>6. Create predictions:</strong></p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-6-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-1" role="tab" aria-controls="tabset-6-1" aria-selected="true">Keras</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-6-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-2" role="tab" aria-controls="tabset-6-2" aria-selected="false">Torch</a></li></ul>
<div class="tab-content">
<div id="tabset-6-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-6-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>predictions <span class="ot">=</span> <span class="fu">predict</span>(model, X) <span class="co"># Probabilities for each class.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Get probabilities:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(predictions) <span class="co"># Quasi-probabilities for each species.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          [,1]        [,2]         [,3]
[1,] 0.9915600 0.006817889 0.0016221496
[2,] 0.9584184 0.037489697 0.0040918575
[3,] 0.9910416 0.007848956 0.0011094128
[4,] 0.9813542 0.016901711 0.0017440914
[5,] 0.9949830 0.004031503 0.0009855649
[6,] 0.9905725 0.006884387 0.0025430375</code></pre>
</div>
</div>
<p>For each plant, we want to know for which species we got the highest probability:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">=</span> <span class="fu">apply</span>(predictions, <span class="dv">1</span>, which.max) </span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(preds)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [38] 1 1 1 1 2 1 1 1 1 1 1 1 1 3 3 3 2 2 2 3 2 2 2 2 2 2 2 2 3 2 2 2 2 3 2 2 2
 [75] 2 2 2 3 2 2 2 2 2 2 2 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 2 3 3 3 3
[112] 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3
[149] 3 3</code></pre>
</div>
</div>
</div>
<div id="tabset-6-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-6-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>model_torch<span class="sc">$</span><span class="fu">eval</span>()</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>preds_torch <span class="ot">=</span> <span class="fu">model_torch</span>(<span class="fu">torch_tensor</span>(X))</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>preds_torch <span class="ot">=</span> <span class="fu">apply</span>(preds_torch, <span class="dv">1</span>, which.max) </span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(preds_torch)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2
 [75] 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3
[112] 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3
[149] 3 3</code></pre>
</div>
</div>
</div>
</div>
</div>
<p><strong>7. Calculate Accuracy (how often we have been correct):</strong></p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-7-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-1" role="tab" aria-controls="tabset-7-1" aria-selected="true">Keras</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-7-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-2" role="tab" aria-controls="tabset-7-2" aria-selected="false">Torch</a></li></ul>
<div class="tab-content">
<div id="tabset-7-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-7-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(preds <span class="sc">==</span> <span class="fu">as.integer</span>(iris<span class="sc">$</span>Species))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9066667</code></pre>
</div>
</div>
</div>
<div id="tabset-7-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-7-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(preds_torch <span class="sc">==</span> <span class="fu">as.integer</span>(iris<span class="sc">$</span>Species))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9733333</code></pre>
</div>
</div>
</div>
</div>
</div>
<p><strong>8. Plot predictions, to see if we have done a good job:</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>oldpar <span class="ot">=</span> <span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(iris<span class="sc">$</span>Sepal.Length, iris<span class="sc">$</span>Petal.Length, <span class="at">col =</span> iris<span class="sc">$</span>Species,</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Observed"</span>)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(iris<span class="sc">$</span>Sepal.Length, iris<span class="sc">$</span>Petal.Length, <span class="at">col =</span> preds,</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Predicted"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C2-DeepNeuralNetworks_files/figure-html/chunk_chapter3_79-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(oldpar)   <span class="co"># Reset par.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>So you see, building a neural network is very easy with Keras or Torch and you can already do it on your own.</p>
</section>
</section>
<section id="exercises" class="level2" data-number="9.2">
<h2 data-number="9.2" class="anchored" data-anchor-id="exercises"><span class="header-section-number">9.2</span> Exercises</h2>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Task: Regression with keras
</div>
</div>
<div class="callout-body-container callout-body">
<p>We now build a regression for the airquality data set with Keras/Torch. We want to predict the variable “Ozone” (continuous).</p>
<p>Tasks:</p>
<ol type="1">
<li>Complete the steps and the code chunk so that the model is successfully trained!</li>
<li>Try different learning rates and neural network sizes (increase/decrease number of hidden layers and neurons (units) in each layer). What happens?</li>
</ol>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-8-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-1" role="tab" aria-controls="tabset-8-1" aria-selected="true">Keras</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-8-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-2" role="tab" aria-controls="tabset-8-2" aria-selected="false">Torch</a></li></ul>
<div class="tab-content">
<div id="tabset-8-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-8-1-tab">
<ol start="0" type="1">
<li>Load and prepare the data set:</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R's random seed.</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Explore the data with summary() and plot():</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     Ozone           Solar.R           Wind             Temp      
 Min.   :  1.00   Min.   :  7.0   Min.   : 1.700   Min.   :56.00  
 1st Qu.: 18.00   1st Qu.:115.8   1st Qu.: 7.400   1st Qu.:72.00  
 Median : 31.50   Median :205.0   Median : 9.700   Median :79.00  
 Mean   : 42.13   Mean   :185.9   Mean   : 9.958   Mean   :77.88  
 3rd Qu.: 63.25   3rd Qu.:258.8   3rd Qu.:11.500   3rd Qu.:85.00  
 Max.   :168.00   Max.   :334.0   Max.   :20.700   Max.   :97.00  
 NA's   :37       NA's   :7                                       
     Month            Day      
 Min.   :5.000   Min.   : 1.0  
 1st Qu.:6.000   1st Qu.: 8.0  
 Median :7.000   Median :16.0  
 Mean   :6.993   Mean   :15.8  
 3rd Qu.:8.000   3rd Qu.:23.0  
 Max.   :9.000   Max.   :31.0  
                               </code></pre>
</div>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C2-DeepNeuralNetworks_files/figure-html/chunk_chapter3_task_27-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<ol type="1">
<li><p>There are NAs in the data, which we have to remove because Keras cannot handle NAs. If you don’t know how to remove NAs from a data.frame, use Google (e.g.&nbsp;with the query: “remove-rows-with-all-or-some-nas-missing-values-in-data-frame”).</p></li>
<li><p>Split the data in predictors (<span class="math inline">\(\boldsymbol{X}\)</span>) and response (<span class="math inline">\(\boldsymbol{y}\)</span>, Ozone) and scale the <span class="math inline">\(\boldsymbol{X}\)</span> matrix.</p></li>
<li><p>Build a sequential Keras model.</p></li>
<li><p>Add hidden layers (input and output layer are already specified, you have to add hidden layers between them):</p></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">"relu"</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(5L)) <span class="sc">%&gt;%</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>   ....</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">"linear"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>Why do we use 5L as input shape?</li>
<li>Why only one output node and “linear” activation layer?</li>
</ul>
<ol start="5" type="1">
<li>Compile model.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.05</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>What is the “mean_squared_error” loss?</p>
<ol start="6" type="1">
<li>Fit model:</li>
</ol>
<p>Tip: Only matrices are accepted for <span class="math inline">\(\boldsymbol{X}\)</span> and <span class="math inline">\(\boldsymbol{y}\)</span> by Keras. R often drops a one column matrix into a vector (change it back to a matrix!)</p>
<ol start="7" type="1">
<li><p>Plot training history.</p></li>
<li><p>Create predictions.</p></li>
<li><p>Compare your Keras model with a linear model:</p></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">lm</span>(Ozone <span class="sc">~</span> ., <span class="at">data =</span> data)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>pred_lm <span class="ot">=</span> <span class="fu">predict</span>(fit, data)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>rmse_lm <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_lm)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>rmse_keras <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_keras)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_lm)</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_keras)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-8-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-8-2-tab">
<ol start="0" type="1">
<li>Load and prepare the data set:</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Explore the data with summary() and plot():</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     Ozone           Solar.R           Wind             Temp      
 Min.   :  1.00   Min.   :  7.0   Min.   : 1.700   Min.   :56.00  
 1st Qu.: 18.00   1st Qu.:115.8   1st Qu.: 7.400   1st Qu.:72.00  
 Median : 31.50   Median :205.0   Median : 9.700   Median :79.00  
 Mean   : 42.13   Mean   :185.9   Mean   : 9.958   Mean   :77.88  
 3rd Qu.: 63.25   3rd Qu.:258.8   3rd Qu.:11.500   3rd Qu.:85.00  
 Max.   :168.00   Max.   :334.0   Max.   :20.700   Max.   :97.00  
 NA's   :37       NA's   :7                                       
     Month            Day      
 Min.   :5.000   Min.   : 1.0  
 1st Qu.:6.000   1st Qu.: 8.0  
 Median :7.000   Median :16.0  
 Mean   :6.993   Mean   :15.8  
 3rd Qu.:8.000   3rd Qu.:23.0  
 Max.   :9.000   Max.   :31.0  
                               </code></pre>
</div>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C2-DeepNeuralNetworks_files/figure-html/chunk_chapter3_task_27_torch-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<ol type="1">
<li><p>There are NAs in the data, which we have to remove because Keras cannot handle NAs. If you don’t know how to remove NAs from a data.frame, use Google (e.g.&nbsp;with the query: “remove-rows-with-all-or-some-nas-missing-values-in-data-frame”).</p></li>
<li><p>Split the data in predictors (<span class="math inline">\(\boldsymbol{X}\)</span>) and response (<span class="math inline">\(\boldsymbol{y}\)</span>, Ozone) and scale the <span class="math inline">\(\boldsymbol{X}\)</span> matrix.</p></li>
<li><p>Pass a list of layer objects to a sequential network class of torch (input and output layer are already specified, you have to add hidden layers between them):</p></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>model_torch <span class="ot">=</span> </span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_sequential</span>(</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(5L, 20L),</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>    ...</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 1L),</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>Why do we use 5L as input shape?</li>
<li>Why only one output node and no activation layer?</li>
</ul>
<ol start="4" type="1">
<li>Create optimizer</li>
</ol>
<p>We have to pass the network’s parameters to the optimizer (how is this different to keras?)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>optimizer_torch <span class="ot">=</span> <span class="fu">optim_adam</span>(<span class="at">params =</span> model_torch<span class="sc">$</span>parameters, <span class="at">lr =</span> <span class="fl">0.05</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="5" type="1">
<li>Fit model</li>
</ol>
<p>In torch we have to write the trainings loop on our own. Complete the trainings loop:</p>
<p>Tips:</p>
<ul>
<li>Number of training $ steps = Number of rows / batchsize * Epochs $</li>
<li>Search torch::nnf_… for the correct loss function (mse…)</li>
<li>Make sure that X_torch and Y_torch have the same data type! (you can set the dtype via torch_tensor(…, dtype = …)) _ Check the dimension of Y_torch, we need a matrix!</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate number of training steps.</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> ...</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>batch_size <span class="ot">=</span> <span class="dv">32</span></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>steps <span class="ot">=</span> ...</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>X_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(x)</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>Y_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(y, ...) </span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Set model into training status.</span></span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>model_torch<span class="sc">$</span><span class="fu">train</span>()</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>log_losses <span class="ot">=</span> <span class="cn">NULL</span></span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Training loop.</span></span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>steps){</span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Get batch indices.</span></span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(x), batch_size)</span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a>  X_batch <span class="ot">=</span> ...</span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a>  Y_batch <span class="ot">=</span> ...</span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Reset backpropagation.</span></span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a>  optimizer_torch<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb43-23"><a href="#cb43-23" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb43-24"><a href="#cb43-24" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Predict and calculate loss.</span></span>
<span id="cb43-25"><a href="#cb43-25" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">=</span> <span class="fu">model_torch</span>(X_batch)</span>
<span id="cb43-26"><a href="#cb43-26" aria-hidden="true" tabindex="-1"></a>  loss <span class="ot">=</span> ...</span>
<span id="cb43-27"><a href="#cb43-27" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb43-28"><a href="#cb43-28" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Backpropagation and weight update.</span></span>
<span id="cb43-29"><a href="#cb43-29" aria-hidden="true" tabindex="-1"></a>  loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb43-30"><a href="#cb43-30" aria-hidden="true" tabindex="-1"></a>  optimizer_torch<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb43-31"><a href="#cb43-31" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb43-32"><a href="#cb43-32" aria-hidden="true" tabindex="-1"></a>  log_losses[i] <span class="ot">=</span> <span class="fu">as.numeric</span>(loss)</span>
<span id="cb43-33"><a href="#cb43-33" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="6" type="1">
<li><p>Plot training history.</p></li>
<li><p>Create predictions.</p></li>
<li><p>Compare your Torch model with a linear model:</p></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">lm</span>(Ozone <span class="sc">~</span> ., <span class="at">data =</span> data)</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>pred_lm <span class="ot">=</span> <span class="fu">predict</span>(fit, data)</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>rmse_lm <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_lm)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>rmse_torch <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_torch)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_lm)</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_torch)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<div class="webex-solution">
<button>
Click here to see the solution
</button>
<div class="cell">
<div class="cell-output-display">
<p><img src="C2-DeepNeuralNetworks_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</div>
</div>
</div>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:18px;">Solution</span></strong>
    </summary>
    <p>
</p><div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>1. There are NAs in the data, which we have to remove because Keras and Torch cannot handle NAs!</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> data[<span class="fu">complete.cases</span>(data),]  <span class="co"># Remove NAs.</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     Ozone          Solar.R           Wind            Temp      
 Min.   :  1.0   Min.   :  7.0   Min.   : 2.30   Min.   :57.00  
 1st Qu.: 18.0   1st Qu.:113.5   1st Qu.: 7.40   1st Qu.:71.00  
 Median : 31.0   Median :207.0   Median : 9.70   Median :79.00  
 Mean   : 42.1   Mean   :184.8   Mean   : 9.94   Mean   :77.79  
 3rd Qu.: 62.0   3rd Qu.:255.5   3rd Qu.:11.50   3rd Qu.:84.50  
 Max.   :168.0   Max.   :334.0   Max.   :20.70   Max.   :97.00  
     Month            Day       
 Min.   :5.000   Min.   : 1.00  
 1st Qu.:6.000   1st Qu.: 9.00  
 Median :7.000   Median :16.00  
 Mean   :7.216   Mean   :15.95  
 3rd Qu.:9.000   3rd Qu.:22.50  
 Max.   :9.000   Max.   :31.00  </code></pre>
</div>
</div>
<p><strong>2. Split the data in predictors and response and scale the matrix.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="dv">2</span><span class="sc">:</span><span class="dv">6</span>])</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> data[,<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="panelset">
<div class="panel">
<p><span class="panel-name">Keras</span></p>
<p><strong>3. Build sequential Keras model.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R's random seed.</span></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>4. Add hidden layers (input and output layer are already specified, you have to add hidden layers between them).</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">"relu"</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(5L)) <span class="sc">%&gt;%</span></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L) <span class="sc">%&gt;%</span></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L) <span class="sc">%&gt;%</span></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">"linear"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We use 5L as input shape, because we have 5 predictors. Analogously, we use 1L for our 1d response. Because we do not want any compression, dilation or other nonlinear effects, we use the simple linear layer (equal to no activation function at all). For more about activation functions, look for example <a href="https://en.wikipedia.org/wiki/Activation_function" target="_blank" rel="noopener">here</a>. Or wait for the next days. You may also have seen the previously shown link <a href="https://mlfromscratch.com/activation-functions-explained/#/" target="_blank" rel="noopener">about activation functions in more detail</a>.</p>
<p><strong>5. Compile model.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.05</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The mean_squared_error is the ordinary least squares approach in regression analysis.</p>
<p><strong>6. Fit model.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> x, <span class="at">y =</span> <span class="fu">matrix</span>(y, <span class="at">ncol =</span> 1L), <span class="at">epochs =</span> 100L,</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>7. Plot training history.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C2-DeepNeuralNetworks_files/figure-html/chunk_chapter3_task_38-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">evaluate</span>(x, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    loss 
147.5745 </code></pre>
</div>
</div>
<p><strong>8. Create predictions.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>pred_keras <span class="ot">=</span> <span class="fu">predict</span>(model, x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>9. Compare Keras model with a linear model.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">lm</span>(Ozone <span class="sc">~</span> ., <span class="at">data =</span> data)</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>pred_lm <span class="ot">=</span> <span class="fu">predict</span>(fit, data)</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>rmse_lm <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_lm)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>rmse_keras <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_keras)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_lm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 14.78897</code></pre>
</div>
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_keras)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 9.067499</code></pre>
</div>
</div>
</div>
<div class="panel">
<p><span class="panel-name">Torch</span></p>
<p><strong>3. Pass a list of layer objects to a sequential network class of torch (input and output layer are already specified, you have to add hidden layers between them):</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>model_torch <span class="ot">=</span> </span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_sequential</span>(</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(5L, 20L),</span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 20L),</span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 20L),</span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 1L),</span>
<span id="cb61-12"><a href="#cb61-12" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We use 5L as input shape, because we have 5 predictors. Analogously, we use 1L for our 1d response. Because we do not want any compression, dilation or other nonlinear effects, we use the simple linear layer (equal to no activation function at all). For more about activation functions, look for example <a href="https://en.wikipedia.org/wiki/Activation_function" target="_blank" rel="noopener">here</a>. Or wait for the next days. You may also have seen the previously shown link <a href="https://mlfromscratch.com/activation-functions-explained/#/" target="_blank" rel="noopener">about activation functions in more detail</a>.</p>
<p><strong>4. Create optimizer</strong></p>
<p>We have to pass the network’s parameters to the optimizer (how is this different to keras?)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>optimizer_torch <span class="ot">=</span> <span class="fu">optim_adam</span>(<span class="at">params =</span> model_torch<span class="sc">$</span>parameters, <span class="at">lr =</span> <span class="fl">0.001</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In keras we use the compile function to pass a optimizer and a loss function to the model whereas in torch we have to pass the network’s parameters to the optimizer.</p>
<p><strong>5. Fit model</strong></p>
<p>In torch we have to write the trainings loop on our own. Complete the trainings loop:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate number of training steps.</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> <span class="dv">100</span></span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>batch_size <span class="ot">=</span> <span class="dv">32</span></span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>steps <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">nrow</span>(x)<span class="sc">/</span>batch_size<span class="sc">*</span>epochs)</span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a>X_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(x)</span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a>Y_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(y, <span class="at">dtype =</span> <span class="fu">torch_float32</span>())<span class="sc">$</span><span class="fu">view</span>(<span class="fu">list</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)) </span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-9"><a href="#cb63-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Set model into training status.</span></span>
<span id="cb63-10"><a href="#cb63-10" aria-hidden="true" tabindex="-1"></a>model_torch<span class="sc">$</span><span class="fu">train</span>()</span>
<span id="cb63-11"><a href="#cb63-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-12"><a href="#cb63-12" aria-hidden="true" tabindex="-1"></a>log_losses <span class="ot">=</span> <span class="cn">NULL</span></span>
<span id="cb63-13"><a href="#cb63-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-14"><a href="#cb63-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Training loop.</span></span>
<span id="cb63-15"><a href="#cb63-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>steps){</span>
<span id="cb63-16"><a href="#cb63-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Get batch indices.</span></span>
<span id="cb63-17"><a href="#cb63-17" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(x), batch_size)</span>
<span id="cb63-18"><a href="#cb63-18" aria-hidden="true" tabindex="-1"></a>  X_batch <span class="ot">=</span> X_torch[indices,]</span>
<span id="cb63-19"><a href="#cb63-19" aria-hidden="true" tabindex="-1"></a>  Y_batch <span class="ot">=</span> Y_torch[indices,]</span>
<span id="cb63-20"><a href="#cb63-20" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb63-21"><a href="#cb63-21" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Reset backpropagation.</span></span>
<span id="cb63-22"><a href="#cb63-22" aria-hidden="true" tabindex="-1"></a>  optimizer_torch<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb63-23"><a href="#cb63-23" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb63-24"><a href="#cb63-24" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Predict and calculate loss.</span></span>
<span id="cb63-25"><a href="#cb63-25" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">=</span> <span class="fu">model_torch</span>(X_batch)</span>
<span id="cb63-26"><a href="#cb63-26" aria-hidden="true" tabindex="-1"></a>  loss <span class="ot">=</span> <span class="fu">nnf_mse_loss</span>(pred, Y_batch)</span>
<span id="cb63-27"><a href="#cb63-27" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb63-28"><a href="#cb63-28" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Backpropagation and weight update.</span></span>
<span id="cb63-29"><a href="#cb63-29" aria-hidden="true" tabindex="-1"></a>  loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb63-30"><a href="#cb63-30" aria-hidden="true" tabindex="-1"></a>  optimizer_torch<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb63-31"><a href="#cb63-31" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb63-32"><a href="#cb63-32" aria-hidden="true" tabindex="-1"></a>  log_losses[i] <span class="ot">=</span> <span class="fu">as.numeric</span>(loss)</span>
<span id="cb63-33"><a href="#cb63-33" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>6. Plot training history.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">y =</span> log_losses, <span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span>steps, <span class="at">xlab =</span> <span class="st">"Epoch"</span>, <span class="at">ylab =</span> <span class="st">"MSE"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>7. Create predictions.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>pred_torch <span class="ot">=</span> <span class="fu">model_torch</span>(X_torch)</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>pred_torch <span class="ot">=</span> <span class="fu">as.numeric</span>(pred_torch) <span class="co"># cast torch to R object </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>8. Compare your Torch model with a linear model:</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">lm</span>(Ozone <span class="sc">~</span> ., <span class="at">data =</span> data)</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>pred_lm <span class="ot">=</span> <span class="fu">predict</span>(fit, data)</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>rmse_lm <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_lm)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>rmse_torch <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_torch)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_lm)</span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_torch)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<p><strong>Look at this slightly more complex model and compare the loss plot and the accuracy in contrast to the former.</strong></p>
<div class="panelset">
<div class="panel">
<p><span class="panel-name">Keras</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R's random seed.</span></span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">"relu"</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(5L)) <span class="sc">%&gt;%</span></span>
<span id="cb67-9"><a href="#cb67-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb67-10"><a href="#cb67-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 30L, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb67-11"><a href="#cb67-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb67-12"><a href="#cb67-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">"linear"</span>)</span>
<span id="cb67-13"><a href="#cb67-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-14"><a href="#cb67-14" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb67-15"><a href="#cb67-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.05</span>))</span>
<span id="cb67-16"><a href="#cb67-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-17"><a href="#cb67-17" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb67-18"><a href="#cb67-18" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb67-19"><a href="#cb67-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> x, <span class="at">y =</span> <span class="fu">matrix</span>(y, <span class="at">ncol =</span> 1L), <span class="at">epochs =</span> 100L,</span>
<span id="cb67-20"><a href="#cb67-20" aria-hidden="true" tabindex="-1"></a>      <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb67-21"><a href="#cb67-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-22"><a href="#cb67-22" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C2-DeepNeuralNetworks_files/figure-html/chunk_chapter3_task_41-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">evaluate</span>(x, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    loss 
210.4453 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>pred_keras <span class="ot">=</span> <span class="fu">predict</span>(model, x)</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">lm</span>(Ozone <span class="sc">~</span> ., <span class="at">data =</span> data)</span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a>pred_lm <span class="ot">=</span> <span class="fu">predict</span>(fit, data)</span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>rmse_lm <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_lm)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a>rmse_keras <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_keras)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_lm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 14.78897</code></pre>
</div>
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_keras)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 10.51122</code></pre>
</div>
</div>
</div>
<div class="panel">
<p><span class="panel-name">Torch</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>model_torch <span class="ot">=</span> </span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_sequential</span>(</span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(5L, 20L),</span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 20L),</span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb74-9"><a href="#cb74-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 30L),</span>
<span id="cb74-10"><a href="#cb74-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb74-11"><a href="#cb74-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(30L, 20L),</span>
<span id="cb74-12"><a href="#cb74-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb74-13"><a href="#cb74-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 1L),</span>
<span id="cb74-14"><a href="#cb74-14" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb74-15"><a href="#cb74-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-16"><a href="#cb74-16" aria-hidden="true" tabindex="-1"></a>optimizer_torch <span class="ot">=</span> <span class="fu">optim_adam</span>(<span class="at">params =</span> model_torch<span class="sc">$</span>parameters, <span class="at">lr =</span> <span class="fl">0.05</span>)</span>
<span id="cb74-17"><a href="#cb74-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-18"><a href="#cb74-18" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> <span class="dv">100</span></span>
<span id="cb74-19"><a href="#cb74-19" aria-hidden="true" tabindex="-1"></a>batch_size <span class="ot">=</span> <span class="dv">32</span></span>
<span id="cb74-20"><a href="#cb74-20" aria-hidden="true" tabindex="-1"></a>steps <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">nrow</span>(x)<span class="sc">/</span>batch_size<span class="sc">*</span>epochs)</span>
<span id="cb74-21"><a href="#cb74-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-22"><a href="#cb74-22" aria-hidden="true" tabindex="-1"></a>X_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(x)</span>
<span id="cb74-23"><a href="#cb74-23" aria-hidden="true" tabindex="-1"></a>Y_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(y, <span class="at">dtype =</span> <span class="fu">torch_float32</span>())<span class="sc">$</span><span class="fu">view</span>(<span class="fu">list</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)) </span>
<span id="cb74-24"><a href="#cb74-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-25"><a href="#cb74-25" aria-hidden="true" tabindex="-1"></a>model_torch<span class="sc">$</span><span class="fu">train</span>()</span>
<span id="cb74-26"><a href="#cb74-26" aria-hidden="true" tabindex="-1"></a>log_losses <span class="ot">=</span> <span class="cn">NULL</span></span>
<span id="cb74-27"><a href="#cb74-27" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>steps){</span>
<span id="cb74-28"><a href="#cb74-28" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(x), batch_size)</span>
<span id="cb74-29"><a href="#cb74-29" aria-hidden="true" tabindex="-1"></a>  X_batch <span class="ot">=</span> X_torch[indices,]</span>
<span id="cb74-30"><a href="#cb74-30" aria-hidden="true" tabindex="-1"></a>  Y_batch <span class="ot">=</span> Y_torch[indices,]</span>
<span id="cb74-31"><a href="#cb74-31" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Reset backpropagation.</span></span>
<span id="cb74-32"><a href="#cb74-32" aria-hidden="true" tabindex="-1"></a>  optimizer_torch<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb74-33"><a href="#cb74-33" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Predict and calculate loss.</span></span>
<span id="cb74-34"><a href="#cb74-34" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">=</span> <span class="fu">model_torch</span>(X_batch)</span>
<span id="cb74-35"><a href="#cb74-35" aria-hidden="true" tabindex="-1"></a>  loss <span class="ot">=</span> <span class="fu">nnf_mse_loss</span>(pred, Y_batch)</span>
<span id="cb74-36"><a href="#cb74-36" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Backpropagation and weight update.</span></span>
<span id="cb74-37"><a href="#cb74-37" aria-hidden="true" tabindex="-1"></a>  loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb74-38"><a href="#cb74-38" aria-hidden="true" tabindex="-1"></a>  optimizer_torch<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb74-39"><a href="#cb74-39" aria-hidden="true" tabindex="-1"></a>  log_losses[i] <span class="ot">=</span> <span class="fu">as.numeric</span>(loss)</span>
<span id="cb74-40"><a href="#cb74-40" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb74-41"><a href="#cb74-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-42"><a href="#cb74-42" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">y =</span> log_losses, <span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span>steps, <span class="at">xlab =</span> <span class="st">"Epoch"</span>, <span class="at">ylab =</span> <span class="st">"MSE"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C2-DeepNeuralNetworks_files/figure-html/chunk_chapter3_task_41_torch-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>pred_torch <span class="ot">=</span> <span class="fu">model_torch</span>(X_torch)</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>pred_torch <span class="ot">=</span> <span class="fu">as.numeric</span>(pred_torch) <span class="co"># cast torch to R object </span></span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">lm</span>(Ozone <span class="sc">~</span> ., <span class="at">data =</span> data)</span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a>pred_lm <span class="ot">=</span> <span class="fu">predict</span>(fit, data)</span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a>rmse_lm <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_lm)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a>rmse_torch <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_torch)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb75-8"><a href="#cb75-8" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_lm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 14.78897</code></pre>
</div>
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_torch)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5.12053</code></pre>
</div>
</div>
</div>
</div>
<p>You see, the more complex model works better, because it can learn the functional form between the features and the response better (if necessary). But keep the overfitting problem in mind!</p>
<p><strong>Look at the little change in learning rates for the next 2 models and compare the loss plot and the accuracy in contrast to the former.</strong></p>
<div class="panelset">
<div class="panel">
<p><span class="panel-name">Keras</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R's random seed.</span></span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb79-6"><a href="#cb79-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-7"><a href="#cb79-7" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb79-8"><a href="#cb79-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">"relu"</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(5L)) <span class="sc">%&gt;%</span></span>
<span id="cb79-9"><a href="#cb79-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb79-10"><a href="#cb79-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 30L, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb79-11"><a href="#cb79-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb79-12"><a href="#cb79-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">"linear"</span>)</span>
<span id="cb79-13"><a href="#cb79-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-14"><a href="#cb79-14" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb79-15"><a href="#cb79-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.1</span>))</span>
<span id="cb79-16"><a href="#cb79-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-17"><a href="#cb79-17" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb79-18"><a href="#cb79-18" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb79-19"><a href="#cb79-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> x, <span class="at">y =</span> <span class="fu">matrix</span>(y, <span class="at">ncol =</span> 1L), <span class="at">epochs =</span> 100L,</span>
<span id="cb79-20"><a href="#cb79-20" aria-hidden="true" tabindex="-1"></a>      <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb79-21"><a href="#cb79-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-22"><a href="#cb79-22" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C2-DeepNeuralNetworks_files/figure-html/chunk_chapter3_task_42-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">evaluate</span>(x, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    loss 
56.70872 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>pred_keras <span class="ot">=</span> <span class="fu">predict</span>(model, x)</span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">lm</span>(Ozone <span class="sc">~</span> ., <span class="at">data =</span> data)</span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a>pred_lm <span class="ot">=</span> <span class="fu">predict</span>(fit, data)</span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a>rmse_lm <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_lm)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb82-6"><a href="#cb82-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-7"><a href="#cb82-7" aria-hidden="true" tabindex="-1"></a>rmse_keras <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_keras)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb82-8"><a href="#cb82-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-9"><a href="#cb82-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_lm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 14.78897</code></pre>
</div>
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_keras)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5.661808</code></pre>
</div>
</div>
</div>
<div class="panel">
<p><span class="panel-name">Torch</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>model_torch <span class="ot">=</span> </span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_sequential</span>(</span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(5L, 20L),</span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 20L),</span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb86-9"><a href="#cb86-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 30L),</span>
<span id="cb86-10"><a href="#cb86-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb86-11"><a href="#cb86-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(30L, 20L),</span>
<span id="cb86-12"><a href="#cb86-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb86-13"><a href="#cb86-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 1L),</span>
<span id="cb86-14"><a href="#cb86-14" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb86-15"><a href="#cb86-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-16"><a href="#cb86-16" aria-hidden="true" tabindex="-1"></a>optimizer_torch <span class="ot">=</span> <span class="fu">optim_adam</span>(<span class="at">params =</span> model_torch<span class="sc">$</span>parameters, <span class="at">lr =</span> <span class="fl">0.1</span>)</span>
<span id="cb86-17"><a href="#cb86-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-18"><a href="#cb86-18" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> <span class="dv">100</span></span>
<span id="cb86-19"><a href="#cb86-19" aria-hidden="true" tabindex="-1"></a>batch_size <span class="ot">=</span> <span class="dv">32</span></span>
<span id="cb86-20"><a href="#cb86-20" aria-hidden="true" tabindex="-1"></a>steps <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">nrow</span>(x)<span class="sc">/</span>batch_size<span class="sc">*</span>epochs)</span>
<span id="cb86-21"><a href="#cb86-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-22"><a href="#cb86-22" aria-hidden="true" tabindex="-1"></a>X_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(x)</span>
<span id="cb86-23"><a href="#cb86-23" aria-hidden="true" tabindex="-1"></a>Y_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(y, <span class="at">dtype =</span> <span class="fu">torch_float32</span>())<span class="sc">$</span><span class="fu">view</span>(<span class="fu">list</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)) </span>
<span id="cb86-24"><a href="#cb86-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-25"><a href="#cb86-25" aria-hidden="true" tabindex="-1"></a>model_torch<span class="sc">$</span><span class="fu">train</span>()</span>
<span id="cb86-26"><a href="#cb86-26" aria-hidden="true" tabindex="-1"></a>log_losses <span class="ot">=</span> <span class="cn">NULL</span></span>
<span id="cb86-27"><a href="#cb86-27" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>steps){</span>
<span id="cb86-28"><a href="#cb86-28" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(x), batch_size)</span>
<span id="cb86-29"><a href="#cb86-29" aria-hidden="true" tabindex="-1"></a>  X_batch <span class="ot">=</span> X_torch[indices,]</span>
<span id="cb86-30"><a href="#cb86-30" aria-hidden="true" tabindex="-1"></a>  Y_batch <span class="ot">=</span> Y_torch[indices,]</span>
<span id="cb86-31"><a href="#cb86-31" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Reset backpropagation.</span></span>
<span id="cb86-32"><a href="#cb86-32" aria-hidden="true" tabindex="-1"></a>  optimizer_torch<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb86-33"><a href="#cb86-33" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Predict and calculate loss.</span></span>
<span id="cb86-34"><a href="#cb86-34" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">=</span> <span class="fu">model_torch</span>(X_batch)</span>
<span id="cb86-35"><a href="#cb86-35" aria-hidden="true" tabindex="-1"></a>  loss <span class="ot">=</span> <span class="fu">nnf_mse_loss</span>(pred, Y_batch)</span>
<span id="cb86-36"><a href="#cb86-36" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Backpropagation and weight update.</span></span>
<span id="cb86-37"><a href="#cb86-37" aria-hidden="true" tabindex="-1"></a>  loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb86-38"><a href="#cb86-38" aria-hidden="true" tabindex="-1"></a>  optimizer_torch<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb86-39"><a href="#cb86-39" aria-hidden="true" tabindex="-1"></a>  log_losses[i] <span class="ot">=</span> <span class="fu">as.numeric</span>(loss)</span>
<span id="cb86-40"><a href="#cb86-40" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb86-41"><a href="#cb86-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-42"><a href="#cb86-42" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">y =</span> log_losses, <span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span>steps, <span class="at">xlab =</span> <span class="st">"Epoch"</span>, <span class="at">ylab =</span> <span class="st">"MSE"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C2-DeepNeuralNetworks_files/figure-html/chunk_chapter3_task_43_torch-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>pred_torch <span class="ot">=</span> <span class="fu">model_torch</span>(X_torch)</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>pred_torch <span class="ot">=</span> <span class="fu">as.numeric</span>(pred_torch) <span class="co"># cast torch to R object </span></span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">lm</span>(Ozone <span class="sc">~</span> ., <span class="at">data =</span> data)</span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a>pred_lm <span class="ot">=</span> <span class="fu">predict</span>(fit, data)</span>
<span id="cb87-6"><a href="#cb87-6" aria-hidden="true" tabindex="-1"></a>rmse_lm <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_lm)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb87-7"><a href="#cb87-7" aria-hidden="true" tabindex="-1"></a>rmse_torch <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_torch)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb87-8"><a href="#cb87-8" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_lm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 14.78897</code></pre>
</div>
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_torch)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 6.461597</code></pre>
</div>
</div>
</div>
</div>
<p>You can see, the higher learning rate yields a little bit worse results. The optimum is jumped over.</p>
<div class="panelset">
<div class="panel">
<p><span class="panel-name">Keras</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R's random seed.</span></span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-7"><a href="#cb91-7" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb91-8"><a href="#cb91-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">"relu"</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(5L)) <span class="sc">%&gt;%</span></span>
<span id="cb91-9"><a href="#cb91-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb91-10"><a href="#cb91-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 30L, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb91-11"><a href="#cb91-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb91-12"><a href="#cb91-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">"linear"</span>)</span>
<span id="cb91-13"><a href="#cb91-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-14"><a href="#cb91-14" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb91-15"><a href="#cb91-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.001</span>))</span>
<span id="cb91-16"><a href="#cb91-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-17"><a href="#cb91-17" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb91-18"><a href="#cb91-18" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb91-19"><a href="#cb91-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> x, <span class="at">y =</span> <span class="fu">matrix</span>(y, <span class="at">ncol =</span> 1L), <span class="at">epochs =</span> 100L,</span>
<span id="cb91-20"><a href="#cb91-20" aria-hidden="true" tabindex="-1"></a>      <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb91-21"><a href="#cb91-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-22"><a href="#cb91-22" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C2-DeepNeuralNetworks_files/figure-html/chunk_chapter3_task_43-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">evaluate</span>(x, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    loss 
340.8205 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>pred_keras <span class="ot">=</span> <span class="fu">predict</span>(model, x)</span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">lm</span>(Ozone <span class="sc">~</span> ., <span class="at">data =</span> data)</span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a>pred_lm <span class="ot">=</span> <span class="fu">predict</span>(fit, data)</span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a>rmse_lm <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_lm)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb94-6"><a href="#cb94-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-7"><a href="#cb94-7" aria-hidden="true" tabindex="-1"></a>rmse_keras <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_keras)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb94-8"><a href="#cb94-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-9"><a href="#cb94-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_lm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 14.78897</code></pre>
</div>
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_keras)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 13.18632</code></pre>
</div>
</div>
</div>
<div class="panel">
<p><span class="panel-name">Torch</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a>model_torch <span class="ot">=</span> </span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_sequential</span>(</span>
<span id="cb98-5"><a href="#cb98-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(5L, 20L),</span>
<span id="cb98-6"><a href="#cb98-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb98-7"><a href="#cb98-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 20L),</span>
<span id="cb98-8"><a href="#cb98-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb98-9"><a href="#cb98-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 30L),</span>
<span id="cb98-10"><a href="#cb98-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb98-11"><a href="#cb98-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(30L, 20L),</span>
<span id="cb98-12"><a href="#cb98-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb98-13"><a href="#cb98-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 1L),</span>
<span id="cb98-14"><a href="#cb98-14" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb98-15"><a href="#cb98-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-16"><a href="#cb98-16" aria-hidden="true" tabindex="-1"></a>optimizer_torch <span class="ot">=</span> <span class="fu">optim_adam</span>(<span class="at">params =</span> model_torch<span class="sc">$</span>parameters, <span class="at">lr =</span> <span class="fl">0.001</span>)</span>
<span id="cb98-17"><a href="#cb98-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-18"><a href="#cb98-18" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> <span class="dv">100</span></span>
<span id="cb98-19"><a href="#cb98-19" aria-hidden="true" tabindex="-1"></a>batch_size <span class="ot">=</span> <span class="dv">32</span></span>
<span id="cb98-20"><a href="#cb98-20" aria-hidden="true" tabindex="-1"></a>steps <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">nrow</span>(x)<span class="sc">/</span>batch_size<span class="sc">*</span>epochs)</span>
<span id="cb98-21"><a href="#cb98-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-22"><a href="#cb98-22" aria-hidden="true" tabindex="-1"></a>X_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(x)</span>
<span id="cb98-23"><a href="#cb98-23" aria-hidden="true" tabindex="-1"></a>Y_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(y, <span class="at">dtype =</span> <span class="fu">torch_float32</span>())<span class="sc">$</span><span class="fu">view</span>(<span class="fu">list</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)) </span>
<span id="cb98-24"><a href="#cb98-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-25"><a href="#cb98-25" aria-hidden="true" tabindex="-1"></a>model_torch<span class="sc">$</span><span class="fu">train</span>()</span>
<span id="cb98-26"><a href="#cb98-26" aria-hidden="true" tabindex="-1"></a>log_losses <span class="ot">=</span> <span class="cn">NULL</span></span>
<span id="cb98-27"><a href="#cb98-27" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>steps){</span>
<span id="cb98-28"><a href="#cb98-28" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(x), batch_size)</span>
<span id="cb98-29"><a href="#cb98-29" aria-hidden="true" tabindex="-1"></a>  X_batch <span class="ot">=</span> X_torch[indices,]</span>
<span id="cb98-30"><a href="#cb98-30" aria-hidden="true" tabindex="-1"></a>  Y_batch <span class="ot">=</span> Y_torch[indices,]</span>
<span id="cb98-31"><a href="#cb98-31" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Reset backpropagation.</span></span>
<span id="cb98-32"><a href="#cb98-32" aria-hidden="true" tabindex="-1"></a>  optimizer_torch<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb98-33"><a href="#cb98-33" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Predict and calculate loss.</span></span>
<span id="cb98-34"><a href="#cb98-34" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">=</span> <span class="fu">model_torch</span>(X_batch)</span>
<span id="cb98-35"><a href="#cb98-35" aria-hidden="true" tabindex="-1"></a>  loss <span class="ot">=</span> <span class="fu">nnf_mse_loss</span>(pred, Y_batch)</span>
<span id="cb98-36"><a href="#cb98-36" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Backpropagation and weight update.</span></span>
<span id="cb98-37"><a href="#cb98-37" aria-hidden="true" tabindex="-1"></a>  loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb98-38"><a href="#cb98-38" aria-hidden="true" tabindex="-1"></a>  optimizer_torch<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb98-39"><a href="#cb98-39" aria-hidden="true" tabindex="-1"></a>  log_losses[i] <span class="ot">=</span> <span class="fu">as.numeric</span>(loss)</span>
<span id="cb98-40"><a href="#cb98-40" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb98-41"><a href="#cb98-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-42"><a href="#cb98-42" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">y =</span> log_losses, <span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span>steps, <span class="at">xlab =</span> <span class="st">"Epoch"</span>, <span class="at">ylab =</span> <span class="st">"MSE"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C2-DeepNeuralNetworks_files/figure-html/chunk_chapter3_task_442_torch-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a>pred_torch <span class="ot">=</span> <span class="fu">model_torch</span>(X_torch)</span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a>pred_torch <span class="ot">=</span> <span class="fu">as.numeric</span>(pred_torch) <span class="co"># cast torch to R object </span></span>
<span id="cb99-3"><a href="#cb99-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-4"><a href="#cb99-4" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">lm</span>(Ozone <span class="sc">~</span> ., <span class="at">data =</span> data)</span>
<span id="cb99-5"><a href="#cb99-5" aria-hidden="true" tabindex="-1"></a>pred_lm <span class="ot">=</span> <span class="fu">predict</span>(fit, data)</span>
<span id="cb99-6"><a href="#cb99-6" aria-hidden="true" tabindex="-1"></a>rmse_lm <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_lm)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb99-7"><a href="#cb99-7" aria-hidden="true" tabindex="-1"></a>rmse_torch <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_torch)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb99-8"><a href="#cb99-8" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_lm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 14.78897</code></pre>
</div>
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_torch)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 12.48754</code></pre>
</div>
</div>
</div>
</div>
<p>You can see, that for the lower learning rate, the optimum (compared to the run with learning rate 0.05) is not yet reached (to few epochs have gone by). But also here, mind the overfitting problem. For too many epochs, things might get worse!</p>
    <p></p>
  </details>
  <br>
  <hr>
  <strong><span style="color: #0011AA; font-size:18px;">2. Task</span></strong><br>
<p>The next task differs for Torch and Keras users. Keras users will learn more about the inner working of training while Torch users will learn how to simplify and generalize the training loop.</p>
<div class="panelset">
<div class="panel">
<p><span class="panel-name">Keras</span></p>
<p>Similar to Torch, here we will write the training loop ourselves in the following. The training loop consists of several steps:</p>
<ol type="1">
<li>Sample batches of X and Y data</li>
<li>Open the gradientTape to create a computational graph (autodiff)</li>
<li>Make predictions and calculate loss</li>
<li>Update parameters based on the gradients at the loss (go back to 1. and repeat)</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R's random seed.</span></span>
<span id="cb103-4"><a href="#cb103-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-5"><a href="#cb103-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality</span>
<span id="cb103-6"><a href="#cb103-6" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> data[<span class="fu">complete.cases</span>(data),]  <span class="co"># Remove NAs.</span></span>
<span id="cb103-7"><a href="#cb103-7" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="dv">2</span><span class="sc">:</span><span class="dv">6</span>])</span>
<span id="cb103-8"><a href="#cb103-8" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> data[,<span class="dv">1</span>]</span>
<span id="cb103-9"><a href="#cb103-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-10"><a href="#cb103-10" aria-hidden="true" tabindex="-1"></a>layers <span class="ot">=</span> tf<span class="sc">$</span>keras<span class="sc">$</span>layers</span>
<span id="cb103-11"><a href="#cb103-11" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> tf<span class="sc">$</span>keras<span class="sc">$</span>models<span class="sc">$</span><span class="fu">Sequential</span>(</span>
<span id="cb103-12"><a href="#cb103-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>(</span>
<span id="cb103-13"><a href="#cb103-13" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">InputLayer</span>(<span class="at">input_shape =</span> <span class="fu">list</span>(5L)),</span>
<span id="cb103-14"><a href="#cb103-14" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">Dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> tf<span class="sc">$</span>nn<span class="sc">$</span>relu),</span>
<span id="cb103-15"><a href="#cb103-15" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">Dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> tf<span class="sc">$</span>nn<span class="sc">$</span>relu),</span>
<span id="cb103-16"><a href="#cb103-16" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">Dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> tf<span class="sc">$</span>nn<span class="sc">$</span>relu),</span>
<span id="cb103-17"><a href="#cb103-17" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">Dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="cn">NULL</span>) <span class="co"># No activation == "linear".</span></span>
<span id="cb103-18"><a href="#cb103-18" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb103-19"><a href="#cb103-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb103-20"><a href="#cb103-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-21"><a href="#cb103-21" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> 200L</span>
<span id="cb103-22"><a href="#cb103-22" aria-hidden="true" tabindex="-1"></a>optimizer <span class="ot">=</span> tf<span class="sc">$</span>keras<span class="sc">$</span>optimizers<span class="sc">$</span><span class="fu">Adamax</span>(<span class="fl">0.01</span>)</span>
<span id="cb103-23"><a href="#cb103-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-24"><a href="#cb103-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Stochastic gradient optimization is more efficient</span></span>
<span id="cb103-25"><a href="#cb103-25" aria-hidden="true" tabindex="-1"></a><span class="co"># in each optimization step, we use a random subset of the data.</span></span>
<span id="cb103-26"><a href="#cb103-26" aria-hidden="true" tabindex="-1"></a>get_batch <span class="ot">=</span> <span class="cf">function</span>(<span class="at">batch_size =</span> 32L){</span>
<span id="cb103-27"><a href="#cb103-27" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(x), <span class="at">size =</span> batch_size)</span>
<span id="cb103-28"><a href="#cb103-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">bX =</span> x[indices,], <span class="at">bY =</span> y[indices]))</span>
<span id="cb103-29"><a href="#cb103-29" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb103-30"><a href="#cb103-30" aria-hidden="true" tabindex="-1"></a><span class="fu">get_batch</span>() <span class="co"># Try out this function.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$bX
        Solar.R        Wind        Temp      Month        Day
87  -1.13877323 -0.37654514  0.44147123 -0.1467431  1.1546835
117  0.58361881 -1.83815816  0.33653910  0.5319436  1.0398360
129 -1.01809608  1.56290291  0.65133550  1.2106304 -1.1422676
121  0.44100036 -2.14734553  1.70065685  0.5319436  1.4992262
91   0.74817856 -0.71384046  0.54640337 -0.1467431  1.6140738
137 -1.76410028  0.26993754 -0.71278225  1.2106304 -0.2234871
21  -1.93963068 -0.06735777 -1.97196786 -1.5041165  0.5804458
141 -1.73118833  0.10128988 -0.18812157  1.2106304  0.2359031
78   0.97856221  0.10128988  0.44147123 -0.1467431  0.1210555
15  -1.31430363  0.91642022 -2.07689999 -1.5041165 -0.1086396
38  -0.63412333 -0.06735777  0.44147123 -0.8254298 -1.0274200
49  -1.62148183 -0.20789749 -1.34237505 -0.8254298  0.2359031
123  0.03508631 -1.02302783  1.70065685  0.5319436  1.7289213
136  0.58361881 -1.02302783 -0.08318944  1.2106304 -0.3383347
120  0.19964606 -0.06735777  2.01545325  0.5319436  1.3843787
114 -1.63245248  1.22560759 -0.60785011  0.5319436  0.6952933
145 -1.87380678 -0.20789749 -0.71278225  1.2106304  0.6952933
140  0.43002971  1.08506788 -1.13251078  1.2106304  0.1210555
64   0.56167751 -0.20789749  0.33653910 -0.1467431 -1.4868103
118  0.33129386 -0.54519280  0.86119977  0.5319436  1.1546835
128 -0.98518413 -0.71384046  0.96613190  1.2106304 -1.2571152
62   0.92370896 -1.64140257  0.65133550 -0.1467431 -1.7165054
125  0.13382216 -1.36032314  1.49079258  1.2106304 -1.6016578
4    1.40641756  0.43858520 -1.65717146 -1.5041165 -1.3719627
79   1.09923936 -1.02302783  0.65133550 -0.1467431  0.2359031
82  -1.95060133 -0.85438017 -0.39798584 -0.1467431  0.5804458
149  0.08993956 -0.85438017 -0.81771438  1.2106304  1.1546835
17   1.34059366  0.57912491 -1.23744292 -1.5041165  0.1210555
48   1.08826871  3.02451593 -0.60785011 -0.8254298  0.1210555
130  0.73720791  0.26993754  0.23160696  1.2106304 -1.0274200
132  0.49585361  0.26993754 -0.29305371  1.2106304 -0.7977249
30   0.41905906 -1.19167548  0.12667483 -1.5041165  1.6140738

$bY
 [1]  20 168  32 118  64   9   1  13  35  18  29  20  85  28  76   9  23  18  32
[20]  73  47 135  78  18  61  16  30  34  37  20  21 115</code></pre>
</div>
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a>steps <span class="ot">=</span> <span class="fu">floor</span>(<span class="fu">nrow</span>(x)<span class="sc">/</span><span class="dv">32</span>) <span class="sc">*</span> epochs  <span class="co"># We need nrow(x)/32 steps for each epoch.</span></span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>steps){</span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Get data.</span></span>
<span id="cb105-4"><a href="#cb105-4" aria-hidden="true" tabindex="-1"></a>  batch <span class="ot">=</span> <span class="fu">get_batch</span>()</span>
<span id="cb105-5"><a href="#cb105-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-6"><a href="#cb105-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Transform it into tensors.</span></span>
<span id="cb105-7"><a href="#cb105-7" aria-hidden="true" tabindex="-1"></a>  bX <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(batch<span class="sc">$</span>bX)</span>
<span id="cb105-8"><a href="#cb105-8" aria-hidden="true" tabindex="-1"></a>  bY <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(<span class="fu">matrix</span>(batch<span class="sc">$</span>bY, <span class="at">ncol =</span> 1L))</span>
<span id="cb105-9"><a href="#cb105-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb105-10"><a href="#cb105-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Automatic differentiation:</span></span>
<span id="cb105-11"><a href="#cb105-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Record computations with respect to our model variables.</span></span>
<span id="cb105-12"><a href="#cb105-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">with</span>(tf<span class="sc">$</span><span class="fu">GradientTape</span>() <span class="sc">%as%</span> tape,</span>
<span id="cb105-13"><a href="#cb105-13" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb105-14"><a href="#cb105-14" aria-hidden="true" tabindex="-1"></a>      pred <span class="ot">=</span> <span class="fu">model</span>(bX) <span class="co"># We record the operation for our model weights.</span></span>
<span id="cb105-15"><a href="#cb105-15" aria-hidden="true" tabindex="-1"></a>      loss <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">reduce_mean</span>(tf<span class="sc">$</span>keras<span class="sc">$</span>losses<span class="sc">$</span><span class="fu">mean_squared_error</span>(bY, pred))</span>
<span id="cb105-16"><a href="#cb105-16" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb105-17"><a href="#cb105-17" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb105-18"><a href="#cb105-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb105-19"><a href="#cb105-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Calculate the gradients for our model$weights at the loss / backpropagation.</span></span>
<span id="cb105-20"><a href="#cb105-20" aria-hidden="true" tabindex="-1"></a>  gradients <span class="ot">=</span> tape<span class="sc">$</span><span class="fu">gradient</span>(loss, model<span class="sc">$</span>weights) </span>
<span id="cb105-21"><a href="#cb105-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-22"><a href="#cb105-22" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Update our model weights with the learning rate specified above.</span></span>
<span id="cb105-23"><a href="#cb105-23" aria-hidden="true" tabindex="-1"></a>  optimizer<span class="sc">$</span><span class="fu">apply_gradients</span>(purrr<span class="sc">::</span><span class="fu">transpose</span>(<span class="fu">list</span>(gradients, model<span class="sc">$</span>weights))) </span>
<span id="cb105-24"><a href="#cb105-24" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="sc">!</span> i<span class="sc">%%</span><span class="dv">30</span>){</span>
<span id="cb105-25"><a href="#cb105-25" aria-hidden="true" tabindex="-1"></a>    <span class="fu">cat</span>(<span class="st">"Loss: "</span>, loss<span class="sc">$</span><span class="fu">numpy</span>(), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>) <span class="co"># Print loss every 30 steps (not epochs!).</span></span>
<span id="cb105-26"><a href="#cb105-26" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb105-27"><a href="#cb105-27" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss:  1444.033 
Loss:  488.953 
Loss:  270.0465 
Loss:  450.0282 
Loss:  138.2488 
Loss:  227.6001 
Loss:  216.2361 
Loss:  109.9781 
Loss:  352.7486 
Loss:  239.2065 
Loss:  234.0703 
Loss:  224.0462 
Loss:  227.475 
Loss:  336.5538 
Loss:  348.1582 
Loss:  158.787 
Loss:  209.5738 
Loss:  321.0661 
Loss:  232.6139 
Loss:  289.6932 </code></pre>
</div>
</div>
</div>
<div class="panel">
<p><span class="panel-name">Torch</span></p>
<p>Keras and Torch use dataloaders to generate the data batches. Dataloaders are objects that return batches of data infinetly. Keras create the dataloader object automatically in the fit function, in Torch we have to write them ourselves:</p>
<ol type="1">
<li>Define a dataset object. This object informs the dataloader function about the inputs, outputs, length (nrow), and how to sample from it.</li>
<li>Create an instance of the dataset object by calling it and passing the actual data to it</li>
<li>Pass the initiated dataset to the dataloader function</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-3"><a href="#cb107-3" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality</span>
<span id="cb107-4"><a href="#cb107-4" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> data[<span class="fu">complete.cases</span>(data),]  <span class="co"># Remove NAs.</span></span>
<span id="cb107-5"><a href="#cb107-5" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="dv">2</span><span class="sc">:</span><span class="dv">6</span>])</span>
<span id="cb107-6"><a href="#cb107-6" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">matrix</span>(data[,<span class="dv">1</span>], <span class="at">ncol =</span> 1L)</span>
<span id="cb107-7"><a href="#cb107-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-8"><a href="#cb107-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-9"><a href="#cb107-9" aria-hidden="true" tabindex="-1"></a>torch_dataset <span class="ot">=</span> torch<span class="sc">::</span><span class="fu">dataset</span>(</span>
<span id="cb107-10"><a href="#cb107-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">name =</span> <span class="st">"airquality"</span>,</span>
<span id="cb107-11"><a href="#cb107-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">initialize =</span> <span class="cf">function</span>(X,Y) {</span>
<span id="cb107-12"><a href="#cb107-12" aria-hidden="true" tabindex="-1"></a>      self<span class="sc">$</span>X <span class="ot">=</span> torch<span class="sc">::</span><span class="fu">torch_tensor</span>(<span class="fu">as.matrix</span>(X), <span class="at">dtype =</span> <span class="fu">torch_float32</span>())</span>
<span id="cb107-13"><a href="#cb107-13" aria-hidden="true" tabindex="-1"></a>      self<span class="sc">$</span>Y <span class="ot">=</span> torch<span class="sc">::</span><span class="fu">torch_tensor</span>(<span class="fu">as.matrix</span>(Y), <span class="at">dtype =</span> <span class="fu">torch_float32</span>())</span>
<span id="cb107-14"><a href="#cb107-14" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb107-15"><a href="#cb107-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">.getitem =</span> <span class="cf">function</span>(index) {</span>
<span id="cb107-16"><a href="#cb107-16" aria-hidden="true" tabindex="-1"></a>      x <span class="ot">=</span> self<span class="sc">$</span>X[index,]</span>
<span id="cb107-17"><a href="#cb107-17" aria-hidden="true" tabindex="-1"></a>      y <span class="ot">=</span> self<span class="sc">$</span>Y[index,]</span>
<span id="cb107-18"><a href="#cb107-18" aria-hidden="true" tabindex="-1"></a>      <span class="fu">list</span>(x, y)</span>
<span id="cb107-19"><a href="#cb107-19" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb107-20"><a href="#cb107-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">.length =</span> <span class="cf">function</span>() {</span>
<span id="cb107-21"><a href="#cb107-21" aria-hidden="true" tabindex="-1"></a>      self<span class="sc">$</span>Y<span class="sc">$</span><span class="fu">size</span>()[[<span class="dv">1</span>]]</span>
<span id="cb107-22"><a href="#cb107-22" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb107-23"><a href="#cb107-23" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb107-24"><a href="#cb107-24" aria-hidden="true" tabindex="-1"></a>dataset <span class="ot">=</span> <span class="fu">torch_dataset</span>(x,y)</span>
<span id="cb107-25"><a href="#cb107-25" aria-hidden="true" tabindex="-1"></a>dataloader <span class="ot">=</span> torch<span class="sc">::</span><span class="fu">dataloader</span>(dataset, <span class="at">batch_size =</span> 30L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Our dataloader is again an object which has to be initiated. The initiated object returns a list of two elements, batch x and batch y. The initated object stops returning batches when the dataset was completly transversed (no worries, we don’t have to all of this ourselves).</p>
<p>Our training has also changed now:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a>model_torch <span class="ot">=</span> <span class="fu">nn_sequential</span>(</span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_linear</span>(5L, 50L),</span>
<span id="cb108-3"><a href="#cb108-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_relu</span>(),</span>
<span id="cb108-4"><a href="#cb108-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_linear</span>(50L, 50L),</span>
<span id="cb108-5"><a href="#cb108-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_relu</span>(), </span>
<span id="cb108-6"><a href="#cb108-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_linear</span>(50L, 50L),</span>
<span id="cb108-7"><a href="#cb108-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_relu</span>(), </span>
<span id="cb108-8"><a href="#cb108-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_linear</span>(50L, 1L)</span>
<span id="cb108-9"><a href="#cb108-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb108-10"><a href="#cb108-10" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> 50L</span>
<span id="cb108-11"><a href="#cb108-11" aria-hidden="true" tabindex="-1"></a>opt <span class="ot">=</span> <span class="fu">optim_adam</span>(model_torch<span class="sc">$</span>parameters, <span class="fl">0.01</span>)</span>
<span id="cb108-12"><a href="#cb108-12" aria-hidden="true" tabindex="-1"></a>train_losses <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb108-13"><a href="#cb108-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(epoch <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>epochs){</span>
<span id="cb108-14"><a href="#cb108-14" aria-hidden="true" tabindex="-1"></a>  train_loss <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb108-15"><a href="#cb108-15" aria-hidden="true" tabindex="-1"></a>  coro<span class="sc">::</span><span class="fu">loop</span>(</span>
<span id="cb108-16"><a href="#cb108-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(batch <span class="cf">in</span> dataloader) { </span>
<span id="cb108-17"><a href="#cb108-17" aria-hidden="true" tabindex="-1"></a>      opt<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb108-18"><a href="#cb108-18" aria-hidden="true" tabindex="-1"></a>      pred <span class="ot">=</span> <span class="fu">model_torch</span>(batch[[<span class="dv">1</span>]])</span>
<span id="cb108-19"><a href="#cb108-19" aria-hidden="true" tabindex="-1"></a>      loss <span class="ot">=</span> <span class="fu">nnf_mse_loss</span>(pred, batch[[<span class="dv">2</span>]])</span>
<span id="cb108-20"><a href="#cb108-20" aria-hidden="true" tabindex="-1"></a>      loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb108-21"><a href="#cb108-21" aria-hidden="true" tabindex="-1"></a>      opt<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb108-22"><a href="#cb108-22" aria-hidden="true" tabindex="-1"></a>      train_loss <span class="ot">=</span> <span class="fu">c</span>(train_loss, loss<span class="sc">$</span><span class="fu">item</span>())</span>
<span id="cb108-23"><a href="#cb108-23" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb108-24"><a href="#cb108-24" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb108-25"><a href="#cb108-25" aria-hidden="true" tabindex="-1"></a>  train_losses <span class="ot">=</span> <span class="fu">c</span>(train_losses, <span class="fu">mean</span>(train_loss))</span>
<span id="cb108-26"><a href="#cb108-26" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="sc">!</span>epoch<span class="sc">%%</span><span class="dv">10</span>) <span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">"Loss at epoch %d: %3f</span><span class="sc">\n</span><span class="st">"</span>, epoch, <span class="fu">mean</span>(train_loss)))</span>
<span id="cb108-27"><a href="#cb108-27" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss at epoch 10: 387.950073
Loss at epoch 20: 282.698288
Loss at epoch 30: 257.855043
Loss at epoch 40: 244.420750
Loss at epoch 50: 217.362108</code></pre>
</div>
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(train_losses, <span class="at">type =</span> <span class="st">"o"</span>, <span class="at">pch =</span> <span class="dv">15</span>,</span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">col =</span> <span class="st">"darkblue"</span>, <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">xlab =</span> <span class="st">"Epoch"</span>,</span>
<span id="cb110-3"><a href="#cb110-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">ylab =</span> <span class="st">"Loss"</span>, <span class="at">las =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C2-DeepNeuralNetworks_files/figure-html/chunk_chapter3_task_45_torch-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The previous sampling wasn’t ideal, why?</p>
</div>
</div>
<p>Now change the code from above for the iris data set. Tip: In tf$keras$losses$… you can find various loss functions.</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:18px;">Solution</span></strong>
    </summary>
    <p>
</p><div class="panelset">
<div class="panel">
<p><span class="panel-name">Keras</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb111-2"><a href="#cb111-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb111-3"><a href="#cb111-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R's random seed.</span></span>
<span id="cb111-4"><a href="#cb111-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-5"><a href="#cb111-5" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">scale</span>(iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span>
<span id="cb111-6"><a href="#cb111-6" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> iris[,<span class="dv">5</span>]</span>
<span id="cb111-7"><a href="#cb111-7" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> keras<span class="sc">::</span><span class="fu">to_categorical</span>(<span class="fu">as.integer</span>(Y)<span class="sc">-</span>1L, <span class="dv">3</span>)</span>
<span id="cb111-8"><a href="#cb111-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-9"><a href="#cb111-9" aria-hidden="true" tabindex="-1"></a>layers <span class="ot">=</span> tf<span class="sc">$</span>keras<span class="sc">$</span>layers</span>
<span id="cb111-10"><a href="#cb111-10" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> tf<span class="sc">$</span>keras<span class="sc">$</span>models<span class="sc">$</span><span class="fu">Sequential</span>(</span>
<span id="cb111-11"><a href="#cb111-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>(</span>
<span id="cb111-12"><a href="#cb111-12" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">InputLayer</span>(<span class="at">input_shape =</span> <span class="fu">list</span>(4L)),</span>
<span id="cb111-13"><a href="#cb111-13" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">Dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> tf<span class="sc">$</span>nn<span class="sc">$</span>relu),</span>
<span id="cb111-14"><a href="#cb111-14" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">Dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> tf<span class="sc">$</span>nn<span class="sc">$</span>relu),</span>
<span id="cb111-15"><a href="#cb111-15" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">Dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> tf<span class="sc">$</span>nn<span class="sc">$</span>relu),</span>
<span id="cb111-16"><a href="#cb111-16" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">Dense</span>(<span class="at">units =</span> 3L, <span class="at">activation =</span> tf<span class="sc">$</span>nn<span class="sc">$</span>softmax)</span>
<span id="cb111-17"><a href="#cb111-17" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb111-18"><a href="#cb111-18" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb111-19"><a href="#cb111-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-20"><a href="#cb111-20" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> 200L</span>
<span id="cb111-21"><a href="#cb111-21" aria-hidden="true" tabindex="-1"></a>optimizer <span class="ot">=</span> tf<span class="sc">$</span>keras<span class="sc">$</span>optimizers<span class="sc">$</span><span class="fu">Adamax</span>(<span class="fl">0.01</span>)</span>
<span id="cb111-22"><a href="#cb111-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-23"><a href="#cb111-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Stochastic gradient optimization is more efficient.</span></span>
<span id="cb111-24"><a href="#cb111-24" aria-hidden="true" tabindex="-1"></a>get_batch <span class="ot">=</span> <span class="cf">function</span>(<span class="at">batch_size =</span> 32L){</span>
<span id="cb111-25"><a href="#cb111-25" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(x), <span class="at">size =</span> batch_size)</span>
<span id="cb111-26"><a href="#cb111-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">bX =</span> x[indices,], <span class="at">bY =</span> y[indices,]))</span>
<span id="cb111-27"><a href="#cb111-27" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb111-28"><a href="#cb111-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-29"><a href="#cb111-29" aria-hidden="true" tabindex="-1"></a>steps <span class="ot">=</span> <span class="fu">floor</span>(<span class="fu">nrow</span>(x)<span class="sc">/</span><span class="dv">32</span>) <span class="sc">*</span> epochs <span class="co"># We need nrow(x)/32 steps for each epoch.</span></span>
<span id="cb111-30"><a href="#cb111-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-31"><a href="#cb111-31" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>steps){</span>
<span id="cb111-32"><a href="#cb111-32" aria-hidden="true" tabindex="-1"></a>  batch <span class="ot">=</span> <span class="fu">get_batch</span>()</span>
<span id="cb111-33"><a href="#cb111-33" aria-hidden="true" tabindex="-1"></a>  bX <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(batch<span class="sc">$</span>bX)</span>
<span id="cb111-34"><a href="#cb111-34" aria-hidden="true" tabindex="-1"></a>  bY <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(batch<span class="sc">$</span>bY)</span>
<span id="cb111-35"><a href="#cb111-35" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb111-36"><a href="#cb111-36" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Automatic differentiation.</span></span>
<span id="cb111-37"><a href="#cb111-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">with</span>(tf<span class="sc">$</span><span class="fu">GradientTape</span>() <span class="sc">%as%</span> tape,</span>
<span id="cb111-38"><a href="#cb111-38" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb111-39"><a href="#cb111-39" aria-hidden="true" tabindex="-1"></a>      pred <span class="ot">=</span> <span class="fu">model</span>(bX) <span class="co"># we record the operation for our model weights</span></span>
<span id="cb111-40"><a href="#cb111-40" aria-hidden="true" tabindex="-1"></a>      loss <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">reduce_mean</span>(tf<span class="sc">$</span>keras<span class="sc">$</span>losses<span class="sc">$</span><span class="fu">categorical_crossentropy</span>(bY, pred))</span>
<span id="cb111-41"><a href="#cb111-41" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb111-42"><a href="#cb111-42" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb111-43"><a href="#cb111-43" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb111-44"><a href="#cb111-44" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Calculate the gradients for the loss at our model$weights / backpropagation.</span></span>
<span id="cb111-45"><a href="#cb111-45" aria-hidden="true" tabindex="-1"></a>  gradients <span class="ot">=</span> tape<span class="sc">$</span><span class="fu">gradient</span>(loss, model<span class="sc">$</span>weights)</span>
<span id="cb111-46"><a href="#cb111-46" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb111-47"><a href="#cb111-47" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Update our model weights with the learning rate specified above.</span></span>
<span id="cb111-48"><a href="#cb111-48" aria-hidden="true" tabindex="-1"></a>  optimizer<span class="sc">$</span><span class="fu">apply_gradients</span>(purrr<span class="sc">::</span><span class="fu">transpose</span>(<span class="fu">list</span>(gradients, model<span class="sc">$</span>weights)))</span>
<span id="cb111-49"><a href="#cb111-49" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb111-50"><a href="#cb111-50" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="sc">!</span> i<span class="sc">%%</span><span class="dv">30</span>){</span>
<span id="cb111-51"><a href="#cb111-51" aria-hidden="true" tabindex="-1"></a>    <span class="fu">cat</span>(<span class="st">"Loss: "</span>, loss<span class="sc">$</span><span class="fu">numpy</span>(), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>) <span class="co"># Print loss every 30 steps (not epochs!).</span></span>
<span id="cb111-52"><a href="#cb111-52" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb111-53"><a href="#cb111-53" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss:  0.002633849 
Loss:  0.0005500487 
Loss:  0.001006462 
Loss:  0.0001315936 
Loss:  0.0004843124 
Loss:  0.0004023896 
Loss:  0.0004356128 
Loss:  0.000235351 
Loss:  4.823796e-05 
Loss:  0.0001512702 
Loss:  0.0002624761 
Loss:  0.0001274793 
Loss:  7.111725e-05 
Loss:  0.0001509234 
Loss:  0.0002024032 
Loss:  0.0001532886 
Loss:  9.489701e-05 
Loss:  0.0001040314 
Loss:  7.334561e-05 
Loss:  2.743953e-05 
Loss:  9.655961e-05 
Loss:  2.361947e-05 
Loss:  6.918395e-05 
Loss:  1.603245e-05 
Loss:  1.772152e-05 
Loss:  2.512357e-05 </code></pre>
</div>
</div>
</div>
<div class="panel">
<p><span class="panel-name">Torch</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb113-3"><a href="#cb113-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">scale</span>(iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span>
<span id="cb113-4"><a href="#cb113-4" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> iris[,<span class="dv">5</span>]</span>
<span id="cb113-5"><a href="#cb113-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">as.integer</span>(iris<span class="sc">$</span>Species)</span>
<span id="cb113-6"><a href="#cb113-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb113-7"><a href="#cb113-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb113-8"><a href="#cb113-8" aria-hidden="true" tabindex="-1"></a>torch_dataset <span class="ot">=</span> torch<span class="sc">::</span><span class="fu">dataset</span>(</span>
<span id="cb113-9"><a href="#cb113-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">name =</span> <span class="st">"iris"</span>,</span>
<span id="cb113-10"><a href="#cb113-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">initialize =</span> <span class="cf">function</span>(X,Y) {</span>
<span id="cb113-11"><a href="#cb113-11" aria-hidden="true" tabindex="-1"></a>      self<span class="sc">$</span>X <span class="ot">=</span> torch<span class="sc">::</span><span class="fu">torch_tensor</span>(<span class="fu">as.matrix</span>(X), <span class="at">dtype =</span> <span class="fu">torch_float32</span>())</span>
<span id="cb113-12"><a href="#cb113-12" aria-hidden="true" tabindex="-1"></a>      self<span class="sc">$</span>Y <span class="ot">=</span> torch<span class="sc">::</span><span class="fu">torch_tensor</span>(Y, <span class="at">dtype =</span> <span class="fu">torch_long</span>())</span>
<span id="cb113-13"><a href="#cb113-13" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb113-14"><a href="#cb113-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">.getitem =</span> <span class="cf">function</span>(index) {</span>
<span id="cb113-15"><a href="#cb113-15" aria-hidden="true" tabindex="-1"></a>      x <span class="ot">=</span> self<span class="sc">$</span>X[index,]</span>
<span id="cb113-16"><a href="#cb113-16" aria-hidden="true" tabindex="-1"></a>      y <span class="ot">=</span> self<span class="sc">$</span>Y[index]</span>
<span id="cb113-17"><a href="#cb113-17" aria-hidden="true" tabindex="-1"></a>      <span class="fu">list</span>(x, y)</span>
<span id="cb113-18"><a href="#cb113-18" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb113-19"><a href="#cb113-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">.length =</span> <span class="cf">function</span>() {</span>
<span id="cb113-20"><a href="#cb113-20" aria-hidden="true" tabindex="-1"></a>      self<span class="sc">$</span>Y<span class="sc">$</span><span class="fu">size</span>()[[<span class="dv">1</span>]]</span>
<span id="cb113-21"><a href="#cb113-21" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb113-22"><a href="#cb113-22" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb113-23"><a href="#cb113-23" aria-hidden="true" tabindex="-1"></a>dataset <span class="ot">=</span> <span class="fu">torch_dataset</span>(x,y)</span>
<span id="cb113-24"><a href="#cb113-24" aria-hidden="true" tabindex="-1"></a>dataloader <span class="ot">=</span> torch<span class="sc">::</span><span class="fu">dataloader</span>(dataset, <span class="at">batch_size =</span> 30L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb113-25"><a href="#cb113-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb113-26"><a href="#cb113-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb113-27"><a href="#cb113-27" aria-hidden="true" tabindex="-1"></a>model_torch <span class="ot">=</span> <span class="fu">nn_sequential</span>(</span>
<span id="cb113-28"><a href="#cb113-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_linear</span>(4L, 50L),</span>
<span id="cb113-29"><a href="#cb113-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_relu</span>(),</span>
<span id="cb113-30"><a href="#cb113-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_linear</span>(50L, 50L),</span>
<span id="cb113-31"><a href="#cb113-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_relu</span>(), </span>
<span id="cb113-32"><a href="#cb113-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_linear</span>(50L, 50L),</span>
<span id="cb113-33"><a href="#cb113-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_relu</span>(), </span>
<span id="cb113-34"><a href="#cb113-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_linear</span>(50L, 3L)</span>
<span id="cb113-35"><a href="#cb113-35" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb113-36"><a href="#cb113-36" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> 50L</span>
<span id="cb113-37"><a href="#cb113-37" aria-hidden="true" tabindex="-1"></a>opt <span class="ot">=</span> <span class="fu">optim_adam</span>(model_torch<span class="sc">$</span>parameters, <span class="fl">0.01</span>)</span>
<span id="cb113-38"><a href="#cb113-38" aria-hidden="true" tabindex="-1"></a>train_losses <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb113-39"><a href="#cb113-39" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(epoch <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>epochs){</span>
<span id="cb113-40"><a href="#cb113-40" aria-hidden="true" tabindex="-1"></a>  train_loss</span>
<span id="cb113-41"><a href="#cb113-41" aria-hidden="true" tabindex="-1"></a>  coro<span class="sc">::</span><span class="fu">loop</span>(</span>
<span id="cb113-42"><a href="#cb113-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(batch <span class="cf">in</span> dataloader) { </span>
<span id="cb113-43"><a href="#cb113-43" aria-hidden="true" tabindex="-1"></a>      opt<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb113-44"><a href="#cb113-44" aria-hidden="true" tabindex="-1"></a>      pred <span class="ot">=</span> <span class="fu">model_torch</span>(batch[[<span class="dv">1</span>]])</span>
<span id="cb113-45"><a href="#cb113-45" aria-hidden="true" tabindex="-1"></a>      loss <span class="ot">=</span> <span class="fu">nnf_cross_entropy</span>(pred, batch[[<span class="dv">2</span>]])</span>
<span id="cb113-46"><a href="#cb113-46" aria-hidden="true" tabindex="-1"></a>      loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb113-47"><a href="#cb113-47" aria-hidden="true" tabindex="-1"></a>      opt<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb113-48"><a href="#cb113-48" aria-hidden="true" tabindex="-1"></a>      train_loss <span class="ot">=</span> <span class="fu">c</span>(train_loss, loss<span class="sc">$</span><span class="fu">item</span>())</span>
<span id="cb113-49"><a href="#cb113-49" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb113-50"><a href="#cb113-50" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb113-51"><a href="#cb113-51" aria-hidden="true" tabindex="-1"></a>  train_losses <span class="ot">=</span> <span class="fu">c</span>(train_losses, <span class="fu">mean</span>(train_loss))</span>
<span id="cb113-52"><a href="#cb113-52" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="sc">!</span>epoch<span class="sc">%%</span><span class="dv">10</span>) <span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">"Loss at epoch %d: %3f</span><span class="sc">\n</span><span class="st">"</span>, epoch, <span class="fu">mean</span>(train_loss)))</span>
<span id="cb113-53"><a href="#cb113-53" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss at epoch 10: 16.298814
Loss at epoch 20: 8.492696
Loss at epoch 30: 5.744957
Loss at epoch 40: 4.344102
Loss at epoch 50: 3.493563</code></pre>
</div>
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(train_losses, <span class="at">type =</span> <span class="st">"o"</span>, <span class="at">pch =</span> <span class="dv">15</span>,</span>
<span id="cb115-2"><a href="#cb115-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">col =</span> <span class="st">"darkblue"</span>, <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">xlab =</span> <span class="st">"Epoch"</span>,</span>
<span id="cb115-3"><a href="#cb115-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">ylab =</span> <span class="st">"Loss"</span>, <span class="at">las =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C2-DeepNeuralNetworks_files/figure-html/chunk_chapter3_task_47_torch-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</div>
</div>
<p>Remarks:</p>
<ul>
<li>Mind the different input and output layer numbers.</li>
<li>The loss function increases randomly, because different subsets of the data were drawn. This is a downside of stochastic gradient descent.</li>
<li>A positive thing about stochastic gradient descent is, that local valleys or hills may be left and global ones can be found instead.</li>
</ul>
    <p></p>
  </details>
  <br><hr>
</section>
<section id="basicMath" class="level2" data-number="9.3">
<h2 data-number="9.3" class="anchored" data-anchor-id="basicMath"><span class="header-section-number">9.3</span> Underlying mathematical concepts - optional</h2>
<p>If are not yet familiar with the underlying concepts of neural networks and want to know more about that, it is suggested to read / view the following videos / sites. Consider the Links and videos with descriptions in parentheses as optional bonus.</p>
<p><strong><em>This might be useful to understand the further concepts in more depth.</em></strong></p>
<ul>
<li><p>(<a href="https://en.wikipedia.org/wiki/Newton%27s_method#Description" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Newton%27s_method#Description</a> (Especially the animated graphic is interesting).)</p></li>
<li><p><a href="https://en.wikipedia.org/wiki/Gradient_descent#Description" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Gradient_descent#Description</a></p></li>
<li><p><a href="https://mlfromscratch.com/neural-networks-explained/#/" target="_blank" rel="noopener">Neural networks (Backpropagation, etc.)</a>.</p></li>
<li><p><a href="https://mlfromscratch.com/activation-functions-explained/#/" target="_blank" rel="noopener">Activation functions in detail</a> (requires the above as prerequisite).</p></li>
</ul>
<p><strong><em>Videos about the topic</em></strong>:</p>
<ul>
<li><strong>Gradient descent explained</strong></li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/sDv4f4s2SB8" frameborder="0" allow="accelerometer; autoplay; clipboard-write;
  encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<ul>
<li>(Stochastic gradient descent explained)</li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/vMh0zPT0tLI" frameborder="0" allow="accelerometer; autoplay; clipboard-write;
  encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<ul>
<li>(Entropy explained)</li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/YtebGVx-Fxw" frameborder="0" allow="accelerometer; autoplay; clipboard-write;
  encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<ul>
<li><strong>Short explanation of entropy, cross entropy and Kullback–Leibler divergence</strong></li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/ErfnhcEV1O8" frameborder="0" allow="accelerometer; autoplay; clipboard-write;
  encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<ul>
<li><strong>Deep Learning (chapter 1)</strong></li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/aircAruvnKk" frameborder="0" allow="accelerometer; autoplay; clipboard-write;
  encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<ul>
<li><strong>How neural networks learn - Deep Learning (chapter 2)</strong></li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/IHZwWFHWa-w" frameborder="0" allow="accelerometer; autoplay; clipboard-write;
  encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<ul>
<li><strong>Backpropagation - Deep Learning (chapter 3)</strong></li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Ilg3gGewQ5U" frameborder="0" allow="accelerometer; autoplay; clipboard-write;
  encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<ul>
<li><strong>Another video about backpropagation (extends the previous one) - Deep Learning (chapter 4)</strong></li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/tIeHLnjs5U8" frameborder="0" allow="accelerometer; autoplay; clipboard-write;
  encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<section id="caveats-of-neural-network-optimization" class="level3" data-number="9.3.1">
<h3 data-number="9.3.1" class="anchored" data-anchor-id="caveats-of-neural-network-optimization"><span class="header-section-number">9.3.1</span> Caveats of neural network optimization</h3>
<p>Depending on activation functions, it might occur that the network won’t get updated, even with high learning rates (called <em>vanishing gradient</em>, especially for “sigmoid” functions). Furthermore, updates might overshoot (called <em>exploding gradients</em>) or activation functions will result in many zeros (especially for “relu”, <em>dying relu</em>).</p>
<p>In general, the first layers of a network tend to learn (much) more slowly than subsequent ones.</p>


</section>
</section>

</main> <!-- /main -->
<script>

/* update total correct if #webex-total_correct exists */
update_total_correct = function() {
  console.log("webex: update total_correct");

  var t = document.getElementsByClassName("webex-total_correct");
  for (var i = 0; i < t.length; i++) {
    p = t[i].parentElement;
    var correct = p.getElementsByClassName("webex-correct").length;
    var solvemes = p.getElementsByClassName("webex-solveme").length;
    var radiogroups = p.getElementsByClassName("webex-radiogroup").length;
    var selects = p.getElementsByClassName("webex-select").length;

    t[i].innerHTML = correct + " of " + (solvemes + radiogroups + selects) + " correct";
  }
}

/* webex-solution button toggling function */
b_func = function() {
  console.log("webex: toggle hide");

  var cl = this.parentElement.classList;
  if (cl.contains('open')) {
    cl.remove("open");
  } else {
    cl.add("open");
  }
}

/* check answers */
check_func = function() {
  console.log("webex: check answers");

  var cl = this.parentElement.classList;
  if (cl.contains('unchecked')) {
    cl.remove("unchecked");
    this.innerHTML = "Hide Answers";
  } else {
    cl.add("unchecked");
    this.innerHTML = "Show Answers";
  }
}

/* function for checking solveme answers */
solveme_func = function(e) {
  console.log("webex: check solveme");

  var real_answers = JSON.parse(this.dataset.answer);
  var my_answer = this.value;
  var cl = this.classList;
  if (cl.contains("ignorecase")) {
    my_answer = my_answer.toLowerCase();
  }
  if (cl.contains("nospaces")) {
    my_answer = my_answer.replace(/ /g, "")
  }

  if (my_answer == "") {
    cl.remove("webex-correct");
    cl.remove("webex-incorrect");
  } else if (real_answers.includes(my_answer)) {
    cl.add("webex-correct");
    cl.remove("webex-incorrect");
  } else {
    cl.add("webex-incorrect");
    cl.remove("webex-correct");
  }

  // match numeric answers within a specified tolerance
  if(this.dataset.tol > 0){
    var tol = JSON.parse(this.dataset.tol);
    var matches = real_answers.map(x => Math.abs(x - my_answer) < tol)
    if (matches.reduce((a, b) => a + b, 0) > 0) {
      cl.add("webex-correct");
    } else {
      cl.remove("webex-correct");
    }
  }

  // added regex bit
  if (cl.contains("regex")){
    answer_regex = RegExp(real_answers.join("|"))
    if (answer_regex.test(my_answer)) {
      cl.add("webex-correct");
    }
  }

  update_total_correct();
}

/* function for checking select answers */
select_func = function(e) {
  console.log("webex: check select");

  var cl = this.classList

  /* add style */
  cl.remove("webex-incorrect");
  cl.remove("webex-correct");
  if (this.value == "answer") {
    cl.add("webex-correct");
  } else if (this.value != "blank") {
    cl.add("webex-incorrect");
  }

  update_total_correct();
}

/* function for checking radiogroups answers */
radiogroups_func = function(e) {
  console.log("webex: check radiogroups");

  var checked_button = document.querySelector('input[name=' + this.id + ']:checked');
  var cl = checked_button.parentElement.classList;
  var labels = checked_button.parentElement.parentElement.children;

  /* get rid of styles */
  for (i = 0; i < labels.length; i++) {
    labels[i].classList.remove("webex-incorrect");
    labels[i].classList.remove("webex-correct");
  }

  /* add style */
  if (checked_button.value == "answer") {
    cl.add("webex-correct");
  } else {
    cl.add("webex-incorrect");
  }

  update_total_correct();
}

window.onload = function() {
  console.log("webex onload");
  /* set up solution buttons */
  var buttons = document.getElementsByTagName("button");

  for (var i = 0; i < buttons.length; i++) {
    if (buttons[i].parentElement.classList.contains('webex-solution')) {
      buttons[i].onclick = b_func;
    }
  }

  var check_sections = document.getElementsByClassName("webex-check");
  console.log("check:", check_sections.length);
  for (var i = 0; i < check_sections.length; i++) {
    check_sections[i].classList.add("unchecked");

    let btn = document.createElement("button");
    btn.innerHTML = "Show Answers";
    btn.classList.add("webex-check-button");
    btn.onclick = check_func;
    check_sections[i].appendChild(btn);

    let spn = document.createElement("span");
    spn.classList.add("webex-total_correct");
    check_sections[i].appendChild(spn);
  }

  /* set up webex-solveme inputs */
  var solveme = document.getElementsByClassName("webex-solveme");

  for (var i = 0; i < solveme.length; i++) {
    /* make sure input boxes don't auto-anything */
    solveme[i].setAttribute("autocomplete","off");
    solveme[i].setAttribute("autocorrect", "off");
    solveme[i].setAttribute("autocapitalize", "off");
    solveme[i].setAttribute("spellcheck", "false");
    solveme[i].value = "";

    /* adjust answer for ignorecase or nospaces */
    var cl = solveme[i].classList;
    var real_answer = solveme[i].dataset.answer;
    if (cl.contains("ignorecase")) {
      real_answer = real_answer.toLowerCase();
    }
    if (cl.contains("nospaces")) {
      real_answer = real_answer.replace(/ /g, "");
    }
    solveme[i].dataset.answer = real_answer;

    /* attach checking function */
    solveme[i].onkeyup = solveme_func;
    solveme[i].onchange = solveme_func;

    solveme[i].insertAdjacentHTML("afterend", " <span class='webex-icon'></span>")
  }

  /* set up radiogroups */
  var radiogroups = document.getElementsByClassName("webex-radiogroup");
  for (var i = 0; i < radiogroups.length; i++) {
    radiogroups[i].onchange = radiogroups_func;
  }

  /* set up selects */
  var selects = document.getElementsByClassName("webex-select");
  for (var i = 0; i < selects.length; i++) {
    selects[i].onchange = select_func;
    selects[i].insertAdjacentHTML("afterend", " <span class='webex-icon'></span>")
  }

  update_total_correct();
}

</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./C1-TensorFlow.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Introduction to TensorFlow and Keras</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./C3-ConvolutionalNeuralNetworks.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Convolutional Neural Networks</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>
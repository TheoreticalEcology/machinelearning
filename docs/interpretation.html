<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6 Interpretation and Causality With Machine Learning | Machine Learning and AI in TensorFlow and R</title>
  <meta name="description" content="6 Interpretation and Causality With Machine Learning | Machine Learning and AI in TensorFlow and R" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="6 Interpretation and Causality With Machine Learning | Machine Learning and AI in TensorFlow and R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="6 Interpretation and Causality With Machine Learning | Machine Learning and AI in TensorFlow and R" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6 Interpretation and Causality With Machine Learning | Machine Learning and AI in TensorFlow and R" />
  
  <meta name="twitter:description" content="6 Interpretation and Causality With Machine Learning | Machine Learning and AI in TensorFlow and R" />
  

<meta name="author" content="Maximilian Pichler and Florian Hartig" />


<meta name="date" content="2021-11-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="deep.html"/>
<link rel="next" href="gan.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/viz-1.8.2/viz.js"></script>
<link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="libs/grViz-binding-1.0.6.1/grViz.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #ffffff;
    color: #a0a0a0;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
div.sourceCode
  { color: #1f1c1b; background-color: #ffffff; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span { color: #1f1c1b; } /* Normal */
code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
code span.an { color: #ca60ca; } /* Annotation */
code span.at { color: #0057ae; } /* Attribute */
code span.bn { color: #b08000; } /* BaseN */
code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #924c9d; } /* Char */
code span.cn { color: #aa5500; } /* Constant */
code span.co { color: #898887; } /* Comment */
code span.cv { color: #0095ff; } /* CommentVar */
code span.do { color: #607880; } /* Documentation */
code span.dt { color: #0057ae; } /* DataType */
code span.dv { color: #b08000; } /* DecVal */
code span.er { color: #bf0303; text-decoration: underline; } /* Error */
code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
code span.fl { color: #b08000; } /* Float */
code span.fu { color: #644a9b; } /* Function */
code span.im { color: #ff5500; } /* Import */
code span.in { color: #b08000; } /* Information */
code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
code span.op { color: #1f1c1b; } /* Operator */
code span.ot { color: #006e28; } /* Other */
code span.pp { color: #006e28; } /* Preprocessor */
code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #ff5500; } /* SpecialString */
code span.st { color: #bf0303; } /* String */
code span.va { color: #0057ae; } /* Variable */
code span.vs { color: #bf0303; } /* VerbatimString */
code span.wa { color: #bf0303; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#r-system"><i class="fa fa-check"></i><b>1.1</b> R System</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#tensorflow-and-keras"><i class="fa fa-check"></i><b>1.2</b> TensorFlow and Keras</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#torch-for-r"><i class="fa fa-check"></i><b>1.3</b> Torch for R</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#ecodata"><i class="fa fa-check"></i><b>1.4</b> EcoData</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#further-used-libraries"><i class="fa fa-check"></i><b>1.5</b> Further Used Libraries</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#linuxunix-systems-have-to-fulfill-some-durther-dependencies"><i class="fa fa-check"></i><b>1.6</b> Linux/UNIX systems have to fulfill some durther dependencies</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="reminder.html"><a href="reminder.html"><i class="fa fa-check"></i><b>2</b> Reminders About Basic Operations in R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="reminder.html"><a href="reminder.html#your-r-system"><i class="fa fa-check"></i><b>2.1</b> Your R System</a></li>
<li class="chapter" data-level="2.2" data-path="reminder.html"><a href="reminder.html#data-types-in-r"><i class="fa fa-check"></i><b>2.2</b> Data types in R</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="reminder.html"><a href="reminder.html#test-your-knowledge"><i class="fa fa-check"></i><b>2.2.1</b> Test Your Knowledge</a></li>
<li class="chapter" data-level="2.2.2" data-path="reminder.html"><a href="reminder.html#iris-data"><i class="fa fa-check"></i><b>2.2.2</b> Iris Data</a></li>
<li class="chapter" data-level="2.2.3" data-path="reminder.html"><a href="reminder.html#dynamic-typing"><i class="fa fa-check"></i><b>2.2.3</b> Dynamic typing</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="reminder.html"><a href="reminder.html#data-selection-slicing-and-subsetting"><i class="fa fa-check"></i><b>2.3</b> Data selection, Slicing and Subsetting</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="reminder.html"><a href="reminder.html#subsetting-and-slicing-for-single-data-types"><i class="fa fa-check"></i><b>2.3.1</b> Subsetting and Slicing for Single Data Types</a></li>
<li class="chapter" data-level="2.3.2" data-path="reminder.html"><a href="reminder.html#logic-and-slicing"><i class="fa fa-check"></i><b>2.3.2</b> Logic and Slicing</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="reminder.html"><a href="reminder.html#applying-functions-and-aggregates-across-a-data-set"><i class="fa fa-check"></i><b>2.4</b> Applying Functions and Aggregates Across a Data set</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="reminder.html"><a href="reminder.html#functions"><i class="fa fa-check"></i><b>2.4.1</b> Functions</a></li>
<li class="chapter" data-level="2.4.2" data-path="reminder.html"><a href="reminder.html#the-apply-function"><i class="fa fa-check"></i><b>2.4.2</b> The apply() Function</a></li>
<li class="chapter" data-level="2.4.3" data-path="reminder.html"><a href="reminder.html#the-aggregate-function"><i class="fa fa-check"></i><b>2.4.3</b> The aggregate() Function</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="reminder.html"><a href="reminder.html#plotting"><i class="fa fa-check"></i><b>2.5</b> Plotting</a></li>
<li class="chapter" data-level="2.6" data-path="reminder.html"><a href="reminder.html#additional-resources"><i class="fa fa-check"></i><b>2.6</b> Additional Resources</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="reminder.html"><a href="reminder.html#books"><i class="fa fa-check"></i><b>2.6.1</b> Books</a></li>
<li class="chapter" data-level="2.6.2" data-path="reminder.html"><a href="reminder.html#instructional-videos"><i class="fa fa-check"></i><b>2.6.2</b> Instructional videos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>3</b> Introduction to Machine Learning</a>
<ul>
<li class="chapter" data-level="3.1" data-path="introduction.html"><a href="introduction.html#unsupervised-learning"><i class="fa fa-check"></i><b>3.1</b> Unsupervised Learning</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="introduction.html"><a href="introduction.html#hierarchical-clustering"><i class="fa fa-check"></i><b>3.1.1</b> Hierarchical Clustering</a></li>
<li class="chapter" data-level="3.1.2" data-path="introduction.html"><a href="introduction.html#k-means-clustering"><i class="fa fa-check"></i><b>3.1.2</b> K-means Clustering</a></li>
<li class="chapter" data-level="3.1.3" data-path="introduction.html"><a href="introduction.html#density-based-clustering"><i class="fa fa-check"></i><b>3.1.3</b> Density-based Clustering</a></li>
<li class="chapter" data-level="3.1.4" data-path="introduction.html"><a href="introduction.html#model-based-clustering"><i class="fa fa-check"></i><b>3.1.4</b> Model-based Clustering</a></li>
<li class="chapter" data-level="3.1.5" data-path="introduction.html"><a href="introduction.html#ordination"><i class="fa fa-check"></i><b>3.1.5</b> Ordination</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="introduction.html"><a href="introduction.html#supervised-learning-regression-and-classification"><i class="fa fa-check"></i><b>3.2</b> Supervised Learning: Regression and Classification</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="introduction.html"><a href="introduction.html#supervised-regression-using-random-forest"><i class="fa fa-check"></i><b>3.2.1</b> Supervised Regression Using Random Forest</a></li>
<li class="chapter" data-level="3.2.2" data-path="introduction.html"><a href="introduction.html#supervised-classification-using-random-forest"><i class="fa fa-check"></i><b>3.2.2</b> Supervised Classification Using Random Forest</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="introduction.html"><a href="introduction.html#basicMath"><i class="fa fa-check"></i><b>3.3</b> Small Introduction Into the Underlying Mathematical Concepts of all Following Lessons - Optional</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="introduction.html"><a href="introduction.html#caveat-about-learning-rates-and-activation-functions"><i class="fa fa-check"></i><b>3.3.1</b> Caveat About Learning Rates and Activation Functions</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="introduction.html"><a href="introduction.html#introduction-to-tensorflow"><i class="fa fa-check"></i><b>3.4</b> Introduction to TensorFlow</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="introduction.html"><a href="introduction.html#tensorflow-data-containers"><i class="fa fa-check"></i><b>3.4.1</b> TensorFlow Data Containers</a></li>
<li class="chapter" data-level="3.4.2" data-path="introduction.html"><a href="introduction.html#basic-operations"><i class="fa fa-check"></i><b>3.4.2</b> Basic Operations</a></li>
<li class="chapter" data-level="3.4.3" data-path="introduction.html"><a href="introduction.html#tensorflow-data-types---good-practice-with-r-tensorflow"><i class="fa fa-check"></i><b>3.4.3</b> TensorFlow Data Types - Good Practice With R-TensorFlow</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="introduction.html"><a href="introduction.html#introduction-to-pytorch"><i class="fa fa-check"></i><b>3.5</b> Introduction to PyTorch</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="introduction.html"><a href="introduction.html#pytorch-data-containers"><i class="fa fa-check"></i><b>3.5.1</b> PyTorch Data Containers</a></li>
<li class="chapter" data-level="3.5.2" data-path="introduction.html"><a href="introduction.html#basic-operations-1"><i class="fa fa-check"></i><b>3.5.2</b> Basic Operations</a></li>
<li class="chapter" data-level="3.5.3" data-path="introduction.html"><a href="introduction.html#torch-data-types---good-practice-with-r-torch"><i class="fa fa-check"></i><b>3.5.3</b> Torch Data Types - Good Practice With R-Torch</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="introduction.html"><a href="introduction.html#first-steps-with-the-keras-framework"><i class="fa fa-check"></i><b>3.6</b> First Steps With the Keras Framework</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="introduction.html"><a href="introduction.html#example-workflow-in-keras"><i class="fa fa-check"></i><b>3.6.1</b> Example Workflow in Keras</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="fundamental.html"><a href="fundamental.html"><i class="fa fa-check"></i><b>4</b> Fundamental Principles and Techniques</a>
<ul>
<li class="chapter" data-level="4.1" data-path="fundamental.html"><a href="fundamental.html#machine-learning-principles"><i class="fa fa-check"></i><b>4.1</b> Machine Learning Principles</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="fundamental.html"><a href="fundamental.html#optimization"><i class="fa fa-check"></i><b>4.1.1</b> Optimization</a></li>
<li class="chapter" data-level="4.1.2" data-path="fundamental.html"><a href="fundamental.html#advanced-optimization-example"><i class="fa fa-check"></i><b>4.1.2</b> Advanced Optimization Example</a></li>
<li class="chapter" data-level="4.1.3" data-path="fundamental.html"><a href="fundamental.html#regularization"><i class="fa fa-check"></i><b>4.1.3</b> Regularization</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="fundamental.html"><a href="fundamental.html#artificial-neural-networks"><i class="fa fa-check"></i><b>4.2</b> Artificial Neural Networks</a></li>
<li class="chapter" data-level="4.3" data-path="fundamental.html"><a href="fundamental.html#tree-based-machine-learning-algorithms"><i class="fa fa-check"></i><b>4.3</b> Tree-based Machine Learning Algorithms</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="fundamental.html"><a href="fundamental.html#classification-and-regression-trees"><i class="fa fa-check"></i><b>4.3.1</b> Classification and Regression Trees</a></li>
<li class="chapter" data-level="4.3.2" data-path="fundamental.html"><a href="fundamental.html#random-forest"><i class="fa fa-check"></i><b>4.3.2</b> Random Forest</a></li>
<li class="chapter" data-level="4.3.3" data-path="fundamental.html"><a href="fundamental.html#boosted-regression-trees"><i class="fa fa-check"></i><b>4.3.3</b> Boosted Regression Trees</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="fundamental.html"><a href="fundamental.html#distance-based-algorithms"><i class="fa fa-check"></i><b>4.4</b> Distance-based Algorithms</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="fundamental.html"><a href="fundamental.html#k-nearest-neighbor"><i class="fa fa-check"></i><b>4.4.1</b> K-Nearest-Neighbor</a></li>
<li class="chapter" data-level="4.4.2" data-path="fundamental.html"><a href="fundamental.html#support-vector-machines-svms"><i class="fa fa-check"></i><b>4.4.2</b> Support Vector Machines (SVMs)</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="fundamental.html"><a href="fundamental.html#the-standard-machine-learning-pipeline-at-the-eexample-of-the-titanic-data-set"><i class="fa fa-check"></i><b>4.5</b> The Standard Machine Learning Pipeline at the Eexample of the Titanic Data set</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="fundamental.html"><a href="fundamental.html#data-cleaning"><i class="fa fa-check"></i><b>4.5.1</b> Data Cleaning</a></li>
<li class="chapter" data-level="4.5.2" data-path="fundamental.html"><a href="fundamental.html#preprocessing-and-feature-selection"><i class="fa fa-check"></i><b>4.5.2</b> Preprocessing and Feature Selection</a></li>
<li class="chapter" data-level="4.5.3" data-path="fundamental.html"><a href="fundamental.html#split-data-for-training-and-testing"><i class="fa fa-check"></i><b>4.5.3</b> Split Data for Training and Testing</a></li>
<li class="chapter" data-level="4.5.4" data-path="fundamental.html"><a href="fundamental.html#model-fitting"><i class="fa fa-check"></i><b>4.5.4</b> Model Fitting</a></li>
<li class="chapter" data-level="4.5.5" data-path="fundamental.html"><a href="fundamental.html#model-evaluation"><i class="fa fa-check"></i><b>4.5.5</b> Model Evaluation</a></li>
<li class="chapter" data-level="4.5.6" data-path="fundamental.html"><a href="fundamental.html#predictions-and-submission"><i class="fa fa-check"></i><b>4.5.6</b> Predictions and Submission</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="fundamental.html"><a href="fundamental.html#mlr"><i class="fa fa-check"></i><b>4.6</b> Bonus - Machine Learning Pipelines with mlr3</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="fundamental.html"><a href="fundamental.html#mlr3---the-basic-workflow"><i class="fa fa-check"></i><b>4.6.1</b> mlr3 - The Basic Workflow</a></li>
<li class="chapter" data-level="4.6.2" data-path="fundamental.html"><a href="fundamental.html#mlr3---hyperparameter-tuning"><i class="fa fa-check"></i><b>4.6.2</b> mlr3 - Hyperparameter Tuning</a></li>
<li class="chapter" data-level="4.6.3" data-path="fundamental.html"><a href="fundamental.html#mlr3---hyperparameter-tuning-with-oversampling"><i class="fa fa-check"></i><b>4.6.3</b> mlr3 - Hyperparameter Tuning with Oversampling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="deep.html"><a href="deep.html"><i class="fa fa-check"></i><b>5</b> Deep Learning</a>
<ul>
<li class="chapter" data-level="5.1" data-path="deep.html"><a href="deep.html#network-architectures"><i class="fa fa-check"></i><b>5.1</b> Network Architectures</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="deep.html"><a href="deep.html#deep-neural-networks-dnns"><i class="fa fa-check"></i><b>5.1.1</b> Deep Neural Networks (DNNs)</a></li>
<li class="chapter" data-level="5.1.2" data-path="deep.html"><a href="deep.html#convolutional-neural-networks-cnns"><i class="fa fa-check"></i><b>5.1.2</b> Convolutional Neural Networks (CNNs)</a></li>
<li class="chapter" data-level="5.1.3" data-path="deep.html"><a href="deep.html#recurrent-neural-networks-rnns"><i class="fa fa-check"></i><b>5.1.3</b> Recurrent Neural Networks (RNNs)</a></li>
<li class="chapter" data-level="5.1.4" data-path="deep.html"><a href="deep.html#natural-language-processing-nlp"><i class="fa fa-check"></i><b>5.1.4</b> Natural Language Processing (NLP)</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="deep.html"><a href="deep.html#case-study-dropout-and-early-stopping-in-a-deep-neural-network"><i class="fa fa-check"></i><b>5.2</b> Case Study: Dropout and Early Stopping in a Deep Neural Network</a></li>
<li class="chapter" data-level="5.3" data-path="deep.html"><a href="deep.html#case-study-fitting-a-convolutional-neural-network-on-mnist"><i class="fa fa-check"></i><b>5.3</b> Case Study: Fitting a Convolutional Neural Network on MNIST</a></li>
<li class="chapter" data-level="5.4" data-path="deep.html"><a href="deep.html#advanced-training-techniques"><i class="fa fa-check"></i><b>5.4</b> Advanced Training Techniques</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="deep.html"><a href="deep.html#data-augmentation"><i class="fa fa-check"></i><b>5.4.1</b> Data Augmentation</a></li>
<li class="chapter" data-level="5.4.2" data-path="deep.html"><a href="deep.html#transfer"><i class="fa fa-check"></i><b>5.4.2</b> Transfer Learning</a></li>
<li class="chapter" data-level="5.4.3" data-path="deep.html"><a href="deep.html#influence-of-batch-size-and-learning-rate"><i class="fa fa-check"></i><b>5.4.3</b> Influence of Batch Size and Learning Rate</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="interpretation.html"><a href="interpretation.html"><i class="fa fa-check"></i><b>6</b> Interpretation and Causality With Machine Learning</a>
<ul>
<li class="chapter" data-level="6.1" data-path="interpretation.html"><a href="interpretation.html#explainable-ai"><i class="fa fa-check"></i><b>6.1</b> Explainable AI</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="interpretation.html"><a href="interpretation.html#a-practical-example"><i class="fa fa-check"></i><b>6.1.1</b> A Practical Example</a></li>
<li class="chapter" data-level="6.1.2" data-path="interpretation.html"><a href="interpretation.html#feature-importance"><i class="fa fa-check"></i><b>6.1.2</b> Feature Importance</a></li>
<li class="chapter" data-level="6.1.3" data-path="interpretation.html"><a href="interpretation.html#partial-dependencies"><i class="fa fa-check"></i><b>6.1.3</b> Partial Dependencies</a></li>
<li class="chapter" data-level="6.1.4" data-path="interpretation.html"><a href="interpretation.html#accumulated-local-effects"><i class="fa fa-check"></i><b>6.1.4</b> Accumulated Local Effects</a></li>
<li class="chapter" data-level="6.1.5" data-path="interpretation.html"><a href="interpretation.html#friedmans-h-statistic"><i class="fa fa-check"></i><b>6.1.5</b> Friedman’s H-statistic</a></li>
<li class="chapter" data-level="6.1.6" data-path="interpretation.html"><a href="interpretation.html#global-explainer---simplifying-the-machine-learning-model"><i class="fa fa-check"></i><b>6.1.6</b> Global Explainer - Simplifying the Machine Learning Model</a></li>
<li class="chapter" data-level="6.1.7" data-path="interpretation.html"><a href="interpretation.html#local-explainer---lime-explaining-single-instances-observations"><i class="fa fa-check"></i><b>6.1.7</b> Local Explainer - LIME Explaining Single Instances (observations)</a></li>
<li class="chapter" data-level="6.1.8" data-path="interpretation.html"><a href="interpretation.html#local-explainer---shapley"><i class="fa fa-check"></i><b>6.1.8</b> Local Explainer - Shapley</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="interpretation.html"><a href="interpretation.html#causal-inference-and-machine-learning"><i class="fa fa-check"></i><b>6.2</b> Causal Inference and Machine Learning</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="interpretation.html"><a href="interpretation.html#causalInference"><i class="fa fa-check"></i><b>6.2.1</b> Causal Inference on Static Data</a></li>
<li class="chapter" data-level="6.2.2" data-path="interpretation.html"><a href="interpretation.html#structural-equation-models"><i class="fa fa-check"></i><b>6.2.2</b> Structural Equation Models</a></li>
<li class="chapter" data-level="6.2.3" data-path="interpretation.html"><a href="interpretation.html#automatic-causal-discovery"><i class="fa fa-check"></i><b>6.2.3</b> Automatic Causal Discovery</a></li>
<li class="chapter" data-level="6.2.4" data-path="interpretation.html"><a href="interpretation.html#causal-inference-on-dynamic-data"><i class="fa fa-check"></i><b>6.2.4</b> Causal Inference on Dynamic Data</a></li>
<li class="chapter" data-level="6.2.5" data-path="interpretation.html"><a href="interpretation.html#outlook-for-machine-learning"><i class="fa fa-check"></i><b>6.2.5</b> Outlook for Machine Learning</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="gan.html"><a href="gan.html"><i class="fa fa-check"></i><b>7</b> Generative Modeling and Reinforcement Learning</a>
<ul>
<li class="chapter" data-level="7.1" data-path="gan.html"><a href="gan.html#autoencoder"><i class="fa fa-check"></i><b>7.1</b> Autoencoder</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="gan.html"><a href="gan.html#autoencoder---deep-neural-network-mnist"><i class="fa fa-check"></i><b>7.1.1</b> Autoencoder - Deep Neural Network MNIST</a></li>
<li class="chapter" data-level="7.1.2" data-path="gan.html"><a href="gan.html#autoencoder---mnist-convolutional-neural-networks"><i class="fa fa-check"></i><b>7.1.2</b> Autoencoder - MNIST Convolutional Neural Networks</a></li>
<li class="chapter" data-level="7.1.3" data-path="gan.html"><a href="gan.html#VAE"><i class="fa fa-check"></i><b>7.1.3</b> Variational Autoencoder (VAE)</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="gan.html"><a href="gan.html#GANS"><i class="fa fa-check"></i><b>7.2</b> Generative Adversarial Networks (GANs)</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="gan.html"><a href="gan.html#mnist---generative-adversarial-networks-based-on-deep-neural-networks"><i class="fa fa-check"></i><b>7.2.1</b> MNIST - Generative Adversarial Networks Based on Deep Neural Networks</a></li>
<li class="chapter" data-level="7.2.2" data-path="gan.html"><a href="gan.html#flower---gan"><i class="fa fa-check"></i><b>7.2.2</b> Flower - GAN</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="gan.html"><a href="gan.html#reinforcement-learning"><i class="fa fa-check"></i><b>7.3</b> Reinforcement learning</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="datasets.html"><a href="datasets.html"><i class="fa fa-check"></i><b>8</b> Data sets</a>
<ul>
<li class="chapter" data-level="8.1" data-path="datasets.html"><a href="datasets.html#titanic"><i class="fa fa-check"></i><b>8.1</b> Titanic</a></li>
<li class="chapter" data-level="8.2" data-path="datasets.html"><a href="datasets.html#plant-pollinator-database"><i class="fa fa-check"></i><b>8.2</b> Plant-pollinator Database</a></li>
<li class="chapter" data-level="8.3" data-path="datasets.html"><a href="datasets.html#wine"><i class="fa fa-check"></i><b>8.3</b> Wine</a></li>
<li class="chapter" data-level="8.4" data-path="datasets.html"><a href="datasets.html#nasa"><i class="fa fa-check"></i><b>8.4</b> Nasa</a></li>
<li class="chapter" data-level="8.5" data-path="datasets.html"><a href="datasets.html#flower"><i class="fa fa-check"></i><b>8.5</b> Flower</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning and AI in TensorFlow and R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="interpretation" class="section level1" number="6">
<h1><span class="header-section-number">6</span> Interpretation and Causality With Machine Learning</h1>
<!-- Put this here (right after the first markdown headline) and only here for each document! -->
<script src="./scripts/multipleChoice.js"></script>
<div id="explainable-ai" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> Explainable AI</h2>
<p>The goal of explainable AI (xAI, aka interpretable machine learning) is to explain <strong>why</strong> a fitted machine learning model makes certain predictions. A typical example is to understand how important different variables are for predictions. The incentives for doing so range from a better technical understanding of the models over understanding which data is important for improving predictions to questions of fairness and discrimination (e.g. to understand if an algorithm uses skin color to make a decision).</p>
<div id="a-practical-example" class="section level3" number="6.1.1">
<h3><span class="header-section-number">6.1.1</span> A Practical Example</h3>
<p>In this lecture we will work with another famous data set, the <em>Boston housing</em> data set:</p>
<p>We will fit a random forest and use the iml package for xAI, see <a href="https://christophm.github.io/interpretable-ml-book/" target="_blank" rel="noopener">https://christophm.github.io/interpretable-ml-book/</a>.</p>
<div class="sourceCode" id="cb798"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb798-1"><a href="interpretation.html#cb798-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(iml)</span>
<span id="cb798-2"><a href="interpretation.html#cb798-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span>
<span id="cb798-3"><a href="interpretation.html#cb798-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb798-4"><a href="interpretation.html#cb798-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb798-5"><a href="interpretation.html#cb798-5" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;Boston&quot;</span>, <span class="at">package =</span> <span class="st">&quot;MASS&quot;</span>)</span>
<span id="cb798-6"><a href="interpretation.html#cb798-6" aria-hidden="true" tabindex="-1"></a>rf <span class="ot">=</span> <span class="fu">randomForest</span>(medv <span class="sc">~</span> ., <span class="at">data =</span> Boston, <span class="at">ntree =</span> <span class="dv">50</span>)</span></code></pre></div>
<p>xAI packages are written generic, i.e. they can handle almost all machine learning models.
When we want to use them, we first have to create a predictor object, that holds the model and the data. The iml package uses R6 classes, that means new objects can be created by calling Predictor$new(). (Do not worry if you do not know what R6 classes are, just use the command.)</p>
<div class="sourceCode" id="cb799"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb799-1"><a href="interpretation.html#cb799-1" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> Boston[<span class="fu">which</span>(<span class="fu">names</span>(Boston) <span class="sc">!=</span> <span class="st">&quot;medv&quot;</span>)]</span>
<span id="cb799-2"><a href="interpretation.html#cb799-2" aria-hidden="true" tabindex="-1"></a>predictor <span class="ot">=</span> Predictor<span class="sc">$</span><span class="fu">new</span>(rf, <span class="at">data =</span> X, <span class="at">y =</span> Boston<span class="sc">$</span>medv)</span>
<span id="cb799-3"><a href="interpretation.html#cb799-3" aria-hidden="true" tabindex="-1"></a><span class="co"># &quot;Predictor&quot; is an object generator.</span></span></code></pre></div>
</div>
<div id="feature-importance" class="section level3" number="6.1.2">
<h3><span class="header-section-number">6.1.2</span> Feature Importance</h3>
<p>Feature importance should not be mistaken with the random forest variable importance though they are related. It tells us how important the individual variables are for predictions, can be calculated for all machine learning models and is based on a permutation approach (have a look at the book):</p>
<div class="sourceCode" id="cb800"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb800-1"><a href="interpretation.html#cb800-1" aria-hidden="true" tabindex="-1"></a>imp <span class="ot">=</span> FeatureImp<span class="sc">$</span><span class="fu">new</span>(predictor, <span class="at">loss =</span> <span class="st">&quot;mae&quot;</span>)</span>
<span id="cb800-2"><a href="interpretation.html#cb800-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(imp)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter6_2-1.png" width="672" /></p>
</div>
<div id="partial-dependencies" class="section level3" number="6.1.3">
<h3><span class="header-section-number">6.1.3</span> Partial Dependencies</h3>
<p>Partial dependencies are similar to allEffects plots for normal regressions. The idea is to visualize “marginal effects” of predictors (with the “feature” argument we specify the variable we want to visualize):</p>
<div class="sourceCode" id="cb801"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb801-1"><a href="interpretation.html#cb801-1" aria-hidden="true" tabindex="-1"></a>eff <span class="ot">=</span> FeatureEffect<span class="sc">$</span><span class="fu">new</span>(predictor, <span class="at">feature =</span> <span class="st">&quot;rm&quot;</span>, <span class="at">method =</span> <span class="st">&quot;pdp&quot;</span>,</span>
<span id="cb801-2"><a href="interpretation.html#cb801-2" aria-hidden="true" tabindex="-1"></a>                        <span class="at">grid.size =</span> <span class="dv">30</span>)</span>
<span id="cb801-3"><a href="interpretation.html#cb801-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(eff)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter6_3-1.png" width="672" /></p>
<p>Partial dependencies can also be plotted for single observations:</p>
<div class="sourceCode" id="cb802"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb802-1"><a href="interpretation.html#cb802-1" aria-hidden="true" tabindex="-1"></a>eff <span class="ot">=</span> FeatureEffect<span class="sc">$</span><span class="fu">new</span>(predictor, <span class="at">feature =</span> <span class="st">&quot;rm&quot;</span>, <span class="at">method =</span> <span class="st">&quot;pdp+ice&quot;</span>,</span>
<span id="cb802-2"><a href="interpretation.html#cb802-2" aria-hidden="true" tabindex="-1"></a>                        <span class="at">grid.size =</span> <span class="dv">30</span>)</span>
<span id="cb802-3"><a href="interpretation.html#cb802-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(eff)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter6_4-1.png" width="672" /></p>
<p>One disadvantage of partial dependencies is that they are sensitive to correlated predictors. Accumulated local effects can be used for accounting for correlation of predictors.</p>
</div>
<div id="accumulated-local-effects" class="section level3" number="6.1.4">
<h3><span class="header-section-number">6.1.4</span> Accumulated Local Effects</h3>
<p>Accumulated local effects (ALE) are basically partial dependencies plots but try to correct for correlations between predictors.</p>
<div class="sourceCode" id="cb803"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb803-1"><a href="interpretation.html#cb803-1" aria-hidden="true" tabindex="-1"></a>ale <span class="ot">=</span> FeatureEffect<span class="sc">$</span><span class="fu">new</span>(predictor, <span class="at">feature =</span> <span class="st">&quot;rm&quot;</span>, <span class="at">method =</span> <span class="st">&quot;ale&quot;</span>)</span>
<span id="cb803-2"><a href="interpretation.html#cb803-2" aria-hidden="true" tabindex="-1"></a>ale<span class="sc">$</span><span class="fu">plot</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter6_5-1.png" width="672" /></p>
<p>If there is no collinearity, you shouldn’t see much difference between partial dependencies and ALE plots.</p>
</div>
<div id="friedmans-h-statistic" class="section level3" number="6.1.5">
<h3><span class="header-section-number">6.1.5</span> Friedman’s H-statistic</h3>
<p>The H-statistic can be used to find interactions between predictors. However, again, keep in mind that the H-statistic is sensible to correlation between predictors:</p>
<div class="sourceCode" id="cb804"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb804-1"><a href="interpretation.html#cb804-1" aria-hidden="true" tabindex="-1"></a>interact <span class="ot">=</span> Interaction<span class="sc">$</span><span class="fu">new</span>(predictor, <span class="st">&quot;lstat&quot;</span>)</span>
<span id="cb804-2"><a href="interpretation.html#cb804-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(interact)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter6_6-1.png" width="672" /></p>
</div>
<div id="global-explainer---simplifying-the-machine-learning-model" class="section level3" number="6.1.6">
<h3><span class="header-section-number">6.1.6</span> Global Explainer - Simplifying the Machine Learning Model</h3>
<p>Another idea is simplifying the machine learning model with another simpler model such as a decision tree. We create predictions with the machine learning model for a lot of different input values and then we fit a decision tree on these predictions. We can then interpret the easier model.</p>
<div class="sourceCode" id="cb805"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb805-1"><a href="interpretation.html#cb805-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(partykit)</span>
<span id="cb805-2"><a href="interpretation.html#cb805-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb805-3"><a href="interpretation.html#cb805-3" aria-hidden="true" tabindex="-1"></a>tree <span class="ot">=</span> TreeSurrogate<span class="sc">$</span><span class="fu">new</span>(predictor, <span class="at">maxdepth =</span> <span class="dv">2</span>)</span>
<span id="cb805-4"><a href="interpretation.html#cb805-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(tree<span class="sc">$</span>tree)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter6_7-1.png" width="672" /></p>
</div>
<div id="local-explainer---lime-explaining-single-instances-observations" class="section level3" number="6.1.7">
<h3><span class="header-section-number">6.1.7</span> Local Explainer - LIME Explaining Single Instances (observations)</h3>
<p>The global approach is to simplify the entire machine learning-black-box model via a simpler model, which is then interpretable.</p>
<p>However, sometimes we are only interested in understanding how single predictions are generated. The LIME (Local interpretable model-agnostic explanations) approach explores the feature space around one observation and based on this locally fits a simpler model (e.g. a linear model):</p>
<div class="sourceCode" id="cb806"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb806-1"><a href="interpretation.html#cb806-1" aria-hidden="true" tabindex="-1"></a>lime.explain <span class="ot">=</span> LocalModel<span class="sc">$</span><span class="fu">new</span>(predictor, <span class="at">x.interest =</span> X[<span class="dv">1</span>,])</span>
<span id="cb806-2"><a href="interpretation.html#cb806-2" aria-hidden="true" tabindex="-1"></a>lime.explain<span class="sc">$</span>results</span></code></pre></div>
<pre><code>##               beta x.recoded    effect x.original feature feature.value
## rm       4.1893817     6.575 27.545185      6.575      rm      rm=6.575
## ptratio -0.5307031    15.300 -8.119758       15.3 ptratio  ptratio=15.3
## lstat   -0.4398104     4.980 -2.190256       4.98   lstat    lstat=4.98</code></pre>
<div class="sourceCode" id="cb808"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb808-1"><a href="interpretation.html#cb808-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lime.explain)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter6_8-1.png" width="672" /></p>
</div>
<div id="local-explainer---shapley" class="section level3" number="6.1.8">
<h3><span class="header-section-number">6.1.8</span> Local Explainer - Shapley</h3>
<p>The Shapley method computes the so called Shapley value, feature contributions for single predictions, and is based on an approach from cooperative game theory. The idea is that each feature value of the instance is a “player” in a game, where the prediction is the reward. The Shapley value tells us how to fairly distribute the reward among the features.</p>
<div class="sourceCode" id="cb809"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb809-1"><a href="interpretation.html#cb809-1" aria-hidden="true" tabindex="-1"></a>shapley <span class="ot">=</span> Shapley<span class="sc">$</span><span class="fu">new</span>(predictor, <span class="at">x.interest =</span> X[<span class="dv">1</span>,])</span>
<span id="cb809-2"><a href="interpretation.html#cb809-2" aria-hidden="true" tabindex="-1"></a>shapley<span class="sc">$</span><span class="fu">plot</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter6_9-1.png" width="672" /></p>
</div>
</div>
<div id="causal-inference-and-machine-learning" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> Causal Inference and Machine Learning</h2>
<p>xAI aims at explaining how predictions are being made. In general, xAI != causality. xAI methods measure which variables are used for predictions by the algorithm, or how far variables improve predictions. The important point to note here: If a variable causes something, we could also expect that it helps predicting the very thing. The opposite, however, is not generally true - very often it is possible that a variable that doesn’t cause anything can predict something.</p>
<p>In statistics courses (in particular our course: Advanced Biostatistics), we discuss the issue of causality at full length. Here, we don’t want to go into the details, but again, you should in general resist to interpret indicators of importance in xAI as causal effects. They tell you something about what’s going on in the algorithm, not about what’s going on in reality.</p>
<div id="causalInference" class="section level3" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> Causal Inference on Static Data</h3>
<p>Methods for causal inference depend on whether we have dynamic or static data. The latter is the more common case. With static data, the problem is confounding. If you have several correlated predictors, you can get spurious correlations between a given predictor and the response, although there is no causal effect in general.</p>
<p>Multiple regression and few other methods are able to correct for other predictors and thus isolate the causal effect. The same is not necessarily true for machine learning algorithms and xAI methods. This is not a bug, but a feature - for making good predictions, it is often no problem, but rather an advantage to also use non-causal predictors.</p>
<p>Here an example for the indicators of variable importance in the random forest algorithm. The purpose of this script is to show that random forest variable importance will split importance values for collinear variables evenly, even if collinearity is low enough so that variables are separable and would be correctly separated by an lm / ANOVA.</p>
<p>We first simulate a data set with 2 predictors that are strongly correlated, but only one of them has an effect on the response.</p>
<div class="sourceCode" id="cb810"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb810-1"><a href="interpretation.html#cb810-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb810-2"><a href="interpretation.html#cb810-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb810-3"><a href="interpretation.html#cb810-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulation parameters.</span></span>
<span id="cb810-4"><a href="interpretation.html#cb810-4" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="dv">1000</span></span>
<span id="cb810-5"><a href="interpretation.html#cb810-5" aria-hidden="true" tabindex="-1"></a>col <span class="ot">=</span> <span class="fl">0.7</span></span>
<span id="cb810-6"><a href="interpretation.html#cb810-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb810-7"><a href="interpretation.html#cb810-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Create collinear predictors.</span></span>
<span id="cb810-8"><a href="interpretation.html#cb810-8" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">=</span> <span class="fu">runif</span>(n)</span>
<span id="cb810-9"><a href="interpretation.html#cb810-9" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">=</span> col <span class="sc">*</span> x1 <span class="sc">+</span> (<span class="dv">1</span><span class="sc">-</span>col) <span class="sc">*</span> <span class="fu">runif</span>(n)</span>
<span id="cb810-10"><a href="interpretation.html#cb810-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb810-11"><a href="interpretation.html#cb810-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Response is only influenced by x1.</span></span>
<span id="cb810-12"><a href="interpretation.html#cb810-12" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> x1 <span class="sc">+</span> <span class="fu">rnorm</span>(n)</span></code></pre></div>
<p>lm / anova correctly identify <span class="math inline">\(x1\)</span> as causal variable.</p>
<div class="sourceCode" id="cb811"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb811-1"><a href="interpretation.html#cb811-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1 + x2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.0709 -0.6939  0.0102  0.6976  3.3373 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.02837    0.08705   0.326 0.744536    
## x1           1.07383    0.27819   3.860 0.000121 ***
## x2          -0.04547    0.37370  -0.122 0.903186    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.011 on 997 degrees of freedom
## Multiple R-squared:  0.08104,    Adjusted R-squared:  0.0792 
## F-statistic: 43.96 on 2 and 997 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Fit random forest and show variable importance:</p>
<div class="sourceCode" id="cb813"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb813-1"><a href="interpretation.html#cb813-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb813-2"><a href="interpretation.html#cb813-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb813-3"><a href="interpretation.html#cb813-3" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">randomForest</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2, <span class="at">importance =</span> <span class="cn">TRUE</span>)</span>
<span id="cb813-4"><a href="interpretation.html#cb813-4" aria-hidden="true" tabindex="-1"></a><span class="fu">varImpPlot</span>(fit)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter6_12-1.png" width="672" /></p>
<p>Variable importance is now split nearly evenly.</p>
<p>Task: understand why this is - remember:</p>
<ul>
<li>How the random forest works - variables are randomly hidden from the regression tree when the trees for the forest are built.</li>
<li>Remember that as <span class="math inline">\(x1 \propto x2\)</span>, we can use <span class="math inline">\(x2\)</span> as a replacement for <span class="math inline">\(x1\)</span>.</li>
<li>Remember that the variable importance measures the average contributions of the different variables in the trees of the forest.</li>
</ul>
</div>
<div id="structural-equation-models" class="section level3" number="6.2.2">
<h3><span class="header-section-number">6.2.2</span> Structural Equation Models</h3>
<p>If causal relationships get more complicated, it will not be possible to adjust correctly with a simple lm. In this case, in statistics, we will usually use structural equation models (SEMs). Structural equation models are designed to estimate entire causal diagrams. There are two main SEM packages in R: For anything that is non-normal, you will currently have to estimate the directed acyclic graph (that depicts causal relations) piece-wise with CRAN package piecewiseSEM. Example for a vegetation data set:</p>
<div class="sourceCode" id="cb814"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb814-1"><a href="interpretation.html#cb814-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(piecewiseSEM)</span>
<span id="cb814-2"><a href="interpretation.html#cb814-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb814-3"><a href="interpretation.html#cb814-3" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">=</span> <span class="fu">psem</span>(</span>
<span id="cb814-4"><a href="interpretation.html#cb814-4" aria-hidden="true" tabindex="-1"></a> <span class="fu">lm</span>(rich <span class="sc">~</span> distance <span class="sc">+</span> elev <span class="sc">+</span> abiotic <span class="sc">+</span> age <span class="sc">+</span> hetero <span class="sc">+</span> firesev <span class="sc">+</span> cover,</span>
<span id="cb814-5"><a href="interpretation.html#cb814-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> keeley),</span>
<span id="cb814-6"><a href="interpretation.html#cb814-6" aria-hidden="true" tabindex="-1"></a> <span class="fu">lm</span>(firesev <span class="sc">~</span> elev <span class="sc">+</span> age <span class="sc">+</span> cover, <span class="at">data =</span> keeley),</span>
<span id="cb814-7"><a href="interpretation.html#cb814-7" aria-hidden="true" tabindex="-1"></a> <span class="fu">lm</span>(cover <span class="sc">~</span> age <span class="sc">+</span> elev <span class="sc">+</span> hetero <span class="sc">+</span> abiotic, <span class="at">data =</span> keeley)</span>
<span id="cb814-8"><a href="interpretation.html#cb814-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb814-9"><a href="interpretation.html#cb814-9" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)</span>
<span id="cb814-10"><a href="interpretation.html#cb814-10" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod)</span></code></pre></div>
<p>For linear structural equation models, we can estimate the entire directed acyclic graph at once. This also allows having unobserved variables in the directed acyclic graph. One of the most popular packages for this is lavaan.</p>
<div class="sourceCode" id="cb815"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb815-1"><a href="interpretation.html#cb815-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lavaan)</span>
<span id="cb815-2"><a href="interpretation.html#cb815-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb815-3"><a href="interpretation.html#cb815-3" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">=</span> <span class="st">&quot;</span></span>
<span id="cb815-4"><a href="interpretation.html#cb815-4" aria-hidden="true" tabindex="-1"></a><span class="st"> rich ~ distance + elev + abiotic + age + hetero + firesev + cover</span></span>
<span id="cb815-5"><a href="interpretation.html#cb815-5" aria-hidden="true" tabindex="-1"></a><span class="st"> firesev ~ elev + age + cover</span></span>
<span id="cb815-6"><a href="interpretation.html#cb815-6" aria-hidden="true" tabindex="-1"></a><span class="st"> cover ~ age + elev + abiotic</span></span>
<span id="cb815-7"><a href="interpretation.html#cb815-7" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span></span>
<span id="cb815-8"><a href="interpretation.html#cb815-8" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">sem</span>(mod, <span class="at">data =</span> keeley)</span>
<span id="cb815-9"><a href="interpretation.html#cb815-9" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit)</span></code></pre></div>
<pre><code>## lavaan 0.6-9 ended normally after 77 iterations
## 
##   Estimator                                         ML
##   Optimization method                           NLMINB
##   Number of model parameters                        16
##                                                       
##   Number of observations                            90
##                                                       
## Model Test User Model:
##                                                       
##   Test statistic                                10.437
##   Degrees of freedom                                 5
##   P-value (Chi-square)                           0.064
## 
## Parameter Estimates:
## 
##   Standard errors                             Standard
##   Information                                 Expected
##   Information saturated (h1) model          Structured
## 
## Regressions:
##                    Estimate   Std.Err  z-value  P(&gt;|z|)
##   rich ~                                               
##     distance           0.616    0.177    3.485    0.000
##     elev              -0.009    0.006   -1.644    0.100
##     abiotic            0.488    0.156    3.134    0.002
##     age                0.024    0.105    0.229    0.819
##     hetero            44.414    9.831    4.517    0.000
##     firesev           -1.018    0.759   -1.341    0.180
##     cover             12.400    3.841    3.228    0.001
##   firesev ~                                            
##     elev              -0.001    0.001   -0.951    0.342
##     age                0.047    0.013    3.757    0.000
##     cover             -1.521    0.509   -2.991    0.003
##   cover ~                                              
##     age               -0.009    0.002   -3.875    0.000
##     elev               0.000    0.000    2.520    0.012
##     abiotic           -0.000    0.004   -0.115    0.909
## 
## Variances:
##                    Estimate   Std.Err  z-value  P(&gt;|z|)
##    .rich              97.844   14.586    6.708    0.000
##    .firesev            1.887    0.281    6.708    0.000
##    .cover              0.081    0.012    6.708    0.000</code></pre>
<p>The default plot options are not so nice as before.</p>
<div class="sourceCode" id="cb817"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb817-1"><a href="interpretation.html#cb817-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lavaanPlot)</span>
<span id="cb817-2"><a href="interpretation.html#cb817-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb817-3"><a href="interpretation.html#cb817-3" aria-hidden="true" tabindex="-1"></a><span class="fu">lavaanPlot</span>(<span class="at">model =</span> fit)</span></code></pre></div>
<div id="htmlwidget-1d7b0caf1660a8ba4dcc" style="width:672px;height:480px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-1d7b0caf1660a8ba4dcc">{"x":{"diagram":" digraph plot { \n graph [ overlap = true, fontsize = 10 ] \n node [ shape = box ] \n node [shape = box] \n distance; elev; abiotic; age; hetero; firesev; cover; rich \n node [shape = oval] \n  \n \n edge [ color = black ] \n distance->rich elev->rich abiotic->rich age->rich hetero->rich firesev->rich cover->rich elev->firesev age->firesev cover->firesev age->cover elev->cover abiotic->cover  \n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
<p>Another plotting option is using semPlot.</p>
<div class="sourceCode" id="cb818"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb818-1"><a href="interpretation.html#cb818-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(semPlot)</span>
<span id="cb818-2"><a href="interpretation.html#cb818-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb818-3"><a href="interpretation.html#cb818-3" aria-hidden="true" tabindex="-1"></a><span class="fu">semPaths</span>(fit)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter6_16-1.png" width="672" /></p>
</div>
<div id="automatic-causal-discovery" class="section level3" number="6.2.3">
<h3><span class="header-section-number">6.2.3</span> Automatic Causal Discovery</h3>
<p>But how to get the causal graph? In statistics, it is common to “guess” it and afterwards do residual checks, in the same way as we guess the structure of a regression. For more complicated problems, however, this is unsatisfying. Some groups therefore work on so-called causal discovery algorithms, i.e. algorithms that automatically generate causal graphs from data. One of the most classic algorithms of this sort is the <em>PC algorithm</em>. Here an example using the pcalg package:</p>
<div class="sourceCode" id="cb819"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb819-1"><a href="interpretation.html#cb819-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pcalg)</span></code></pre></div>
<p>Loading the data:</p>
<div class="sourceCode" id="cb820"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb820-1"><a href="interpretation.html#cb820-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;gmG&quot;</span>, <span class="at">package =</span> <span class="st">&quot;pcalg&quot;</span>) <span class="co"># Loads data sets gmG and gmG8.</span></span>
<span id="cb820-2"><a href="interpretation.html#cb820-2" aria-hidden="true" tabindex="-1"></a>suffStat <span class="ot">=</span> <span class="fu">list</span>(<span class="at">C =</span> <span class="fu">cor</span>(gmG8<span class="sc">$</span>x), <span class="at">n =</span> <span class="fu">nrow</span>(gmG8<span class="sc">$</span>x))</span>
<span id="cb820-3"><a href="interpretation.html#cb820-3" aria-hidden="true" tabindex="-1"></a>varNames <span class="ot">=</span> gmG8<span class="sc">$</span>g<span class="sc">@</span>nodes</span></code></pre></div>
<p>First, the skeleton algorithm creates a basic graph without connections (a skeleton of the graph).</p>
<div class="sourceCode" id="cb821"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb821-1"><a href="interpretation.html#cb821-1" aria-hidden="true" tabindex="-1"></a>skel.gmG8 <span class="ot">=</span> <span class="fu">skeleton</span>(suffStat, <span class="at">indepTest =</span> gaussCItest,</span>
<span id="cb821-2"><a href="interpretation.html#cb821-2" aria-hidden="true" tabindex="-1"></a><span class="at">labels =</span> varNames, <span class="at">alpha =</span> <span class="fl">0.01</span>)</span>
<span id="cb821-3"><a href="interpretation.html#cb821-3" aria-hidden="true" tabindex="-1"></a>Rgraphviz<span class="sc">::</span><span class="fu">plot</span>(skel.gmG8)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter6_19-1.png" width="672" /></p>
<p>What is missing here is the direction of the errors. The PC algorithm now makes tests for conditional independence, which allows fixing a part (but typically not all) of the directions of the causal arrows.</p>
<div class="sourceCode" id="cb822"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb822-1"><a href="interpretation.html#cb822-1" aria-hidden="true" tabindex="-1"></a>pc.gmG8 <span class="ot">=</span> <span class="fu">pc</span>(suffStat, <span class="at">indepTest =</span> gaussCItest,</span>
<span id="cb822-2"><a href="interpretation.html#cb822-2" aria-hidden="true" tabindex="-1"></a><span class="at">labels =</span> varNames, <span class="at">alpha =</span> <span class="fl">0.01</span>)</span>
<span id="cb822-3"><a href="interpretation.html#cb822-3" aria-hidden="true" tabindex="-1"></a>Rgraphviz<span class="sc">::</span><span class="fu">plot</span>(pc.gmG8 )</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter6_20-1.png" width="672" /></p>
</div>
<div id="causal-inference-on-dynamic-data" class="section level3" number="6.2.4">
<h3><span class="header-section-number">6.2.4</span> Causal Inference on Dynamic Data</h3>
<p>When working with dynamic data, we can use an additional piece of information - the cause usually precedes the effect, which means that we can test for a time-lag between cause and effect to determine the direction of causality. This way of testing for causality is known as <em>Granger causality</em>, or Granger methods. Here an example:</p>
<div class="sourceCode" id="cb823"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb823-1"><a href="interpretation.html#cb823-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lmtest)</span>
<span id="cb823-2"><a href="interpretation.html#cb823-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb823-3"><a href="interpretation.html#cb823-3" aria-hidden="true" tabindex="-1"></a><span class="do">## What came first: the chicken or the egg?</span></span>
<span id="cb823-4"><a href="interpretation.html#cb823-4" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(ChickEgg)</span>
<span id="cb823-5"><a href="interpretation.html#cb823-5" aria-hidden="true" tabindex="-1"></a><span class="fu">grangertest</span>(egg <span class="sc">~</span> chicken, <span class="at">order =</span> <span class="dv">3</span>, <span class="at">data =</span> ChickEgg)</span></code></pre></div>
<pre><code>## Granger causality test
## 
## Model 1: egg ~ Lags(egg, 1:3) + Lags(chicken, 1:3)
## Model 2: egg ~ Lags(egg, 1:3)
##   Res.Df Df      F Pr(&gt;F)
## 1     44                 
## 2     47 -3 0.5916 0.6238</code></pre>
<div class="sourceCode" id="cb825"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb825-1"><a href="interpretation.html#cb825-1" aria-hidden="true" tabindex="-1"></a><span class="fu">grangertest</span>(chicken <span class="sc">~</span> egg, <span class="at">order =</span> <span class="dv">3</span>, <span class="at">data =</span> ChickEgg)</span></code></pre></div>
<pre><code>## Granger causality test
## 
## Model 1: chicken ~ Lags(chicken, 1:3) + Lags(egg, 1:3)
## Model 2: chicken ~ Lags(chicken, 1:3)
##   Res.Df Df     F   Pr(&gt;F)   
## 1     44                     
## 2     47 -3 5.405 0.002966 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="outlook-for-machine-learning" class="section level3" number="6.2.5">
<h3><span class="header-section-number">6.2.5</span> Outlook for Machine Learning</h3>
<p>As we have seen, there are already a few methods / algorithms for discovering causality from large data sets, but the systematic transfer of these concepts to machine learning, in particular deep learning, is still at its infancy. At the moment, this field is actively researched and changes extremely fast, so we recommend using Google to see what is currently going on. Particular in business and industry, there is a large interest in learning about causal effect from large data sets. In our opinion, a great topic for young scientists to specialize on.</p>
  <hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<p>Use one of the non-image based data sets (preferably Wine, which is also described in the data sets section <a href="datasets.html#datasets">8</a> but wasn’t used yet, but you can also use Nasa or Titanic) and fit a random forest. Explore / interpret the fitted model using iml (see also the book: <a href="https://christophm.github.io/interpretable-ml-book/" target="_blank" rel="noopener">https://christophm.github.io/interpretable-ml-book/</a>).</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<div class="sourceCode" id="cb827"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb827-1"><a href="interpretation.html#cb827-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span>
<span id="cb827-2"><a href="interpretation.html#cb827-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;iml&quot;</span>)</span>
<span id="cb827-3"><a href="interpretation.html#cb827-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb827-4"><a href="interpretation.html#cb827-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb827-5"><a href="interpretation.html#cb827-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">as.data.frame</span>(EcoData<span class="sc">::</span>wine)</span>
<span id="cb827-6"><a href="interpretation.html#cb827-6" aria-hidden="true" tabindex="-1"></a>submission <span class="ot">=</span> data[<span class="fu">which</span>(<span class="fu">is.na</span>(data<span class="sc">$</span>quality)), <span class="sc">-</span><span class="fu">which</span>(<span class="fu">colnames</span>(data) <span class="sc">==</span> <span class="st">&quot;quality&quot;</span>)]</span>
<span id="cb827-7"><a href="interpretation.html#cb827-7" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> data[<span class="fu">complete.cases</span>(data), ] <span class="co"># Removes sumbmission data as well.</span></span>
<span id="cb827-8"><a href="interpretation.html#cb827-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb827-9"><a href="interpretation.html#cb827-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Remark: Features don&#39;t need to be scaled for regression trees.</span></span>
<span id="cb827-10"><a href="interpretation.html#cb827-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb827-11"><a href="interpretation.html#cb827-11" aria-hidden="true" tabindex="-1"></a>rf <span class="ot">=</span> <span class="fu">randomForest</span>(quality <span class="sc">~</span> ., <span class="at">data =</span> data)</span>
<span id="cb827-12"><a href="interpretation.html#cb827-12" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">predict</span>(rf, data))</span>
<span id="cb827-13"><a href="interpretation.html#cb827-13" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(pred, data<span class="sc">$</span>quality)</span></code></pre></div>
<pre><code>##     
## pred   3   4   5   6   7   8
##    4   2   4   0   0   0   0
##    5   0   6 133   0   0   0
##    6   0   0   3 113  10   0
##    7   0   0   0   0  25   3</code></pre>
<div class="sourceCode" id="cb829"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb829-1"><a href="interpretation.html#cb829-1" aria-hidden="true" tabindex="-1"></a>(<span class="at">accuracy =</span> <span class="fu">mean</span>(pred <span class="sc">==</span> data<span class="sc">$</span>quality)) <span class="co"># Fits pretty well (on the training data...)</span></span></code></pre></div>
<pre><code>## [1] 0.9197324</code></pre>
<div class="sourceCode" id="cb831"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb831-1"><a href="interpretation.html#cb831-1" aria-hidden="true" tabindex="-1"></a><span class="co"># For submission:</span></span>
<span id="cb831-2"><a href="interpretation.html#cb831-2" aria-hidden="true" tabindex="-1"></a><span class="co">#write.csv(round(predict(rf, submission)), file = &quot;wine_RF.csv&quot;)</span></span>
<span id="cb831-3"><a href="interpretation.html#cb831-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb831-4"><a href="interpretation.html#cb831-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Standard depiction of importance:</span></span>
<span id="cb831-5"><a href="interpretation.html#cb831-5" aria-hidden="true" tabindex="-1"></a>rf<span class="sc">$</span>importance</span></code></pre></div>
<pre><code>##                      IncNodePurity
## fixed.acidity            12.279077
## volatile.acidity         21.997368
## citric.acid              13.751476
## residual.sugar           10.787817
## chlorides                11.587301
## free.sulfur.dioxide       9.966824
## total.sulfur.dioxide     13.977669
## density                  17.068801
## pH                       10.302109
## sulphates                20.273156
## alcohol                  37.316264</code></pre>
<div class="sourceCode" id="cb833"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb833-1"><a href="interpretation.html#cb833-1" aria-hidden="true" tabindex="-1"></a><span class="co"># IML:</span></span>
<span id="cb833-2"><a href="interpretation.html#cb833-2" aria-hidden="true" tabindex="-1"></a>predictor <span class="ot">=</span> Predictor<span class="sc">$</span><span class="fu">new</span>(</span>
<span id="cb833-3"><a href="interpretation.html#cb833-3" aria-hidden="true" tabindex="-1"></a>    rf, <span class="at">data =</span> data[,<span class="fu">which</span>(<span class="fu">names</span>(data) <span class="sc">!=</span> <span class="st">&quot;quality&quot;</span>)], <span class="at">y =</span> data<span class="sc">$</span>quality)</span>
<span id="cb833-4"><a href="interpretation.html#cb833-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb833-5"><a href="interpretation.html#cb833-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Mind: This is stochastical!</span></span>
<span id="cb833-6"><a href="interpretation.html#cb833-6" aria-hidden="true" tabindex="-1"></a>importance <span class="ot">=</span> FeatureImp<span class="sc">$</span><span class="fu">new</span>(predictor, <span class="at">loss =</span> <span class="st">&quot;mae&quot;</span>)</span>
<span id="cb833-7"><a href="interpretation.html#cb833-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb833-8"><a href="interpretation.html#cb833-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(importance)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter6_task_0-1.png" width="672" /></p>
<div class="sourceCode" id="cb834"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb834-1"><a href="interpretation.html#cb834-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparison between standard importance and IML importance:</span></span>
<span id="cb834-2"><a href="interpretation.html#cb834-2" aria-hidden="true" tabindex="-1"></a>importanceRf <span class="ot">=</span> <span class="fu">rownames</span>(rf<span class="sc">$</span>importance)[<span class="fu">order</span>(rf<span class="sc">$</span>importance, <span class="at">decreasing =</span> <span class="cn">TRUE</span>)]</span>
<span id="cb834-3"><a href="interpretation.html#cb834-3" aria-hidden="true" tabindex="-1"></a>importanceIML <span class="ot">=</span> importance<span class="sc">$</span>results[<span class="dv">1</span>]</span>
<span id="cb834-4"><a href="interpretation.html#cb834-4" aria-hidden="true" tabindex="-1"></a>comparison <span class="ot">=</span> <span class="fu">cbind</span>(importanceIML, importanceRf)</span>
<span id="cb834-5"><a href="interpretation.html#cb834-5" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(comparison) <span class="ot">=</span> <span class="fu">c</span>(<span class="st">&quot;IML&quot;</span>, <span class="st">&quot;RF&quot;</span>)</span>
<span id="cb834-6"><a href="interpretation.html#cb834-6" aria-hidden="true" tabindex="-1"></a><span class="fu">as.matrix</span>(comparison)</span></code></pre></div>
<pre><code>##       IML                    RF                    
##  [1,] &quot;alcohol&quot;              &quot;alcohol&quot;             
##  [2,] &quot;sulphates&quot;            &quot;volatile.acidity&quot;    
##  [3,] &quot;volatile.acidity&quot;     &quot;sulphates&quot;           
##  [4,] &quot;density&quot;              &quot;density&quot;             
##  [5,] &quot;citric.acid&quot;          &quot;total.sulfur.dioxide&quot;
##  [6,] &quot;total.sulfur.dioxide&quot; &quot;citric.acid&quot;         
##  [7,] &quot;fixed.acidity&quot;        &quot;fixed.acidity&quot;       
##  [8,] &quot;chlorides&quot;            &quot;chlorides&quot;           
##  [9,] &quot;pH&quot;                   &quot;residual.sugar&quot;      
## [10,] &quot;free.sulfur.dioxide&quot;  &quot;pH&quot;                  
## [11,] &quot;residual.sugar&quot;       &quot;free.sulfur.dioxide&quot;</code></pre>
<p>Mind that feature importance, and the random forest’s variable importance are related but not equal!
Variable importance is a measure for determining importance while creating the forest (i.e. for fitting). Feature importance is a measure for how important a variable is for prediction.</p>
<p>Maybe you want to see other explanation methods as well. Surely you can use the other techniques of this section on your own.</p>
    </p>
  </details>
  <br/><hr/>
  <hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<p>As we show in section <a href="interpretation.html#causalInference">6.2.1</a> of this chapter, a random forest will split variable importance across collinear predictors, while a linear regression model (lm()) can identify which predictor is causally affecting the response (at least in theory, if all confounders are controlled). What about a boosted regression tree or an artificial neural network? Take the random forest example and add a boosted regression tree (easier, you can use for example <a href="https://rdrr.io/cran/xgboost/man/xgb.importance.html" class="uri">https://rdrr.io/cran/xgboost/man/xgb.importance.html</a>) or an artificial neural network, and have a look if those are better than the random forest at identifying causal predictors.</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<div class="sourceCode" id="cb836"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb836-1"><a href="interpretation.html#cb836-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(xgboost)</span>
<span id="cb836-2"><a href="interpretation.html#cb836-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb836-3"><a href="interpretation.html#cb836-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb836-4"><a href="interpretation.html#cb836-4" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">as.data.frame</span>(EcoData<span class="sc">::</span>wine)</span>
<span id="cb836-5"><a href="interpretation.html#cb836-5" aria-hidden="true" tabindex="-1"></a>submission <span class="ot">=</span> data[<span class="fu">which</span>(<span class="fu">is.na</span>(data<span class="sc">$</span>quality)), <span class="sc">-</span><span class="fu">which</span>(<span class="fu">colnames</span>(data) <span class="sc">==</span> <span class="st">&quot;quality&quot;</span>)]</span>
<span id="cb836-6"><a href="interpretation.html#cb836-6" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> data[<span class="fu">complete.cases</span>(data), ] <span class="co"># Removes sumbmission data as well.</span></span>
<span id="cb836-7"><a href="interpretation.html#cb836-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb836-8"><a href="interpretation.html#cb836-8" aria-hidden="true" tabindex="-1"></a>data_xg <span class="ot">=</span> <span class="fu">xgb.DMatrix</span>(</span>
<span id="cb836-9"><a href="interpretation.html#cb836-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> <span class="fu">as.matrix</span>(data[,<span class="fu">which</span>(<span class="fu">names</span>(data) <span class="sc">!=</span> <span class="st">&quot;quality&quot;</span>)]),</span>
<span id="cb836-10"><a href="interpretation.html#cb836-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">label =</span> data<span class="sc">$</span>quality</span>
<span id="cb836-11"><a href="interpretation.html#cb836-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb836-12"><a href="interpretation.html#cb836-12" aria-hidden="true" tabindex="-1"></a>brt <span class="ot">=</span> <span class="fu">xgboost</span>(data_xg, <span class="at">nrounds =</span> <span class="dv">24</span>)</span></code></pre></div>
<pre><code>## [1]  train-rmse:3.656523 
## [2]  train-rmse:2.609494 
## [3]  train-rmse:1.884807 
## [4]  train-rmse:1.384918 
## [5]  train-rmse:1.037362 
## [6]  train-rmse:0.800110 
## [7]  train-rmse:0.629324 
## [8]  train-rmse:0.508917 
## [9]  train-rmse:0.426155 
## [10] train-rmse:0.369580 
## [11] train-rmse:0.313017 
## [12] train-rmse:0.274227 
## [13] train-rmse:0.236959 
## [14] train-rmse:0.207364 
## [15] train-rmse:0.195811 
## [16] train-rmse:0.182500 
## [17] train-rmse:0.173310 
## [18] train-rmse:0.154747 
## [19] train-rmse:0.144045 
## [20] train-rmse:0.139083 
## [21] train-rmse:0.129605 
## [22] train-rmse:0.118541 
## [23] train-rmse:0.110689 
## [24] train-rmse:0.097798</code></pre>
<div class="sourceCode" id="cb838"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb838-1"><a href="interpretation.html#cb838-1" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">predict</span>(brt, <span class="at">newdata =</span> data_xg)) <span class="co"># Only integers are allowed.</span></span>
<span id="cb838-2"><a href="interpretation.html#cb838-2" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(pred, data<span class="sc">$</span>quality)</span></code></pre></div>
<pre><code>##     
## pred   3   4   5   6   7   8
##    3   2   0   0   0   0   0
##    4   0  10   0   0   0   0
##    5   0   0 136   0   0   0
##    6   0   0   0 113   1   0
##    7   0   0   0   0  34   0
##    8   0   0   0   0   0   3</code></pre>
<div class="sourceCode" id="cb840"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb840-1"><a href="interpretation.html#cb840-1" aria-hidden="true" tabindex="-1"></a>(<span class="at">accuracy =</span> <span class="fu">mean</span>(pred <span class="sc">==</span> data<span class="sc">$</span>quality)) <span class="co"># Fits very well (on the training data...)</span></span></code></pre></div>
<pre><code>## [1] 0.9966555</code></pre>
<div class="sourceCode" id="cb842"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb842-1"><a href="interpretation.html#cb842-1" aria-hidden="true" tabindex="-1"></a><span class="co"># For submission:</span></span>
<span id="cb842-2"><a href="interpretation.html#cb842-2" aria-hidden="true" tabindex="-1"></a><span class="co">#write.csv(round(predict(rf, submission)), file = &quot;wine_RF.csv&quot;)</span></span>
<span id="cb842-3"><a href="interpretation.html#cb842-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb842-4"><a href="interpretation.html#cb842-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Look at variable importance:</span></span>
<span id="cb842-5"><a href="interpretation.html#cb842-5" aria-hidden="true" tabindex="-1"></a>xgboost<span class="sc">::</span><span class="fu">xgb.importance</span>(<span class="at">model =</span> brt)</span></code></pre></div>
<pre><code>##                  Feature       Gain      Cover  Frequency
##  1:              alcohol 0.28363726 0.13667721 0.07073509
##  2:            sulphates 0.11331763 0.07015405 0.06657420
##  3:        fixed.acidity 0.09844523 0.11359510 0.19278779
##  4:     volatile.acidity 0.09582794 0.07098397 0.12760055
##  5: total.sulfur.dioxide 0.09207986 0.09147259 0.07212205
##  6:              density 0.07374576 0.14910006 0.08321775
##  7:            chlorides 0.06025521 0.07972405 0.08876560
##  8:       residual.sugar 0.05307944 0.07202137 0.08044383
##  9:  free.sulfur.dioxide 0.04602742 0.04743503 0.06518724
## 10:                   pH 0.04477577 0.12562892 0.07489598
## 11:          citric.acid 0.03880847 0.04320764 0.07766990</code></pre>
<p>Every method yields slightly different results, but the main ingredient is alcohol (and sulphates).</p>
    </p>
  </details>
  <br/>
  <hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<p>If you’re done with the previous tasks and have still time and appetite, improve the submissions for our competition, in particular for the Wine data set. Possible ideas:</p>
<ul>
<li><p>Use MLR framework (section <a href="fundamental.html#mlr">4.6</a>).</p></li>
<li><p>Try Transfer learning (section <a href="deep.html#transfer">5.4.2</a>). This was the winner of last years challenge.</p></li>
<li><p>Search on kaggle for more ideas / try to copy the ideas. This was the winner two years ago.</p></li>
</ul>
<p>A little example for the (unbalanced!) Wine data set</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<div class="sourceCode" id="cb844"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb844-1"><a href="interpretation.html#cb844-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb844-2"><a href="interpretation.html#cb844-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb844-3"><a href="interpretation.html#cb844-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(123L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb844-4"><a href="interpretation.html#cb844-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb844-5"><a href="interpretation.html#cb844-5" aria-hidden="true" tabindex="-1"></a>readin <span class="ot">=</span> <span class="cf">function</span>(<span class="at">percentageTest =</span> <span class="fl">0.2</span>, <span class="at">aggregate =</span> <span class="dv">0</span>){</span>
<span id="cb844-6"><a href="interpretation.html#cb844-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Parameter &quot;aggregate&quot; packs the classes with very low abundances into one.</span></span>
<span id="cb844-7"><a href="interpretation.html#cb844-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># If &quot;aggregate&quot; equals to NA, NaN, Null, 0 or FALSE, no aggregation is performed.</span></span>
<span id="cb844-8"><a href="interpretation.html#cb844-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Else, the given number is the boundary.</span></span>
<span id="cb844-9"><a href="interpretation.html#cb844-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Every class with less elements than the boundary is aggregated into one.</span></span>
<span id="cb844-10"><a href="interpretation.html#cb844-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb844-11"><a href="interpretation.html#cb844-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># </span><span class="al">WARNING</span><span class="co">: These classes cannot be distinguished from then on!</span></span>
<span id="cb844-12"><a href="interpretation.html#cb844-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Using the predictions for submission needs further processing!</span></span>
<span id="cb844-13"><a href="interpretation.html#cb844-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb844-14"><a href="interpretation.html#cb844-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Just for random selection of features, independent of the amount of function calls.</span></span>
<span id="cb844-15"><a href="interpretation.html#cb844-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb844-16"><a href="interpretation.html#cb844-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb844-17"><a href="interpretation.html#cb844-17" aria-hidden="true" tabindex="-1"></a>    train <span class="ot">=</span> <span class="fu">as.data.frame</span>(EcoData<span class="sc">::</span>wine)</span>
<span id="cb844-18"><a href="interpretation.html#cb844-18" aria-hidden="true" tabindex="-1"></a>    indicesTrain <span class="ot">=</span> <span class="fu">which</span>(<span class="sc">!</span><span class="fu">is.na</span>(train<span class="sc">$</span>quality))</span>
<span id="cb844-19"><a href="interpretation.html#cb844-19" aria-hidden="true" tabindex="-1"></a>    labelsTrain <span class="ot">=</span> train<span class="sc">$</span>quality[indicesTrain]</span>
<span id="cb844-20"><a href="interpretation.html#cb844-20" aria-hidden="true" tabindex="-1"></a>    labelsTrain <span class="ot">=</span> labelsTrain <span class="sc">-</span> <span class="fu">min</span>(labelsTrain)  <span class="co"># Start at 0 (for softmax).</span></span>
<span id="cb844-21"><a href="interpretation.html#cb844-21" aria-hidden="true" tabindex="-1"></a>    train <span class="ot">=</span> train[, <span class="sc">-</span><span class="fu">which</span>(<span class="fu">colnames</span>(train) <span class="sc">==</span> <span class="st">&quot;quality&quot;</span>)]</span>
<span id="cb844-22"><a href="interpretation.html#cb844-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb844-23"><a href="interpretation.html#cb844-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(<span class="sc">!</span><span class="fu">is.na</span>(aggregate) <span class="sc">&amp;</span> aggregate){</span>
<span id="cb844-24"><a href="interpretation.html#cb844-24" aria-hidden="true" tabindex="-1"></a>        indices <span class="ot">=</span> <span class="fu">names</span>(<span class="fu">table</span>(labelsTrain)[</span>
<span id="cb844-25"><a href="interpretation.html#cb844-25" aria-hidden="true" tabindex="-1"></a>            <span class="fu">table</span>(labelsTrain) <span class="sc">&lt;</span> aggregate <span class="sc">&amp;</span> <span class="fu">table</span>(labelsTrain) <span class="sc">&gt;</span> <span class="dv">0</span></span>
<span id="cb844-26"><a href="interpretation.html#cb844-26" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb844-27"><a href="interpretation.html#cb844-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(<span class="fu">length</span>(indices)){</span>
<span id="cb844-28"><a href="interpretation.html#cb844-28" aria-hidden="true" tabindex="-1"></a>            labelsTrain[labelsTrain <span class="sc">%in%</span> indices] <span class="ot">=</span> <span class="sc">-</span><span class="dv">1</span></span>
<span id="cb844-29"><a href="interpretation.html#cb844-29" aria-hidden="true" tabindex="-1"></a>            labelsTrain <span class="ot">=</span> <span class="fu">as.factor</span>(labelsTrain)</span>
<span id="cb844-30"><a href="interpretation.html#cb844-30" aria-hidden="true" tabindex="-1"></a>            <span class="fu">levels</span>(labelsTrain) <span class="ot">=</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(<span class="fu">levels</span>(labelsTrain)) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb844-31"><a href="interpretation.html#cb844-31" aria-hidden="true" tabindex="-1"></a>            labelsTrain <span class="ot">=</span> <span class="fu">as.integer</span>(labelsTrain)</span>
<span id="cb844-32"><a href="interpretation.html#cb844-32" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb844-33"><a href="interpretation.html#cb844-33" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb844-34"><a href="interpretation.html#cb844-34" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb844-35"><a href="interpretation.html#cb844-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Impute missing values (before any splitting, to get the highest power):</span></span>
<span id="cb844-36"><a href="interpretation.html#cb844-36" aria-hidden="true" tabindex="-1"></a>    train <span class="ot">=</span> missRanger<span class="sc">::</span><span class="fu">missRanger</span>(</span>
<span id="cb844-37"><a href="interpretation.html#cb844-37" aria-hidden="true" tabindex="-1"></a>        <span class="at">data =</span> train,</span>
<span id="cb844-38"><a href="interpretation.html#cb844-38" aria-hidden="true" tabindex="-1"></a>        <span class="at">maxiter =</span> 10L,</span>
<span id="cb844-39"><a href="interpretation.html#cb844-39" aria-hidden="true" tabindex="-1"></a>        <span class="at">seed =</span> <span class="dv">123</span>,</span>
<span id="cb844-40"><a href="interpretation.html#cb844-40" aria-hidden="true" tabindex="-1"></a>        <span class="at">num.trees =</span> 200L</span>
<span id="cb844-41"><a href="interpretation.html#cb844-41" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb844-42"><a href="interpretation.html#cb844-42" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb844-43"><a href="interpretation.html#cb844-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Separate submission data (mind scaling!):</span></span>
<span id="cb844-44"><a href="interpretation.html#cb844-44" aria-hidden="true" tabindex="-1"></a>    submission <span class="ot">=</span> <span class="fu">scale</span>(train[<span class="sc">-</span>indicesTrain,])</span>
<span id="cb844-45"><a href="interpretation.html#cb844-45" aria-hidden="true" tabindex="-1"></a>    train <span class="ot">=</span> <span class="fu">scale</span>(train[indicesTrain,])</span>
<span id="cb844-46"><a href="interpretation.html#cb844-46" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb844-47"><a href="interpretation.html#cb844-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Very asymmetric training data:</span></span>
<span id="cb844-48"><a href="interpretation.html#cb844-48" aria-hidden="true" tabindex="-1"></a>    <span class="fu">cat</span>(<span class="fu">paste0</span>(<span class="st">&quot;Size of training set: &quot;</span>, <span class="fu">length</span>(labelsTrain), <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>))</span>
<span id="cb844-49"><a href="interpretation.html#cb844-49" aria-hidden="true" tabindex="-1"></a>    <span class="fu">print</span>(<span class="fu">table</span>(labelsTrain))</span>
<span id="cb844-50"><a href="interpretation.html#cb844-50" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb844-51"><a href="interpretation.html#cb844-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(percentageTest <span class="sc">==</span> <span class="dv">0</span>){</span>
<span id="cb844-52"><a href="interpretation.html#cb844-52" aria-hidden="true" tabindex="-1"></a>      <span class="fu">return</span>(<span class="fu">list</span>(</span>
<span id="cb844-53"><a href="interpretation.html#cb844-53" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;labelsTrain&quot;</span> <span class="ot">=</span> labelsTrain,</span>
<span id="cb844-54"><a href="interpretation.html#cb844-54" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;labelsTest&quot;</span> <span class="ot">=</span> <span class="fu">list</span>(),</span>
<span id="cb844-55"><a href="interpretation.html#cb844-55" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;train&quot;</span> <span class="ot">=</span> train,</span>
<span id="cb844-56"><a href="interpretation.html#cb844-56" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;test&quot;</span> <span class="ot">=</span> <span class="fu">list</span>(),</span>
<span id="cb844-57"><a href="interpretation.html#cb844-57" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;submission&quot;</span> <span class="ot">=</span> submission</span>
<span id="cb844-58"><a href="interpretation.html#cb844-58" aria-hidden="true" tabindex="-1"></a>      ))</span>
<span id="cb844-59"><a href="interpretation.html#cb844-59" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb844-60"><a href="interpretation.html#cb844-60" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb844-61"><a href="interpretation.html#cb844-61" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Split into training and test set:</span></span>
<span id="cb844-62"><a href="interpretation.html#cb844-62" aria-hidden="true" tabindex="-1"></a>    len <span class="ot">=</span> <span class="fu">nrow</span>(train)</span>
<span id="cb844-63"><a href="interpretation.html#cb844-63" aria-hidden="true" tabindex="-1"></a>    indicesTest <span class="ot">=</span> <span class="fu">sample</span>(<span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span>len, <span class="at">size =</span> percentageTest <span class="sc">*</span> len, <span class="at">replace =</span> <span class="cn">FALSE</span>)</span>
<span id="cb844-64"><a href="interpretation.html#cb844-64" aria-hidden="true" tabindex="-1"></a>    test <span class="ot">=</span> <span class="fu">as.data.frame</span>(train[indicesTest,])</span>
<span id="cb844-65"><a href="interpretation.html#cb844-65" aria-hidden="true" tabindex="-1"></a>    labelsTest <span class="ot">=</span> labelsTrain[indicesTest]</span>
<span id="cb844-66"><a href="interpretation.html#cb844-66" aria-hidden="true" tabindex="-1"></a>    train <span class="ot">=</span> <span class="fu">as.data.frame</span>(train[<span class="sc">-</span>indicesTest,])</span>
<span id="cb844-67"><a href="interpretation.html#cb844-67" aria-hidden="true" tabindex="-1"></a>    labelsTrain <span class="ot">=</span> labelsTrain[<span class="sc">-</span>indicesTest]</span>
<span id="cb844-68"><a href="interpretation.html#cb844-68" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb844-69"><a href="interpretation.html#cb844-69" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">list</span>(</span>
<span id="cb844-70"><a href="interpretation.html#cb844-70" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;labelsTrain&quot;</span> <span class="ot">=</span> labelsTrain,</span>
<span id="cb844-71"><a href="interpretation.html#cb844-71" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;labelsTest&quot;</span> <span class="ot">=</span> labelsTest,</span>
<span id="cb844-72"><a href="interpretation.html#cb844-72" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;train&quot;</span> <span class="ot">=</span> train,</span>
<span id="cb844-73"><a href="interpretation.html#cb844-73" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;test&quot;</span> <span class="ot">=</span> test,</span>
<span id="cb844-74"><a href="interpretation.html#cb844-74" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;submission&quot;</span> <span class="ot">=</span> submission</span>
<span id="cb844-75"><a href="interpretation.html#cb844-75" aria-hidden="true" tabindex="-1"></a>    ))</span>
<span id="cb844-76"><a href="interpretation.html#cb844-76" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb844-77"><a href="interpretation.html#cb844-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb844-78"><a href="interpretation.html#cb844-78" aria-hidden="true" tabindex="-1"></a>retVal <span class="ot">=</span> <span class="fu">readin</span>(<span class="at">aggregate =</span> <span class="dv">0</span>)</span></code></pre></div>
<pre><code>## 
## Missing value imputation by random forests
## 
##   Variables to impute:       fixed.acidity, volatile.acidity, citric.acid, residual.sugar, chlorides, free.sulfur.dioxide, total.sulfur.dioxide, density, pH, sulphates
##   Variables used to impute:  fixed.acidity, volatile.acidity, citric.acid, residual.sugar, chlorides, free.sulfur.dioxide, total.sulfur.dioxide, density, pH, sulphates, alcohol
## iter 1:  ..........
## iter 2:  ..........
## iter 3:  ..........
## Size of training set: 694
## labelsTrain
##   0   1   2   3   4   5 
##   7  25 309 261  84   8</code></pre>
<div class="sourceCode" id="cb846"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb846-1"><a href="interpretation.html#cb846-1" aria-hidden="true" tabindex="-1"></a>labelsTrain <span class="ot">=</span> retVal[[<span class="st">&quot;labelsTrain&quot;</span>]]</span>
<span id="cb846-2"><a href="interpretation.html#cb846-2" aria-hidden="true" tabindex="-1"></a>labelsTest <span class="ot">=</span> retVal[[<span class="st">&quot;labelsTest&quot;</span>]]</span>
<span id="cb846-3"><a href="interpretation.html#cb846-3" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> retVal[[<span class="st">&quot;train&quot;</span>]]</span>
<span id="cb846-4"><a href="interpretation.html#cb846-4" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> retVal[[<span class="st">&quot;test&quot;</span>]]</span>
<span id="cb846-5"><a href="interpretation.html#cb846-5" aria-hidden="true" tabindex="-1"></a>submission <span class="ot">=</span> retVal[[<span class="st">&quot;submission&quot;</span>]]</span>
<span id="cb846-6"><a href="interpretation.html#cb846-6" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(retVal)</span>
<span id="cb846-7"><a href="interpretation.html#cb846-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb846-8"><a href="interpretation.html#cb846-8" aria-hidden="true" tabindex="-1"></a>classNumber <span class="ot">=</span> <span class="fu">length</span>(<span class="fu">table</span>(labelsTrain))</span>
<span id="cb846-9"><a href="interpretation.html#cb846-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb846-10"><a href="interpretation.html#cb846-10" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb846-11"><a href="interpretation.html#cb846-11" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb846-12"><a href="interpretation.html#cb846-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> 200L, <span class="at">activation =</span> <span class="st">&quot;leaky_relu&quot;</span>,</span>
<span id="cb846-13"><a href="interpretation.html#cb846-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l2</span>(<span class="fl">0.00035</span>),</span>
<span id="cb846-14"><a href="interpretation.html#cb846-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">input_shape =</span> <span class="fu">ncol</span>(train)) <span class="sc">%&gt;%</span></span>
<span id="cb846-15"><a href="interpretation.html#cb846-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dropout</span>(<span class="fl">0.45</span>) <span class="sc">%&gt;%</span></span>
<span id="cb846-16"><a href="interpretation.html#cb846-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>,</span>
<span id="cb846-17"><a href="interpretation.html#cb846-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l1_l2</span>(<span class="fl">0.5</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb846-18"><a href="interpretation.html#cb846-18" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dropout</span>(<span class="fl">0.2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb846-19"><a href="interpretation.html#cb846-19" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;leaky_relu&quot;</span>,</span>
<span id="cb846-20"><a href="interpretation.html#cb846-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l2</span>(<span class="fl">0.00035</span>),</span>
<span id="cb846-21"><a href="interpretation.html#cb846-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l1_l2</span>(<span class="fl">0.1</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb846-22"><a href="interpretation.html#cb846-22" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dropout</span>(<span class="fl">0.25</span>) <span class="sc">%&gt;%</span></span>
<span id="cb846-23"><a href="interpretation.html#cb846-23" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> 50L, <span class="at">activation =</span> <span class="st">&quot;gelu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb846-24"><a href="interpretation.html#cb846-24" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> 25L, <span class="at">activation =</span> <span class="st">&quot;elu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb846-25"><a href="interpretation.html#cb846-25" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dropout</span>(<span class="fl">0.35</span>) <span class="sc">%&gt;%</span></span>
<span id="cb846-26"><a href="interpretation.html#cb846-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We need probabilities. So we use the softmax function.</span></span>
<span id="cb846-27"><a href="interpretation.html#cb846-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Remember, the labels MUST start at 0!</span></span>
<span id="cb846-28"><a href="interpretation.html#cb846-28" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> classNumber, <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>)</span>
<span id="cb846-29"><a href="interpretation.html#cb846-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb846-30"><a href="interpretation.html#cb846-30" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb846-31"><a href="interpretation.html#cb846-31" aria-hidden="true" tabindex="-1"></a>    keras<span class="sc">::</span><span class="fu">compile</span>(<span class="at">loss =</span> loss_binary_crossentropy,</span>
<span id="cb846-32"><a href="interpretation.html#cb846-32" aria-hidden="true" tabindex="-1"></a>                   <span class="at">optimizer =</span> <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.015</span>))</span>
<span id="cb846-33"><a href="interpretation.html#cb846-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb846-34"><a href="interpretation.html#cb846-34" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span> </span>
<span id="cb846-35"><a href="interpretation.html#cb846-35" aria-hidden="true" tabindex="-1"></a>    model <span class="sc">%&gt;%</span> <span class="co"># Mind the matrix property (no data.frame)!</span></span>
<span id="cb846-36"><a href="interpretation.html#cb846-36" aria-hidden="true" tabindex="-1"></a>        <span class="fu">fit</span>(<span class="at">x =</span> <span class="fu">as.matrix</span>(train), <span class="at">y =</span> <span class="fu">k_one_hot</span>(labelsTrain, classNumber),</span>
<span id="cb846-37"><a href="interpretation.html#cb846-37" aria-hidden="true" tabindex="-1"></a>            <span class="at">epochs =</span> 80L, <span class="at">batch =</span> 12L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb846-38"><a href="interpretation.html#cb846-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb846-39"><a href="interpretation.html#cb846-39" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter6_task_2-1.png" width="672" /></p>
<div class="sourceCode" id="cb847"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb847-1"><a href="interpretation.html#cb847-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Accuracy on training set (!)</span></span>
<span id="cb847-2"><a href="interpretation.html#cb847-2" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">predict</span>(model, <span class="fu">as.matrix</span>(train)) <span class="sc">%&gt;%</span> <span class="fu">apply</span>(<span class="dv">1</span>, which.max) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb847-3"><a href="interpretation.html#cb847-3" aria-hidden="true" tabindex="-1"></a>Metrics<span class="sc">::</span><span class="fu">accuracy</span>(pred, labelsTrain)</span></code></pre></div>
<pre><code>## [1] 0.7446043</code></pre>
<div class="sourceCode" id="cb849"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb849-1"><a href="interpretation.html#cb849-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(pred, labelsTrain)</span></code></pre></div>
<pre><code>##     labelsTrain
## pred   0   1   2   3   4   5
##    0   2   1   0   0   0   0
##    1   3   8   0   2   0   0
##    2   2  10 217  53   5   0
##    3   0   4  20 159  31   4
##    4   0   0   1   3  28   3</code></pre>
<div class="sourceCode" id="cb851"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb851-1"><a href="interpretation.html#cb851-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Accuracy on test set</span></span>
<span id="cb851-2"><a href="interpretation.html#cb851-2" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">predict</span>(model, <span class="fu">as.matrix</span>(test)) <span class="sc">%&gt;%</span> <span class="fu">apply</span>(<span class="dv">1</span>, which.max) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb851-3"><a href="interpretation.html#cb851-3" aria-hidden="true" tabindex="-1"></a>Metrics<span class="sc">::</span><span class="fu">accuracy</span>(pred, labelsTest)</span></code></pre></div>
<pre><code>## [1] 0.6304348</code></pre>
<div class="sourceCode" id="cb853"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb853-1"><a href="interpretation.html#cb853-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(pred, labelsTest)</span></code></pre></div>
<pre><code>##     labelsTest
## pred  1  2  3  4  5
##    1  0  4  2  0  0
##    2  2 55 17  3  0
##    3  0 11 25 10  1
##    4  0  1  0  7  0</code></pre>
<p>Recognize overfitting of your model selection strategy by changing the seed few times (while keeping the model constant) and increase the percentage of test data.
Furthermore, consider fitting a random forest for good quality as well.</p>
<p>For the final predictions, we use the whole data set without holdouts:</p>
<div class="sourceCode" id="cb855"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb855-1"><a href="interpretation.html#cb855-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb855-2"><a href="interpretation.html#cb855-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb855-3"><a href="interpretation.html#cb855-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb855-4"><a href="interpretation.html#cb855-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb855-5"><a href="interpretation.html#cb855-5" aria-hidden="true" tabindex="-1"></a>retVal <span class="ot">=</span> <span class="fu">readin</span>(<span class="at">percentageTest =</span> <span class="dv">0</span>, <span class="at">aggregate =</span> <span class="dv">0</span>)</span></code></pre></div>
<pre><code>## 
## Missing value imputation by random forests
## 
##   Variables to impute:       fixed.acidity, volatile.acidity, citric.acid, residual.sugar, chlorides, free.sulfur.dioxide, total.sulfur.dioxide, density, pH, sulphates
##   Variables used to impute:  fixed.acidity, volatile.acidity, citric.acid, residual.sugar, chlorides, free.sulfur.dioxide, total.sulfur.dioxide, density, pH, sulphates, alcohol
## iter 1:  ..........
## iter 2:  ..........
## iter 3:  ..........
## Size of training set: 694
## labelsTrain
##   0   1   2   3   4   5 
##   7  25 309 261  84   8</code></pre>
<div class="sourceCode" id="cb857"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb857-1"><a href="interpretation.html#cb857-1" aria-hidden="true" tabindex="-1"></a>labelsTrain <span class="ot">=</span> retVal[[<span class="st">&quot;labelsTrain&quot;</span>]]</span>
<span id="cb857-2"><a href="interpretation.html#cb857-2" aria-hidden="true" tabindex="-1"></a>labelsTest <span class="ot">=</span> retVal[[<span class="st">&quot;labelsTest&quot;</span>]]</span>
<span id="cb857-3"><a href="interpretation.html#cb857-3" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> retVal[[<span class="st">&quot;train&quot;</span>]]</span>
<span id="cb857-4"><a href="interpretation.html#cb857-4" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> retVal[[<span class="st">&quot;test&quot;</span>]]</span>
<span id="cb857-5"><a href="interpretation.html#cb857-5" aria-hidden="true" tabindex="-1"></a>submission <span class="ot">=</span> retVal[[<span class="st">&quot;submission&quot;</span>]]</span>
<span id="cb857-6"><a href="interpretation.html#cb857-6" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(retVal)</span>
<span id="cb857-7"><a href="interpretation.html#cb857-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb857-8"><a href="interpretation.html#cb857-8" aria-hidden="true" tabindex="-1"></a>classNumber <span class="ot">=</span> <span class="fu">length</span>(<span class="fu">table</span>(labelsTrain))</span>
<span id="cb857-9"><a href="interpretation.html#cb857-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb857-10"><a href="interpretation.html#cb857-10" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb857-11"><a href="interpretation.html#cb857-11" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb857-12"><a href="interpretation.html#cb857-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> 200L, <span class="at">activation =</span> <span class="st">&quot;leaky_relu&quot;</span>,</span>
<span id="cb857-13"><a href="interpretation.html#cb857-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l2</span>(<span class="fl">0.00035</span>),</span>
<span id="cb857-14"><a href="interpretation.html#cb857-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">input_shape =</span> <span class="fu">ncol</span>(train)) <span class="sc">%&gt;%</span></span>
<span id="cb857-15"><a href="interpretation.html#cb857-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dropout</span>(<span class="fl">0.45</span>) <span class="sc">%&gt;%</span></span>
<span id="cb857-16"><a href="interpretation.html#cb857-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>,</span>
<span id="cb857-17"><a href="interpretation.html#cb857-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l1_l2</span>(<span class="fl">0.5</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb857-18"><a href="interpretation.html#cb857-18" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dropout</span>(<span class="fl">0.2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb857-19"><a href="interpretation.html#cb857-19" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;leaky_relu&quot;</span>,</span>
<span id="cb857-20"><a href="interpretation.html#cb857-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l2</span>(<span class="fl">0.00035</span>),</span>
<span id="cb857-21"><a href="interpretation.html#cb857-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l1_l2</span>(<span class="fl">0.1</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb857-22"><a href="interpretation.html#cb857-22" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dropout</span>(<span class="fl">0.25</span>) <span class="sc">%&gt;%</span></span>
<span id="cb857-23"><a href="interpretation.html#cb857-23" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> 50L, <span class="at">activation =</span> <span class="st">&quot;gelu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb857-24"><a href="interpretation.html#cb857-24" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> 25L, <span class="at">activation =</span> <span class="st">&quot;elu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb857-25"><a href="interpretation.html#cb857-25" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dropout</span>(<span class="fl">0.35</span>) <span class="sc">%&gt;%</span></span>
<span id="cb857-26"><a href="interpretation.html#cb857-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We need probabilities. So we use the softmax function.</span></span>
<span id="cb857-27"><a href="interpretation.html#cb857-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Remember, the labels MUST start at 0!</span></span>
<span id="cb857-28"><a href="interpretation.html#cb857-28" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> classNumber, <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>)</span>
<span id="cb857-29"><a href="interpretation.html#cb857-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb857-30"><a href="interpretation.html#cb857-30" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb857-31"><a href="interpretation.html#cb857-31" aria-hidden="true" tabindex="-1"></a>    keras<span class="sc">::</span><span class="fu">compile</span>(<span class="at">loss =</span> loss_binary_crossentropy,</span>
<span id="cb857-32"><a href="interpretation.html#cb857-32" aria-hidden="true" tabindex="-1"></a>                   <span class="at">optimizer =</span> <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.015</span>))</span>
<span id="cb857-33"><a href="interpretation.html#cb857-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb857-34"><a href="interpretation.html#cb857-34" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span> </span>
<span id="cb857-35"><a href="interpretation.html#cb857-35" aria-hidden="true" tabindex="-1"></a>    model <span class="sc">%&gt;%</span> <span class="co"># Mind the matrix property (no data.frame)!</span></span>
<span id="cb857-36"><a href="interpretation.html#cb857-36" aria-hidden="true" tabindex="-1"></a>        <span class="fu">fit</span>(<span class="at">x =</span> <span class="fu">as.matrix</span>(train), <span class="at">y =</span> <span class="fu">k_one_hot</span>(labelsTrain, classNumber),</span>
<span id="cb857-37"><a href="interpretation.html#cb857-37" aria-hidden="true" tabindex="-1"></a>            <span class="at">epochs =</span> 80L, <span class="at">batch =</span> 12L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb857-38"><a href="interpretation.html#cb857-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb857-39"><a href="interpretation.html#cb857-39" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter6_task_3-1.png" width="672" /></p>
<div class="sourceCode" id="cb858"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb858-1"><a href="interpretation.html#cb858-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Accuracy on training set (!)</span></span>
<span id="cb858-2"><a href="interpretation.html#cb858-2" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">predict</span>(model, <span class="fu">as.matrix</span>(train)) <span class="sc">%&gt;%</span> <span class="fu">apply</span>(<span class="dv">1</span>, which.max) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb858-3"><a href="interpretation.html#cb858-3" aria-hidden="true" tabindex="-1"></a>Metrics<span class="sc">::</span><span class="fu">accuracy</span>(pred, labelsTrain)</span></code></pre></div>
<pre><code>## [1] 0.7853026</code></pre>
<div class="sourceCode" id="cb860"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb860-1"><a href="interpretation.html#cb860-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(pred, labelsTrain)</span></code></pre></div>
<pre><code>##     labelsTrain
## pred   0   1   2   3   4   5
##    0   1   0   0   0   0   0
##    1   0   5   0   0   0   0
##    2   6  15 267  33   4   0
##    3   0   5  35 211  19   1
##    4   0   0   7  17  61   7</code></pre>
<div class="sourceCode" id="cb862"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb862-1"><a href="interpretation.html#cb862-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Reverse subtraction (for start at 0) and create submission file.</span></span>
<span id="cb862-2"><a href="interpretation.html#cb862-2" aria-hidden="true" tabindex="-1"></a><span class="fu">write.csv</span>(pred <span class="sc">+</span> <span class="fu">min</span>(<span class="fu">as.data.frame</span>(EcoData<span class="sc">::</span>wine)<span class="sc">$</span>quality, <span class="at">na.rm =</span> <span class="cn">TRUE</span>),</span>
<span id="cb862-3"><a href="interpretation.html#cb862-3" aria-hidden="true" tabindex="-1"></a>          <span class="at">file =</span> <span class="st">&quot;wine_NN.csv&quot;</span>)</span></code></pre></div>
    </p>
  </details>
  <br/>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="deep.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="gan.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

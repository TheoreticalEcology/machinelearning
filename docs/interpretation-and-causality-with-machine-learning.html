<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5 Interpretation and causality with machine learning | Machine Learning and AI in TensorFlow and R</title>
  <meta name="description" content="5 Interpretation and causality with machine learning | Machine Learning and AI in TensorFlow and R" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="5 Interpretation and causality with machine learning | Machine Learning and AI in TensorFlow and R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="5 Interpretation and causality with machine learning | Machine Learning and AI in TensorFlow and R" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5 Interpretation and causality with machine learning | Machine Learning and AI in TensorFlow and R" />
  
  <meta name="twitter:description" content="5 Interpretation and causality with machine learning | Machine Learning and AI in TensorFlow and R" />
  

<meta name="author" content="Maximilian Pichler and Florian Hartig" />


<meta name="date" content="2021-05-06" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="Deep.html"/>
<link rel="next" href="gans-vaes-and-reinforcement-learning.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #ffffff;
    color: #a0a0a0;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
div.sourceCode
  { color: #1f1c1b; background-color: #ffffff; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span { color: #1f1c1b; } /* Normal */
code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
code span.an { color: #ca60ca; } /* Annotation */
code span.at { color: #0057ae; } /* Attribute */
code span.bn { color: #b08000; } /* BaseN */
code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #924c9d; } /* Char */
code span.cn { color: #aa5500; } /* Constant */
code span.co { color: #898887; } /* Comment */
code span.cv { color: #0095ff; } /* CommentVar */
code span.do { color: #607880; } /* Documentation */
code span.dt { color: #0057ae; } /* DataType */
code span.dv { color: #b08000; } /* DecVal */
code span.er { color: #bf0303; text-decoration: underline; } /* Error */
code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
code span.fl { color: #b08000; } /* Float */
code span.fu { color: #644a9b; } /* Function */
code span.im { color: #ff5500; } /* Import */
code span.in { color: #b08000; } /* Information */
code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
code span.op { color: #1f1c1b; } /* Operator */
code span.ot { color: #006e28; } /* Other */
code span.pp { color: #006e28; } /* Preprocessor */
code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #ff5500; } /* SpecialString */
code span.st { color: #bf0303; } /* String */
code span.va { color: #0057ae; } /* Variable */
code span.vs { color: #bf0303; } /* VerbatimString */
code span.wa { color: #bf0303; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction to Machine Learning</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#unsupervised-learning"><i class="fa fa-check"></i><b>2.1</b> Unsupervised learning</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="introduction.html"><a href="introduction.html#hierarchical-clustering"><i class="fa fa-check"></i><b>2.1.1</b> Hierarchical clustering</a></li>
<li class="chapter" data-level="2.1.2" data-path="introduction.html"><a href="introduction.html#k-means-clustering"><i class="fa fa-check"></i><b>2.1.2</b> k-means clustering</a></li>
<li class="chapter" data-level="2.1.3" data-path="introduction.html"><a href="introduction.html#density-based-clustering"><i class="fa fa-check"></i><b>2.1.3</b> Density-based clustering</a></li>
<li class="chapter" data-level="2.1.4" data-path="introduction.html"><a href="introduction.html#model-based-clustering"><i class="fa fa-check"></i><b>2.1.4</b> Model-based clustering</a></li>
<li class="chapter" data-level="2.1.5" data-path="introduction.html"><a href="introduction.html#ordination"><i class="fa fa-check"></i><b>2.1.5</b> Ordination</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#supervised-learning-regression-and-classification"><i class="fa fa-check"></i><b>2.2</b> Supervised learning: regression and classification</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="introduction.html"><a href="introduction.html#supervised-regression-using-random-forest"><i class="fa fa-check"></i><b>2.2.1</b> Supervised regression using Random Forest</a></li>
<li class="chapter" data-level="2.2.2" data-path="introduction.html"><a href="introduction.html#supervised-classification-using-random-forest"><i class="fa fa-check"></i><b>2.2.2</b> Supervised classification using Random Forest</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#introduction-to-tensorflow"><i class="fa fa-check"></i><b>2.3</b> Introduction to Tensorflow</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="introduction.html"><a href="introduction.html#tensorflow-data-containers"><i class="fa fa-check"></i><b>2.3.1</b> Tensorflow data containers</a></li>
<li class="chapter" data-level="2.3.2" data-path="introduction.html"><a href="introduction.html#tensorflow-data-types---good-practise-with-r-tf"><i class="fa fa-check"></i><b>2.3.2</b> Tensorflow data types - good practise with R-TF</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="introduction.html"><a href="introduction.html#introduction-to-pytorch"><i class="fa fa-check"></i><b>2.4</b> Introduction to PyTorch</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="introduction.html"><a href="introduction.html#pytorch-data-containers"><i class="fa fa-check"></i><b>2.4.1</b> PyTorch data containers</a></li>
<li class="chapter" data-level="2.4.2" data-path="introduction.html"><a href="introduction.html#torch-data-types---good-practise-with-r-tf"><i class="fa fa-check"></i><b>2.4.2</b> Torch data types - good practise with R-TF</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="introduction.html"><a href="introduction.html#first-steps-with-the-keras-framework"><i class="fa fa-check"></i><b>2.5</b> First steps with the keras framework</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="introduction.html"><a href="introduction.html#example-workflow-in-keras"><i class="fa fa-check"></i><b>2.5.1</b> Example workflow in keras</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="fund.html"><a href="fund.html"><i class="fa fa-check"></i><b>3</b> Fundamental principles and techniques</a>
<ul>
<li class="chapter" data-level="3.1" data-path="fund.html"><a href="fund.html#machine-learning-principles"><i class="fa fa-check"></i><b>3.1</b> Machine learning principles</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="fund.html"><a href="fund.html#optimization"><i class="fa fa-check"></i><b>3.1.1</b> Optimization</a></li>
<li class="chapter" data-level="3.1.2" data-path="fund.html"><a href="fund.html#regularization"><i class="fa fa-check"></i><b>3.1.2</b> Regularization</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="fund.html"><a href="fund.html#tree-based-ml-algorithms"><i class="fa fa-check"></i><b>3.2</b> Tree-based ML algorithms</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="fund.html"><a href="fund.html#classification-and-regression-trees"><i class="fa fa-check"></i><b>3.2.1</b> Classification and Regression Trees</a></li>
<li class="chapter" data-level="3.2.2" data-path="fund.html"><a href="fund.html#random-forest"><i class="fa fa-check"></i><b>3.2.2</b> Random Forest</a></li>
<li class="chapter" data-level="3.2.3" data-path="fund.html"><a href="fund.html#boosted-regression-trees"><i class="fa fa-check"></i><b>3.2.3</b> Boosted regression trees</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="fund.html"><a href="fund.html#distance-based-algorithms"><i class="fa fa-check"></i><b>3.3</b> Distance-based algorithms</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="fund.html"><a href="fund.html#k-nearest-neighbor"><i class="fa fa-check"></i><b>3.3.1</b> k-nearest-neighbor</a></li>
<li class="chapter" data-level="3.3.2" data-path="fund.html"><a href="fund.html#support-vector-machines-svm"><i class="fa fa-check"></i><b>3.3.2</b> Support Vector Machines (SVM)</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="fund.html"><a href="fund.html#artificial-neural-networks"><i class="fa fa-check"></i><b>3.4</b> Artificial neural networks</a></li>
<li class="chapter" data-level="3.5" data-path="fund.html"><a href="fund.html#the-standard-ml-pipeline-at-the-example-of-the-titanic-dataset"><i class="fa fa-check"></i><b>3.5</b> The standard ML pipeline at the example of the titanic dataset</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="fund.html"><a href="fund.html#data-cleaning"><i class="fa fa-check"></i><b>3.5.1</b> Data cleaning</a></li>
<li class="chapter" data-level="3.5.2" data-path="fund.html"><a href="fund.html#pre-processing-and-feature-selection"><i class="fa fa-check"></i><b>3.5.2</b> Pre-processing and feature selection</a></li>
<li class="chapter" data-level="3.5.3" data-path="fund.html"><a href="fund.html#split-data-for-training-and-testing"><i class="fa fa-check"></i><b>3.5.3</b> Split data for training and testing</a></li>
<li class="chapter" data-level="3.5.4" data-path="fund.html"><a href="fund.html#model-fitting"><i class="fa fa-check"></i><b>3.5.4</b> Model fitting</a></li>
<li class="chapter" data-level="3.5.5" data-path="fund.html"><a href="fund.html#model-evaluation"><i class="fa fa-check"></i><b>3.5.5</b> Model evaluation</a></li>
<li class="chapter" data-level="3.5.6" data-path="fund.html"><a href="fund.html#predictions-and-submission"><i class="fa fa-check"></i><b>3.5.6</b> Predictions and submission</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="fund.html"><a href="fund.html#mlr"><i class="fa fa-check"></i><b>3.6</b> Bonus - ML pipelines with mlr3</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="fund.html"><a href="fund.html#mlr3---the-basic-workflow"><i class="fa fa-check"></i><b>3.6.1</b> mlr3 - the basic workflow</a></li>
<li class="chapter" data-level="3.6.2" data-path="fund.html"><a href="fund.html#mlr3---hyper-parameter-tuning"><i class="fa fa-check"></i><b>3.6.2</b> mlr3 - hyper-parameter tuning</a></li>
<li class="chapter" data-level="3.6.3" data-path="fund.html"><a href="fund.html#mlr3---hyper-parameter-tuning-with-oversampling"><i class="fa fa-check"></i><b>3.6.3</b> mlr3 - hyper-parameter tuning with oversampling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Deep.html"><a href="Deep.html"><i class="fa fa-check"></i><b>4</b> Deep learning</a>
<ul>
<li class="chapter" data-level="4.1" data-path="Deep.html"><a href="Deep.html#network-architectures"><i class="fa fa-check"></i><b>4.1</b> Network architectures</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="Deep.html"><a href="Deep.html#deep-neural-networks-dnns"><i class="fa fa-check"></i><b>4.1.1</b> Deep neural networks (DNNs)</a></li>
<li class="chapter" data-level="4.1.2" data-path="Deep.html"><a href="Deep.html#convolutional-neural-networks-dnns"><i class="fa fa-check"></i><b>4.1.2</b> Convolutional neural networks (DNNs)</a></li>
<li class="chapter" data-level="4.1.3" data-path="Deep.html"><a href="Deep.html#recurrent-neural-networks-rnns"><i class="fa fa-check"></i><b>4.1.3</b> Recurrent neural networks (RNNs)</a></li>
<li class="chapter" data-level="4.1.4" data-path="Deep.html"><a href="Deep.html#natural-language-processing-nlp"><i class="fa fa-check"></i><b>4.1.4</b> Natural language processing (NLP)</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="Deep.html"><a href="Deep.html#case-study-dropout-and-early-stopping-in-a-deep-neural-network"><i class="fa fa-check"></i><b>4.2</b> Case study: dropout and early stopping in a deep neural network</a></li>
<li class="chapter" data-level="4.3" data-path="Deep.html"><a href="Deep.html#case-study---fitting-a-convolutional-neural-networks-on-mnist"><i class="fa fa-check"></i><b>4.3</b> Case study - fitting a Convolutional Neural Networks on MNIST</a></li>
<li class="chapter" data-level="4.4" data-path="Deep.html"><a href="Deep.html#advanced-training-techniques"><i class="fa fa-check"></i><b>4.4</b> Advanced training techniques</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="Deep.html"><a href="Deep.html#data-augmentation"><i class="fa fa-check"></i><b>4.4.1</b> Data Augmentation</a></li>
<li class="chapter" data-level="4.4.2" data-path="Deep.html"><a href="Deep.html#transfer"><i class="fa fa-check"></i><b>4.4.2</b> Transfer learning</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html"><i class="fa fa-check"></i><b>5</b> Interpretation and causality with machine learning</a>
<ul>
<li class="chapter" data-level="5.1" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#explainable-ai"><i class="fa fa-check"></i><b>5.1</b> Explainable AI</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#a-practical-example"><i class="fa fa-check"></i><b>5.1.1</b> A practical example</a></li>
<li class="chapter" data-level="5.1.2" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#feature-importance"><i class="fa fa-check"></i><b>5.1.2</b> Feature Importance</a></li>
<li class="chapter" data-level="5.1.3" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#partial-dependencies"><i class="fa fa-check"></i><b>5.1.3</b> Partial dependencies</a></li>
<li class="chapter" data-level="5.1.4" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#accumulated-local-effects"><i class="fa fa-check"></i><b>5.1.4</b> Accumulated local effects</a></li>
<li class="chapter" data-level="5.1.5" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#friedmans-h-statistic"><i class="fa fa-check"></i><b>5.1.5</b> Friedmans H-statistic</a></li>
<li class="chapter" data-level="5.1.6" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#global-explainer---simplifying-the-ml-model"><i class="fa fa-check"></i><b>5.1.6</b> Global explainer - Simplifying the ML model</a></li>
<li class="chapter" data-level="5.1.7" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#local-explainer---lime-explaining-single-instances-observations"><i class="fa fa-check"></i><b>5.1.7</b> Local explainer - LIME explaining single instances (observations)</a></li>
<li class="chapter" data-level="5.1.8" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#local-explainer---shapley"><i class="fa fa-check"></i><b>5.1.8</b> Local explainer - Shapley</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#causal-inference-and-machine-learning"><i class="fa fa-check"></i><b>5.2</b> Causal inference and machine learning</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#causal-inference-on-static-data"><i class="fa fa-check"></i><b>5.2.1</b> Causal inference on static data</a></li>
<li class="chapter" data-level="5.2.2" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#structural-equation-models"><i class="fa fa-check"></i><b>5.2.2</b> Structural equation models</a></li>
<li class="chapter" data-level="5.2.3" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#automatic-causal-discovery"><i class="fa fa-check"></i><b>5.2.3</b> Automatic causal discovery</a></li>
<li class="chapter" data-level="5.2.4" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#causal-inference-on-dynamic-data"><i class="fa fa-check"></i><b>5.2.4</b> Causal inference on dynamic data</a></li>
<li class="chapter" data-level="5.2.5" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#outlook-for-machine-learning"><i class="fa fa-check"></i><b>5.2.5</b> Outlook for machine learning</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="gans-vaes-and-reinforcement-learning.html"><a href="gans-vaes-and-reinforcement-learning.html"><i class="fa fa-check"></i><b>6</b> GANs, VAEs, and Reinforcement learning</a>
<ul>
<li class="chapter" data-level="6.1" data-path="gans-vaes-and-reinforcement-learning.html"><a href="gans-vaes-and-reinforcement-learning.html#generative-adversarial-network-gans"><i class="fa fa-check"></i><b>6.1</b> Generative adversarial network (GANs)</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="gans-vaes-and-reinforcement-learning.html"><a href="gans-vaes-and-reinforcement-learning.html#mnist---gan-based-on-dnns"><i class="fa fa-check"></i><b>6.1.1</b> MNIST - GAN based on DNNs</a></li>
<li class="chapter" data-level="6.1.2" data-path="gans-vaes-and-reinforcement-learning.html"><a href="gans-vaes-and-reinforcement-learning.html#flower---gan"><i class="fa fa-check"></i><b>6.1.2</b> Flower - GAN</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="gans-vaes-and-reinforcement-learning.html"><a href="gans-vaes-and-reinforcement-learning.html#autoencoder"><i class="fa fa-check"></i><b>6.2</b> Autoencoder</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="gans-vaes-and-reinforcement-learning.html"><a href="gans-vaes-and-reinforcement-learning.html#autoencoder---mnist-cnn"><i class="fa fa-check"></i><b>6.2.1</b> Autoencoder - MNIST CNN</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="gans-vaes-and-reinforcement-learning.html"><a href="gans-vaes-and-reinforcement-learning.html#varational-autoencoder"><i class="fa fa-check"></i><b>6.3</b> Varational Autoencoder</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="datasets.html"><a href="datasets.html"><i class="fa fa-check"></i><b>7</b> Datasets</a>
<ul>
<li class="chapter" data-level="7.1" data-path="datasets.html"><a href="datasets.html#titanic"><i class="fa fa-check"></i><b>7.1</b> Titanic</a></li>
<li class="chapter" data-level="7.2" data-path="datasets.html"><a href="datasets.html#plant-pollinator-database"><i class="fa fa-check"></i><b>7.2</b> Plant-pollinator database</a></li>
<li class="chapter" data-level="7.3" data-path="datasets.html"><a href="datasets.html#wine"><i class="fa fa-check"></i><b>7.3</b> Wine</a></li>
<li class="chapter" data-level="7.4" data-path="datasets.html"><a href="datasets.html#nasa"><i class="fa fa-check"></i><b>7.4</b> Nasa</a></li>
<li class="chapter" data-level="7.5" data-path="datasets.html"><a href="datasets.html#flower"><i class="fa fa-check"></i><b>7.5</b> Flower</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning and AI in TensorFlow and R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="interpretation-and-causality-with-machine-learning" class="section level1" number="5">
<h1><span class="header-section-number">5</span> Interpretation and causality with machine learning</h1>
<div id="explainable-ai" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Explainable AI</h2>
<p>The goal of explainable AI (xAI, aka interpretable machine learning) is to explain WHY a fitted ML models makes certain predictions. A typical example is to understand how important different variables are for predictions. There incentives to do so range from a better technical understanding of the models over understanding which data is important to improve predictions to questions of fairness and discrimination (e.g. to understand if an algorithm uses skin color to make a decision).</p>
<div id="a-practical-example" class="section level3" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> A practical example</h3>
<p>In this lecture we will work with another famous dataset, the Boston housing dataset:</p>
<p>We will fit a random forest and use the iml pkg for xAI, see <img src="https://christophm.github.io/interpretable-ml-book/" /></p>
<div class="sourceCode" id="cb365"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb365-1"><a href="interpretation-and-causality-with-machine-learning.html#cb365-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb365-2"><a href="interpretation-and-causality-with-machine-learning.html#cb365-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;iml&quot;</span>)</span>
<span id="cb365-3"><a href="interpretation-and-causality-with-machine-learning.html#cb365-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;randomForest&quot;</span>)</span>
<span id="cb365-4"><a href="interpretation-and-causality-with-machine-learning.html#cb365-4" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;Boston&quot;</span>, <span class="at">package =</span> <span class="st">&quot;MASS&quot;</span>)</span>
<span id="cb365-5"><a href="interpretation-and-causality-with-machine-learning.html#cb365-5" aria-hidden="true" tabindex="-1"></a>rf <span class="ot">=</span> <span class="fu">randomForest</span>(medv <span class="sc">~</span> ., <span class="at">data =</span> Boston, <span class="at">ntree =</span> <span class="dv">50</span>)</span></code></pre></div>
<p>xAI packages are written generic, i.e. they can handle almost all ML models.
When we want to use them, we first have to create a Predictor object, that holds the model and the data. The iml package uses R6 classes, that means new objects can be created by calling Predictor$new(). (do not worry if you do not know what R6 classes are, just use the command)</p>
<div class="sourceCode" id="cb366"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb366-1"><a href="interpretation-and-causality-with-machine-learning.html#cb366-1" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> Boston[<span class="fu">which</span>(<span class="fu">names</span>(Boston) <span class="sc">!=</span> <span class="st">&quot;medv&quot;</span>)]</span>
<span id="cb366-2"><a href="interpretation-and-causality-with-machine-learning.html#cb366-2" aria-hidden="true" tabindex="-1"></a>predictor <span class="ot">=</span> Predictor<span class="sc">$</span><span class="fu">new</span>(rf, <span class="at">data =</span> X, <span class="at">y =</span> Boston<span class="sc">$</span>medv)</span></code></pre></div>
</div>
<div id="feature-importance" class="section level3" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Feature Importance</h3>
<p>Feature importance, should not be mistaken with the RF variable importance. It tells us how important the individual variables are for predictions and can be calculated for all ML models and is based on a permutation approach (have a look at the book):</p>
<div class="sourceCode" id="cb367"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb367-1"><a href="interpretation-and-causality-with-machine-learning.html#cb367-1" aria-hidden="true" tabindex="-1"></a>imp <span class="ot">=</span> FeatureImp<span class="sc">$</span><span class="fu">new</span>(predictor, <span class="at">loss =</span> <span class="st">&quot;mae&quot;</span>)</span>
<span id="cb367-2"><a href="interpretation-and-causality-with-machine-learning.html#cb367-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(imp)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-175-1.png" width="672" /></p>
</div>
<div id="partial-dependencies" class="section level3" number="5.1.3">
<h3><span class="header-section-number">5.1.3</span> Partial dependencies</h3>
<p>Partial dependencies are similar to allEffects plots for normal regressions, the idea is to visualize “marginal effects” of predictors (with the feature argument we specify the variable we want to visualize):</p>
<div class="sourceCode" id="cb368"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb368-1"><a href="interpretation-and-causality-with-machine-learning.html#cb368-1" aria-hidden="true" tabindex="-1"></a>eff <span class="ot">=</span> FeatureEffect<span class="sc">$</span><span class="fu">new</span>(predictor, <span class="at">feature =</span> <span class="st">&quot;rm&quot;</span>, <span class="at">method =</span> <span class="st">&quot;pdp&quot;</span>, <span class="at">grid.size =</span> <span class="dv">30</span>)</span>
<span id="cb368-2"><a href="interpretation-and-causality-with-machine-learning.html#cb368-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(eff)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-176-1.png" width="672" /></p>
<p>Partial dependencies can be also plotted for single observations:</p>
<div class="sourceCode" id="cb369"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb369-1"><a href="interpretation-and-causality-with-machine-learning.html#cb369-1" aria-hidden="true" tabindex="-1"></a>eff <span class="ot">=</span> FeatureEffect<span class="sc">$</span><span class="fu">new</span>(predictor, <span class="at">feature =</span> <span class="st">&quot;rm&quot;</span>, <span class="at">method =</span> <span class="st">&quot;pdp+ice&quot;</span>, <span class="at">grid.size =</span> <span class="dv">30</span>)</span>
<span id="cb369-2"><a href="interpretation-and-causality-with-machine-learning.html#cb369-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(eff)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-177-1.png" width="672" /></p>
<p>One disadvantage of partial dependencies is that they are sensitive to correlated predictors. Accumulated local effects can be used to account for correlation for predictors</p>
</div>
<div id="accumulated-local-effects" class="section level3" number="5.1.4">
<h3><span class="header-section-number">5.1.4</span> Accumulated local effects</h3>
<p>Accumulated local effects (ALE) are basically partial dependencies plots but try to correct for correlations between predictors</p>
<div class="sourceCode" id="cb370"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb370-1"><a href="interpretation-and-causality-with-machine-learning.html#cb370-1" aria-hidden="true" tabindex="-1"></a>ale <span class="ot">=</span> FeatureEffect<span class="sc">$</span><span class="fu">new</span>(predictor, <span class="at">feature =</span> <span class="st">&quot;rm&quot;</span>, <span class="at">method =</span> <span class="st">&quot;ale&quot;</span>)</span>
<span id="cb370-2"><a href="interpretation-and-causality-with-machine-learning.html#cb370-2" aria-hidden="true" tabindex="-1"></a>ale<span class="sc">$</span><span class="fu">plot</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-178-1.png" width="672" /></p>
<p>If there is no colinearity, you shouldn’t see much difference between partial dependencies and ALE plots.</p>
</div>
<div id="friedmans-h-statistic" class="section level3" number="5.1.5">
<h3><span class="header-section-number">5.1.5</span> Friedmans H-statistic</h3>
<p>The H-statistic can be used to find interactions between predictors. However, again, keep in mind that the H-statistic is sensible to correlation between predictors:</p>
<div class="sourceCode" id="cb371"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb371-1"><a href="interpretation-and-causality-with-machine-learning.html#cb371-1" aria-hidden="true" tabindex="-1"></a>interact <span class="ot">=</span> Interaction<span class="sc">$</span><span class="fu">new</span>(predictor, <span class="st">&quot;lstat&quot;</span>)</span>
<span id="cb371-2"><a href="interpretation-and-causality-with-machine-learning.html#cb371-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(interact)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-179-1.png" width="672" /></p>
</div>
<div id="global-explainer---simplifying-the-ml-model" class="section level3" number="5.1.6">
<h3><span class="header-section-number">5.1.6</span> Global explainer - Simplifying the ML model</h3>
<p>Another idea is to simplify the ML model with another simpler model such as a decision tree. We create predictions with the ML model for a lot of different input values and then we fit on these predictions a decision tree, which we can then interpret.</p>
<div class="sourceCode" id="cb372"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb372-1"><a href="interpretation-and-causality-with-machine-learning.html#cb372-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(partykit)</span>
<span id="cb372-2"><a href="interpretation-and-causality-with-machine-learning.html#cb372-2" aria-hidden="true" tabindex="-1"></a>tree <span class="ot">=</span> TreeSurrogate<span class="sc">$</span><span class="fu">new</span>(predictor, <span class="at">maxdepth =</span> <span class="dv">2</span>)</span>
<span id="cb372-3"><a href="interpretation-and-causality-with-machine-learning.html#cb372-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(tree)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-180-1.png" width="672" /></p>
</div>
<div id="local-explainer---lime-explaining-single-instances-observations" class="section level3" number="5.1.7">
<h3><span class="header-section-number">5.1.7</span> Local explainer - LIME explaining single instances (observations)</h3>
<p>The global approach is to simplify the entire ML-black-box model via a simpler model, which is then interpretable.</p>
<p>However, sometimes we are only interested in understanding how single observations/predictions are generated. The lime approach explores the feature space around one observations and based on this local spare fits then a simpler model (e.g. a linear model):</p>
<div class="sourceCode" id="cb373"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb373-1"><a href="interpretation-and-causality-with-machine-learning.html#cb373-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb373-2"><a href="interpretation-and-causality-with-machine-learning.html#cb373-2" aria-hidden="true" tabindex="-1"></a>lime.explain <span class="ot">=</span> LocalModel<span class="sc">$</span><span class="fu">new</span>(predictor, <span class="at">x.interest =</span> X[<span class="dv">1</span>,])</span>
<span id="cb373-3"><a href="interpretation-and-causality-with-machine-learning.html#cb373-3" aria-hidden="true" tabindex="-1"></a>lime.explain<span class="sc">$</span>results</span></code></pre></div>
<pre><code>##               beta x.recoded    effect x.original feature feature.value
## rm       4.1893817     6.575 27.545185      6.575      rm      rm=6.575
## ptratio -0.5307031    15.300 -8.119758       15.3 ptratio  ptratio=15.3
## lstat   -0.4398104     4.980 -2.190256       4.98   lstat    lstat=4.98</code></pre>
<div class="sourceCode" id="cb375"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb375-1"><a href="interpretation-and-causality-with-machine-learning.html#cb375-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lime.explain)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-181-1.png" width="672" /></p>
</div>
<div id="local-explainer---shapley" class="section level3" number="5.1.8">
<h3><span class="header-section-number">5.1.8</span> Local explainer - Shapley</h3>
<p>The Shapley method computes the so called Shapley value, feature contributions for single predictions, and is based on an approach from cooperative game theory. The idea is that each feature value of the instance is a “player” in a game, where the prediction is the reward. The Shapley value tells us how to fairly distribute the award among the feature.</p>
<div class="sourceCode" id="cb376"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb376-1"><a href="interpretation-and-causality-with-machine-learning.html#cb376-1" aria-hidden="true" tabindex="-1"></a>shapley <span class="ot">=</span> Shapley<span class="sc">$</span><span class="fu">new</span>(predictor, <span class="at">x.interest =</span> X[<span class="dv">1</span>,])</span>
<span id="cb376-2"><a href="interpretation-and-causality-with-machine-learning.html#cb376-2" aria-hidden="true" tabindex="-1"></a>shapley<span class="sc">$</span><span class="fu">plot</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-182-1.png" width="672" /></p>
</div>
</div>
<div id="causal-inference-and-machine-learning" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Causal inference and machine learning</h2>
<p>xAI aims at explaining how predictions are being made. In general, xAI != causality. xAI methods measure which variables are used by the algorithm for predictions, or how much variables improve predictions. The important point to note here: if a variable causes something, we could also expect that it helps to predict the very thing. The opposite, however, is not generally true - it is very often possible that a variable that doesn’t cause something can predict something.</p>
<p>In statistical courses (in particular course: advanced biostatistics), we discuss the issue of causality at length. Here, we don’t want to go into the details, but again, you should in general resist to interpret indicators of importance in xAI as causal effects. They tell you something about what’s going on in the algorithm, not about what’s going on in reality.</p>
<div id="causal-inference-on-static-data" class="section level3" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Causal inference on static data</h3>
<p>Methods for causal inference depend on whether we have dynamic or static data. The latter is the more common case. With static data, the problem is confounding - if you have several predictors that are correlated, you can get spurious correlations between a given predictor and the response.</p>
<p>A multiple regression, and a few other methods are able to correct for other predictors, and thus isolate the causal effect. The same is not necessarily true for ML algorithms and xAI methods. This is not a bug, but a feature - for making good predictions, it is often no problem, but rather an advantage to also use non-causal predictors.</p>
<p>Here an example for the variable importance indicators in the RF algorithm. The purpose of this script is to show that RF variable importance will split importance values for collinear variables evenly, even if collinearity is low enough so that variables are separable and would be correctly separated by an lm / ANOVA</p>
<p>We first simulate a dataset with 2 predictors that are strongly correlated, but only one of them has an effect on the response.</p>
<div class="sourceCode" id="cb377"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb377-1"><a href="interpretation-and-causality-with-machine-learning.html#cb377-1" aria-hidden="true" tabindex="-1"></a><span class="co"># simulation parameters</span></span>
<span id="cb377-2"><a href="interpretation-and-causality-with-machine-learning.html#cb377-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="dv">1000</span></span>
<span id="cb377-3"><a href="interpretation-and-causality-with-machine-learning.html#cb377-3" aria-hidden="true" tabindex="-1"></a>col <span class="ot">=</span> <span class="fl">0.7</span></span>
<span id="cb377-4"><a href="interpretation-and-causality-with-machine-learning.html#cb377-4" aria-hidden="true" tabindex="-1"></a><span class="co"># create collinear predictors</span></span>
<span id="cb377-5"><a href="interpretation-and-causality-with-machine-learning.html#cb377-5" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">=</span> <span class="fu">runif</span>(n)</span>
<span id="cb377-6"><a href="interpretation-and-causality-with-machine-learning.html#cb377-6" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">=</span> col <span class="sc">*</span> x1 <span class="sc">+</span> (<span class="dv">1</span><span class="sc">-</span>col) <span class="sc">*</span> <span class="fu">runif</span>(n)</span>
<span id="cb377-7"><a href="interpretation-and-causality-with-machine-learning.html#cb377-7" aria-hidden="true" tabindex="-1"></a><span class="co"># response is only influenced by x1</span></span>
<span id="cb377-8"><a href="interpretation-and-causality-with-machine-learning.html#cb377-8" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> x1 <span class="sc">+</span> <span class="fu">rnorm</span>(n)</span></code></pre></div>
<p>lm / anova correctly identify x1 as causal variable</p>
<div class="sourceCode" id="cb378"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb378-1"><a href="interpretation-and-causality-with-machine-learning.html#cb378-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2))</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: y
##            Df Sum Sq Mean Sq  F value Pr(&gt;F)    
## x1          1 106.30 106.300 110.1988 &lt;2e-16 ***
## x2          1   0.23   0.228   0.2368 0.6267    
## Residuals 997 961.73   0.965                    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Fit RF and show variable importance</p>
<div class="sourceCode" id="cb380"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb380-1"><a href="interpretation-and-causality-with-machine-learning.html#cb380-1" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2, <span class="at">importance=</span><span class="cn">TRUE</span>)</span>
<span id="cb380-2"><a href="interpretation-and-causality-with-machine-learning.html#cb380-2" aria-hidden="true" tabindex="-1"></a><span class="fu">varImpPlot</span>(fit)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-185-1.png" width="672" />
Variable importance is now split nearly evenly.</p>
<p>Task: understand why this is - remember:</p>
<ul>
<li>How the random forest works - variables are randomly hidden from the regression tree when the trees for the forest are built</li>
<li>Remember that as x1 ~ x2, we can use x2 as a replacement for x1</li>
<li>Remember that the variable importance measures the average contributions of the different variables in the trees of the forest</li>
</ul>
</div>
<div id="structural-equation-models" class="section level3" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> Structural equation models</h3>
<p>If causal relationships get more complicated, it will not be possible to adjust correctly with a simple lm. In this case, in statistics, we will usually use structural equation models (SEMs). SEMs are are designed to estimate entire causal diagrams. There are two main SEM packages in R: for anything that is non-normal, you will currently have to estimate the DAG piece-wise with CRAN package piecewiseSEM. Example for a vegetation dataset:</p>
<div class="sourceCode" id="cb381"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb381-1"><a href="interpretation-and-causality-with-machine-learning.html#cb381-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(piecewiseSEM)</span>
<span id="cb381-2"><a href="interpretation-and-causality-with-machine-learning.html#cb381-2" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">=</span> <span class="fu">psem</span>(</span>
<span id="cb381-3"><a href="interpretation-and-causality-with-machine-learning.html#cb381-3" aria-hidden="true" tabindex="-1"></a> <span class="fu">lm</span>(rich <span class="sc">~</span> distance <span class="sc">+</span> elev <span class="sc">+</span> abiotic <span class="sc">+</span> age <span class="sc">+</span> hetero <span class="sc">+</span> firesev <span class="sc">+</span> cover, <span class="at">data =</span> keeley),</span>
<span id="cb381-4"><a href="interpretation-and-causality-with-machine-learning.html#cb381-4" aria-hidden="true" tabindex="-1"></a> <span class="fu">lm</span>(firesev <span class="sc">~</span> elev <span class="sc">+</span> age <span class="sc">+</span> cover, <span class="at">data =</span> keeley),</span>
<span id="cb381-5"><a href="interpretation-and-causality-with-machine-learning.html#cb381-5" aria-hidden="true" tabindex="-1"></a> <span class="fu">lm</span>(cover <span class="sc">~</span> age <span class="sc">+</span> elev <span class="sc">+</span> hetero <span class="sc">+</span> abiotic, <span class="at">data =</span> keeley)</span>
<span id="cb381-6"><a href="interpretation-and-causality-with-machine-learning.html#cb381-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb381-7"><a href="interpretation-and-causality-with-machine-learning.html#cb381-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)</span>
<span id="cb381-8"><a href="interpretation-and-causality-with-machine-learning.html#cb381-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod)</span></code></pre></div>
<p>For linear SEMs, we can estimate the entire DAG in one go. This also allows to have unobserved variables in the DAG. One of the most popular packages for this is lavaan</p>
<div class="sourceCode" id="cb382"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb382-1"><a href="interpretation-and-causality-with-machine-learning.html#cb382-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lavaan)</span>
<span id="cb382-2"><a href="interpretation-and-causality-with-machine-learning.html#cb382-2" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="st">&quot;</span></span>
<span id="cb382-3"><a href="interpretation-and-causality-with-machine-learning.html#cb382-3" aria-hidden="true" tabindex="-1"></a><span class="st"> rich ~ distance + elev + abiotic + age + hetero + firesev + cover</span></span>
<span id="cb382-4"><a href="interpretation-and-causality-with-machine-learning.html#cb382-4" aria-hidden="true" tabindex="-1"></a><span class="st"> firesev ~ elev + age + cover</span></span>
<span id="cb382-5"><a href="interpretation-and-causality-with-machine-learning.html#cb382-5" aria-hidden="true" tabindex="-1"></a><span class="st"> cover ~ age + elev + abiotic</span></span>
<span id="cb382-6"><a href="interpretation-and-causality-with-machine-learning.html#cb382-6" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span></span>
<span id="cb382-7"><a href="interpretation-and-causality-with-machine-learning.html#cb382-7" aria-hidden="true" tabindex="-1"></a>fit<span class="ot">&lt;-</span><span class="fu">sem</span>(mod,<span class="at">data=</span>keeley)</span>
<span id="cb382-8"><a href="interpretation-and-causality-with-machine-learning.html#cb382-8" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit)</span></code></pre></div>
<p>Plot options … not so nice as before</p>
<div class="sourceCode" id="cb383"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb383-1"><a href="interpretation-and-causality-with-machine-learning.html#cb383-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lavaanPlot)</span>
<span id="cb383-2"><a href="interpretation-and-causality-with-machine-learning.html#cb383-2" aria-hidden="true" tabindex="-1"></a><span class="fu">lavaanPlot</span>(<span class="at">model =</span> fit)</span></code></pre></div>
<p>Another plotting option</p>
<div class="sourceCode" id="cb384"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb384-1"><a href="interpretation-and-causality-with-machine-learning.html#cb384-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(semPlot)</span>
<span id="cb384-2"><a href="interpretation-and-causality-with-machine-learning.html#cb384-2" aria-hidden="true" tabindex="-1"></a><span class="fu">semPaths</span>(fit)</span></code></pre></div>
</div>
<div id="automatic-causal-discovery" class="section level3" number="5.2.3">
<h3><span class="header-section-number">5.2.3</span> Automatic causal discovery</h3>
<p>But how to we get the causal graph? In statistics, it common to “guess” it and afterwards do residual checks, in the same way as we guess the structure of a regression. For more complicated problems, however, this is unsatisfying. Some groups therefore work on so-called causal discovery algorithsm, i.e. algorithms that automatically generate causal graphs from data. One of the most classic algorithms of this sort is the PC algorithm. Here an example using the pcalg package:</p>
<div class="sourceCode" id="cb385"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb385-1"><a href="interpretation-and-causality-with-machine-learning.html#cb385-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Bioconductor dependencies have to installed by hand, e.g. </span></span>
<span id="cb385-2"><a href="interpretation-and-causality-with-machine-learning.html#cb385-2" aria-hidden="true" tabindex="-1"></a><span class="co"># BiocManager::install(c(&quot;Rgraphviz&quot;, &quot;graph&quot;, &quot;RBGL&quot;)</span></span>
<span id="cb385-3"><a href="interpretation-and-causality-with-machine-learning.html#cb385-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pcalg)</span></code></pre></div>
<p>Loading the data</p>
<div class="sourceCode" id="cb386"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb386-1"><a href="interpretation-and-causality-with-machine-learning.html#cb386-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;gmG&quot;</span>, <span class="at">package =</span> <span class="st">&quot;pcalg&quot;</span>) <span class="do">## loads data sets gmG and gmG8</span></span>
<span id="cb386-2"><a href="interpretation-and-causality-with-machine-learning.html#cb386-2" aria-hidden="true" tabindex="-1"></a>suffStat <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">C =</span> <span class="fu">cor</span>(gmG8<span class="sc">$</span>x), <span class="at">n =</span> <span class="fu">nrow</span>(gmG8<span class="sc">$</span>x))</span>
<span id="cb386-3"><a href="interpretation-and-causality-with-machine-learning.html#cb386-3" aria-hidden="true" tabindex="-1"></a>varNames <span class="ot">&lt;-</span> gmG8<span class="sc">$</span>g<span class="sc">@</span>nodes</span></code></pre></div>
<p>First, the kkeleton algorithm creates a basic graph without connections</p>
<div class="sourceCode" id="cb387"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb387-1"><a href="interpretation-and-causality-with-machine-learning.html#cb387-1" aria-hidden="true" tabindex="-1"></a>skel.gmG8 <span class="ot">&lt;-</span> <span class="fu">skeleton</span>(suffStat, <span class="at">indepTest =</span> gaussCItest,</span>
<span id="cb387-2"><a href="interpretation-and-causality-with-machine-learning.html#cb387-2" aria-hidden="true" tabindex="-1"></a><span class="at">labels =</span> varNames, <span class="at">alpha =</span> <span class="fl">0.01</span>)</span>
<span id="cb387-3"><a href="interpretation-and-causality-with-machine-learning.html#cb387-3" aria-hidden="true" tabindex="-1"></a>Rgraphviz<span class="sc">::</span><span class="fu">plot</span>(skel.gmG8)</span></code></pre></div>
<p>What is missing here is the direction of the errors. The PC algorith now makes tests for conditional independence, which allows fixing a part (but typically not all) of the directions of the causal arrows.</p>
<div class="sourceCode" id="cb388"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb388-1"><a href="interpretation-and-causality-with-machine-learning.html#cb388-1" aria-hidden="true" tabindex="-1"></a>pc.gmG8 <span class="ot">&lt;-</span> <span class="fu">pc</span>(suffStat, <span class="at">indepTest =</span> gaussCItest,</span>
<span id="cb388-2"><a href="interpretation-and-causality-with-machine-learning.html#cb388-2" aria-hidden="true" tabindex="-1"></a><span class="at">labels =</span> varNames, <span class="at">alpha =</span> <span class="fl">0.01</span>)</span>
<span id="cb388-3"><a href="interpretation-and-causality-with-machine-learning.html#cb388-3" aria-hidden="true" tabindex="-1"></a>Rgraphviz<span class="sc">::</span><span class="fu">plot</span>(pc.gmG8 )</span></code></pre></div>
</div>
<div id="causal-inference-on-dynamic-data" class="section level3" number="5.2.4">
<h3><span class="header-section-number">5.2.4</span> Causal inference on dynamic data</h3>
<p>When working with dynamic data, we can use an additional piece of information - the effect usually preceeds the cause, which means that we can test for a time-lag between cause and effect to determine the direction of causality. This way of testing for causality is known as Granger causality, or Granger methods. Here an example:</p>
<div class="sourceCode" id="cb389"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb389-1"><a href="interpretation-and-causality-with-machine-learning.html#cb389-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lmtest)</span></code></pre></div>
<pre><code>## Loading required package: zoo</code></pre>
<pre><code>## 
## Attaching package: &#39;zoo&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     as.Date, as.Date.numeric</code></pre>
<pre><code>## 
## Attaching package: &#39;lmtest&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:crayon&#39;:
## 
##     reset</code></pre>
<div class="sourceCode" id="cb395"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb395-1"><a href="interpretation-and-causality-with-machine-learning.html#cb395-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Which came first: the chicken or the egg?</span></span>
<span id="cb395-2"><a href="interpretation-and-causality-with-machine-learning.html#cb395-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(ChickEgg)</span>
<span id="cb395-3"><a href="interpretation-and-causality-with-machine-learning.html#cb395-3" aria-hidden="true" tabindex="-1"></a><span class="fu">grangertest</span>(egg <span class="sc">~</span> chicken, <span class="at">order =</span> <span class="dv">3</span>, <span class="at">data =</span> ChickEgg)</span></code></pre></div>
<pre><code>## Granger causality test
## 
## Model 1: egg ~ Lags(egg, 1:3) + Lags(chicken, 1:3)
## Model 2: egg ~ Lags(egg, 1:3)
##   Res.Df Df      F Pr(&gt;F)
## 1     44                 
## 2     47 -3 0.5916 0.6238</code></pre>
<div class="sourceCode" id="cb397"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb397-1"><a href="interpretation-and-causality-with-machine-learning.html#cb397-1" aria-hidden="true" tabindex="-1"></a><span class="fu">grangertest</span>(chicken <span class="sc">~</span> egg, <span class="at">order =</span> <span class="dv">3</span>, <span class="at">data =</span> ChickEgg)</span></code></pre></div>
<pre><code>## Granger causality test
## 
## Model 1: chicken ~ Lags(chicken, 1:3) + Lags(egg, 1:3)
## Model 2: chicken ~ Lags(chicken, 1:3)
##   Res.Df Df     F   Pr(&gt;F)   
## 1     44                     
## 2     47 -3 5.405 0.002966 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="outlook-for-machine-learning" class="section level3" number="5.2.5">
<h3><span class="header-section-number">5.2.5</span> Outlook for machine learning</h3>
<p>As we have seen, there are already a few methods / algorithms to discover causality from large data, but the systematic transfer of these concepts to machine learning, in particular deep learning, is still at its infancy. At the moment, this field is actively researched and changes extremely fast, so we recommend to use google to see what is currently going on. Particular, in business and industry, there is a large interest in learning about causal effect from large datasets. In our opinion, a great topic for young scientists to specialize on.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="Deep.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="gans-vaes-and-reinforcement-learning.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

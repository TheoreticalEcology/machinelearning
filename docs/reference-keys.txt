prerequisites
introduction
unsupervised-learning
hierarchical-clustering
k-means-clustering
density-based-clustering
model-based-clustering
ordination
supervised-learning-regression-and-classification
supervised-regression-using-random-forest
supervised-classification-using-random-forest
introduction-to-tensorflow
tensorflow-data-containers
tensorflow-data-types---good-practise-with-r-tf
introduction-to-pytorch
pytorch-data-containers
torch-data-types---good-practise-with-r-tf
first-steps-with-the-keras-framework
example-workflow-in-keras
fund
machine-learning-principles
optimization
small-optimization-example
advanced-optimization-example
regularization
tree-based-ml-algorithms
classification-and-regression-trees
random-forest
boosted-regression-trees
distance-based-algorithms
k-nearest-neighbor
support-vector-machines-svm
artificial-neural-networks
the-standard-ml-pipeline-at-the-example-of-the-titanic-dataset
data-cleaning
pre-processing-and-feature-selection
split-data-for-training-and-testing
model-fitting
model-evaluation
predictions-and-submission
mlr
mlr3---the-basic-workflow
mlr3---hyper-parameter-tuning
mlr3---hyper-parameter-tuning-with-oversampling
Deep
network-architectures
deep-neural-networks-dnns
convolutional-neural-networks-dnns
recurrent-neural-networks-rnns
natural-language-processing-nlp
case-study-dropout-and-early-stopping-in-a-deep-neural-network
case-study---fitting-a-convolutional-neural-networks-on-mnist
advanced-training-techniques
data-augmentation
transfer
interpretation-and-causality-with-machine-learning
explainable-ai
a-practical-example
feature-importance
partial-dependencies
accumulated-local-effects
friedmans-h-statistic
global-explainer---simplifying-the-ml-model
local-explainer---lime-explaining-single-instances-observations
local-explainer---shapley
causal-inference-and-machine-learning
causal-inference-on-static-data
structural-equation-models
automatic-causal-discovery
causal-inference-on-dynamic-data
outlook-for-machine-learning
generative-modeling-and-reinforcement-learning
autoencoder
autoencoder---dnn-mnist
autoencoder---mnist-cnn
varational-autoencoder
generative-adversarial-network-gans
mnist---gan-based-on-dnns
flower---gan
reinforcement-learning
datasets
titanic
plant-pollinator-database
wine
nasa
flower
tensorflow-data-types---good-practice-with-r-tensorflow
torch-data-types---good-practice-with-r-torch
tree-based-machine-learning-algorithms
support-vector-machines-svms
supervised-learning-rregression-and-classification
the-standard-machine-learning-pipeline-at-the-eexample-of-the-titanic-data-set
convolutional-neural-networks-cnns
case-study---fitting-a-convolutional-neural-network-on-mnist
global-explainer---simplifying-the-machine-learning-model
autoencoder---deep-neural-network-mnist
autoencoder---mnist-convolutional-neural-networks
mnist---generative-adversarial-networks-based-on-deep-neural-networks
r-system
tensorflow-and-keras
torch-for-r
ecodata
further-used-libraries
linuxunix-systems-have-to-fulfill-some-further-dependencies

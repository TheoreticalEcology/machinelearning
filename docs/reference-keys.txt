prerequisites
introduction
unsupervised-learning
hierarchical-clustering
k-means-clustering
density-based-clustering
model-based-clustering
ordination
supervised-learning-regression-and-classification
supervised-regression-using-random-forest
supervised-classification-using-random-forest
introduction-to-tensorflow
tensorflow-data-containers
tensorflow-data-types---good-practise-with-r-tf
introduction-to-pytorch
pytorch-data-containers
torch-data-types---good-practise-with-r-tf
first-steps-with-the-keras-framework
example-workflow-in-keras
fund
machine-learning-principles
optimization
small-optimization-example
advanced-optimization-example
regularization
tree-based-ml-algorithms
classification-and-regression-trees
random-forest
boosted-regression-trees
distance-based-algorithms
k-nearest-neighbor
support-vector-machines-svm
artificial-neural-networks
the-standard-ml-pipeline-at-the-example-of-the-titanic-dataset
data-cleaning
pre-processing-and-feature-selection
split-data-for-training-and-testing
model-fitting
model-evaluation
predictions-and-submission
mlr
mlr3---the-basic-workflow
mlr3---hyper-parameter-tuning
mlr3---hyper-parameter-tuning-with-oversampling
Deep
deep-neural-networks
dropout-and-early-stopping
convolutional-neural-networks---mnist
data-augmentation
transfer
natural-language-processing-nlp
recurrent-neural-networks-rnns
xAI
xai-methods
variable-importance
partial-dependencies
accumulated-local-effects
friedmans-h-statistic
global-explainer---simplifying-the-ml-model
local-explainer---lime-explaining-single-instances-observations
local-explainer---shapley
gans-vaes-and-reinforcement-learning
generative-adversarial-network-gans
mnist---gan-based-on-dnns
flower---gan
autoencoder
autoencoder---mnist-cnn
varational-autoencoder
datasets
titanic
plant-pollinator-database
wine
nasa
flower

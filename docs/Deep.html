<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 Deep learning | Machine Learning and AI in TensorFlow and R</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="4 Deep learning | Machine Learning and AI in TensorFlow and R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Deep learning | Machine Learning and AI in TensorFlow and R" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Maximilian Pichler and Florian Hartig" />


<meta name="date" content="2021-05-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="fund.html"/>
<link rel="next" href="xAI.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction to Machine Learning</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#supervised-learning-regression-and-classification"><i class="fa fa-check"></i><b>2.1</b> Supervised learning: regression and classification</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="introduction.html"><a href="introduction.html#supervised-regression-using-random-forest"><i class="fa fa-check"></i><b>2.1.1</b> Supervised regression using Random Forest</a></li>
<li class="chapter" data-level="2.1.2" data-path="introduction.html"><a href="introduction.html#supervised-classification-using-random-forest"><i class="fa fa-check"></i><b>2.1.2</b> Supervised classification using Random Forest</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#unsupervised-learning"><i class="fa fa-check"></i><b>2.2</b> Unsupervised learning</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="introduction.html"><a href="introduction.html#k-means-clustering"><i class="fa fa-check"></i><b>2.2.1</b> k-means clustering</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#introduction-to-tensorflow"><i class="fa fa-check"></i><b>2.3</b> Introduction to Tensorflow</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="introduction.html"><a href="introduction.html#tensorflow-data-containers"><i class="fa fa-check"></i><b>2.3.1</b> Tensorflow data containers</a></li>
<li class="chapter" data-level="2.3.2" data-path="introduction.html"><a href="introduction.html#tensorflow-data-types---good-practise-with-r-tf"><i class="fa fa-check"></i><b>2.3.2</b> Tensorflow data types - good practise with R-TF</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="introduction.html"><a href="introduction.html#first-steps-with-the-keras-framework"><i class="fa fa-check"></i><b>2.4</b> First steps with the keras framework</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="introduction.html"><a href="introduction.html#example-workflow-in-keras"><i class="fa fa-check"></i><b>2.4.1</b> Example workflow in keras</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="fund.html"><a href="fund.html"><i class="fa fa-check"></i><b>3</b> Fundamental principles and techniques</a>
<ul>
<li class="chapter" data-level="3.1" data-path="fund.html"><a href="fund.html#machine-learning-principles"><i class="fa fa-check"></i><b>3.1</b> Machine learning principles</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="fund.html"><a href="fund.html#optimization"><i class="fa fa-check"></i><b>3.1.1</b> Optimization</a></li>
<li class="chapter" data-level="3.1.2" data-path="fund.html"><a href="fund.html#regularization"><i class="fa fa-check"></i><b>3.1.2</b> Regularization</a></li>
<li class="chapter" data-level="3.1.3" data-path="fund.html"><a href="fund.html#classification-and-regression-trees"><i class="fa fa-check"></i><b>3.1.3</b> Classification and Regression Trees</a></li>
<li class="chapter" data-level="3.1.4" data-path="fund.html"><a href="fund.html#random-forest"><i class="fa fa-check"></i><b>3.1.4</b> Random Forest</a></li>
<li class="chapter" data-level="3.1.5" data-path="fund.html"><a href="fund.html#boosted-regression-trees"><i class="fa fa-check"></i><b>3.1.5</b> Boosted regression trees</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="fund.html"><a href="fund.html#distance-based-algorithms"><i class="fa fa-check"></i><b>3.2</b> Distance-based algorithms</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="fund.html"><a href="fund.html#k-nearest-neighbor"><i class="fa fa-check"></i><b>3.2.1</b> k-nearest-neighbor</a></li>
<li class="chapter" data-level="3.2.2" data-path="fund.html"><a href="fund.html#support-vector-machines-svm"><i class="fa fa-check"></i><b>3.2.2</b> Support Vector Machines (SVM)</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="fund.html"><a href="fund.html#artificial-neural-networks"><i class="fa fa-check"></i><b>3.3</b> Artificial neural networks</a></li>
<li class="chapter" data-level="3.4" data-path="fund.html"><a href="fund.html#the-standard-ml-pipeline-at-the-example-of-the-titanic-dataset"><i class="fa fa-check"></i><b>3.4</b> The standard ML pipeline at the example of the titanic dataset</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="fund.html"><a href="fund.html#data-cleaning"><i class="fa fa-check"></i><b>3.4.1</b> Data cleaning</a></li>
<li class="chapter" data-level="3.4.2" data-path="fund.html"><a href="fund.html#pre-processing-and-feature-selection"><i class="fa fa-check"></i><b>3.4.2</b> Pre-processing and feature selection</a></li>
<li class="chapter" data-level="3.4.3" data-path="fund.html"><a href="fund.html#split-data-for-training-and-testing"><i class="fa fa-check"></i><b>3.4.3</b> Split data for training and testing</a></li>
<li class="chapter" data-level="3.4.4" data-path="fund.html"><a href="fund.html#model-fitting"><i class="fa fa-check"></i><b>3.4.4</b> Model fitting</a></li>
<li class="chapter" data-level="3.4.5" data-path="fund.html"><a href="fund.html#model-evaluation"><i class="fa fa-check"></i><b>3.4.5</b> Model evaluation</a></li>
<li class="chapter" data-level="3.4.6" data-path="fund.html"><a href="fund.html#predictions-and-submission"><i class="fa fa-check"></i><b>3.4.6</b> Predictions and submission</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Deep.html"><a href="Deep.html"><i class="fa fa-check"></i><b>4</b> Deep learning</a>
<ul>
<li class="chapter" data-level="4.1" data-path="Deep.html"><a href="Deep.html#deep-neural-networks"><i class="fa fa-check"></i><b>4.1</b> Deep Neural Networks</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="Deep.html"><a href="Deep.html#dropout-and-early-stopping"><i class="fa fa-check"></i><b>4.1.1</b> Dropout and Early stopping</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="Deep.html"><a href="Deep.html#convolutional-neural-networks---mnist"><i class="fa fa-check"></i><b>4.2</b> Convolutional Neural Networks - MNIST</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="Deep.html"><a href="Deep.html#data-augmentation"><i class="fa fa-check"></i><b>4.2.1</b> Data Augmentation</a></li>
<li class="chapter" data-level="4.2.2" data-path="Deep.html"><a href="Deep.html#transfer"><i class="fa fa-check"></i><b>4.2.2</b> Transfer learning</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="Deep.html"><a href="Deep.html#flower-dataset"><i class="fa fa-check"></i><b>4.3</b> Flower dataset</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="xAI.html"><a href="xAI.html"><i class="fa fa-check"></i><b>5</b> Explainable AI (xAI), NLP, and RNNs</a>
<ul>
<li class="chapter" data-level="5.1" data-path="xAI.html"><a href="xAI.html#xai-methods"><i class="fa fa-check"></i><b>5.1</b> xAI Methods</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="xAI.html"><a href="xAI.html#variable-importance"><i class="fa fa-check"></i><b>5.1.1</b> Variable Importance</a></li>
<li class="chapter" data-level="5.1.2" data-path="xAI.html"><a href="xAI.html#partial-dependencies"><i class="fa fa-check"></i><b>5.1.2</b> Partial dependencies</a></li>
<li class="chapter" data-level="5.1.3" data-path="xAI.html"><a href="xAI.html#accumulated-local-effects"><i class="fa fa-check"></i><b>5.1.3</b> Accumulated local effects</a></li>
<li class="chapter" data-level="5.1.4" data-path="xAI.html"><a href="xAI.html#friedmans-h-statistic"><i class="fa fa-check"></i><b>5.1.4</b> Friedmans H-statistic</a></li>
<li class="chapter" data-level="5.1.5" data-path="xAI.html"><a href="xAI.html#global-explainer---simplifying-the-ml-model"><i class="fa fa-check"></i><b>5.1.5</b> Global explainer - Simplifying the ML model</a></li>
<li class="chapter" data-level="5.1.6" data-path="xAI.html"><a href="xAI.html#local-explainer---lime-explaining-single-instances-observations"><i class="fa fa-check"></i><b>5.1.6</b> Local explainer - LIME explaining single instances (observations)</a></li>
<li class="chapter" data-level="5.1.7" data-path="xAI.html"><a href="xAI.html#local-explainer---shapley"><i class="fa fa-check"></i><b>5.1.7</b> Local explainer - Shapley</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="xAI.html"><a href="xAI.html#natural-language-processing-nlp"><i class="fa fa-check"></i><b>5.2</b> Natural Language Processing (NLP)</a></li>
<li class="chapter" data-level="5.3" data-path="xAI.html"><a href="xAI.html#recurrent-neural-networks-rnns"><i class="fa fa-check"></i><b>5.3</b> Recurrent neural networks (RNNs)</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="gans-vaes-and-reinforcement-learning.html"><a href="gans-vaes-and-reinforcement-learning.html"><i class="fa fa-check"></i><b>6</b> GANs, VAEs, and Reinforcement learning</a>
<ul>
<li class="chapter" data-level="6.1" data-path="gans-vaes-and-reinforcement-learning.html"><a href="gans-vaes-and-reinforcement-learning.html#generative-adversarial-network-gans"><i class="fa fa-check"></i><b>6.1</b> Generative adversarial network (GANs)</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="gans-vaes-and-reinforcement-learning.html"><a href="gans-vaes-and-reinforcement-learning.html#flower---gan"><i class="fa fa-check"></i><b>6.1.1</b> Flower - GAN</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="gans-vaes-and-reinforcement-learning.html"><a href="gans-vaes-and-reinforcement-learning.html#autoencoder"><i class="fa fa-check"></i><b>6.2</b> Autoencoder</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="gans-vaes-and-reinforcement-learning.html"><a href="gans-vaes-and-reinforcement-learning.html#autoencoder---mnist-cnn"><i class="fa fa-check"></i><b>6.2.1</b> Autoencoder - MNIST CNN</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="gans-vaes-and-reinforcement-learning.html"><a href="gans-vaes-and-reinforcement-learning.html#varational-autoencoder"><i class="fa fa-check"></i><b>6.3</b> Varational Autoencoder</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="datasets.html"><a href="datasets.html"><i class="fa fa-check"></i><b>7</b> Datasets</a>
<ul>
<li class="chapter" data-level="7.1" data-path="datasets.html"><a href="datasets.html#titanic"><i class="fa fa-check"></i><b>7.1</b> Titanic</a></li>
<li class="chapter" data-level="7.2" data-path="datasets.html"><a href="datasets.html#plant-pollinator-database"><i class="fa fa-check"></i><b>7.2</b> Plant-pollinator database</a></li>
<li class="chapter" data-level="7.3" data-path="datasets.html"><a href="datasets.html#wine"><i class="fa fa-check"></i><b>7.3</b> Wine</a></li>
<li class="chapter" data-level="7.4" data-path="datasets.html"><a href="datasets.html#nasa"><i class="fa fa-check"></i><b>7.4</b> Nasa</a></li>
<li class="chapter" data-level="7.5" data-path="datasets.html"><a href="datasets.html#flower"><i class="fa fa-check"></i><b>7.5</b> Flower</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning and AI in TensorFlow and R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="Deep" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Deep learning</h1>
<div id="deep-neural-networks" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Deep Neural Networks</h2>
<div id="dropout-and-early-stopping" class="section level3" number="4.1.1">
<h3><span class="header-section-number">4.1.1</span> Dropout and Early stopping</h3>
<ul>
<li>Early stopping: you might have noticed yesterday that even with regularization the validation loss will start to increase at some point during the training. Early stopping allows us to stop the training when for instance the test loss does not increase anymore</li>
<li>With l1/l2 regularization we have to carefully tune the regularization strength. Dropout is robuster, and tuning of the dropout rate can be beneficial but a rate between 0.2-0.5 works often quite well</li>
</ul>
</div>
</div>
<div id="convolutional-neural-networks---mnist" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Convolutional Neural Networks - MNIST</h2>
<p>The MNIST dataset is maybe one of the most famous image datasets. It is a dataset of 60,000 handwritten digits from 0-9.</p>
<p>Let’s define a few helper functions:</p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb178-1"><a href="Deep.html#cb178-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb178-2"><a href="Deep.html#cb178-2" aria-hidden="true" tabindex="-1"></a>rotate <span class="ot">=</span> <span class="cf">function</span>(x) <span class="fu">t</span>(<span class="fu">apply</span>(x, <span class="dv">2</span>, rev))</span>
<span id="cb178-3"><a href="Deep.html#cb178-3" aria-hidden="true" tabindex="-1"></a>imgPlot <span class="ot">=</span> <span class="cf">function</span>(img, <span class="at">title =</span> <span class="st">&quot;&quot;</span>){</span>
<span id="cb178-4"><a href="Deep.html#cb178-4" aria-hidden="true" tabindex="-1"></a> col<span class="ot">=</span><span class="fu">grey.colors</span>(<span class="dv">255</span>)</span>
<span id="cb178-5"><a href="Deep.html#cb178-5" aria-hidden="true" tabindex="-1"></a> <span class="fu">image</span>(<span class="fu">rotate</span>(img), <span class="at">col =</span> col, <span class="at">xlab =</span> <span class="st">&quot;&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;&quot;</span>, <span class="at">axes=</span><span class="cn">FALSE</span>, <span class="at">main =</span> <span class="fu">paste0</span>(<span class="st">&quot;Label: &quot;</span>, <span class="fu">as.character</span>(title)))</span>
<span id="cb178-6"><a href="Deep.html#cb178-6" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>The dataset is so famous that there is an automatic download function in keras:</p>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb179-1"><a href="Deep.html#cb179-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">dataset_mnist</span>()</span>
<span id="cb179-2"><a href="Deep.html#cb179-2" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> data<span class="sc">$</span>train</span>
<span id="cb179-3"><a href="Deep.html#cb179-3" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> data<span class="sc">$</span>test</span></code></pre></div>
<p>Let’s visualize a few digits:</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="Deep.html#cb180-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">3</span>))</span>
<span id="cb180-2"><a href="Deep.html#cb180-2" aria-hidden="true" tabindex="-1"></a>.n <span class="ot">=</span> <span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>, <span class="cf">function</span>(x) <span class="fu">imgPlot</span>(train<span class="sc">$</span>x[x,,], train<span class="sc">$</span>y[x]))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-94-1.png" width="672" /></p>
<p>Similar to the normal ML workflow, we have to scale the pixels (from 0-255) to the range of [0,1] and one hot encode the response:</p>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb181-1"><a href="Deep.html#cb181-1" aria-hidden="true" tabindex="-1"></a>train_x <span class="ot">=</span> <span class="fu">array</span>(train<span class="sc">$</span>x<span class="sc">/</span><span class="dv">255</span>, <span class="fu">c</span>(<span class="fu">dim</span>(train<span class="sc">$</span>x), <span class="dv">1</span>))</span>
<span id="cb181-2"><a href="Deep.html#cb181-2" aria-hidden="true" tabindex="-1"></a>test_x <span class="ot">=</span> <span class="fu">array</span>(test<span class="sc">$</span>x<span class="sc">/</span><span class="dv">255</span>, <span class="fu">c</span>(<span class="fu">dim</span>(test<span class="sc">$</span>x), <span class="dv">1</span>))</span>
<span id="cb181-3"><a href="Deep.html#cb181-3" aria-hidden="true" tabindex="-1"></a>train_y <span class="ot">=</span> <span class="fu">to_categorical</span>(train<span class="sc">$</span>y, <span class="dv">10</span>)</span>
<span id="cb181-4"><a href="Deep.html#cb181-4" aria-hidden="true" tabindex="-1"></a>test_y <span class="ot">=</span> <span class="fu">to_categorical</span>(test<span class="sc">$</span>y, <span class="dv">10</span>)</span></code></pre></div>
<p>We also use here now arrays instead of matrices. Arrays are higher dimensional matrices (tensor of rank 3). Finally, we have a “real” tensor.</p>
<p>The last dimension stands for the number of channels in the image. In our case we have only one channel because the images are white-black.</p>
<p>Normally we would have three channels - colors are encoded by the combination of three channels (e.g. rgb).</p>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="Deep.html#cb182-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb182-2"><a href="Deep.html#cb182-2" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> </span>
<span id="cb182-3"><a href="Deep.html#cb182-3" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_conv_2d</span>(<span class="at">input_shape =</span> <span class="fu">c</span>(28L, 28L,1L),<span class="at">filters =</span> 16L, <span class="at">kernel_size =</span> <span class="fu">c</span>(2L,2L), <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb182-4"><a href="Deep.html#cb182-4" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb182-5"><a href="Deep.html#cb182-5" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> 16L, <span class="at">kernel_size =</span> <span class="fu">c</span>(3L,3L), <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb182-6"><a href="Deep.html#cb182-6" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb182-7"><a href="Deep.html#cb182-7" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_flatten</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb182-8"><a href="Deep.html#cb182-8" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_dense</span>(100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb182-9"><a href="Deep.html#cb182-9" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_dense</span>(10L, <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>)</span>
<span id="cb182-10"><a href="Deep.html#cb182-10" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## Model: &quot;sequential_46&quot;
## _______________________________________________________________________________________________________________________________________________________
## Layer (type)                                                       Output Shape                                                 Param #                
## =======================================================================================================================================================
## conv2d_19 (Conv2D)                                                 (None, 27, 27, 16)                                           80                     
## _______________________________________________________________________________________________________________________________________________________
## max_pooling2d_16 (MaxPooling2D)                                    (None, 13, 13, 16)                                           0                      
## _______________________________________________________________________________________________________________________________________________________
## conv2d_20 (Conv2D)                                                 (None, 11, 11, 16)                                           2320                   
## _______________________________________________________________________________________________________________________________________________________
## max_pooling2d_17 (MaxPooling2D)                                    (None, 5, 5, 16)                                             0                      
## _______________________________________________________________________________________________________________________________________________________
## flatten_10 (Flatten)                                               (None, 400)                                                  0                      
## _______________________________________________________________________________________________________________________________________________________
## dense_121 (Dense)                                                  (None, 100)                                                  40100                  
## _______________________________________________________________________________________________________________________________________________________
## dense_122 (Dense)                                                  (None, 10)                                                   1010                   
## =======================================================================================================================================================
## Total params: 43,510
## Trainable params: 43,510
## Non-trainable params: 0
## _______________________________________________________________________________________________________________________________________________________</code></pre>
<p>We will start now with a 2D convolutional layer, (3D would be e.g. for movies, so the third dimension would correspond to time and not to the color channels!).</p>
<p>We use 16 convolutional kernels (filters) with a size of 2x2.</p>
<p>The pooling layer downsizes the resulting feature maps.</p>
<p>After another conv and pooling layer we flatten the output, i.e. the following dense layer treats the previous layer as normal dense layer (so the dense layer is connected to all weights from the last feature maps).</p>
<p>We end the model with our typical output layer.</p>
<p>The rest is as usual:</p>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb184-1"><a href="Deep.html#cb184-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> </span>
<span id="cb184-2"><a href="Deep.html#cb184-2" aria-hidden="true" tabindex="-1"></a> <span class="fu">compile</span>(</span>
<span id="cb184-3"><a href="Deep.html#cb184-3" aria-hidden="true" tabindex="-1"></a> <span class="at">optimizer =</span> keras<span class="sc">::</span><span class="fu">optimizer_adamax</span>(<span class="fl">0.01</span>),</span>
<span id="cb184-4"><a href="Deep.html#cb184-4" aria-hidden="true" tabindex="-1"></a> <span class="at">loss =</span> loss_categorical_crossentropy</span>
<span id="cb184-5"><a href="Deep.html#cb184-5" aria-hidden="true" tabindex="-1"></a> )</span>
<span id="cb184-6"><a href="Deep.html#cb184-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## Model: &quot;sequential_46&quot;
## _______________________________________________________________________________________________________________________________________________________
## Layer (type)                                                       Output Shape                                                 Param #                
## =======================================================================================================================================================
## conv2d_19 (Conv2D)                                                 (None, 27, 27, 16)                                           80                     
## _______________________________________________________________________________________________________________________________________________________
## max_pooling2d_16 (MaxPooling2D)                                    (None, 13, 13, 16)                                           0                      
## _______________________________________________________________________________________________________________________________________________________
## conv2d_20 (Conv2D)                                                 (None, 11, 11, 16)                                           2320                   
## _______________________________________________________________________________________________________________________________________________________
## max_pooling2d_17 (MaxPooling2D)                                    (None, 5, 5, 16)                                             0                      
## _______________________________________________________________________________________________________________________________________________________
## flatten_10 (Flatten)                                               (None, 400)                                                  0                      
## _______________________________________________________________________________________________________________________________________________________
## dense_121 (Dense)                                                  (None, 100)                                                  40100                  
## _______________________________________________________________________________________________________________________________________________________
## dense_122 (Dense)                                                  (None, 10)                                                   1010                   
## =======================================================================================================================================================
## Total params: 43,510
## Trainable params: 43,510
## Non-trainable params: 0
## _______________________________________________________________________________________________________________________________________________________</code></pre>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb186-1"><a href="Deep.html#cb186-1" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> 5L</span>
<span id="cb186-2"><a href="Deep.html#cb186-2" aria-hidden="true" tabindex="-1"></a>batch_size <span class="ot">=</span> 32L</span>
<span id="cb186-3"><a href="Deep.html#cb186-3" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> </span>
<span id="cb186-4"><a href="Deep.html#cb186-4" aria-hidden="true" tabindex="-1"></a> <span class="fu">fit</span>(</span>
<span id="cb186-5"><a href="Deep.html#cb186-5" aria-hidden="true" tabindex="-1"></a> <span class="at">x =</span> train_x, </span>
<span id="cb186-6"><a href="Deep.html#cb186-6" aria-hidden="true" tabindex="-1"></a> <span class="at">y =</span> train_y,</span>
<span id="cb186-7"><a href="Deep.html#cb186-7" aria-hidden="true" tabindex="-1"></a> <span class="at">epochs =</span> epochs,</span>
<span id="cb186-8"><a href="Deep.html#cb186-8" aria-hidden="true" tabindex="-1"></a> <span class="at">batch_size =</span> batch_size,</span>
<span id="cb186-9"><a href="Deep.html#cb186-9" aria-hidden="true" tabindex="-1"></a> <span class="at">shuffle =</span> <span class="cn">TRUE</span>,</span>
<span id="cb186-10"><a href="Deep.html#cb186-10" aria-hidden="true" tabindex="-1"></a> <span class="at">validation_split =</span> <span class="fl">0.2</span></span>
<span id="cb186-11"><a href="Deep.html#cb186-11" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div id="data-augmentation" class="section level3" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> Data Augmentation</h3>
<p>Having to train a CNN using very little data is a common problem. Data augmentation helps to artificially increase the number of images.</p>
<p>The idea is that the CNN has to learn specific structures such as edges from images. Rotating, adding noise, and zooming in and out will preserve the overall key structure we are interested in, but the model will see new images and has to search once again for the key structures.</p>
<p>Luckily, it is very easy to use data augmentation in keras.</p>
<p>We will use again the MNIST dataset:</p>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb187-1"><a href="Deep.html#cb187-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb187-2"><a href="Deep.html#cb187-2" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">dataset_mnist</span>()</span>
<span id="cb187-3"><a href="Deep.html#cb187-3" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> data<span class="sc">$</span>train</span>
<span id="cb187-4"><a href="Deep.html#cb187-4" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> data<span class="sc">$</span>test</span>
<span id="cb187-5"><a href="Deep.html#cb187-5" aria-hidden="true" tabindex="-1"></a>train_x <span class="ot">=</span> <span class="fu">array</span>(train<span class="sc">$</span>x<span class="sc">/</span><span class="dv">255</span>, <span class="fu">c</span>(<span class="fu">dim</span>(train<span class="sc">$</span>x), <span class="dv">1</span>))</span>
<span id="cb187-6"><a href="Deep.html#cb187-6" aria-hidden="true" tabindex="-1"></a>test_x <span class="ot">=</span> <span class="fu">array</span>(test<span class="sc">$</span>x<span class="sc">/</span><span class="dv">255</span>, <span class="fu">c</span>(<span class="fu">dim</span>(test<span class="sc">$</span>x), <span class="dv">1</span>))</span>
<span id="cb187-7"><a href="Deep.html#cb187-7" aria-hidden="true" tabindex="-1"></a>train_y <span class="ot">=</span> <span class="fu">to_categorical</span>(train<span class="sc">$</span>y, <span class="dv">10</span>)</span>
<span id="cb187-8"><a href="Deep.html#cb187-8" aria-hidden="true" tabindex="-1"></a>test_y <span class="ot">=</span> <span class="fu">to_categorical</span>(test<span class="sc">$</span>y, <span class="dv">10</span>)</span>
<span id="cb187-9"><a href="Deep.html#cb187-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">dim</span>(train_x))</span></code></pre></div>
<pre><code>## [1] 60000    28    28     1</code></pre>
<div class="sourceCode" id="cb189"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb189-1"><a href="Deep.html#cb189-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">dim</span>(test_y))</span></code></pre></div>
<pre><code>## [1] 10000    10</code></pre>
<div class="sourceCode" id="cb191"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb191-1"><a href="Deep.html#cb191-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb191-2"><a href="Deep.html#cb191-2" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> </span>
<span id="cb191-3"><a href="Deep.html#cb191-3" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_conv_2d</span>(<span class="at">input_shape =</span> <span class="fu">c</span>(<span class="cn">NULL</span>, <span class="dv">28</span>, <span class="dv">28</span>,<span class="dv">1</span>),<span class="at">filters =</span> <span class="dv">16</span>, <span class="at">kernel_size =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">use_bias =</span> F) <span class="sc">%&gt;%</span> </span>
<span id="cb191-4"><a href="Deep.html#cb191-4" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb191-5"><a href="Deep.html#cb191-5" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> <span class="dv">16</span>, <span class="at">kernel_size =</span> <span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">3</span>), <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">use_bias =</span> F) <span class="sc">%&gt;%</span> </span>
<span id="cb191-6"><a href="Deep.html#cb191-6" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb191-7"><a href="Deep.html#cb191-7" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_flatten</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb191-8"><a href="Deep.html#cb191-8" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_dense</span>(<span class="dv">100</span>, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb191-9"><a href="Deep.html#cb191-9" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_dense</span>(<span class="dv">10</span>, <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>)</span>
<span id="cb191-10"><a href="Deep.html#cb191-10" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## Model: &quot;sequential_47&quot;
## _______________________________________________________________________________________________________________________________________________________
## Layer (type)                                                       Output Shape                                                 Param #                
## =======================================================================================================================================================
## conv2d_21 (Conv2D)                                                 (None, 27, 27, 16)                                           64                     
## _______________________________________________________________________________________________________________________________________________________
## max_pooling2d_18 (MaxPooling2D)                                    (None, 13, 13, 16)                                           0                      
## _______________________________________________________________________________________________________________________________________________________
## conv2d_22 (Conv2D)                                                 (None, 11, 11, 16)                                           2304                   
## _______________________________________________________________________________________________________________________________________________________
## max_pooling2d_19 (MaxPooling2D)                                    (None, 5, 5, 16)                                             0                      
## _______________________________________________________________________________________________________________________________________________________
## flatten_11 (Flatten)                                               (None, 400)                                                  0                      
## _______________________________________________________________________________________________________________________________________________________
## dense_123 (Dense)                                                  (None, 100)                                                  40100                  
## _______________________________________________________________________________________________________________________________________________________
## dense_124 (Dense)                                                  (None, 10)                                                   1010                   
## =======================================================================================================================================================
## Total params: 43,478
## Trainable params: 43,478
## Non-trainable params: 0
## _______________________________________________________________________________________________________________________________________________________</code></pre>
<div class="sourceCode" id="cb193"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb193-1"><a href="Deep.html#cb193-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> </span>
<span id="cb193-2"><a href="Deep.html#cb193-2" aria-hidden="true" tabindex="-1"></a> <span class="fu">compile</span>(</span>
<span id="cb193-3"><a href="Deep.html#cb193-3" aria-hidden="true" tabindex="-1"></a> <span class="at">optimizer =</span> <span class="fu">optimizer_adamax</span>(),</span>
<span id="cb193-4"><a href="Deep.html#cb193-4" aria-hidden="true" tabindex="-1"></a> <span class="at">loss =</span> loss_categorical_crossentropy</span>
<span id="cb193-5"><a href="Deep.html#cb193-5" aria-hidden="true" tabindex="-1"></a> )</span></code></pre></div>
<p>We have now to define a generator object (it is a specific object which infinitly draws samples from our dataset). In the generator we can turn on the data augementation:</p>
<div class="sourceCode" id="cb194"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb194-1"><a href="Deep.html#cb194-1" aria-hidden="true" tabindex="-1"></a>aug <span class="ot">=</span> <span class="fu">image_data_generator</span>()</span>
<span id="cb194-2"><a href="Deep.html#cb194-2" aria-hidden="true" tabindex="-1"></a>generator <span class="ot">=</span> <span class="fu">flow_images_from_data</span>(train_x, train_y,<span class="at">generator =</span> aug)</span>
<span id="cb194-3"><a href="Deep.html#cb194-3" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> </span>
<span id="cb194-4"><a href="Deep.html#cb194-4" aria-hidden="true" tabindex="-1"></a> <span class="fu">fit_generator</span>(generator, <span class="at">steps_per_epoch =</span> <span class="fu">dim</span>(train_x)[<span class="dv">1</span>],<span class="at">epochs =</span> 5L)</span></code></pre></div>
<pre><code>## Warning in fit_generator(., generator, steps_per_epoch = dim(train_x)[1], : `fit_generator` is deprecated. Use `fit` instead, it now accept generators.</code></pre>
<p>However, now we have to set the step size because the model does not know the first dimension of the image.</p>
</div>
<div id="transfer" class="section level3" number="4.2.2">
<h3><span class="header-section-number">4.2.2</span> Transfer learning</h3>
<p>Another approach to reduce the necessary number of images or to speed up convergence of the models is the use of transfer learning.</p>
<p>The idea is that all the convolutional layers have mainly one task - learning to identify highly correlated neighbored features and therefore to learn structures such as edges in the image.</p>
<p>Also, the second idea is that only the top layer, the dense layer is the actual classifier of the CNN. The top classifier will be confronted by sets of different edges/structures and has to decide the label.</p>
<p>Again, this sounds very complicating but is again quite easy with keras:</p>
<p>CIFAR10 preparation:</p>
<div class="sourceCode" id="cb196"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb196-1"><a href="Deep.html#cb196-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> keras<span class="sc">::</span><span class="fu">dataset_cifar10</span>()</span>
<span id="cb196-2"><a href="Deep.html#cb196-2" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> data<span class="sc">$</span>train</span>
<span id="cb196-3"><a href="Deep.html#cb196-3" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> data<span class="sc">$</span>test</span>
<span id="cb196-4"><a href="Deep.html#cb196-4" aria-hidden="true" tabindex="-1"></a>image <span class="ot">=</span> train<span class="sc">$</span>x[<span class="dv">5</span>,,,]</span>
<span id="cb196-5"><a href="Deep.html#cb196-5" aria-hidden="true" tabindex="-1"></a>image <span class="sc">%&gt;%</span> </span>
<span id="cb196-6"><a href="Deep.html#cb196-6" aria-hidden="true" tabindex="-1"></a> <span class="fu">image_to_array</span>() <span class="sc">%&gt;%</span></span>
<span id="cb196-7"><a href="Deep.html#cb196-7" aria-hidden="true" tabindex="-1"></a> <span class="st">`</span><span class="at">/</span><span class="st">`</span>(., <span class="dv">255</span>) <span class="sc">%&gt;%</span></span>
<span id="cb196-8"><a href="Deep.html#cb196-8" aria-hidden="true" tabindex="-1"></a> <span class="fu">as.raster</span>() <span class="sc">%&gt;%</span></span>
<span id="cb196-9"><a href="Deep.html#cb196-9" aria-hidden="true" tabindex="-1"></a> <span class="fu">plot</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-101-1.png" width="672" /></p>
<div class="sourceCode" id="cb197"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb197-1"><a href="Deep.html#cb197-1" aria-hidden="true" tabindex="-1"></a>train_x <span class="ot">=</span> <span class="fu">array</span>(train<span class="sc">$</span>x<span class="sc">/</span><span class="dv">255</span>, <span class="fu">c</span>(<span class="fu">dim</span>(train<span class="sc">$</span>x)))</span>
<span id="cb197-2"><a href="Deep.html#cb197-2" aria-hidden="true" tabindex="-1"></a>test_x <span class="ot">=</span> <span class="fu">array</span>(test<span class="sc">$</span>x<span class="sc">/</span><span class="dv">255</span>, <span class="fu">c</span>(<span class="fu">dim</span>(test<span class="sc">$</span>x)))</span>
<span id="cb197-3"><a href="Deep.html#cb197-3" aria-hidden="true" tabindex="-1"></a>train_y <span class="ot">=</span> <span class="fu">to_categorical</span>(train<span class="sc">$</span>y, <span class="dv">10</span>)</span>
<span id="cb197-4"><a href="Deep.html#cb197-4" aria-hidden="true" tabindex="-1"></a>test_y <span class="ot">=</span> <span class="fu">to_categorical</span>(test<span class="sc">$</span>y, <span class="dv">10</span>)</span></code></pre></div>
<p>Keras provides download functions for all famous architectures/CNN models which are already trained on the imagenet dataset (anoother famous dataset) and the CNNs come already without their top layer</p>
<div class="sourceCode" id="cb198"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb198-1"><a href="Deep.html#cb198-1" aria-hidden="true" tabindex="-1"></a>densenet <span class="ot">=</span> <span class="fu">application_densenet201</span>(<span class="at">include_top =</span> <span class="cn">FALSE</span>, <span class="at">input_shape  =</span> <span class="fu">c</span>(32L, 32L, 3L))</span></code></pre></div>
<p>We have to specify directly here in the model our input dimension.</p>
<p>Now, we will use not a sequential model but just a “keras_model” where we can specify the inputs and outputs:</p>
<div class="sourceCode" id="cb199"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb199-1"><a href="Deep.html#cb199-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> keras<span class="sc">::</span><span class="fu">keras_model</span>(<span class="at">inputs =</span> densenet<span class="sc">$</span>input, <span class="at">outputs =</span> </span>
<span id="cb199-2"><a href="Deep.html#cb199-2" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_flatten</span>(<span class="fu">layer_dense</span>(densenet<span class="sc">$</span>output, <span class="at">units =</span> 10L, <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>))</span>
<span id="cb199-3"><a href="Deep.html#cb199-3" aria-hidden="true" tabindex="-1"></a> )</span></code></pre></div>
<p>The outputs are our own top layer.</p>
<p>In the next step we want to freeze all layers except for our own last layer (with freezing I mean that we do not want to train the complete model, we only want to train the last layer):</p>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb200-1"><a href="Deep.html#cb200-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">freeze_weights</span>(<span class="at">to =</span> <span class="fu">length</span>(model<span class="sc">$</span>layers)<span class="sc">-</span><span class="dv">1</span>)</span></code></pre></div>
<p>Btw, you can always check the number of trainable weights via summary(model)</p>
<p>And then the usual training:</p>
<div class="sourceCode" id="cb201"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb201-1"><a href="Deep.html#cb201-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> </span>
<span id="cb201-2"><a href="Deep.html#cb201-2" aria-hidden="true" tabindex="-1"></a> <span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy, <span class="at">optimizer =</span> <span class="fu">optimizer_adamax</span>())</span>
<span id="cb201-3"><a href="Deep.html#cb201-3" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> </span>
<span id="cb201-4"><a href="Deep.html#cb201-4" aria-hidden="true" tabindex="-1"></a> <span class="fu">fit</span>(</span>
<span id="cb201-5"><a href="Deep.html#cb201-5" aria-hidden="true" tabindex="-1"></a> <span class="at">x =</span> train_x, </span>
<span id="cb201-6"><a href="Deep.html#cb201-6" aria-hidden="true" tabindex="-1"></a> <span class="at">y =</span> train_y,</span>
<span id="cb201-7"><a href="Deep.html#cb201-7" aria-hidden="true" tabindex="-1"></a> <span class="at">epochs =</span> 1L,</span>
<span id="cb201-8"><a href="Deep.html#cb201-8" aria-hidden="true" tabindex="-1"></a> <span class="at">batch_size =</span> 32L,</span>
<span id="cb201-9"><a href="Deep.html#cb201-9" aria-hidden="true" tabindex="-1"></a> <span class="at">shuffle =</span> T,</span>
<span id="cb201-10"><a href="Deep.html#cb201-10" aria-hidden="true" tabindex="-1"></a> <span class="at">validation_split =</span> <span class="fl">0.2</span>,</span>
<span id="cb201-11"><a href="Deep.html#cb201-11" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
</div>
<div id="flower-dataset" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> Flower dataset</h2>
<p>create a CNN
submit predictions
see kaggle flower dataset for specific architectures!
Data preparation:</p>
<div class="sourceCode" id="cb202"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb202-1"><a href="Deep.html#cb202-1" aria-hidden="true" tabindex="-1"></a>data_files <span class="ot">=</span> <span class="fu">list.files</span>(<span class="st">&quot;flower/&quot;</span>, <span class="at">full.names =</span> <span class="cn">TRUE</span>)</span>
<span id="cb202-2"><a href="Deep.html#cb202-2" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> data_files[<span class="fu">str_detect</span>(data_files, <span class="st">&quot;train&quot;</span>)]</span>
<span id="cb202-3"><a href="Deep.html#cb202-3" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> <span class="fu">readRDS</span>(<span class="at">file =</span> <span class="st">&quot;flower/test.RDS&quot;</span>)</span>
<span id="cb202-4"><a href="Deep.html#cb202-4" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> <span class="fu">lapply</span>(train, readRDS)</span>
<span id="cb202-5"><a href="Deep.html#cb202-5" aria-hidden="true" tabindex="-1"></a>train_classes <span class="ot">=</span> <span class="fu">lapply</span>(train, <span class="cf">function</span>(d) <span class="fu">dim</span>(d)[<span class="dv">1</span>])</span>
<span id="cb202-6"><a href="Deep.html#cb202-6" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> abind<span class="sc">::</span><span class="fu">abind</span>(train, <span class="at">along =</span> 1L)</span>
<span id="cb202-7"><a href="Deep.html#cb202-7" aria-hidden="true" tabindex="-1"></a>labels_train <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">4</span>, <span class="fu">unlist</span>(train_classes))</span></code></pre></div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="fund.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="xAI.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.427">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Machine Learning and Deep Learning with R - 8&nbsp; Introduction to TensorFlow and Keras</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./C2-DeepNeuralNetworks.html" rel="next">
<link href="./B3-NeuralNetworks.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="include/webex.css">
<meta name="citation_title" content="[[8]{.chapter-number}&nbsp; [Introduction to TensorFlow and Keras]{.chapter-title}]{#tensorflowintro .quarto-section-identifier}">
<meta name="citation_fulltext_html_url" content="https://TheoreticalEcology.github.io/machinelearning//C1-TensorFlow.html">
<meta name="citation_language" content="en">
<meta name="citation_reference" content="citation_title=Regularization and variable selection via the elastic net;,citation_author=Hui Zou;,citation_author=Trevor Hastie;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_issue=2;,citation_volume=67;,citation_journal_title=Journal of the royal statistical society: series B (statistical methodology);,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Model averaging in ecology: A review of bayesian, information-theoretic, and tactical approaches for predictive inference;,citation_author=Carsten F Dormann;,citation_author=Justin M Calabrese;,citation_author=Gurutzeta Guillera-Arroita;,citation_author=Eleni Matechou;,citation_author=Volker Bahn;,citation_author=Kamil Bartoń;,citation_author=Colin M Beale;,citation_author=Simone Ciuti;,citation_author=Jane Elith;,citation_author=Katharina Gerstner;,citation_author=others;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=4;,citation_volume=88;,citation_journal_title=Ecological Monographs;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Dropout: A simple way to prevent neural networks from overfitting;,citation_author=Nitish Srivastava;,citation_author=Geoffrey Hinton;,citation_author=Alex Krizhevsky;,citation_author=Ilya Sutskever;,citation_author=Ruslan Salakhutdinov;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=1;,citation_volume=15;,citation_journal_title=The journal of machine learning research;,citation_publisher=JMLR. org;">
<meta name="citation_reference" content="citation_title=Machine learning and deep learning—a review for ecologists;,citation_author=Maximilian Pichler;,citation_author=Florian Hartig;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_issue=4;,citation_volume=14;,citation_journal_title=Methods in Ecology and Evolution;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Deep learning as a tool for ecology and evolution;,citation_author=Marek L Borowiec;,citation_author=Rebecca B Dikow;,citation_author=Paul B Frandsen;,citation_author=Alexander McKeeken;,citation_author=Gabriele Valentini;,citation_author=Alexander E White;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_issue=8;,citation_volume=13;,citation_journal_title=Methods in Ecology and Evolution;,citation_publisher=Wiley Online Library;">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./C1-TensorFlow.html">Deep Learning</a></li><li class="breadcrumb-item"><a href="./C1-TensorFlow.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Introduction to TensorFlow and Keras</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Machine Learning and Deep Learning with R</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/TheoreticalEcology/machinelearning" rel="" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
              <i class="bi bi-bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A1-GettingStarted.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Getting Started</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Machine Learning Workflow</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A2-MachineLearningTasks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Typical Machine Learning Tasks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A3-BiasVarianceTradeOff.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Bias-variance trade-off</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A4-MLpipeline.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Machine learning pipeline</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Machine Learning Algorithms</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B1-Trees.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Tree-based Algorithms</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B2-Distance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Distance-based Algorithms</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B3-NeuralNetworks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Artificial Neural Networks</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Deep Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C1-TensorFlow.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Introduction to TensorFlow and Keras</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C2-DeepNeuralNetworks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Deep Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C3-ConvolutionalNeuralNetworks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Convolutional Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C4-RecurrentNeuralNetworks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Recurrent Neural Networks</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Appendix-Datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Datasets</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction-to-tensorflow" id="toc-introduction-to-tensorflow" class="nav-link active" data-scroll-target="#introduction-to-tensorflow"><span class="header-section-number">8.1</span> Introduction to TensorFlow</a>
  <ul class="collapse">
  <li><a href="#data-containers" id="toc-data-containers" class="nav-link" data-scroll-target="#data-containers"><span class="header-section-number">8.1.1</span> Data Containers</a></li>
  <li><a href="#basic-operations" id="toc-basic-operations" class="nav-link" data-scroll-target="#basic-operations"><span class="header-section-number">8.1.2</span> Basic Operations</a></li>
  <li><a href="#data-types" id="toc-data-types" class="nav-link" data-scroll-target="#data-types"><span class="header-section-number">8.1.3</span> Data Types</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="header-section-number">8.1.4</span> Exercises</a></li>
  </ul></li>
  <li><a href="#introduction-to-pytorch" id="toc-introduction-to-pytorch" class="nav-link" data-scroll-target="#introduction-to-pytorch"><span class="header-section-number">8.2</span> Introduction to PyTorch</a>
  <ul class="collapse">
  <li><a href="#data-containers-1" id="toc-data-containers-1" class="nav-link" data-scroll-target="#data-containers-1"><span class="header-section-number">8.2.1</span> Data Containers</a></li>
  <li><a href="#basic-operations-1" id="toc-basic-operations-1" class="nav-link" data-scroll-target="#basic-operations-1"><span class="header-section-number">8.2.2</span> Basic Operations</a></li>
  <li><a href="#data-types-1" id="toc-data-types-1" class="nav-link" data-scroll-target="#data-types-1"><span class="header-section-number">8.2.3</span> Data Types</a></li>
  <li><a href="#exercises-1" id="toc-exercises-1" class="nav-link" data-scroll-target="#exercises-1"><span class="header-section-number">8.2.4</span> Exercises</a></li>
  </ul></li>
  <li><a href="#kerastorch-framework" id="toc-kerastorch-framework" class="nav-link" data-scroll-target="#kerastorch-framework"><span class="header-section-number">8.3</span> Keras/Torch Framework</a>
  <ul class="collapse">
  <li><a href="#example-workflow-in-keras-torch" id="toc-example-workflow-in-keras-torch" class="nav-link" data-scroll-target="#example-workflow-in-keras-torch"><span class="header-section-number">8.3.1</span> Example workflow in Keras / Torch</a></li>
  <li><a href="#exercises-2" id="toc-exercises-2" class="nav-link" data-scroll-target="#exercises-2"><span class="header-section-number">8.3.2</span> Exercises</a></li>
  </ul></li>
  <li><a href="#basicMath" id="toc-basicMath" class="nav-link" data-scroll-target="#basicMath"><span class="header-section-number">8.4</span> Underlying mathematical concepts - optional</a>
  <ul class="collapse">
  <li><a href="#caveats-of-neural-network-optimization" id="toc-caveats-of-neural-network-optimization" class="nav-link" data-scroll-target="#caveats-of-neural-network-optimization"><span class="header-section-number">8.4.1</span> Caveats of neural network optimization</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/TheoreticalEcology/machinelearning/edit/master/C1-TensorFlow.qmd" class="toc-action">Edit this page</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="tensorflowintro" class="quarto-section-identifier"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Introduction to TensorFlow and Keras</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="introduction-to-tensorflow" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="introduction-to-tensorflow"><span class="header-section-number">8.1</span> Introduction to TensorFlow</h2>
<p>One of the most commonly used frameworks for machine learning is <strong>TensorFlow</strong>. TensorFlow is an open source <a href="https://en.wikipedia.org/wiki/Linear_algebra" target="_blank" rel="noopener">linear algebra</a> library with focus on neural networks, published by Google in 2015. TensorFlow supports several interesting features, in particular automatic differentiation, several gradient optimizers and CPU and GPU parallelization.</p>
<p>These advantages are nicely explained in the following video:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/MotG3XI2qSs" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<p>To sum up the most important points of the video:</p>
<ul>
<li>TensorFlow is a math library which is highly optimized for neural networks.</li>
<li>If a GPU is available, computations can be easily run on the GPU but even on a CPU TensorFlow is still very fast.</li>
<li>The “backend” (i.e.&nbsp;all the functions and all computations) are written in C++ and CUDA (CUDA is a programming language for NVIDIA GPUs).</li>
<li>The interface (the part of TensorFlow we use) is written in Python and is also available in R, which means, we can write the code in R/Python but it will be executed by the (compiled) C++ backend.</li>
</ul>
<p>All operations in TensorFlow are written in C++ and are highly optimized. But don’t worry, we don’t have to use C++ to use TensorFlow because there are several bindings for other languages. TensorFlow officially supports a Python API, but meanwhile there are several community carried APIs for other languages:</p>
<ul>
<li>R</li>
<li>Go</li>
<li>Rust</li>
<li>Swift</li>
<li>JavaScript</li>
</ul>
<p>In this course we will use TensorFlow with the <a href="https://tensorflow.rstudio.com/" target="_blank" rel="noopener">https://tensorflow.rstudio.com/</a> binding, that was developed and published 2017 by the RStudio team. First, they developed an R package (reticulate) for calling Python in R. Actually, we are using the Python TensorFlow module in R (more about this later).</p>
<p>TensorFlow offers different levels of API. We could implement a neural network completely by ourselves or we could use Keras which is provided as a submodule by TensorFlow. Keras is a powerful module for building and training neural networks. It allows us building and training neural networks in a few lines of codes. Since the end of 2018, Keras and TensorFlow are completly interoperable, allowing us to utilize the best of both. In this course, we will show how we can use Keras for neural networks but also how we can use the TensorFlow’s automatic differenation for using complex objective functions.</p>
<p>Useful links:</p>
<ul>
<li><a href="https://www.tensorflow.org/api_docs/python/tf" target="_blank" rel="noopener">TensorFlow documentation</a> (This is for the Python API, but just replace the “.” with “$”.)</li>
<li><a href="https://tensorflow.rstudio.com/" target="_blank" rel="noopener">Rstudio TensorFlow website</a></li>
</ul>
<section id="data-containers" class="level3" data-number="8.1.1">
<h3 data-number="8.1.1" class="anchored" data-anchor-id="data-containers"><span class="header-section-number">8.1.1</span> Data Containers</h3>
<p>TensorFlow has two data containers (structures):</p>
<ul>
<li>constant (tf$constant): Creates a constant (immutable) value in the computation graph.</li>
<li>variable (tf$Variable): Creates a mutable value in the computation graph (used as parameter/weight in models).</li>
</ul>
<p>To get started with TensorFlow, we have to load the library and check if the installation worked.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Don't worry about weird messages. TensorFlow supports additional optimizations.</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">exists</span>(<span class="st">"tf"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] TRUE</code></pre>
</div>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>immutable <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(<span class="fl">5.0</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>mutable <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(<span class="fl">5.0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Don’t worry about weird messages (they will only appear once at the start of the session).</p>
</section>
<section id="basic-operations" class="level3" data-number="8.1.2">
<h3 data-number="8.1.2" class="anchored" data-anchor-id="basic-operations"><span class="header-section-number">8.1.2</span> Basic Operations</h3>
<p>We now can define the variables and do some math with them:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>a <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(<span class="dv">5</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>b <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(<span class="dv">10</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(a)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(5.0, shape=(), dtype=float32)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(b)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(10.0, shape=(), dtype=float32)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>c <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">add</span>(a, b)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(c)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(15.0, shape=(), dtype=float32)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span><span class="fu">print</span>(c) <span class="co"># Prints to stderr. For stdout, use k_print_tensor(..., message).</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">k_print_tensor</span>(c) <span class="co"># Comes out of Keras!</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(15.0, shape=(), dtype=float32)</code></pre>
</div>
</div>
<p>Normal R methods such as print() are provided by the R package “tensorflow”.</p>
<p>The TensorFlow library (created by the RStudio team) built R methods for all common operations:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="st">`</span><span class="at">+.tensorflow.tensor</span><span class="st">`</span> <span class="ot">=</span> <span class="cf">function</span>(a, b){ <span class="fu">return</span>(tf<span class="sc">$</span><span class="fu">add</span>(a,b)) }</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Mind the backticks.</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="fu">k_print_tensor</span>(a<span class="sc">+</span>b)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(15.0, shape=(), dtype=float32)</code></pre>
</div>
</div>
<p>Their operators also automatically transform R numbers into constant tensors when attempting to add a tensor to an R number:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>d <span class="ot">=</span> c <span class="sc">+</span> <span class="dv">5</span>  <span class="co"># 5 is automatically converted to a tensor.</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(d)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(20.0, shape=(), dtype=float32)</code></pre>
</div>
</div>
<p>TensorFlow containers are objects, what means that they are not just simple variables of type numeric (class(5)), but they instead have so called methods. Methods are changing the state of a class (which for most of our purposes here is the values of the object). For instance, there is a method to transform the tensor object back to an R object:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(d)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "tensorflow.tensor"                               
[2] "tensorflow.python.framework.ops.EagerTensor"     
[3] "tensorflow.python.framework.ops._EagerTensorBase"
[4] "tensorflow.python.framework.ops.Tensor"          
[5] "tensorflow.python.types.internal.NativeObject"   
[6] "tensorflow.python.types.core.Tensor"             
[7] "python.builtin.object"                           </code></pre>
</div>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(d<span class="sc">$</span><span class="fu">numpy</span>())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "numeric"</code></pre>
</div>
</div>
</section>
<section id="data-types" class="level3" data-number="8.1.3">
<h3 data-number="8.1.3" class="anchored" data-anchor-id="data-types"><span class="header-section-number">8.1.3</span> Data Types</h3>
<p>R uses dynamic typing, what means you can assign a number, character, function or whatever to a variable and the the type is automatically inferred. In other languages you have to state the type explicitly, e.g.&nbsp;in C:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode c code-with-copy"><code class="sourceCode c"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="dt">int</span> a <span class="op">=</span> <span class="dv">5</span><span class="op">;</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="dt">float</span> a <span class="op">=</span> <span class="fl">5.0</span><span class="op">;</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="dt">char</span> a <span class="op">=</span> <span class="st">"a"</span><span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>While TensorFlow tries to infer the type dynamically, you must often state it explicitly. Common important types:</p>
<ul>
<li>float32 (floating point number with 32 bits, “single precision”)</li>
<li>float64 (floating point number with 64 bits, “double precision”)</li>
<li>int8 (integer with 8 bits)</li>
</ul>
<p>The reason why TensorFlow is so explicit about types is that many GPUs (e.g.&nbsp;the NVIDIA GeForces) can handle only up to 32 bit numbers! (you do not need high precision in graphical modeling)</p>
<p>But let us see in practice what we have to do with these types and how to specifcy them:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>r_matrix <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(<span class="dv">10</span><span class="sc">*</span><span class="dv">10</span>), <span class="dv">10</span>, <span class="dv">10</span>)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>m <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(r_matrix, <span class="at">dtype =</span> <span class="st">"float32"</span>) </span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>b <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(<span class="fl">2.0</span>, <span class="at">dtype =</span> <span class="st">"float64"</span>)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>c <span class="ot">=</span> m <span class="sc">/</span> b <span class="co"># Doesn't work! We try to divide float32/float64.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>So what went wrong here? We tried to divide a float32 by a float64 number, but we can only divide numbers of the same type!</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>r_matrix <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(<span class="dv">10</span><span class="sc">*</span><span class="dv">10</span>), <span class="dv">10</span>, <span class="dv">10</span>)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>m <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(r_matrix, <span class="at">dtype =</span> <span class="st">"float64"</span>)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>b <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(<span class="fl">2.0</span>, <span class="at">dtype =</span> <span class="st">"float64"</span>)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>c <span class="ot">=</span> m <span class="sc">/</span> b <span class="co"># Now it works.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can also specify the type of the object by providing an object e.g.&nbsp;tf$float64.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>r_matrix <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(<span class="dv">10</span><span class="sc">*</span><span class="dv">10</span>), <span class="dv">10</span>, <span class="dv">10</span>)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>m <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(r_matrix, <span class="at">dtype =</span> tf<span class="sc">$</span>float64)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In TensorFlow, arguments often require exact/explicit data types: TensorFlow often expects integers as arguments. In R however an integer is normally saved as float. Thus, we have to use an “L” after an integer to tell the R interpreter that it should be treated as an integer:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">is.integer</span>(<span class="dv">5</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="fu">is.integer</span>(5L)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="fu">matrix</span>(<span class="fu">t</span>(r_matrix), <span class="dv">5</span>, <span class="dv">20</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span><span class="fu">reshape</span>(r_matrix, <span class="at">shape =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">20</span>))<span class="sc">$</span><span class="fu">numpy</span>()</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span><span class="fu">reshape</span>(r_matrix, <span class="at">shape =</span> <span class="fu">c</span>(5L, 20L))<span class="sc">$</span><span class="fu">numpy</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Skipping the “L” is one of the most common errors when using R-TensorFlow!</p>
</section>
<section id="exercises" class="level3" data-number="8.1.4">
<h3 data-number="8.1.4" class="anchored" data-anchor-id="exercises"><span class="header-section-number">8.1.4</span> Exercises</h3>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question: TensorFlow Operations
</div>
</div>
<div class="callout-body-container callout-body">
<p>To run TensorFlow from R, note that you can access the different mathematical operations in TensorFlow via tf$…, e.g.&nbsp;there is a tf$math$… for all common math operations or the tf$linalg$… for different linear algebra operations. Tip: type tf$ and then hit the tab key to list all available options (sometimes you have to do this directly in the console).</p>
<p>An example: How to get the maximum value of a vector?</p>
<p>An example: How to get the maximum value of a vector?</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="dv">100</span><span class="sc">:</span><span class="dv">1</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">as.double</span>(<span class="dv">100</span><span class="sc">:</span><span class="dv">1</span>)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="fu">max</span>(x)  <span class="co"># R solution. Integer!</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span>math<span class="sc">$</span><span class="fu">reduce_max</span>(x) <span class="co"># TensorFlow solution. Integer!</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="fu">max</span>(y)  <span class="co"># Float!</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span>math<span class="sc">$</span><span class="fu">reduce_max</span>(y) <span class="co"># Float!</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Rewrite the following expressions (a to g) in TensorFlow:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="dv">100</span><span class="sc">:</span><span class="dv">1</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">as.double</span>(<span class="dv">100</span><span class="sc">:</span><span class="dv">1</span>)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="co"># a)</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="fu">min</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1</code></pre>
</div>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># b)</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 50.5</code></pre>
</div>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># c) Tip: Use Google!</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="fu">which.max</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1</code></pre>
</div>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># d) </span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="fu">which.min</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 100</code></pre>
</div>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># e) Tip: Use Google! </span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="fu">order</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  [1] 100  99  98  97  96  95  94  93  92  91  90  89  88  87  86  85  84  83
 [19]  82  81  80  79  78  77  76  75  74  73  72  71  70  69  68  67  66  65
 [37]  64  63  62  61  60  59  58  57  56  55  54  53  52  51  50  49  48  47
 [55]  46  45  44  43  42  41  40  39  38  37  36  35  34  33  32  31  30  29
 [73]  28  27  26  25  24  23  22  21  20  19  18  17  16  15  14  13  12  11
 [91]  10   9   8   7   6   5   4   3   2   1</code></pre>
</div>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># f) Tip: See tf$reshape.</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>m <span class="ot">=</span> <span class="fu">matrix</span>(y, <span class="dv">10</span>, <span class="dv">10</span>) <span class="co"># Mind: We use y here! (Float)</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>m_2 <span class="ot">=</span> <span class="fu">abs</span>(m <span class="sc">%*%</span> <span class="fu">t</span>(m))  <span class="co"># m %*% m is the normal matrix multiplication.</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>m_2_log <span class="ot">=</span> <span class="fu">log</span>(m_2)</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(m_2_log)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8]
 [1,] 10.55841 10.54402 10.52943 10.51461 10.49957 10.48431 10.46880 10.45305
 [2,] 10.54402 10.52969 10.51515 10.50040 10.48542 10.47022 10.45478 10.43910
 [3,] 10.52943 10.51515 10.50067 10.48598 10.47107 10.45593 10.44057 10.42496
 [4,] 10.51461 10.50040 10.48598 10.47135 10.45651 10.44144 10.42614 10.41061
 [5,] 10.49957 10.48542 10.47107 10.45651 10.44173 10.42674 10.41151 10.39605
 [6,] 10.48431 10.47022 10.45593 10.44144 10.42674 10.41181 10.39666 10.38127
 [7,] 10.46880 10.45478 10.44057 10.42614 10.41151 10.39666 10.38158 10.36628
 [8,] 10.45305 10.43910 10.42496 10.41061 10.39605 10.38127 10.36628 10.35105
 [9,] 10.43705 10.42317 10.40910 10.39482 10.38034 10.36565 10.35073 10.33559
[10,] 10.42079 10.40699 10.39299 10.37879 10.36439 10.34977 10.33495 10.31989
          [,9]    [,10]
 [1,] 10.43705 10.42079
 [2,] 10.42317 10.40699
 [3,] 10.40910 10.39299
 [4,] 10.39482 10.37879
 [5,] 10.38034 10.36439
 [6,] 10.36565 10.34977
 [7,] 10.35073 10.33495
 [8,] 10.33559 10.31989
 [9,] 10.32022 10.30461
[10,] 10.30461 10.28909</code></pre>
</div>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># g) Custom mean function i.e. rewrite the function using TensorFlow. </span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>mean_R <span class="ot">=</span> <span class="cf">function</span>(y){</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>  result <span class="ot">=</span> <span class="fu">sum</span>(y) <span class="sc">/</span> <span class="fu">length</span>(y)</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(result)</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a><span class="fu">mean_R</span>(y) <span class="sc">==</span> <span class="fu">mean</span>(y)    <span class="co"># Test for equality.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] TRUE</code></pre>
</div>
</div>
<div class="webex-solution">
<button>
Click here to see the solution
</button>
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="dv">100</span><span class="sc">:</span><span class="dv">1</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">as.double</span>(<span class="dv">100</span><span class="sc">:</span><span class="dv">1</span>)</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a><span class="co"># a)    min(x)</span></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span>math<span class="sc">$</span><span class="fu">reduce_min</span>(x) <span class="co"># Integer!</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(1, shape=(), dtype=int32)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span>math<span class="sc">$</span><span class="fu">reduce_min</span>(y) <span class="co"># Float!</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(1.0, shape=(), dtype=float32)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># b)    mean(x)</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Check out the difference here:</span></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 50.5</code></pre>
</div>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 50.5</code></pre>
</div>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span>math<span class="sc">$</span><span class="fu">reduce_mean</span>(x)  <span class="co"># Integer!</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(50, shape=(), dtype=int32)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span>math<span class="sc">$</span><span class="fu">reduce_mean</span>(y)  <span class="co"># Float!</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(50.5, shape=(), dtype=float32)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co"># c)    which.max(x)</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span><span class="fu">argmax</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(0, shape=(), dtype=int64)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span><span class="fu">argmax</span>(y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(0, shape=(), dtype=int64)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># d)    which.min(x)</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span><span class="fu">argmin</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(99, shape=(), dtype=int64)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># e)    order(x)</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span><span class="fu">argsort</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(
[99 98 97 96 95 94 93 92 91 90 89 88 87 86 85 84 83 82 81 80 79 78 77 76
 75 74 73 72 71 70 69 68 67 66 65 64 63 62 61 60 59 58 57 56 55 54 53 52
 51 50 49 48 47 46 45 44 43 42 41 40 39 38 37 36 35 34 33 32 31 30 29 28
 27 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10  9  8  7  6  5  4
  3  2  1  0], shape=(100), dtype=int32)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co"># f)</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a><span class="co"># m = matrix(y, 10, 10)</span></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a><span class="co"># m_2 = abs(m %*% m)</span></span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a><span class="co"># m_2_log = log(m_2)</span></span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Mind: We use y here! TensorFlow just accepts floats in the following lines!</span></span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a>mTF <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">reshape</span>(y, <span class="fu">list</span>(10L, 10L))</span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a>m_2TF <span class="ot">=</span> tf<span class="sc">$</span>math<span class="sc">$</span><span class="fu">abs</span>( tf<span class="sc">$</span><span class="fu">matmul</span>(mTF, tf<span class="sc">$</span><span class="fu">transpose</span>(mTF)) )</span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a>m_2_logTF <span class="ot">=</span> tf<span class="sc">$</span>math<span class="sc">$</span><span class="fu">log</span>(m_2TF)</span>
<span id="cb60-10"><a href="#cb60-10" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(m_2_logTF)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(
[[11.4217415 11.311237  11.186988  11.045079  10.87965   10.68132
  10.433675  10.103772   9.608109   8.582045 ]
 [11.311237  11.200746  11.076511  10.934624  10.769221  10.570932
  10.323349   9.993557   9.498147   8.473241 ]
 [11.186988  11.076511  10.952296  10.810434  10.645068  10.446829
  10.199324   9.869672   9.374583   8.351139 ]
 [11.045079  10.934624  10.810434  10.668607  10.503285  10.305112
  10.05771    9.728241   9.233568   8.212026 ]
 [10.87965   10.769221  10.645068  10.503285  10.338026  10.139942
   9.892679   9.563459   9.069353   8.0503845]
 [10.68132   10.570932  10.446829  10.305112  10.139942   9.941987
   9.694924   9.366061   8.872767   7.857481 ]
 [10.433675  10.323349  10.199324  10.05771    9.892679   9.694924
   9.448175   9.119868   8.62784    7.6182513]
 [10.103772   9.993557   9.869672   9.728241   9.563459   9.366061
   9.119868   8.79255    8.302762   7.30317  ]
 [ 9.608109   9.498147   9.374583   9.233568   9.069353   8.872767
   8.62784    8.302762   7.818028   6.8405466]
 [ 8.582045   8.473241   8.351139   8.212026   8.0503845  7.857481
   7.6182513  7.30317    6.8405466  5.9532433]], shape=(10, 10), dtype=float32)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># g)    # Custom mean function</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>mean_TF <span class="ot">=</span> <span class="cf">function</span>(y){</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>  result <span class="ot">=</span> tf<span class="sc">$</span>math<span class="sc">$</span><span class="fu">reduce_sum</span>(y)</span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>( result <span class="sc">/</span> <span class="fu">length</span>(y) )  <span class="co"># If y is an R object.</span></span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a><span class="fu">mean_TF</span>(y) <span class="sc">==</span> <span class="fu">mean</span>(y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(True, shape=(), dtype=bool)</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question: Runtime
</div>
</div>
<div class="callout-body-container callout-body">
<p>This exercise compares the speed of R to TensorFlow. The first exercise is to rewrite the following function in TensorFlow:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>do_something_R <span class="ot">=</span> <span class="cf">function</span>(<span class="at">x =</span> <span class="fu">matrix</span>(<span class="fl">0.0</span>, 10L, 10L)){</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>  mean_per_row <span class="ot">=</span> <span class="fu">apply</span>(x, <span class="dv">1</span>, mean)</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>  result <span class="ot">=</span> x <span class="sc">-</span> mean_per_row</span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(result)</span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here, we provide a skeleton for a TensorFlow function:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>do_something_TF <span class="ot">=</span> <span class="cf">function</span>(<span class="at">x =</span> <span class="fu">matrix</span>(<span class="fl">0.0</span>, 10L, 10L)){</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>   ...</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can compare the speed using the Microbenchmark package:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fl">0.0</span>, 100L, 100L)</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>microbenchmark<span class="sc">::</span><span class="fu">microbenchmark</span>(<span class="fu">do_something_R</span>(test), <span class="fu">do_something_TF</span>(test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Try different matrix sizes for the test matrix and compare the speed.</p>
<p>Tip: Have a look at the the tf.reduce_mean documentation and the “axis” argument.</p>
<p><br></p>
<p>Compare the following with different matrix sizes:</p>
<ul>
<li>test = matrix(0.0, 1000L, 500L)</li>
<li>testTF = tf$constant(test)</li>
</ul>
<p>Also try the following:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>microbenchmark<span class="sc">::</span><span class="fu">microbenchmark</span>(</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>   tf<span class="sc">$</span><span class="fu">matmul</span>(testTF, tf<span class="sc">$</span><span class="fu">transpose</span>(testTF)), <span class="co"># TensorFlow style.</span></span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>   test <span class="sc">%*%</span> <span class="fu">t</span>(test)  <span class="co"># R style.</span></span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="webex-solution">
<button>
Click here to see the solution
</button>
<div class="cell">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>do_something_TF <span class="ot">=</span> <span class="cf">function</span>(<span class="at">x =</span> <span class="fu">matrix</span>(<span class="fl">0.0</span>, 10L, 10L)){</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(x)  <span class="co"># Remember, this is a local copy!</span></span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>  mean_per_row <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">reduce_mean</span>(x, <span class="at">axis =</span> 0L)</span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>  result <span class="ot">=</span> x <span class="sc">-</span> mean_per_row</span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(result)</span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fl">0.0</span>, 100L, 100L)</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>microbenchmark<span class="sc">::</span><span class="fu">microbenchmark</span>(<span class="fu">do_something_R</span>(test), <span class="fu">do_something_TF</span>(test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in microbenchmark::microbenchmark(do_something_R(test),
do_something_TF(test)): less accurate nanosecond times to avoid potential
integer overflows</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Unit: microseconds
                  expr     min       lq     mean   median       uq      max
  do_something_R(test) 261.334 281.0345 307.6406 303.6050 313.5270 1085.680
 do_something_TF(test) 602.659 626.2750 695.9266 657.4965 676.0285 3533.708
 neval cld
   100  a 
   100   b</code></pre>
</div>
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fl">0.0</span>, 1000L, 500L)</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>microbenchmark<span class="sc">::</span><span class="fu">microbenchmark</span>(<span class="fu">do_something_R</span>(test), <span class="fu">do_something_TF</span>(test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Unit: milliseconds
                  expr      min       lq     mean   median       uq       max
  do_something_R(test) 5.164442 5.704391 7.705723 6.723959 8.316830 67.702521
 do_something_TF(test) 1.294575 1.577004 1.871683 1.734915 1.975093  5.039146
 neval cld
   100  a 
   100   b</code></pre>
</div>
</div>
<p>Why is R faster (the first time)?</p>
<ul>
<li><ol type="a">
<li>The R functions we used (apply, mean, “-”) are also implemented in C.</li>
</ol></li>
<li><ol start="2" type="a">
<li>The problem is not large enough and TensorFlow has an overhead.</li>
</ol></li>
</ul>
<p><br></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fl">0.0</span>, 1000L, 500L)</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>testTF <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(test)</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>microbenchmark<span class="sc">::</span><span class="fu">microbenchmark</span>(</span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a>  tf<span class="sc">$</span><span class="fu">matmul</span>(testTF, tf<span class="sc">$</span><span class="fu">transpose</span>(testTF)),  <span class="co"># TensorFlow style.</span></span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a>  test <span class="sc">%*%</span> <span class="fu">t</span>(test) <span class="co"># R style.</span></span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Unit: milliseconds
                                    expr       min         lq       mean
 tf$matmul(testTF, tf$transpose(testTF))   7.07619   7.375777   8.019691
                        test %*% t(test) 161.22077 162.531503 164.182029
     median         uq       max neval cld
   7.577148   8.507972  11.41071   100  a 
 163.291725 164.431669 226.62451   100   b</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question: Linear Algebra
</div>
</div>
<div class="callout-body-container callout-body">
<p>Google to find out how to write the following expressions in TensorFlow:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>A <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">3</span>), <span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a><span class="co"># i)</span></span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a><span class="fu">solve</span>(A)  <span class="co"># Solve equation AX = B. If just A  is given, invert it.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2]       [,3]
[1,]    1  0.0 -0.6666667
[2,]   -1  0.5 -0.1666667
[3,]    0  0.0  0.3333333</code></pre>
</div>
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co"># j)</span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a><span class="fu">diag</span>(A) <span class="co"># Diagonal of A, if no matrix is given, construct diagonal matrix.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1 2 3</code></pre>
</div>
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="co"># k)</span></span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a><span class="fu">diag</span>(<span class="fu">diag</span>(A)) <span class="co"># Diagonal matrix with entries diag(A).</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2] [,3]
[1,]    1    0    0
[2,]    0    2    0
[3,]    0    0    3</code></pre>
</div>
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="co"># l)</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a><span class="fu">eigen</span>(A)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>eigen() decomposition
$values
[1] 3 2 1

$vectors
          [,1] [,2]       [,3]
[1,] 0.1400280    0  0.4472136
[2,] 0.9801961    1 -0.8944272
[3,] 0.1400280    0  0.0000000</code></pre>
</div>
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="co"># m)</span></span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a><span class="fu">det</span>(A)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 6</code></pre>
</div>
</div>
<div class="webex-solution">
<button>
Click here to see the solution
</button>
<div class="cell">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>A <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="fl">1.</span>, <span class="fl">2.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">2.</span>, <span class="fl">0.</span>, <span class="fl">2.</span>, <span class="fl">5.</span>, <span class="fl">3.</span>), <span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Do not use the "L" form here!</span></span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a><span class="co"># i)    solve(A)</span></span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span>linalg<span class="sc">$</span><span class="fu">inv</span>(A)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(
[[ 1.          0.         -0.66666667]
 [-1.          0.5        -0.16666667]
 [ 0.          0.          0.33333333]], shape=(3, 3), dtype=float64)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="co"># j)    diag(A)</span></span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span>linalg<span class="sc">$</span><span class="fu">diag_part</span>(A)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor([1. 2. 3.], shape=(3), dtype=float64)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="co"># k)    diag(diag(A))</span></span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span>linalg<span class="sc">$</span><span class="fu">diag</span>(tf<span class="sc">$</span>linalg<span class="sc">$</span><span class="fu">diag_part</span>(A))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(
[[1. 0. 0.]
 [0. 2. 0.]
 [0. 0. 3.]], shape=(3, 3), dtype=float64)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="co"># l)    eigen(A)</span></span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span>linalg<span class="sc">$</span><span class="fu">eigh</span>(A)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[1]]
tf.Tensor([-0.56155281  3.          3.56155281], shape=(3), dtype=float64)

[[2]]
tf.Tensor(
[[-0.78820544  0.         -0.61541221]
 [ 0.61541221  0.         -0.78820544]
 [ 0.          1.         -0.        ]], shape=(3, 3), dtype=float64)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="co"># m)    det(A)</span></span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span>linalg<span class="sc">$</span><span class="fu">det</span>(A)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(6.0, shape=(), dtype=float64)</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question: Automatic differentation
</div>
</div>
<div class="callout-body-container callout-body">
<p>TensorFlow supports automatic differentiation (analytical and not numerical!). Let’s have a look at the function <span class="math inline">\(f(x) = 5 x^2 + 3\)</span> with derivative <span class="math inline">\(f'(x) = 10x\)</span>. So for <span class="math inline">\(f'(5)\)</span> we will get <span class="math inline">\(10\)</span>.</p>
<p>Let’s do this in TensorFlow. Define the function:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>f <span class="ot">=</span> <span class="cf">function</span>(x){ <span class="fu">return</span>(<span class="fl">5.0</span> <span class="sc">*</span> tf<span class="sc">$</span><span class="fu">square</span>(x) <span class="sc">+</span> <span class="fl">3.0</span>) }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We want to calculate the derivative for <span class="math inline">\(x = 2.0\)</span>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(<span class="fl">2.0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To do automatic differentiation, we have to forward <span class="math inline">\(x\)</span> through the function within the tf$GradientTape() environment. We have also have to tell TensorFlow which value to “watch”:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="fu">with</span>(tf<span class="sc">$</span><span class="fu">GradientTape</span>() <span class="sc">%as%</span> tape,</span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>  {</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a>    tape<span class="sc">$</span><span class="fu">watch</span>(x)</span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true" tabindex="-1"></a>    y <span class="ot">=</span> <span class="fu">f</span>(x)</span>
<span id="cb98-5"><a href="#cb98-5" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb98-6"><a href="#cb98-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To print the gradient:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a>(tape<span class="sc">$</span><span class="fu">gradient</span>(y, x))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(20.0, shape=(), dtype=float32)</code></pre>
</div>
</div>
<p>We can also calculate the second order derivative <span class="math inline">\(f''(x) = 10\)</span>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="fu">with</span>(tf<span class="sc">$</span><span class="fu">GradientTape</span>() <span class="sc">%as%</span> first,</span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a>  {</span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a>    first<span class="sc">$</span><span class="fu">watch</span>(x)</span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">with</span>(tf<span class="sc">$</span><span class="fu">GradientTape</span>() <span class="sc">%as%</span> second,</span>
<span id="cb101-5"><a href="#cb101-5" aria-hidden="true" tabindex="-1"></a>      {</span>
<span id="cb101-6"><a href="#cb101-6" aria-hidden="true" tabindex="-1"></a>        second<span class="sc">$</span><span class="fu">watch</span>(x)</span>
<span id="cb101-7"><a href="#cb101-7" aria-hidden="true" tabindex="-1"></a>        y <span class="ot">=</span> <span class="fu">f</span>(x)</span>
<span id="cb101-8"><a href="#cb101-8" aria-hidden="true" tabindex="-1"></a>        g <span class="ot">=</span> first<span class="sc">$</span><span class="fu">gradient</span>(y, x)</span>
<span id="cb101-9"><a href="#cb101-9" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb101-10"><a href="#cb101-10" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb101-11"><a href="#cb101-11" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb101-12"><a href="#cb101-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb101-13"><a href="#cb101-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-14"><a href="#cb101-14" aria-hidden="true" tabindex="-1"></a>(second<span class="sc">$</span><span class="fu">gradient</span>(g, x))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor(10.0, shape=(), dtype=float32)</code></pre>
</div>
</div>
<p>What is happening here? Think about and discuss it.</p>
<p>A more advanced example: <em>Linear regression</em></p>
<p>In this case we first simulate data following <span class="math inline">\(\boldsymbol{y} = \boldsymbol{X} \boldsymbol{w} + \boldsymbol{\epsilon}\)</span> (<span class="math inline">\(\boldsymbol{\epsilon}\)</span> follows a normal distribution == error).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R's random seed.</span></span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">round</span>(<span class="fu">runif</span>(<span class="dv">500</span>, <span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>), <span class="dv">3</span>), <span class="dv">100</span>, <span class="dv">5</span>)</span>
<span id="cb103-4"><a href="#cb103-4" aria-hidden="true" tabindex="-1"></a>w <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="dv">5</span>, <span class="dv">2</span>, <span class="dv">1</span>), <span class="dv">3</span>)</span>
<span id="cb103-5"><a href="#cb103-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> x <span class="sc">%*%</span> w <span class="sc">+</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="dv">0</span>, <span class="fl">0.25</span>), <span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In R we would do the following to fit a linear regression model:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ x)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.67893 -0.16399  0.00968  0.15058  0.51099 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 0.004865   0.027447   0.177     0.86    
x1          2.191511   0.023243  94.287   &lt;2e-16 ***
x2          2.741690   0.025328 108.249   &lt;2e-16 ***
x3          1.179181   0.023644  49.872   &lt;2e-16 ***
x4          0.591873   0.025154  23.530   &lt;2e-16 ***
x5          2.302417   0.022575 101.991   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.2645 on 94 degrees of freedom
Multiple R-squared:  0.9974,    Adjusted R-squared:  0.9972 
F-statistic:  7171 on 5 and 94 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>Let’s build our own model in TensorFlow. Here, we use now the variable data container type (remember they are mutable and we need this type for the weights (<span class="math inline">\(\boldsymbol{w}\)</span>) of the regression model). We want our model to learn these weights.</p>
<p>The input (predictors, independent variables or features, <span class="math inline">\(\boldsymbol{X}\)</span>) and the observed (response, <span class="math inline">\(\boldsymbol{y}\)</span>) are constant and will not be learned/optimized.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R's random seed.</span></span>
<span id="cb106-4"><a href="#cb106-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-5"><a href="#cb106-5" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">round</span>(<span class="fu">runif</span>(<span class="dv">500</span>, <span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>), <span class="dv">3</span>), <span class="dv">100</span>, <span class="dv">5</span>)</span>
<span id="cb106-6"><a href="#cb106-6" aria-hidden="true" tabindex="-1"></a>w <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="dv">5</span>, <span class="dv">2</span>, <span class="dv">1</span>), <span class="dv">3</span>)</span>
<span id="cb106-7"><a href="#cb106-7" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> x <span class="sc">%*%</span> w <span class="sc">+</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="dv">0</span>, <span class="fl">0.25</span>), <span class="dv">4</span>)</span>
<span id="cb106-8"><a href="#cb106-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-9"><a href="#cb106-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Weights we want to learn.</span></span>
<span id="cb106-10"><a href="#cb106-10" aria-hidden="true" tabindex="-1"></a><span class="co"># We know the real weights but in reality we wouldn't know them.</span></span>
<span id="cb106-11"><a href="#cb106-11" aria-hidden="true" tabindex="-1"></a><span class="co"># So use guessed ones.</span></span>
<span id="cb106-12"><a href="#cb106-12" aria-hidden="true" tabindex="-1"></a>wTF <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">Variable</span>(<span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="dv">5</span>, <span class="dv">0</span>, <span class="fl">0.01</span>), <span class="dv">5</span>, <span class="dv">1</span>))</span>
<span id="cb106-13"><a href="#cb106-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-14"><a href="#cb106-14" aria-hidden="true" tabindex="-1"></a>xTF <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(x)</span>
<span id="cb106-15"><a href="#cb106-15" aria-hidden="true" tabindex="-1"></a>yTF <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(y)</span>
<span id="cb106-16"><a href="#cb106-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-17"><a href="#cb106-17" aria-hidden="true" tabindex="-1"></a><span class="co"># We need an optimizer which updates the weights (wTF).</span></span>
<span id="cb106-18"><a href="#cb106-18" aria-hidden="true" tabindex="-1"></a>optimizer <span class="ot">=</span> tf<span class="sc">$</span>keras<span class="sc">$</span>optimizers<span class="sc">$</span><span class="fu">Adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.1</span>)</span>
<span id="cb106-19"><a href="#cb106-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-20"><a href="#cb106-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>){</span>
<span id="cb106-21"><a href="#cb106-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">with</span>(tf<span class="sc">$</span><span class="fu">GradientTape</span>() <span class="sc">%as%</span> tape,</span>
<span id="cb106-22"><a href="#cb106-22" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb106-23"><a href="#cb106-23" aria-hidden="true" tabindex="-1"></a>      pred <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">matmul</span>(xTF, wTF)</span>
<span id="cb106-24"><a href="#cb106-24" aria-hidden="true" tabindex="-1"></a>      loss <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">sqrt</span>(tf<span class="sc">$</span><span class="fu">reduce_mean</span>(tf<span class="sc">$</span><span class="fu">square</span>(yTF <span class="sc">-</span> pred)))</span>
<span id="cb106-25"><a href="#cb106-25" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb106-26"><a href="#cb106-26" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb106-27"><a href="#cb106-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-28"><a href="#cb106-28" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="sc">!</span>i<span class="sc">%%</span><span class="dv">10</span>){ <span class="fu">k_print_tensor</span>(loss, <span class="at">message =</span> <span class="st">"Loss: "</span>) }  <span class="co"># Every 10 times.</span></span>
<span id="cb106-29"><a href="#cb106-29" aria-hidden="true" tabindex="-1"></a>  grads <span class="ot">=</span> tape<span class="sc">$</span><span class="fu">gradient</span>(loss, wTF)</span>
<span id="cb106-30"><a href="#cb106-30" aria-hidden="true" tabindex="-1"></a>  optimizer<span class="sc">$</span><span class="fu">apply_gradients</span>(purrr<span class="sc">::</span><span class="fu">transpose</span>(<span class="fu">list</span>(<span class="fu">list</span>(grads), <span class="fu">list</span>(wTF))))</span>
<span id="cb106-31"><a href="#cb106-31" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb106-32"><a href="#cb106-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-33"><a href="#cb106-33" aria-hidden="true" tabindex="-1"></a><span class="fu">k_print_tensor</span>(wTF, <span class="at">message =</span> <span class="st">"Resulting weights:</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;tf.Variable 'Variable:0' shape=(5, 1) dtype=float64, numpy=
array([[2.19290567],
       [2.74534135],
       [1.17146559],
       [0.58811305],
       [2.30174941]])&gt;</code></pre>
</div>
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Original weights: "</span>, w, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Original weights:  2.217 2.719 1.165 0.593 2.303 </code></pre>
</div>
</div>
<p>Discuss the code, go through the code line by line and try to understand it.</p>
<p>Additional exercise:</p>
<p>Play around with the simulation, increase/decrease the number of weights, add an intercept (you also need an additional variable in model).</p>
<div class="webex-solution">
<button>
Click here to see the solution
</button>
<div class="cell">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb110-3"><a href="#cb110-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R's random seed.</span></span>
<span id="cb110-4"><a href="#cb110-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb110-5"><a href="#cb110-5" aria-hidden="true" tabindex="-1"></a>numberOfWeights <span class="ot">=</span> <span class="dv">3</span></span>
<span id="cb110-6"><a href="#cb110-6" aria-hidden="true" tabindex="-1"></a>numberOfFeatures <span class="ot">=</span> <span class="dv">10000</span></span>
<span id="cb110-7"><a href="#cb110-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb110-8"><a href="#cb110-8" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">round</span>(<span class="fu">runif</span>(numberOfFeatures <span class="sc">*</span> numberOfWeights, <span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>), <span class="dv">3</span>),</span>
<span id="cb110-9"><a href="#cb110-9" aria-hidden="true" tabindex="-1"></a>           numberOfFeatures, numberOfWeights)</span>
<span id="cb110-10"><a href="#cb110-10" aria-hidden="true" tabindex="-1"></a>w <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(numberOfWeights, <span class="dv">2</span>, <span class="dv">1</span>), <span class="dv">3</span>)</span>
<span id="cb110-11"><a href="#cb110-11" aria-hidden="true" tabindex="-1"></a>intercept <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="dv">1</span>, <span class="dv">3</span>, .<span class="dv">5</span>), <span class="dv">3</span>)</span>
<span id="cb110-12"><a href="#cb110-12" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> intercept <span class="sc">+</span> x <span class="sc">%*%</span> w <span class="sc">+</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(numberOfFeatures, <span class="dv">0</span>, <span class="fl">0.25</span>), <span class="dv">4</span>)</span>
<span id="cb110-13"><a href="#cb110-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb110-14"><a href="#cb110-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Guessed weights and intercept.</span></span>
<span id="cb110-15"><a href="#cb110-15" aria-hidden="true" tabindex="-1"></a>wTF <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">Variable</span>(<span class="fu">matrix</span>(<span class="fu">rnorm</span>(numberOfWeights, <span class="dv">0</span>, <span class="fl">0.01</span>), numberOfWeights, <span class="dv">1</span>))</span>
<span id="cb110-16"><a href="#cb110-16" aria-hidden="true" tabindex="-1"></a>interceptTF <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">Variable</span>(<span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="dv">1</span>, <span class="dv">0</span>, .<span class="dv">5</span>)), <span class="dv">1</span>, <span class="dv">1</span>) <span class="co"># Double, not float32.</span></span>
<span id="cb110-17"><a href="#cb110-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb110-18"><a href="#cb110-18" aria-hidden="true" tabindex="-1"></a>xTF <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(x)</span>
<span id="cb110-19"><a href="#cb110-19" aria-hidden="true" tabindex="-1"></a>yTF <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(y)</span>
<span id="cb110-20"><a href="#cb110-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb110-21"><a href="#cb110-21" aria-hidden="true" tabindex="-1"></a>optimizer <span class="ot">=</span> tf<span class="sc">$</span>keras<span class="sc">$</span>optimizers<span class="sc">$</span><span class="fu">Adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.05</span>)</span>
<span id="cb110-22"><a href="#cb110-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb110-23"><a href="#cb110-23" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>){</span>
<span id="cb110-24"><a href="#cb110-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">with</span>(tf<span class="sc">$</span><span class="fu">GradientTape</span>(<span class="at">persistent =</span> <span class="cn">TRUE</span>) <span class="sc">%as%</span> tape,</span>
<span id="cb110-25"><a href="#cb110-25" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb110-26"><a href="#cb110-26" aria-hidden="true" tabindex="-1"></a>      pred <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">add</span>(interceptTF, tf<span class="sc">$</span><span class="fu">matmul</span>(xTF, wTF))</span>
<span id="cb110-27"><a href="#cb110-27" aria-hidden="true" tabindex="-1"></a>      loss <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">sqrt</span>(tf<span class="sc">$</span><span class="fu">reduce_mean</span>(tf<span class="sc">$</span><span class="fu">square</span>(yTF <span class="sc">-</span> pred)))</span>
<span id="cb110-28"><a href="#cb110-28" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb110-29"><a href="#cb110-29" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb110-30"><a href="#cb110-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb110-31"><a href="#cb110-31" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="sc">!</span>i<span class="sc">%%</span><span class="dv">10</span>){ <span class="fu">k_print_tensor</span>(loss, <span class="at">message =</span> <span class="st">"Loss: "</span>) }  <span class="co"># Every 10 times.</span></span>
<span id="cb110-32"><a href="#cb110-32" aria-hidden="true" tabindex="-1"></a>  grads <span class="ot">=</span> tape<span class="sc">$</span><span class="fu">gradient</span>(loss, <span class="fu">list</span>(wTF, interceptTF))</span>
<span id="cb110-33"><a href="#cb110-33" aria-hidden="true" tabindex="-1"></a>  optimizer<span class="sc">$</span><span class="fu">apply_gradients</span>(purrr<span class="sc">::</span><span class="fu">transpose</span>(<span class="fu">list</span>(grads, <span class="fu">list</span>(wTF, interceptTF))))</span>
<span id="cb110-34"><a href="#cb110-34" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb110-35"><a href="#cb110-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb110-36"><a href="#cb110-36" aria-hidden="true" tabindex="-1"></a><span class="fu">k_print_tensor</span>(wTF, <span class="at">message =</span> <span class="st">"Resulting weights:</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;tf.Variable 'Variable:0' shape=(3, 1) dtype=float64, numpy=
array([[2.48089253],
       [2.47586968],
       [1.00278615]])&gt;</code></pre>
</div>
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Original weights: "</span>, w, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Original weights:  2.47 2.465 1.003 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a><span class="fu">k_print_tensor</span>(interceptTF, <span class="at">message =</span> <span class="st">"Resulting intercept:</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;tf.Variable 'Variable:0' shape=(1, 1) dtype=float64, numpy=array([[4.15394202]])&gt;</code></pre>
</div>
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Original intercept: "</span>, intercept, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Original intercept:  4.09 </code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="introduction-to-pytorch" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="introduction-to-pytorch"><span class="header-section-number">8.2</span> Introduction to PyTorch</h2>
<p>PyTorch is another famous library for deep learning. Like TensorFlow, Torch itself is written in C++ with an API for Python. In 2020, the RStudio team released R-Torch, and while R-TensorFlow calls the Python API in the background, the R-Torch API is built directly on the C++ Torch library!</p>
<p>Useful links:</p>
<ul>
<li><a href="https://pytorch.org/docs/stable/index.html" target="_blank" rel="noopener">PyTorch documentation</a> (This is for the Python API, bust just replace the “.” with “$”.)</li>
<li><a href="https://torch.mlverse.org/" target="_blank" rel="noopener">R-Torch website</a></li>
</ul>
<p>To get started with Torch, we have to load the library and check if the installation worked.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb118"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="data-containers-1" class="level3" data-number="8.2.1">
<h3 data-number="8.2.1" class="anchored" data-anchor-id="data-containers-1"><span class="header-section-number">8.2.1</span> Data Containers</h3>
<p>Unlike TensorFlow, Torch doesn’t have two data containers for mutable and immutable variables. All variables are initialized via the torch_tensor function:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb119"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a>a <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fl">1.</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To mark variables as mutable (and to track their operations for automatic differentiation) we have to set the argument ‘requires_grad’ to true in the torch_tensor function:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a>mutable <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="dv">5</span>, <span class="at">requires_grad =</span> <span class="cn">TRUE</span>) <span class="co"># tf$Variable(...)</span></span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true" tabindex="-1"></a>immutable <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="dv">5</span>, <span class="at">requires_grad =</span> <span class="cn">FALSE</span>) <span class="co"># tf$constant(...)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="basic-operations-1" class="level3" data-number="8.2.2">
<h3 data-number="8.2.2" class="anchored" data-anchor-id="basic-operations-1"><span class="header-section-number">8.2.2</span> Basic Operations</h3>
<p>We now can define the variables and do some math with them:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a>a <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fl">5.</span>)</span>
<span id="cb121-2"><a href="#cb121-2" aria-hidden="true" tabindex="-1"></a>b <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fl">10.</span>)</span>
<span id="cb121-3"><a href="#cb121-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(a)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 5
[ CPUFloatType{1} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb123"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(b)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 10
[ CPUFloatType{1} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a>c <span class="ot">=</span> a<span class="sc">$</span><span class="fu">add</span>(b)</span>
<span id="cb125-2"><a href="#cb125-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(c)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 15
[ CPUFloatType{1} ]</code></pre>
</div>
</div>
<p>The R-Torch package provides all common R methods (an advantage over TensorFlow).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a>a <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fl">5.</span>)</span>
<span id="cb127-2"><a href="#cb127-2" aria-hidden="true" tabindex="-1"></a>b <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fl">10.</span>)</span>
<span id="cb127-3"><a href="#cb127-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(a<span class="sc">+</span>b)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 15
[ CPUFloatType{1} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(a<span class="sc">/</span>b)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 0.5000
[ CPUFloatType{1} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb131"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(a<span class="sc">*</span>b)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 50
[ CPUFloatType{1} ]</code></pre>
</div>
</div>
<p>Their operators also automatically transform R numbers into tensors when attempting to add a tensor to a R number:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb133"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a>d <span class="ot">=</span> a <span class="sc">+</span> <span class="dv">5</span>  <span class="co"># 5 is automatically converted to a tensor.</span></span>
<span id="cb133-2"><a href="#cb133-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(d)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 10
[ CPUFloatType{1} ]</code></pre>
</div>
</div>
<p>As for TensorFlow, we have to explicitly transform the tensors back to R:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb135"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(d)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "torch_tensor" "R7"          </code></pre>
</div>
<div class="sourceCode cell-code" id="cb137"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(<span class="fu">as.numeric</span>(d))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "numeric"</code></pre>
</div>
</div>
</section>
<section id="data-types-1" class="level3" data-number="8.2.3">
<h3 data-number="8.2.3" class="anchored" data-anchor-id="data-types-1"><span class="header-section-number">8.2.3</span> Data Types</h3>
<p>Similar to TensorFlow:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb139"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a>r_matrix <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(<span class="dv">10</span><span class="sc">*</span><span class="dv">10</span>), <span class="dv">10</span>, <span class="dv">10</span>)</span>
<span id="cb139-2"><a href="#cb139-2" aria-hidden="true" tabindex="-1"></a>m <span class="ot">=</span> <span class="fu">torch_tensor</span>(r_matrix, <span class="at">dtype =</span> <span class="fu">torch_float32</span>()) </span>
<span id="cb139-3"><a href="#cb139-3" aria-hidden="true" tabindex="-1"></a>b <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fl">2.0</span>, <span class="at">dtype =</span> <span class="fu">torch_float64</span>())</span>
<span id="cb139-4"><a href="#cb139-4" aria-hidden="true" tabindex="-1"></a>c <span class="ot">=</span> m <span class="sc">/</span> b </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>But here’s a difference! With TensorFlow we would get an error, but with R-Torch, m is automatically casted to a double (float64). However, this is still bad practice!</p>
<p>During the course we will try to provide the corresponding PyTorch code snippets for all Keras/TensorFlow examples.</p>
</section>
<section id="exercises-1" class="level3" data-number="8.2.4">
<h3 data-number="8.2.4" class="anchored" data-anchor-id="exercises-1"><span class="header-section-number">8.2.4</span> Exercises</h3>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question: Torch Operations
</div>
</div>
<div class="callout-body-container callout-body">
<p>Rewrite the following expressions (a to g) in torch:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb140"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="dv">100</span><span class="sc">:</span><span class="dv">1</span></span>
<span id="cb140-2"><a href="#cb140-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">as.double</span>(<span class="dv">100</span><span class="sc">:</span><span class="dv">1</span>)</span>
<span id="cb140-3"><a href="#cb140-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-4"><a href="#cb140-4" aria-hidden="true" tabindex="-1"></a><span class="co"># a)</span></span>
<span id="cb140-5"><a href="#cb140-5" aria-hidden="true" tabindex="-1"></a><span class="fu">min</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1</code></pre>
</div>
<div class="sourceCode cell-code" id="cb142"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a><span class="co"># b)</span></span>
<span id="cb142-2"><a href="#cb142-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 50.5</code></pre>
</div>
<div class="sourceCode cell-code" id="cb144"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb144-1"><a href="#cb144-1" aria-hidden="true" tabindex="-1"></a><span class="co"># c) Tip: Use Google!</span></span>
<span id="cb144-2"><a href="#cb144-2" aria-hidden="true" tabindex="-1"></a><span class="fu">which.max</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1</code></pre>
</div>
<div class="sourceCode cell-code" id="cb146"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a><span class="co"># d) </span></span>
<span id="cb146-2"><a href="#cb146-2" aria-hidden="true" tabindex="-1"></a><span class="fu">which.min</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 100</code></pre>
</div>
<div class="sourceCode cell-code" id="cb148"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a><span class="co"># e) Tip: Use Google! </span></span>
<span id="cb148-2"><a href="#cb148-2" aria-hidden="true" tabindex="-1"></a><span class="fu">order</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  [1] 100  99  98  97  96  95  94  93  92  91  90  89  88  87  86  85  84  83
 [19]  82  81  80  79  78  77  76  75  74  73  72  71  70  69  68  67  66  65
 [37]  64  63  62  61  60  59  58  57  56  55  54  53  52  51  50  49  48  47
 [55]  46  45  44  43  42  41  40  39  38  37  36  35  34  33  32  31  30  29
 [73]  28  27  26  25  24  23  22  21  20  19  18  17  16  15  14  13  12  11
 [91]  10   9   8   7   6   5   4   3   2   1</code></pre>
</div>
<div class="sourceCode cell-code" id="cb150"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a><span class="co"># f) Tip: See tf$reshape.</span></span>
<span id="cb150-2"><a href="#cb150-2" aria-hidden="true" tabindex="-1"></a>m <span class="ot">=</span> <span class="fu">matrix</span>(y, <span class="dv">10</span>, <span class="dv">10</span>) <span class="co"># Mind: We use y here! (Float)</span></span>
<span id="cb150-3"><a href="#cb150-3" aria-hidden="true" tabindex="-1"></a>m_2 <span class="ot">=</span> <span class="fu">abs</span>(m <span class="sc">%*%</span> <span class="fu">t</span>(m))  <span class="co"># m %*% m is the normal matrix multiplication.</span></span>
<span id="cb150-4"><a href="#cb150-4" aria-hidden="true" tabindex="-1"></a>m_2_log <span class="ot">=</span> <span class="fu">log</span>(m_2)</span>
<span id="cb150-5"><a href="#cb150-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(m_2_log)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8]
 [1,] 10.55841 10.54402 10.52943 10.51461 10.49957 10.48431 10.46880 10.45305
 [2,] 10.54402 10.52969 10.51515 10.50040 10.48542 10.47022 10.45478 10.43910
 [3,] 10.52943 10.51515 10.50067 10.48598 10.47107 10.45593 10.44057 10.42496
 [4,] 10.51461 10.50040 10.48598 10.47135 10.45651 10.44144 10.42614 10.41061
 [5,] 10.49957 10.48542 10.47107 10.45651 10.44173 10.42674 10.41151 10.39605
 [6,] 10.48431 10.47022 10.45593 10.44144 10.42674 10.41181 10.39666 10.38127
 [7,] 10.46880 10.45478 10.44057 10.42614 10.41151 10.39666 10.38158 10.36628
 [8,] 10.45305 10.43910 10.42496 10.41061 10.39605 10.38127 10.36628 10.35105
 [9,] 10.43705 10.42317 10.40910 10.39482 10.38034 10.36565 10.35073 10.33559
[10,] 10.42079 10.40699 10.39299 10.37879 10.36439 10.34977 10.33495 10.31989
          [,9]    [,10]
 [1,] 10.43705 10.42079
 [2,] 10.42317 10.40699
 [3,] 10.40910 10.39299
 [4,] 10.39482 10.37879
 [5,] 10.38034 10.36439
 [6,] 10.36565 10.34977
 [7,] 10.35073 10.33495
 [8,] 10.33559 10.31989
 [9,] 10.32022 10.30461
[10,] 10.30461 10.28909</code></pre>
</div>
<div class="sourceCode cell-code" id="cb152"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb152-1"><a href="#cb152-1" aria-hidden="true" tabindex="-1"></a><span class="co"># g) Custom mean function i.e. rewrite the function using TensorFlow. </span></span>
<span id="cb152-2"><a href="#cb152-2" aria-hidden="true" tabindex="-1"></a>mean_R <span class="ot">=</span> <span class="cf">function</span>(y){</span>
<span id="cb152-3"><a href="#cb152-3" aria-hidden="true" tabindex="-1"></a>  result <span class="ot">=</span> <span class="fu">sum</span>(y) <span class="sc">/</span> <span class="fu">length</span>(y)</span>
<span id="cb152-4"><a href="#cb152-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(result)</span>
<span id="cb152-5"><a href="#cb152-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb152-6"><a href="#cb152-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb152-7"><a href="#cb152-7" aria-hidden="true" tabindex="-1"></a><span class="fu">mean_R</span>(y) <span class="sc">==</span> <span class="fu">mean</span>(y)    <span class="co"># Test for equality.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] TRUE</code></pre>
</div>
</div>
<div class="webex-solution">
<button>
Click here to see the solution
</button>
<div class="cell">
<div class="sourceCode cell-code" id="cb154"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb154-2"><a href="#cb154-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb154-3"><a href="#cb154-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb154-4"><a href="#cb154-4" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="dv">100</span><span class="sc">:</span><span class="dv">1</span></span>
<span id="cb154-5"><a href="#cb154-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">as.double</span>(<span class="dv">100</span><span class="sc">:</span><span class="dv">1</span>)</span>
<span id="cb154-6"><a href="#cb154-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb154-7"><a href="#cb154-7" aria-hidden="true" tabindex="-1"></a><span class="co"># a)    min(x)</span></span>
<span id="cb154-8"><a href="#cb154-8" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_min</span>(x) <span class="co"># Integer!</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
1
[ CPULongType{} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb156"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb156-1"><a href="#cb156-1" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_min</span>(y) <span class="co"># Float!</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
1
[ CPUFloatType{} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb158"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb158-1"><a href="#cb158-1" aria-hidden="true" tabindex="-1"></a><span class="co"># b)    mean(x)</span></span>
<span id="cb158-2"><a href="#cb158-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Check out the difference here:</span></span>
<span id="cb158-3"><a href="#cb158-3" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 50.5</code></pre>
</div>
<div class="sourceCode cell-code" id="cb160"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb160-1"><a href="#cb160-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 50.5</code></pre>
</div>
<div class="sourceCode cell-code" id="cb162"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb162-1"><a href="#cb162-1" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_mean</span>(<span class="fu">torch_tensor</span>(x, <span class="at">dtype =</span> <span class="fu">torch_float32</span>()))  <span class="co"># Integer! Why?</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
50.5
[ CPUFloatType{} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb164"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb164-1"><a href="#cb164-1" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_mean</span>(y)  <span class="co"># Float!</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
50.5
[ CPUFloatType{} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb166"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb166-1"><a href="#cb166-1" aria-hidden="true" tabindex="-1"></a><span class="co"># c)    which.max(x)</span></span>
<span id="cb166-2"><a href="#cb166-2" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_argmax</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
1
[ CPULongType{} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb168"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb168-1"><a href="#cb168-1" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_argmax</span>(y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
1
[ CPULongType{} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb170"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb170-1"><a href="#cb170-1" aria-hidden="true" tabindex="-1"></a><span class="co"># d)    which.min(x)</span></span>
<span id="cb170-2"><a href="#cb170-2" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_argmin</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
100
[ CPULongType{} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb172"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb172-1"><a href="#cb172-1" aria-hidden="true" tabindex="-1"></a><span class="co"># e)    order(x)</span></span>
<span id="cb172-2"><a href="#cb172-2" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_argsort</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 100
  99
  98
  97
  96
  95
  94
  93
  92
  91
  90
  89
  88
  87
  86
  85
  84
  83
  82
  81
  80
  79
  78
  77
  76
  75
  74
  73
  72
  71
... [the output was truncated (use n=-1 to disable)]
[ CPULongType{100} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb174"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb174-1"><a href="#cb174-1" aria-hidden="true" tabindex="-1"></a><span class="co"># f)</span></span>
<span id="cb174-2"><a href="#cb174-2" aria-hidden="true" tabindex="-1"></a><span class="co"># m = matrix(y, 10, 10)</span></span>
<span id="cb174-3"><a href="#cb174-3" aria-hidden="true" tabindex="-1"></a><span class="co"># m_2 = abs(m %*% m)</span></span>
<span id="cb174-4"><a href="#cb174-4" aria-hidden="true" tabindex="-1"></a><span class="co"># m_2_log = log(m_2)</span></span>
<span id="cb174-5"><a href="#cb174-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-6"><a href="#cb174-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Mind: We use y here! </span></span>
<span id="cb174-7"><a href="#cb174-7" aria-hidden="true" tabindex="-1"></a>mTorch <span class="ot">=</span> <span class="fu">torch_reshape</span>(y, <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb174-8"><a href="#cb174-8" aria-hidden="true" tabindex="-1"></a>mTorch2 <span class="ot">=</span> <span class="fu">torch_abs</span>(<span class="fu">torch_matmul</span>(mTorch, <span class="fu">torch_t</span>(mTorch))) <span class="co"># hard to read!</span></span>
<span id="cb174-9"><a href="#cb174-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-10"><a href="#cb174-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Better:</span></span>
<span id="cb174-11"><a href="#cb174-11" aria-hidden="true" tabindex="-1"></a>mTorch2 <span class="ot">=</span> mTorch<span class="sc">$</span><span class="fu">matmul</span>( mTorch<span class="sc">$</span><span class="fu">t</span>() )<span class="sc">$</span><span class="fu">abs</span>()</span>
<span id="cb174-12"><a href="#cb174-12" aria-hidden="true" tabindex="-1"></a>mTorch2_log <span class="ot">=</span> mTorch<span class="sc">$</span><span class="fu">log</span>()</span>
<span id="cb174-13"><a href="#cb174-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-14"><a href="#cb174-14" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(mTorch2_log)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 4.6052  4.5951  4.5850  4.5747  4.5643  4.5539  4.5433  4.5326  4.5218  4.5109
 4.4998  4.4886  4.4773  4.4659  4.4543  4.4427  4.4308  4.4188  4.4067  4.3944
 4.3820  4.3694  4.3567  4.3438  4.3307  4.3175  4.3041  4.2905  4.2767  4.2627
 4.2485  4.2341  4.2195  4.2047  4.1897  4.1744  4.1589  4.1431  4.1271  4.1109
 4.0943  4.0775  4.0604  4.0431  4.0254  4.0073  3.9890  3.9703  3.9512  3.9318
 3.9120  3.8918  3.8712  3.8501  3.8286  3.8067  3.7842  3.7612  3.7377  3.7136
 3.6889  3.6636  3.6376  3.6109  3.5835  3.5553  3.5264  3.4965  3.4657  3.4340
 3.4012  3.3673  3.3322  3.2958  3.2581  3.2189  3.1781  3.1355  3.0910  3.0445
 2.9957  2.9444  2.8904  2.8332  2.7726  2.7081  2.6391  2.5649  2.4849  2.3979
 2.3026  2.1972  2.0794  1.9459  1.7918  1.6094  1.3863  1.0986  0.6931  0.0000
[ CPUFloatType{10,10} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb176"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb176-1"><a href="#cb176-1" aria-hidden="true" tabindex="-1"></a><span class="co"># g)    # Custom mean function</span></span>
<span id="cb176-2"><a href="#cb176-2" aria-hidden="true" tabindex="-1"></a>mean_Torch <span class="ot">=</span> <span class="cf">function</span>(y){</span>
<span id="cb176-3"><a href="#cb176-3" aria-hidden="true" tabindex="-1"></a>  result <span class="ot">=</span> <span class="fu">torch_sum</span>(y)</span>
<span id="cb176-4"><a href="#cb176-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>( result <span class="sc">/</span> <span class="fu">length</span>(y) )  <span class="co"># If y is an R object.</span></span>
<span id="cb176-5"><a href="#cb176-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb176-6"><a href="#cb176-6" aria-hidden="true" tabindex="-1"></a><span class="fu">mean_Torch</span>(y) <span class="sc">==</span> <span class="fu">mean</span>(y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 1
[ CPUBoolType{1} ]</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>::: {.callout-caution icon=“false”} #### Question: Runtime</p>
<ol type="1">
<li>What is the meaning of “An effect is not significant”?</li>
<li>Is an effect with three *** more significant / certain than an effect with one *?</li>
</ol>
<div class="webex-solution">
<button>
Click here to see the solution
</button>
<p>This exercise compares the speed of R to torch The first exercise is to rewrite the following function in torch:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb178"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb178-1"><a href="#cb178-1" aria-hidden="true" tabindex="-1"></a>do_something_R <span class="ot">=</span> <span class="cf">function</span>(<span class="at">x =</span> <span class="fu">matrix</span>(<span class="fl">0.0</span>, 10L, 10L)){</span>
<span id="cb178-2"><a href="#cb178-2" aria-hidden="true" tabindex="-1"></a>  mean_per_row <span class="ot">=</span> <span class="fu">apply</span>(x, <span class="dv">1</span>, mean)</span>
<span id="cb178-3"><a href="#cb178-3" aria-hidden="true" tabindex="-1"></a>  result <span class="ot">=</span> x <span class="sc">-</span> mean_per_row</span>
<span id="cb178-4"><a href="#cb178-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(result)</span>
<span id="cb178-5"><a href="#cb178-5" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here, we provide a skeleton for a TensorFlow function:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb179"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb179-1"><a href="#cb179-1" aria-hidden="true" tabindex="-1"></a>do_something_torch<span class="ot">=</span> <span class="cf">function</span>(<span class="at">x =</span> <span class="fu">matrix</span>(<span class="fl">0.0</span>, 10L, 10L)){</span>
<span id="cb179-2"><a href="#cb179-2" aria-hidden="true" tabindex="-1"></a>   ...</span>
<span id="cb179-3"><a href="#cb179-3" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can compare the speed using the Microbenchmark package:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb180"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb180-1"><a href="#cb180-1" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fl">0.0</span>, 100L, 100L)</span>
<span id="cb180-2"><a href="#cb180-2" aria-hidden="true" tabindex="-1"></a>microbenchmark<span class="sc">::</span><span class="fu">microbenchmark</span>(<span class="fu">do_something_R</span>(test), <span class="fu">do_something_torch</span>(test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Try different matrix sizes for the test matrix and compare the speed.</p>
<p>Tip: Have a look at the the torch_mean documentation and the “dim” argument.</p>
<p><br></p>
<p>Compare the following with different matrix sizes:</p>
<ul>
<li>test = matrix(0.0, 1000L, 500L)</li>
<li>testTorch = torch_tensor(test)</li>
</ul>
<p>Also try the following:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb181"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb181-1"><a href="#cb181-1" aria-hidden="true" tabindex="-1"></a>microbenchmark<span class="sc">::</span><span class="fu">microbenchmark</span>(</span>
<span id="cb181-2"><a href="#cb181-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">torch_matmul</span>(testTorch, testTorch<span class="sc">$</span><span class="fu">t</span>()), <span class="co"># Torch style.</span></span>
<span id="cb181-3"><a href="#cb181-3" aria-hidden="true" tabindex="-1"></a>   test <span class="sc">%*%</span> <span class="fu">t</span>(test)  <span class="co"># R style.</span></span>
<span id="cb181-4"><a href="#cb181-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="webex-solution">
<button>
Click here to see the solution
</button>
<div class="cell">
<div class="sourceCode cell-code" id="cb182"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb182-1"><a href="#cb182-1" aria-hidden="true" tabindex="-1"></a>do_something_torch <span class="ot">=</span> <span class="cf">function</span>(<span class="at">x =</span> <span class="fu">matrix</span>(<span class="fl">0.0</span>, 10L, 10L)){</span>
<span id="cb182-2"><a href="#cb182-2" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">=</span> <span class="fu">torch_tensor</span>(x)  <span class="co"># Remember, this is a local copy!</span></span>
<span id="cb182-3"><a href="#cb182-3" aria-hidden="true" tabindex="-1"></a>  mean_per_row <span class="ot">=</span> <span class="fu">torch_mean</span>(x, <span class="at">dim =</span> <span class="dv">1</span>)</span>
<span id="cb182-4"><a href="#cb182-4" aria-hidden="true" tabindex="-1"></a>  result <span class="ot">=</span> x <span class="sc">-</span> mean_per_row</span>
<span id="cb182-5"><a href="#cb182-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(result)</span>
<span id="cb182-6"><a href="#cb182-6" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb183"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb183-1"><a href="#cb183-1" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fl">0.0</span>, 100L, 100L)</span>
<span id="cb183-2"><a href="#cb183-2" aria-hidden="true" tabindex="-1"></a>microbenchmark<span class="sc">::</span><span class="fu">microbenchmark</span>(<span class="fu">do_something_R</span>(test), <span class="fu">do_something_torch</span>(test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Unit: microseconds
                     expr     min      lq     mean   median       uq      max
     do_something_R(test) 260.473 276.627 294.3796 283.3510 291.4280 1100.932
 do_something_torch(test)  63.591  70.602 125.7531  75.4195  83.7425 3764.866
 neval cld
   100  a 
   100   b</code></pre>
</div>
<div class="sourceCode cell-code" id="cb185"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb185-1"><a href="#cb185-1" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fl">0.0</span>, 1000L, 500L)</span>
<span id="cb185-2"><a href="#cb185-2" aria-hidden="true" tabindex="-1"></a>microbenchmark<span class="sc">::</span><span class="fu">microbenchmark</span>(<span class="fu">do_something_R</span>(test), <span class="fu">do_something_torch</span>(test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Unit: microseconds
                     expr      min       lq     mean   median       uq
     do_something_R(test) 5463.250 5757.138 7600.090 5965.705 9320.612
 do_something_torch(test)  944.517 1308.412 1737.009 1451.626 1690.041
       max neval cld
 28450.515   100  a 
  8954.482   100   b</code></pre>
</div>
</div>
<p>Why is R faster (the first time)?</p>
<ul>
<li><ol type="a">
<li>The R functions we used (apply, mean, “-”) are also implemented in C.</li>
</ol></li>
<li><ol start="2" type="a">
<li>The problem is not large enough and torch has an overhead.</li>
</ol></li>
</ul>
<p><br></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb187"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb187-1"><a href="#cb187-1" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fl">0.0</span>, 1000L, 500L)</span>
<span id="cb187-2"><a href="#cb187-2" aria-hidden="true" tabindex="-1"></a>testTorch <span class="ot">=</span> <span class="fu">torch_tensor</span>(test)</span>
<span id="cb187-3"><a href="#cb187-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-4"><a href="#cb187-4" aria-hidden="true" tabindex="-1"></a>microbenchmark<span class="sc">::</span><span class="fu">microbenchmark</span>(</span>
<span id="cb187-5"><a href="#cb187-5" aria-hidden="true" tabindex="-1"></a>   <span class="fu">torch_matmul</span>(testTorch, testTorch<span class="sc">$</span><span class="fu">t</span>()), <span class="co"># Torch style.</span></span>
<span id="cb187-6"><a href="#cb187-6" aria-hidden="true" tabindex="-1"></a>   test <span class="sc">%*%</span> <span class="fu">t</span>(test)  <span class="co"># R style.</span></span>
<span id="cb187-7"><a href="#cb187-7" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Unit: milliseconds
                                   expr        min         lq       mean
 torch_matmul(testTorch, testTorch$t())   1.053618   1.250398   1.690949
                       test %*% t(test) 163.971054 164.814608 169.907867
     median         uq        max neval cld
   1.384242   1.884298   5.823066   100  a 
 166.669326 169.065325 247.873946   100   b</code></pre>
</div>
</div>
</div>
<p>:::</p>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question: Linear Algebra
</div>
</div>
<div class="callout-body-container callout-body">
<p>Google to find out how to write the following tasks in torch:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb189"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb189-1"><a href="#cb189-1" aria-hidden="true" tabindex="-1"></a>A <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">3</span>), <span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb189-2"><a href="#cb189-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb189-3"><a href="#cb189-3" aria-hidden="true" tabindex="-1"></a><span class="co"># i)</span></span>
<span id="cb189-4"><a href="#cb189-4" aria-hidden="true" tabindex="-1"></a><span class="fu">solve</span>(A)  <span class="co"># Solve equation AX = B. If just A  is given, invert it.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2]       [,3]
[1,]    1  0.0 -0.6666667
[2,]   -1  0.5 -0.1666667
[3,]    0  0.0  0.3333333</code></pre>
</div>
<div class="sourceCode cell-code" id="cb191"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb191-1"><a href="#cb191-1" aria-hidden="true" tabindex="-1"></a><span class="co"># j)</span></span>
<span id="cb191-2"><a href="#cb191-2" aria-hidden="true" tabindex="-1"></a><span class="fu">diag</span>(A) <span class="co"># Diagonal of A, if no matrix is given, construct diagonal matrix.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1 2 3</code></pre>
</div>
<div class="sourceCode cell-code" id="cb193"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb193-1"><a href="#cb193-1" aria-hidden="true" tabindex="-1"></a><span class="co"># k)</span></span>
<span id="cb193-2"><a href="#cb193-2" aria-hidden="true" tabindex="-1"></a><span class="fu">diag</span>(<span class="fu">diag</span>(A)) <span class="co"># Diagonal matrix with entries diag(A).</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2] [,3]
[1,]    1    0    0
[2,]    0    2    0
[3,]    0    0    3</code></pre>
</div>
<div class="sourceCode cell-code" id="cb195"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb195-1"><a href="#cb195-1" aria-hidden="true" tabindex="-1"></a><span class="co"># l)</span></span>
<span id="cb195-2"><a href="#cb195-2" aria-hidden="true" tabindex="-1"></a><span class="fu">eigen</span>(A)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>eigen() decomposition
$values
[1] 3 2 1

$vectors
          [,1] [,2]       [,3]
[1,] 0.1400280    0  0.4472136
[2,] 0.9801961    1 -0.8944272
[3,] 0.1400280    0  0.0000000</code></pre>
</div>
<div class="sourceCode cell-code" id="cb197"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb197-1"><a href="#cb197-1" aria-hidden="true" tabindex="-1"></a><span class="co"># m)</span></span>
<span id="cb197-2"><a href="#cb197-2" aria-hidden="true" tabindex="-1"></a><span class="fu">det</span>(A)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 6</code></pre>
</div>
</div>
<div class="webex-solution">
<button>
Click here to see the solution
</button>
<div class="cell">
<div class="sourceCode cell-code" id="cb199"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb199-1"><a href="#cb199-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb199-2"><a href="#cb199-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb199-3"><a href="#cb199-3" aria-hidden="true" tabindex="-1"></a>A <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="fl">1.</span>, <span class="fl">2.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">2.</span>, <span class="fl">0.</span>, <span class="fl">2.</span>, <span class="fl">5.</span>, <span class="fl">3.</span>), <span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb199-4"><a href="#cb199-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Do not use the "L" form here!</span></span>
<span id="cb199-5"><a href="#cb199-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb199-6"><a href="#cb199-6" aria-hidden="true" tabindex="-1"></a><span class="co"># i)    solve(A)</span></span>
<span id="cb199-7"><a href="#cb199-7" aria-hidden="true" tabindex="-1"></a><span class="fu">linalg_inv</span>(A)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 1.0000 -0.0000 -0.6667
-1.0000  0.5000 -0.1667
 0.0000  0.0000  0.3333
[ CPUFloatType{3,3} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb201"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb201-1"><a href="#cb201-1" aria-hidden="true" tabindex="-1"></a><span class="co"># j)    diag(A)</span></span>
<span id="cb201-2"><a href="#cb201-2" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_diag</span>(A)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 1
 2
 3
[ CPUFloatType{3} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb203"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb203-1"><a href="#cb203-1" aria-hidden="true" tabindex="-1"></a><span class="co"># k)    diag(diag(A))</span></span>
<span id="cb203-2"><a href="#cb203-2" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_diag</span>(A)<span class="sc">$</span><span class="fu">diag</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 1  0  0
 0  2  0
 0  0  3
[ CPUFloatType{3,3} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb205"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb205-1"><a href="#cb205-1" aria-hidden="true" tabindex="-1"></a><span class="co"># l)    eigen(A)</span></span>
<span id="cb205-2"><a href="#cb205-2" aria-hidden="true" tabindex="-1"></a><span class="fu">linalg_eigh</span>(A)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[1]]
torch_tensor
-0.5616
 3.0000
 3.5616
[ CPUFloatType{3} ]

[[2]]
torch_tensor
-0.7882  0.0000  0.6154
 0.6154  0.0000  0.7882
 0.0000  1.0000  0.0000
[ CPUFloatType{3,3} ]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb207"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb207-1"><a href="#cb207-1" aria-hidden="true" tabindex="-1"></a><span class="co"># m)    det(A)</span></span>
<span id="cb207-2"><a href="#cb207-2" aria-hidden="true" tabindex="-1"></a><span class="fu">linalg_det</span>(A)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
6
[ CPUFloatType{} ]</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Question: Automatic differentation
</div>
</div>
<div class="callout-body-container callout-body">
<p>Torch supports automatic differentiation (analytical and not numerical!). Let’s have a look at the function <span class="math inline">\(f(x) = 5 x^2 + 3\)</span> with derivative <span class="math inline">\(f'(x) = 10x\)</span>. So for <span class="math inline">\(f'(5)\)</span> we will get <span class="math inline">\(10\)</span>.</p>
<p>Let’s do this in torch Define the function:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb209"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb209-1"><a href="#cb209-1" aria-hidden="true" tabindex="-1"></a>f <span class="ot">=</span> <span class="cf">function</span>(x){ <span class="fu">return</span>(<span class="fl">5.0</span> <span class="sc">*</span> <span class="fu">torch_pow</span>(x, <span class="fl">2.</span>) <span class="sc">+</span> <span class="fl">3.0</span>) }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We want to calculate the derivative for <span class="math inline">\(x = 2.0\)</span>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb210"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb210-1"><a href="#cb210-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fl">2.0</span>, <span class="at">requires_grad =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To do automatic differentiation, we have to forward <span class="math inline">\(x\)</span> through the function and call the $backward() method of the result:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb211"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb211-1"><a href="#cb211-1" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">f</span>(x)</span>
<span id="cb211-2"><a href="#cb211-2" aria-hidden="true" tabindex="-1"></a>y<span class="sc">$</span><span class="fu">backward</span>(<span class="at">retain_graph=</span><span class="cn">TRUE</span> )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To print the gradient:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb212"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb212-1"><a href="#cb212-1" aria-hidden="true" tabindex="-1"></a>x<span class="sc">$</span>grad</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 20
[ CPUFloatType{1} ]</code></pre>
</div>
</div>
<p>We can also calculate the second order derivative <span class="math inline">\(f''(x) = 10\)</span>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb214"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb214-1"><a href="#cb214-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fl">2.0</span>, <span class="at">requires_grad =</span> <span class="cn">TRUE</span>)</span>
<span id="cb214-2"><a href="#cb214-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">f</span>(x)</span>
<span id="cb214-3"><a href="#cb214-3" aria-hidden="true" tabindex="-1"></a>grad <span class="ot">=</span> torch<span class="sc">::</span><span class="fu">autograd_grad</span>(y, x, <span class="at">retain_graph =</span> <span class="cn">TRUE</span>, <span class="at">create_graph =</span> <span class="cn">TRUE</span>)[[<span class="dv">1</span>]] <span class="co"># first</span></span>
<span id="cb214-4"><a href="#cb214-4" aria-hidden="true" tabindex="-1"></a>(torch<span class="sc">::</span><span class="fu">autograd_grad</span>(grad, x, <span class="at">retain_graph =</span> <span class="cn">TRUE</span>, <span class="at">create_graph =</span> <span class="cn">TRUE</span>)[[<span class="dv">1</span>]]) <span class="co"># second</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch_tensor
 10
[ CPUFloatType{1} ][ grad_fn = &lt;MulBackward0&gt; ]</code></pre>
</div>
</div>
<p>What is happening here? Think about and discuss it.</p>
<p>A more advanced example: <em>Linear regression</em></p>
<p>In this case we first simulate data following <span class="math inline">\(\boldsymbol{y} = \boldsymbol{X} \boldsymbol{w} + \boldsymbol{\epsilon}\)</span> (<span class="math inline">\(\boldsymbol{\epsilon}\)</span> follows a normal distribution == error).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb216"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb216-1"><a href="#cb216-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R's random seed.</span></span>
<span id="cb216-2"><a href="#cb216-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb216-3"><a href="#cb216-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">round</span>(<span class="fu">runif</span>(<span class="dv">500</span>, <span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>), <span class="dv">3</span>), <span class="dv">100</span>, <span class="dv">5</span>)</span>
<span id="cb216-4"><a href="#cb216-4" aria-hidden="true" tabindex="-1"></a>w <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="dv">5</span>, <span class="dv">2</span>, <span class="dv">1</span>), <span class="dv">3</span>)</span>
<span id="cb216-5"><a href="#cb216-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> x <span class="sc">%*%</span> w <span class="sc">+</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="dv">0</span>, <span class="fl">0.25</span>), <span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In R we would do the following to fit a linear regression model:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb217"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb217-1"><a href="#cb217-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ x)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.67893 -0.16399  0.00968  0.15058  0.51099 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 0.004865   0.027447   0.177     0.86    
x1          2.191511   0.023243  94.287   &lt;2e-16 ***
x2          2.741690   0.025328 108.249   &lt;2e-16 ***
x3          1.179181   0.023644  49.872   &lt;2e-16 ***
x4          0.591873   0.025154  23.530   &lt;2e-16 ***
x5          2.302417   0.022575 101.991   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.2645 on 94 degrees of freedom
Multiple R-squared:  0.9974,    Adjusted R-squared:  0.9972 
F-statistic:  7171 on 5 and 94 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>Let’s build our own model in TensorFlow. Here, we use now the variable data container type (remember they are mutable and we need this type for the weights (<span class="math inline">\(\boldsymbol{w}\)</span>) of the regression model). We want our model to learn these weights.</p>
<p>The input (predictors, independent variables or features, <span class="math inline">\(\boldsymbol{X}\)</span>) and the observed (response, <span class="math inline">\(\boldsymbol{y}\)</span>) are constant and will not be learned/optimized.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb219"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb219-1"><a href="#cb219-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb219-2"><a href="#cb219-2" aria-hidden="true" tabindex="-1"></a>torch<span class="sc">::</span><span class="fu">torch_manual_seed</span>(42L)</span>
<span id="cb219-3"><a href="#cb219-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb219-4"><a href="#cb219-4" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">round</span>(<span class="fu">runif</span>(<span class="dv">500</span>, <span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>), <span class="dv">3</span>), <span class="dv">100</span>, <span class="dv">5</span>)</span>
<span id="cb219-5"><a href="#cb219-5" aria-hidden="true" tabindex="-1"></a>w <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="dv">5</span>, <span class="dv">2</span>, <span class="dv">1</span>), <span class="dv">3</span>)</span>
<span id="cb219-6"><a href="#cb219-6" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> x <span class="sc">%*%</span> w <span class="sc">+</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="dv">0</span>, <span class="fl">0.25</span>), <span class="dv">4</span>)</span>
<span id="cb219-7"><a href="#cb219-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb219-8"><a href="#cb219-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Weights we want to learn.</span></span>
<span id="cb219-9"><a href="#cb219-9" aria-hidden="true" tabindex="-1"></a><span class="co"># We know the real weights but in reality we wouldn't know them.</span></span>
<span id="cb219-10"><a href="#cb219-10" aria-hidden="true" tabindex="-1"></a><span class="co"># So use guessed ones.</span></span>
<span id="cb219-11"><a href="#cb219-11" aria-hidden="true" tabindex="-1"></a>wTorch <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="dv">5</span>, <span class="dv">0</span>, <span class="fl">0.01</span>), <span class="dv">5</span>, <span class="dv">1</span>), <span class="at">requires_grad =</span> <span class="cn">TRUE</span>)</span>
<span id="cb219-12"><a href="#cb219-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb219-13"><a href="#cb219-13" aria-hidden="true" tabindex="-1"></a>xTorch <span class="ot">=</span> <span class="fu">torch_tensor</span>(x)</span>
<span id="cb219-14"><a href="#cb219-14" aria-hidden="true" tabindex="-1"></a>yTorch <span class="ot">=</span> <span class="fu">torch_tensor</span>(y)</span>
<span id="cb219-15"><a href="#cb219-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb219-16"><a href="#cb219-16" aria-hidden="true" tabindex="-1"></a><span class="co"># We need an optimizer which updates the weights (wTF).</span></span>
<span id="cb219-17"><a href="#cb219-17" aria-hidden="true" tabindex="-1"></a>optimizer <span class="ot">=</span> <span class="fu">optim_adam</span>(<span class="at">params =</span> <span class="fu">list</span>(wTorch), <span class="at">lr =</span> <span class="fl">0.1</span>)</span>
<span id="cb219-18"><a href="#cb219-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb219-19"><a href="#cb219-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>){</span>
<span id="cb219-20"><a href="#cb219-20" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">=</span> xTorch<span class="sc">$</span><span class="fu">matmul</span>(wTorch)</span>
<span id="cb219-21"><a href="#cb219-21" aria-hidden="true" tabindex="-1"></a>  loss <span class="ot">=</span> (yTorch <span class="sc">-</span> pred)<span class="sc">$</span><span class="fu">pow</span>(<span class="fl">2.0</span>)<span class="sc">$</span><span class="fu">mean</span>()<span class="sc">$</span><span class="fu">sqrt</span>()</span>
<span id="cb219-22"><a href="#cb219-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb219-23"><a href="#cb219-23" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="sc">!</span>i<span class="sc">%%</span><span class="dv">10</span>){ <span class="fu">print</span>(<span class="fu">paste0</span>(<span class="st">"Loss: "</span>, <span class="fu">as.numeric</span>(loss)))}  <span class="co"># Every 10 times.</span></span>
<span id="cb219-24"><a href="#cb219-24" aria-hidden="true" tabindex="-1"></a>  loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb219-25"><a href="#cb219-25" aria-hidden="true" tabindex="-1"></a>  optimizer<span class="sc">$</span><span class="fu">step</span>() <span class="co"># do optimization step</span></span>
<span id="cb219-26"><a href="#cb219-26" aria-hidden="true" tabindex="-1"></a>  optimizer<span class="sc">$</span><span class="fu">zero_grad</span>() <span class="co"># reset gradients</span></span>
<span id="cb219-27"><a href="#cb219-27" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Loss: 4.4065318107605"
[1] "Loss: 2.37926030158997"
[1] "Loss: 0.901207685470581"
[1] "Loss: 0.403193712234497"
[1] "Loss: 0.296265542507172"
[1] "Loss: 0.268377959728241"
[1] "Loss: 0.232994809746742"
[1] "Loss: 0.219554677605629"
[1] "Loss: 0.215328559279442"
[1] "Loss: 0.213282078504562"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb221"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb221-1"><a href="#cb221-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Inferred weights: "</span>, <span class="fu">round</span>(<span class="fu">as.numeric</span>(wTorch), <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Inferred weights:  0.701 3.089 1.801 1.123 3.452 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb223"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb223-1"><a href="#cb223-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Original weights: "</span>, w, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Original weights:  0.67 3.085 1.787 1.121 3.455 </code></pre>
</div>
</div>
<p>Discuss the code, go through the code line by line and try to understand it.</p>
<p>Additional exercise:</p>
<p>Play around with the simulation, increase/decrease the number of weights, add an intercept (you also need an additional variable in model).</p>
<div class="webex-solution">
<button>
Click here to see the solution
</button>
<div class="cell">
<div class="sourceCode cell-code" id="cb225"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb225-1"><a href="#cb225-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb225-2"><a href="#cb225-2" aria-hidden="true" tabindex="-1"></a>torch<span class="sc">::</span><span class="fu">torch_manual_seed</span>(42L)</span>
<span id="cb225-3"><a href="#cb225-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb225-4"><a href="#cb225-4" aria-hidden="true" tabindex="-1"></a>numberOfWeights <span class="ot">=</span> <span class="dv">3</span></span>
<span id="cb225-5"><a href="#cb225-5" aria-hidden="true" tabindex="-1"></a>numberOfFeatures <span class="ot">=</span> <span class="dv">10000</span></span>
<span id="cb225-6"><a href="#cb225-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb225-7"><a href="#cb225-7" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">round</span>(<span class="fu">runif</span>(numberOfFeatures <span class="sc">*</span> numberOfWeights, <span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>), <span class="dv">3</span>),</span>
<span id="cb225-8"><a href="#cb225-8" aria-hidden="true" tabindex="-1"></a>           numberOfFeatures, numberOfWeights)</span>
<span id="cb225-9"><a href="#cb225-9" aria-hidden="true" tabindex="-1"></a>w <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(numberOfWeights, <span class="dv">2</span>, <span class="dv">1</span>), <span class="dv">3</span>)</span>
<span id="cb225-10"><a href="#cb225-10" aria-hidden="true" tabindex="-1"></a>intercept <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="dv">1</span>, <span class="dv">3</span>, .<span class="dv">5</span>), <span class="dv">3</span>)</span>
<span id="cb225-11"><a href="#cb225-11" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> intercept <span class="sc">+</span> x <span class="sc">%*%</span> w <span class="sc">+</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(numberOfFeatures, <span class="dv">0</span>, <span class="fl">0.25</span>), <span class="dv">4</span>)</span>
<span id="cb225-12"><a href="#cb225-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb225-13"><a href="#cb225-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Guessed weights and intercept.</span></span>
<span id="cb225-14"><a href="#cb225-14" aria-hidden="true" tabindex="-1"></a>wTorch <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fu">matrix</span>(<span class="fu">rnorm</span>(numberOfWeights, <span class="dv">0</span>, <span class="fl">0.01</span>), numberOfWeights, <span class="dv">1</span>), <span class="at">requires_grad =</span> <span class="cn">TRUE</span>)</span>
<span id="cb225-15"><a href="#cb225-15" aria-hidden="true" tabindex="-1"></a>interceptTorch <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="dv">1</span>, <span class="dv">0</span>, .<span class="dv">5</span>), <span class="dv">1</span>, <span class="dv">1</span>), <span class="at">requires_grad =</span> <span class="cn">TRUE</span>) <span class="co"># Double, not float32.</span></span>
<span id="cb225-16"><a href="#cb225-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb225-17"><a href="#cb225-17" aria-hidden="true" tabindex="-1"></a>xTorch <span class="ot">=</span> <span class="fu">torch_tensor</span>(x)</span>
<span id="cb225-18"><a href="#cb225-18" aria-hidden="true" tabindex="-1"></a>yTorch <span class="ot">=</span> <span class="fu">torch_tensor</span>(y)</span>
<span id="cb225-19"><a href="#cb225-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb225-20"><a href="#cb225-20" aria-hidden="true" tabindex="-1"></a><span class="co"># We need an optimizer which updates the weights (wTF).</span></span>
<span id="cb225-21"><a href="#cb225-21" aria-hidden="true" tabindex="-1"></a>optimizer <span class="ot">=</span> <span class="fu">optim_adam</span>(<span class="at">params =</span> <span class="fu">list</span>(wTorch, interceptTorch), <span class="at">lr =</span> <span class="fl">0.1</span>)</span>
<span id="cb225-22"><a href="#cb225-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb225-23"><a href="#cb225-23" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>){</span>
<span id="cb225-24"><a href="#cb225-24" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">=</span> xTorch<span class="sc">$</span><span class="fu">matmul</span>(wTorch)<span class="sc">$</span><span class="fu">add</span>(interceptTorch)</span>
<span id="cb225-25"><a href="#cb225-25" aria-hidden="true" tabindex="-1"></a>  loss <span class="ot">=</span> (yTorch <span class="sc">-</span> pred)<span class="sc">$</span><span class="fu">pow</span>(<span class="fl">2.0</span>)<span class="sc">$</span><span class="fu">mean</span>()<span class="sc">$</span><span class="fu">sqrt</span>()</span>
<span id="cb225-26"><a href="#cb225-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb225-27"><a href="#cb225-27" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="sc">!</span>i<span class="sc">%%</span><span class="dv">10</span>){ <span class="fu">print</span>(<span class="fu">paste0</span>(<span class="st">"Loss: "</span>, <span class="fu">as.numeric</span>(loss)))}  <span class="co"># Every 10 times.</span></span>
<span id="cb225-28"><a href="#cb225-28" aria-hidden="true" tabindex="-1"></a>  loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb225-29"><a href="#cb225-29" aria-hidden="true" tabindex="-1"></a>  optimizer<span class="sc">$</span><span class="fu">step</span>() <span class="co"># do optimization step</span></span>
<span id="cb225-30"><a href="#cb225-30" aria-hidden="true" tabindex="-1"></a>  optimizer<span class="sc">$</span><span class="fu">zero_grad</span>() <span class="co"># reset gradients</span></span>
<span id="cb225-31"><a href="#cb225-31" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Loss: 3.51533484458923"
[1] "Loss: 1.74870145320892"
[1] "Loss: 0.41416934132576"
[1] "Loss: 0.518697261810303"
[1] "Loss: 0.293963462114334"
[1] "Loss: 0.263338804244995"
[1] "Loss: 0.258341491222382"
[1] "Loss: 0.254723280668259"
[1] "Loss: 0.252453774213791"
[1] "Loss: 0.25116890668869"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb227"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb227-1"><a href="#cb227-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Inferred weights: "</span>, <span class="fu">round</span>(<span class="fu">as.numeric</span>(wTorch), <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Inferred weights:  3.118 -0.349 2.107 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb229"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb229-1"><a href="#cb229-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Original weights: "</span>, w, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Original weights:  3.131 -0.353 2.11 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb231"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb231-1"><a href="#cb231-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Inferred intercept: "</span>, <span class="fu">round</span>(<span class="fu">as.numeric</span>(interceptTorch), <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Inferred intercept:  2.836 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb233"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb233-1"><a href="#cb233-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Original intercept: "</span>, intercept, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Original intercept:  2.832 </code></pre>
</div>
</div>
</div>
</div>
</div>
</div></section>
</section>
<section id="kerastorch-framework" class="level2" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="kerastorch-framework"><span class="header-section-number">8.3</span> Keras/Torch Framework</h2>
<p>We have seen that we can use TensorFlow directly out of R, and we could use this knowledge to implement a neural network in TensorFlow directly in R. However, this can be quite cumbersome. For simple problems, it is usually faster to use a higher-level API that helps us with implementing the machine learning models in TensorFlow. The most common of those is Keras.</p>
<p>Keras is a powerful framework for building and training neural networks with a few lines of codes. Since the end of 2018, Keras and TensorFlow are completely interoperable, allowing us to utilize the best of both.</p>
<p>The objective of this lesson is to familiarize yourself with Keras. If you have installed TensorFlow, Keras can be found within TensorFlow: tf.keras. However, the RStudio team has built an R package on top of tf.keras, and it is more convenient to use this. To load the Keras package, type</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb235"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb235-1"><a href="#cb235-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb235-2"><a href="#cb235-2" aria-hidden="true" tabindex="-1"></a><span class="co"># or library(torch)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="example-workflow-in-keras-torch" class="level3" data-number="8.3.1">
<h3 data-number="8.3.1" class="anchored" data-anchor-id="example-workflow-in-keras-torch"><span class="header-section-number">8.3.1</span> Example workflow in Keras / Torch</h3>
<p>To show how Keras works, we will now build a small classifier to predict the three species of the iris data set. Load the necessary packages and data sets:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb236"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb236-1"><a href="#cb236-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb236-2"><a href="#cb236-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb236-3"><a href="#cb236-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb236-4"><a href="#cb236-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R's random seed.</span></span>
<span id="cb236-5"><a href="#cb236-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb236-6"><a href="#cb236-6" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(iris)</span>
<span id="cb236-7"><a href="#cb236-7" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(iris)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  Sepal.Length Sepal.Width Petal.Length Petal.Width Species
1          5.1         3.5          1.4         0.2  setosa
2          4.9         3.0          1.4         0.2  setosa
3          4.7         3.2          1.3         0.2  setosa
4          4.6         3.1          1.5         0.2  setosa
5          5.0         3.6          1.4         0.2  setosa
6          5.4         3.9          1.7         0.4  setosa</code></pre>
</div>
</div>
<p>For neural networks, it is beneficial to scale the predictors (scaling = centering and standardization, see ?scale). We also split our data into predictors (X) and response (Y = the three species).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb238"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb238-1"><a href="#cb238-1" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">scale</span>(iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span>
<span id="cb238-2"><a href="#cb238-2" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span> iris[,<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Additionally, Keras/TensorFlow cannot handle factors and we have to create contrasts (one-hot encoding). To do so, we have to specify the number of categories. This can be tricky for a beginner, because in other programming languages like Python and C++, arrays start at zero. Thus, when we would specify 3 as number of classes for our three species, we would have the classes 0,1,2,3. Keep this in mind.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb239"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb239-1"><a href="#cb239-1" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span> <span class="fu">to_categorical</span>(<span class="fu">as.integer</span>(Y) <span class="sc">-</span> 1L, <span class="dv">3</span>)</span>
<span id="cb239-2"><a href="#cb239-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(Y) <span class="co"># 3 columns, one for each level of the response.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2] [,3]
[1,]    1    0    0
[2,]    1    0    0
[3,]    1    0    0
[4,]    1    0    0
[5,]    1    0    0
[6,]    1    0    0</code></pre>
</div>
</div>
<p>After having prepared the data, we will now see a typical workflow to specify a model in Keras/Torch.</p>
<p><strong>1. Initialize a sequential model in Keras:</strong></p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true" aria-current="page">Keras</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">Torch</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb241"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb241-1"><a href="#cb241-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<p>Torch users can skip this step.</p>
</div>
</div>
</div>
<p>A sequential Keras model is a higher order type of model within Keras and consists of one input and one output model.</p>
<p><strong>2. Add hidden layers to the model (we will learn more about hidden layers during the next days).</strong></p>
<p>When specifying the hidden layers, we also have to specify the shape and a so called <em>activation function</em>. You can think of the activation function as decision for what is forwarded to the next neuron (but we will learn more about it later). If you want to know this topic in even more depth, consider watching the videos presented in section @ref(basicMath).</p>
<p>The shape of the input is the number of predictors (here 4) and the shape of the output is the number of classes (here 3).</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true">Keras</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false">Torch</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb242"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb242-1"><a href="#cb242-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb242-2"><a href="#cb242-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">"relu"</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(4L)) <span class="sc">%&gt;%</span></span>
<span id="cb242-3"><a href="#cb242-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L) <span class="sc">%&gt;%</span></span>
<span id="cb242-4"><a href="#cb242-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L) <span class="sc">%&gt;%</span></span>
<span id="cb242-5"><a href="#cb242-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 3L, <span class="at">activation =</span> <span class="st">"softmax"</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<p>The Torch syntax is very similar, we will give a list of layers to the “nn_sequential” function. Here, we have to specify the softmax activation function as an extra layer:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb243"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb243-1"><a href="#cb243-1" aria-hidden="true" tabindex="-1"></a>model_torch <span class="ot">=</span> </span>
<span id="cb243-2"><a href="#cb243-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_sequential</span>(</span>
<span id="cb243-3"><a href="#cb243-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(4L, 20L),</span>
<span id="cb243-4"><a href="#cb243-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 20L),</span>
<span id="cb243-5"><a href="#cb243-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 20L),</span>
<span id="cb243-6"><a href="#cb243-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 3L),</span>
<span id="cb243-7"><a href="#cb243-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_softmax</span>(<span class="dv">2</span>)</span>
<span id="cb243-8"><a href="#cb243-8" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<ul>
<li>softmax scales a potential multidimensional vector to the interval <span class="math inline">\((0, 1]\)</span> for each component. The sum of all components equals 1. This might be very useful for example for handling probabilities. <strong>Ensure ther the labels start at 0! Otherwise the softmax function does not work well!</strong></li>
</ul>
<p><strong>3. Compile the model with a loss function (here: cross entropy) and an optimizer (here: Adamax).</strong></p>
<p>We will learn about other options later, so for now, do not worry about the “<strong>learning_rate</strong>” (“<strong>lr</strong>” in Torch or earlier in TensorFlow) argument, cross entropy or the optimizer.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true">Keras</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false">Torch</a></li></ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb244"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb244-1"><a href="#cb244-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb244-2"><a href="#cb244-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb244-3"><a href="#cb244-3" aria-hidden="true" tabindex="-1"></a>          keras<span class="sc">::</span><span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.001</span>))</span>
<span id="cb244-4"><a href="#cb244-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential"
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_3 (Dense)                    (None, 20)                      100         
 dense_2 (Dense)                    (None, 20)                      420         
 dense_1 (Dense)                    (None, 20)                      420         
 dense (Dense)                      (None, 3)                       63          
================================================================================
Total params: 1,003
Trainable params: 1,003
Non-trainable params: 0
________________________________________________________________________________</code></pre>
</div>
</div>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<p>Specify optimizer and the parameters which will be trained (in our case the parameters of the network):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb246"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb246-1"><a href="#cb246-1" aria-hidden="true" tabindex="-1"></a>optimizer_torch <span class="ot">=</span> <span class="fu">optim_adam</span>(<span class="at">params =</span> model_torch<span class="sc">$</span>parameters, <span class="at">lr =</span> <span class="fl">0.001</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<p><strong>4. Fit model in 30 iterations (epochs)</strong></p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-4-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-1" role="tab" aria-controls="tabset-4-1" aria-selected="true">Keras</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-2" role="tab" aria-controls="tabset-4-2" aria-selected="false">Torch</a></li></ul>
<div class="tab-content">
<div id="tabset-4-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-4-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb247"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb247-1"><a href="#cb247-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb247-2"><a href="#cb247-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb247-3"><a href="#cb247-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R's random seed.</span></span>
<span id="cb247-4"><a href="#cb247-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb247-5"><a href="#cb247-5" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb247-6"><a href="#cb247-6" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb247-7"><a href="#cb247-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> <span class="fu">apply</span>(Y, <span class="dv">2</span>, as.integer), <span class="at">epochs =</span> 30L,</span>
<span id="cb247-8"><a href="#cb247-8" aria-hidden="true" tabindex="-1"></a>        <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-4-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-2-tab">
<p>In Torch, we jump directly to the training loop, however, here we have to write our own training loop:</p>
<ol type="1">
<li>Get a batch of data.</li>
<li>Predict on batch.</li>
<li>Ccalculate loss between predictions and true labels.</li>
<li>Backpropagate error.</li>
<li>Update weights.</li>
<li>Go to step 1 and repeat.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb248"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb248-1"><a href="#cb248-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb248-2"><a href="#cb248-2" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_manual_seed</span>(321L)</span>
<span id="cb248-3"><a href="#cb248-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb248-4"><a href="#cb248-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb248-5"><a href="#cb248-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate number of training steps.</span></span>
<span id="cb248-6"><a href="#cb248-6" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> <span class="dv">30</span></span>
<span id="cb248-7"><a href="#cb248-7" aria-hidden="true" tabindex="-1"></a>batch_size <span class="ot">=</span> <span class="dv">20</span></span>
<span id="cb248-8"><a href="#cb248-8" aria-hidden="true" tabindex="-1"></a>steps <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">nrow</span>(X)<span class="sc">/</span>batch_size <span class="sc">*</span> epochs)</span>
<span id="cb248-9"><a href="#cb248-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb248-10"><a href="#cb248-10" aria-hidden="true" tabindex="-1"></a>X_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(X)</span>
<span id="cb248-11"><a href="#cb248-11" aria-hidden="true" tabindex="-1"></a>Y_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fu">apply</span>(Y, <span class="dv">1</span>, which.max)) </span>
<span id="cb248-12"><a href="#cb248-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb248-13"><a href="#cb248-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Set model into training status.</span></span>
<span id="cb248-14"><a href="#cb248-14" aria-hidden="true" tabindex="-1"></a>model_torch<span class="sc">$</span><span class="fu">train</span>()</span>
<span id="cb248-15"><a href="#cb248-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb248-16"><a href="#cb248-16" aria-hidden="true" tabindex="-1"></a>log_losses <span class="ot">=</span> <span class="cn">NULL</span></span>
<span id="cb248-17"><a href="#cb248-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb248-18"><a href="#cb248-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Training loop.</span></span>
<span id="cb248-19"><a href="#cb248-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>steps){</span>
<span id="cb248-20"><a href="#cb248-20" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Get batch.</span></span>
<span id="cb248-21"><a href="#cb248-21" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(X), batch_size)</span>
<span id="cb248-22"><a href="#cb248-22" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb248-23"><a href="#cb248-23" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Reset backpropagation.</span></span>
<span id="cb248-24"><a href="#cb248-24" aria-hidden="true" tabindex="-1"></a>  optimizer_torch<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb248-25"><a href="#cb248-25" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb248-26"><a href="#cb248-26" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Predict and calculate loss.</span></span>
<span id="cb248-27"><a href="#cb248-27" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">=</span> <span class="fu">model_torch</span>(X_torch[indices, ])</span>
<span id="cb248-28"><a href="#cb248-28" aria-hidden="true" tabindex="-1"></a>  loss <span class="ot">=</span> <span class="fu">nnf_cross_entropy</span>(pred, Y_torch[indices])</span>
<span id="cb248-29"><a href="#cb248-29" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb248-30"><a href="#cb248-30" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Backpropagation and weight update.</span></span>
<span id="cb248-31"><a href="#cb248-31" aria-hidden="true" tabindex="-1"></a>  loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb248-32"><a href="#cb248-32" aria-hidden="true" tabindex="-1"></a>  optimizer_torch<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb248-33"><a href="#cb248-33" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb248-34"><a href="#cb248-34" aria-hidden="true" tabindex="-1"></a>  log_losses[i] <span class="ot">=</span> <span class="fu">as.numeric</span>(loss)</span>
<span id="cb248-35"><a href="#cb248-35" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<p><strong>5. Plot training history:</strong></p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-5-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-1" role="tab" aria-controls="tabset-5-1" aria-selected="true">Keras</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-2" role="tab" aria-controls="tabset-5-2" aria-selected="false">Torch</a></li></ul>
<div class="tab-content">
<div id="tabset-5-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-5-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb249"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb249-1"><a href="#cb249-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C1-TensorFlow_files/figure-html/chunk_chapter3_72-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</div>
<div id="tabset-5-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb250"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb250-1"><a href="#cb250-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(log_losses, <span class="at">xlab =</span> <span class="st">"steps"</span>, <span class="at">ylab =</span> <span class="st">"loss"</span>, <span class="at">las =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C1-TensorFlow_files/figure-html/chunk_chapter3_73-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</div>
</div>
</div>
<p><strong>6. Create predictions:</strong></p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-6-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-1" role="tab" aria-controls="tabset-6-1" aria-selected="true">Keras</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-6-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-2" role="tab" aria-controls="tabset-6-2" aria-selected="false">Torch</a></li></ul>
<div class="tab-content">
<div id="tabset-6-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-6-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb251"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb251-1"><a href="#cb251-1" aria-hidden="true" tabindex="-1"></a>predictions <span class="ot">=</span> <span class="fu">predict</span>(model, X) <span class="co"># Probabilities for each class.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Get probabilities:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb252"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb252-1"><a href="#cb252-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(predictions) <span class="co"># Quasi-probabilities for each species.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          [,1]        [,2]         [,3]
[1,] 0.9915600 0.006817889 0.0016221496
[2,] 0.9584184 0.037489697 0.0040918575
[3,] 0.9910416 0.007848956 0.0011094128
[4,] 0.9813542 0.016901711 0.0017440914
[5,] 0.9949830 0.004031503 0.0009855649
[6,] 0.9905725 0.006884387 0.0025430375</code></pre>
</div>
</div>
<p>For each plant, we want to know for which species we got the highest probability:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb254"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb254-1"><a href="#cb254-1" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">=</span> <span class="fu">apply</span>(predictions, <span class="dv">1</span>, which.max) </span>
<span id="cb254-2"><a href="#cb254-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(preds)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [38] 1 1 1 1 2 1 1 1 1 1 1 1 1 3 3 3 2 2 2 3 2 2 2 2 2 2 2 2 3 2 2 2 2 3 2 2 2
 [75] 2 2 2 3 2 2 2 2 2 2 2 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 2 3 3 3 3
[112] 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3
[149] 3 3</code></pre>
</div>
</div>
</div>
<div id="tabset-6-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-6-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb256"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb256-1"><a href="#cb256-1" aria-hidden="true" tabindex="-1"></a>model_torch<span class="sc">$</span><span class="fu">eval</span>()</span>
<span id="cb256-2"><a href="#cb256-2" aria-hidden="true" tabindex="-1"></a>preds_torch <span class="ot">=</span> <span class="fu">model_torch</span>(<span class="fu">torch_tensor</span>(X))</span>
<span id="cb256-3"><a href="#cb256-3" aria-hidden="true" tabindex="-1"></a>preds_torch <span class="ot">=</span> <span class="fu">apply</span>(preds_torch, <span class="dv">1</span>, which.max) </span>
<span id="cb256-4"><a href="#cb256-4" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(preds_torch)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2
 [75] 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3
[112] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3
[149] 3 3</code></pre>
</div>
</div>
</div>
</div>
</div>
<p><strong>7. Calculate Accuracy (how often we have been correct):</strong></p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-7-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-1" role="tab" aria-controls="tabset-7-1" aria-selected="true">Keras</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-7-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-2" role="tab" aria-controls="tabset-7-2" aria-selected="false">Torch</a></li></ul>
<div class="tab-content">
<div id="tabset-7-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-7-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb258"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb258-1"><a href="#cb258-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(preds <span class="sc">==</span> <span class="fu">as.integer</span>(iris<span class="sc">$</span>Species))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9066667</code></pre>
</div>
</div>
</div>
<div id="tabset-7-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-7-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb260"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb260-1"><a href="#cb260-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(preds_torch <span class="sc">==</span> <span class="fu">as.integer</span>(iris<span class="sc">$</span>Species))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.98</code></pre>
</div>
</div>
</div>
</div>
</div>
<p><strong>8. Plot predictions, to see if we have done a good job:</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb262"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb262-1"><a href="#cb262-1" aria-hidden="true" tabindex="-1"></a>oldpar <span class="ot">=</span> <span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb262-2"><a href="#cb262-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(iris<span class="sc">$</span>Sepal.Length, iris<span class="sc">$</span>Petal.Length, <span class="at">col =</span> iris<span class="sc">$</span>Species,</span>
<span id="cb262-3"><a href="#cb262-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Observed"</span>)</span>
<span id="cb262-4"><a href="#cb262-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(iris<span class="sc">$</span>Sepal.Length, iris<span class="sc">$</span>Petal.Length, <span class="at">col =</span> preds,</span>
<span id="cb262-5"><a href="#cb262-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Predicted"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C1-TensorFlow_files/figure-html/chunk_chapter3_79-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb263"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb263-1"><a href="#cb263-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(oldpar)   <span class="co"># Reset par.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>So you see, building a neural network is very easy with Keras or Torch and you can already do it on your own.</p>
</section>
<section id="exercises-2" class="level3" data-number="8.3.2">
<h3 data-number="8.3.2" class="anchored" data-anchor-id="exercises-2"><span class="header-section-number">8.3.2</span> Exercises</h3>
  <hr>
  <strong><span style="color: #0011AA; font-size:18px;">1. Task</span></strong><br>
<p>We will now build a regression for the airquality data set with Keras/Torch. We want to predict the variable “Ozone”.</p>
<p>Tasks: 1. Complete the steps and the code chunk so that the model is successfully trained! 2. Try different learning rates and neural network sizes (increase/decrease number of hidden layers and neurons (units) in each layer). What happes?</p>
<div class="panelset">
<div class="panel">
<p><span class="panel-name">Keras</span></p>
<ol start="0" type="1">
<li>Load and prepare the data set:</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb264"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb264-1"><a href="#cb264-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb264-2"><a href="#cb264-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb264-3"><a href="#cb264-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R's random seed.</span></span>
<span id="cb264-4"><a href="#cb264-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb264-5"><a href="#cb264-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Explore the data with summary() and plot():</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb265"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb265-1"><a href="#cb265-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     Ozone           Solar.R           Wind             Temp      
 Min.   :  1.00   Min.   :  7.0   Min.   : 1.700   Min.   :56.00  
 1st Qu.: 18.00   1st Qu.:115.8   1st Qu.: 7.400   1st Qu.:72.00  
 Median : 31.50   Median :205.0   Median : 9.700   Median :79.00  
 Mean   : 42.13   Mean   :185.9   Mean   : 9.958   Mean   :77.88  
 3rd Qu.: 63.25   3rd Qu.:258.8   3rd Qu.:11.500   3rd Qu.:85.00  
 Max.   :168.00   Max.   :334.0   Max.   :20.700   Max.   :97.00  
 NA's   :37       NA's   :7                                       
     Month            Day      
 Min.   :5.000   Min.   : 1.0  
 1st Qu.:6.000   1st Qu.: 8.0  
 Median :7.000   Median :16.0  
 Mean   :6.993   Mean   :15.8  
 3rd Qu.:8.000   3rd Qu.:23.0  
 Max.   :9.000   Max.   :31.0  
                               </code></pre>
</div>
<div class="sourceCode cell-code" id="cb267"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb267-1"><a href="#cb267-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C1-TensorFlow_files/figure-html/chunk_chapter3_task_27-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<ol type="1">
<li><p>There are NAs in the data, which we have to remove because Keras cannot handle NAs. If you don’t know how to remove NAs from a data.frame, use Google (e.g.&nbsp;with the query: “remove-rows-with-all-or-some-nas-missing-values-in-data-frame”).</p></li>
<li><p>Split the data in predictors (<span class="math inline">\(\boldsymbol{X}\)</span>) and response (<span class="math inline">\(\boldsymbol{y}\)</span>, Ozone) and scale the <span class="math inline">\(\boldsymbol{X}\)</span> matrix.</p></li>
<li><p>Build a sequential Keras model.</p></li>
<li><p>Add hidden layers (input and output layer are already specified, you have to add hidden layers between them):</p></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb268"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb268-1"><a href="#cb268-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb268-2"><a href="#cb268-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">"relu"</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(5L)) <span class="sc">%&gt;%</span></span>
<span id="cb268-3"><a href="#cb268-3" aria-hidden="true" tabindex="-1"></a>   ....</span>
<span id="cb268-4"><a href="#cb268-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">"linear"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>Why do we use 5L as input shape?</li>
<li>Why only one output node and “linear” activation layer?</li>
</ul>
<ol start="5" type="1">
<li>Compile model.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb269"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb269-1"><a href="#cb269-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb269-2"><a href="#cb269-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.05</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>What is the “mean_squared_error” loss?</p>
<ol start="6" type="1">
<li>Fit model:</li>
</ol>
<p>Tip: Only matrices are accepted for <span class="math inline">\(\boldsymbol{X}\)</span> and <span class="math inline">\(\boldsymbol{y}\)</span> by Keras. R often drops a one column matrix into a vector (change it back to a matrix!)</p>
<ol start="7" type="1">
<li><p>Plot training history.</p></li>
<li><p>Create predictions.</p></li>
<li><p>Compare your Keras model with a linear model:</p></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb270"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb270-1"><a href="#cb270-1" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">lm</span>(Ozone <span class="sc">~</span> ., <span class="at">data =</span> data)</span>
<span id="cb270-2"><a href="#cb270-2" aria-hidden="true" tabindex="-1"></a>pred_lm <span class="ot">=</span> <span class="fu">predict</span>(fit, data)</span>
<span id="cb270-3"><a href="#cb270-3" aria-hidden="true" tabindex="-1"></a>rmse_lm <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_lm)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb270-4"><a href="#cb270-4" aria-hidden="true" tabindex="-1"></a>rmse_keras <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_keras)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb270-5"><a href="#cb270-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_lm)</span>
<span id="cb270-6"><a href="#cb270-6" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_keras)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div class="panel">
<p><span class="panel-name">Torch</span></p>
<ol start="0" type="1">
<li>Load and prepare the data set:</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb271"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb271-1"><a href="#cb271-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb271-2"><a href="#cb271-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb271-3"><a href="#cb271-3" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Explore the data with summary() and plot():</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb272"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb272-1"><a href="#cb272-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     Ozone           Solar.R           Wind             Temp      
 Min.   :  1.00   Min.   :  7.0   Min.   : 1.700   Min.   :56.00  
 1st Qu.: 18.00   1st Qu.:115.8   1st Qu.: 7.400   1st Qu.:72.00  
 Median : 31.50   Median :205.0   Median : 9.700   Median :79.00  
 Mean   : 42.13   Mean   :185.9   Mean   : 9.958   Mean   :77.88  
 3rd Qu.: 63.25   3rd Qu.:258.8   3rd Qu.:11.500   3rd Qu.:85.00  
 Max.   :168.00   Max.   :334.0   Max.   :20.700   Max.   :97.00  
 NA's   :37       NA's   :7                                       
     Month            Day      
 Min.   :5.000   Min.   : 1.0  
 1st Qu.:6.000   1st Qu.: 8.0  
 Median :7.000   Median :16.0  
 Mean   :6.993   Mean   :15.8  
 3rd Qu.:8.000   3rd Qu.:23.0  
 Max.   :9.000   Max.   :31.0  
                               </code></pre>
</div>
<div class="sourceCode cell-code" id="cb274"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb274-1"><a href="#cb274-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C1-TensorFlow_files/figure-html/chunk_chapter3_task_27_torch-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<ol type="1">
<li><p>There are NAs in the data, which we have to remove because Keras cannot handle NAs. If you don’t know how to remove NAs from a data.frame, use Google (e.g.&nbsp;with the query: “remove-rows-with-all-or-some-nas-missing-values-in-data-frame”).</p></li>
<li><p>Split the data in predictors (<span class="math inline">\(\boldsymbol{X}\)</span>) and response (<span class="math inline">\(\boldsymbol{y}\)</span>, Ozone) and scale the <span class="math inline">\(\boldsymbol{X}\)</span> matrix.</p></li>
<li><p>Pass a list of layer objects to a sequential network class of torch (input and output layer are already specified, you have to add hidden layers between them):</p></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb275"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb275-1"><a href="#cb275-1" aria-hidden="true" tabindex="-1"></a>model_torch <span class="ot">=</span> </span>
<span id="cb275-2"><a href="#cb275-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_sequential</span>(</span>
<span id="cb275-3"><a href="#cb275-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(5L, 20L),</span>
<span id="cb275-4"><a href="#cb275-4" aria-hidden="true" tabindex="-1"></a>    ...</span>
<span id="cb275-5"><a href="#cb275-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 1L),</span>
<span id="cb275-6"><a href="#cb275-6" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>Why do we use 5L as input shape?</li>
<li>Why only one output node and no activation layer?</li>
</ul>
<ol start="4" type="1">
<li>Create optimizer</li>
</ol>
<p>We have to pass the network’s parameters to the optimizer (how is this different to keras?)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb276"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb276-1"><a href="#cb276-1" aria-hidden="true" tabindex="-1"></a>optimizer_torch <span class="ot">=</span> <span class="fu">optim_adam</span>(<span class="at">params =</span> model_torch<span class="sc">$</span>parameters, <span class="at">lr =</span> <span class="fl">0.05</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="5" type="1">
<li>Fit model</li>
</ol>
<p>In torch we have to write the trainings loop on our own. Complete the trainings loop:</p>
<p>Tips:</p>
<ul>
<li>Number of training $ steps = Number of rows / batchsize * Epochs $</li>
<li>Search torch::nnf_… for the correct loss function (mse…)</li>
<li>Make sure that X_torch and Y_torch have the same data type! (you can set the dtype via torch_tensor(…, dtype = …)) _ Check the dimension of Y_torch, we need a matrix!</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb277"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb277-1"><a href="#cb277-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate number of training steps.</span></span>
<span id="cb277-2"><a href="#cb277-2" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> ...</span>
<span id="cb277-3"><a href="#cb277-3" aria-hidden="true" tabindex="-1"></a>batch_size <span class="ot">=</span> <span class="dv">32</span></span>
<span id="cb277-4"><a href="#cb277-4" aria-hidden="true" tabindex="-1"></a>steps <span class="ot">=</span> ...</span>
<span id="cb277-5"><a href="#cb277-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb277-6"><a href="#cb277-6" aria-hidden="true" tabindex="-1"></a>X_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(x)</span>
<span id="cb277-7"><a href="#cb277-7" aria-hidden="true" tabindex="-1"></a>Y_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(y, ...) </span>
<span id="cb277-8"><a href="#cb277-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb277-9"><a href="#cb277-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Set model into training status.</span></span>
<span id="cb277-10"><a href="#cb277-10" aria-hidden="true" tabindex="-1"></a>model_torch<span class="sc">$</span><span class="fu">train</span>()</span>
<span id="cb277-11"><a href="#cb277-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb277-12"><a href="#cb277-12" aria-hidden="true" tabindex="-1"></a>log_losses <span class="ot">=</span> <span class="cn">NULL</span></span>
<span id="cb277-13"><a href="#cb277-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb277-14"><a href="#cb277-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Training loop.</span></span>
<span id="cb277-15"><a href="#cb277-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>steps){</span>
<span id="cb277-16"><a href="#cb277-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Get batch indices.</span></span>
<span id="cb277-17"><a href="#cb277-17" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(x), batch_size)</span>
<span id="cb277-18"><a href="#cb277-18" aria-hidden="true" tabindex="-1"></a>  X_batch <span class="ot">=</span> ...</span>
<span id="cb277-19"><a href="#cb277-19" aria-hidden="true" tabindex="-1"></a>  Y_batch <span class="ot">=</span> ...</span>
<span id="cb277-20"><a href="#cb277-20" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb277-21"><a href="#cb277-21" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Reset backpropagation.</span></span>
<span id="cb277-22"><a href="#cb277-22" aria-hidden="true" tabindex="-1"></a>  optimizer_torch<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb277-23"><a href="#cb277-23" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb277-24"><a href="#cb277-24" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Predict and calculate loss.</span></span>
<span id="cb277-25"><a href="#cb277-25" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">=</span> <span class="fu">model_torch</span>(X_batch)</span>
<span id="cb277-26"><a href="#cb277-26" aria-hidden="true" tabindex="-1"></a>  loss <span class="ot">=</span> ...</span>
<span id="cb277-27"><a href="#cb277-27" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb277-28"><a href="#cb277-28" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Backpropagation and weight update.</span></span>
<span id="cb277-29"><a href="#cb277-29" aria-hidden="true" tabindex="-1"></a>  loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb277-30"><a href="#cb277-30" aria-hidden="true" tabindex="-1"></a>  optimizer_torch<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb277-31"><a href="#cb277-31" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb277-32"><a href="#cb277-32" aria-hidden="true" tabindex="-1"></a>  log_losses[i] <span class="ot">=</span> <span class="fu">as.numeric</span>(loss)</span>
<span id="cb277-33"><a href="#cb277-33" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="6" type="1">
<li><p>Plot training history.</p></li>
<li><p>Create predictions.</p></li>
<li><p>Compare your Torch model with a linear model:</p></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb278"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb278-1"><a href="#cb278-1" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">lm</span>(Ozone <span class="sc">~</span> ., <span class="at">data =</span> data)</span>
<span id="cb278-2"><a href="#cb278-2" aria-hidden="true" tabindex="-1"></a>pred_lm <span class="ot">=</span> <span class="fu">predict</span>(fit, data)</span>
<span id="cb278-3"><a href="#cb278-3" aria-hidden="true" tabindex="-1"></a>rmse_lm <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_lm)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb278-4"><a href="#cb278-4" aria-hidden="true" tabindex="-1"></a>rmse_torch <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_torch)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb278-5"><a href="#cb278-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_lm)</span>
<span id="cb278-6"><a href="#cb278-6" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_torch)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:18px;">Solution</span></strong>
    </summary>
    <p>
</p><div class="cell">
<div class="sourceCode cell-code" id="cb279"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb279-1"><a href="#cb279-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>1. There are NAs in the data, which we have to remove because Keras and Torch cannot handle NAs!</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb280"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb280-1"><a href="#cb280-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> data[<span class="fu">complete.cases</span>(data),]  <span class="co"># Remove NAs.</span></span>
<span id="cb280-2"><a href="#cb280-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     Ozone          Solar.R           Wind            Temp      
 Min.   :  1.0   Min.   :  7.0   Min.   : 2.30   Min.   :57.00  
 1st Qu.: 18.0   1st Qu.:113.5   1st Qu.: 7.40   1st Qu.:71.00  
 Median : 31.0   Median :207.0   Median : 9.70   Median :79.00  
 Mean   : 42.1   Mean   :184.8   Mean   : 9.94   Mean   :77.79  
 3rd Qu.: 62.0   3rd Qu.:255.5   3rd Qu.:11.50   3rd Qu.:84.50  
 Max.   :168.0   Max.   :334.0   Max.   :20.70   Max.   :97.00  
     Month            Day       
 Min.   :5.000   Min.   : 1.00  
 1st Qu.:6.000   1st Qu.: 9.00  
 Median :7.000   Median :16.00  
 Mean   :7.216   Mean   :15.95  
 3rd Qu.:9.000   3rd Qu.:22.50  
 Max.   :9.000   Max.   :31.00  </code></pre>
</div>
</div>
<p><strong>2. Split the data in predictors and response and scale the matrix.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb282"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb282-1"><a href="#cb282-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="dv">2</span><span class="sc">:</span><span class="dv">6</span>])</span>
<span id="cb282-2"><a href="#cb282-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> data[,<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="panelset">
<div class="panel">
<p><span class="panel-name">Keras</span></p>
<p><strong>3. Build sequential Keras model.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb283"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb283-1"><a href="#cb283-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb283-2"><a href="#cb283-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb283-3"><a href="#cb283-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R's random seed.</span></span>
<span id="cb283-4"><a href="#cb283-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb283-5"><a href="#cb283-5" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>4. Add hidden layers (input and output layer are already specified, you have to add hidden layers between them).</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb284"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb284-1"><a href="#cb284-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb284-2"><a href="#cb284-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">"relu"</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(5L)) <span class="sc">%&gt;%</span></span>
<span id="cb284-3"><a href="#cb284-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L) <span class="sc">%&gt;%</span></span>
<span id="cb284-4"><a href="#cb284-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L) <span class="sc">%&gt;%</span></span>
<span id="cb284-5"><a href="#cb284-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">"linear"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We use 5L as input shape, because we have 5 predictors. Analogously, we use 1L for our 1d response. Because we do not want any compression, dilation or other nonlinear effects, we use the simple linear layer (equal to no activation function at all). For more about activation functions, look for example <a href="https://en.wikipedia.org/wiki/Activation_function" target="_blank" rel="noopener">here</a>. Or wait for the next days. You may also have seen the previously shown link <a href="https://mlfromscratch.com/activation-functions-explained/#/" target="_blank" rel="noopener">about activation functions in more detail</a>.</p>
<p><strong>5. Compile model.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb285"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb285-1"><a href="#cb285-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb285-2"><a href="#cb285-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.05</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The mean_squared_error is the ordinary least squares approach in regression analysis.</p>
<p><strong>6. Fit model.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb286"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb286-1"><a href="#cb286-1" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb286-2"><a href="#cb286-2" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb286-3"><a href="#cb286-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> x, <span class="at">y =</span> <span class="fu">matrix</span>(y, <span class="at">ncol =</span> 1L), <span class="at">epochs =</span> 100L,</span>
<span id="cb286-4"><a href="#cb286-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>7. Plot training history.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb287"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb287-1"><a href="#cb287-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C1-TensorFlow_files/figure-html/chunk_chapter3_task_38-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb288"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb288-1"><a href="#cb288-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb288-2"><a href="#cb288-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">evaluate</span>(x, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    loss 
147.5745 </code></pre>
</div>
</div>
<p><strong>8. Create predictions.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb290"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb290-1"><a href="#cb290-1" aria-hidden="true" tabindex="-1"></a>pred_keras <span class="ot">=</span> <span class="fu">predict</span>(model, x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>9. Compare Keras model with a linear model.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb291"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb291-1"><a href="#cb291-1" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">lm</span>(Ozone <span class="sc">~</span> ., <span class="at">data =</span> data)</span>
<span id="cb291-2"><a href="#cb291-2" aria-hidden="true" tabindex="-1"></a>pred_lm <span class="ot">=</span> <span class="fu">predict</span>(fit, data)</span>
<span id="cb291-3"><a href="#cb291-3" aria-hidden="true" tabindex="-1"></a>rmse_lm <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_lm)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb291-4"><a href="#cb291-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb291-5"><a href="#cb291-5" aria-hidden="true" tabindex="-1"></a>rmse_keras <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_keras)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb291-6"><a href="#cb291-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb291-7"><a href="#cb291-7" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_lm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 14.78897</code></pre>
</div>
<div class="sourceCode cell-code" id="cb293"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb293-1"><a href="#cb293-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_keras)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 9.067499</code></pre>
</div>
</div>
</div>
<div class="panel">
<p><span class="panel-name">Torch</span></p>
<p><strong>3. Pass a list of layer objects to a sequential network class of torch (input and output layer are already specified, you have to add hidden layers between them):</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb295"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb295-1"><a href="#cb295-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb295-2"><a href="#cb295-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb295-3"><a href="#cb295-3" aria-hidden="true" tabindex="-1"></a>model_torch <span class="ot">=</span> </span>
<span id="cb295-4"><a href="#cb295-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_sequential</span>(</span>
<span id="cb295-5"><a href="#cb295-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(5L, 20L),</span>
<span id="cb295-6"><a href="#cb295-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb295-7"><a href="#cb295-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 20L),</span>
<span id="cb295-8"><a href="#cb295-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb295-9"><a href="#cb295-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 20L),</span>
<span id="cb295-10"><a href="#cb295-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb295-11"><a href="#cb295-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 1L),</span>
<span id="cb295-12"><a href="#cb295-12" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We use 5L as input shape, because we have 5 predictors. Analogously, we use 1L for our 1d response. Because we do not want any compression, dilation or other nonlinear effects, we use the simple linear layer (equal to no activation function at all). For more about activation functions, look for example <a href="https://en.wikipedia.org/wiki/Activation_function" target="_blank" rel="noopener">here</a>. Or wait for the next days. You may also have seen the previously shown link <a href="https://mlfromscratch.com/activation-functions-explained/#/" target="_blank" rel="noopener">about activation functions in more detail</a>.</p>
<p><strong>4. Create optimizer</strong></p>
<p>We have to pass the network’s parameters to the optimizer (how is this different to keras?)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb296"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb296-1"><a href="#cb296-1" aria-hidden="true" tabindex="-1"></a>optimizer_torch <span class="ot">=</span> <span class="fu">optim_adam</span>(<span class="at">params =</span> model_torch<span class="sc">$</span>parameters, <span class="at">lr =</span> <span class="fl">0.001</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In keras we use the compile function to pass a optimizer and a loss function to the model whereas in torch we have to pass the network’s parameters to the optimizer.</p>
<p><strong>5. Fit model</strong></p>
<p>In torch we have to write the trainings loop on our own. Complete the trainings loop:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb297"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb297-1"><a href="#cb297-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate number of training steps.</span></span>
<span id="cb297-2"><a href="#cb297-2" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> <span class="dv">100</span></span>
<span id="cb297-3"><a href="#cb297-3" aria-hidden="true" tabindex="-1"></a>batch_size <span class="ot">=</span> <span class="dv">32</span></span>
<span id="cb297-4"><a href="#cb297-4" aria-hidden="true" tabindex="-1"></a>steps <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">nrow</span>(x)<span class="sc">/</span>batch_size<span class="sc">*</span>epochs)</span>
<span id="cb297-5"><a href="#cb297-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb297-6"><a href="#cb297-6" aria-hidden="true" tabindex="-1"></a>X_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(x)</span>
<span id="cb297-7"><a href="#cb297-7" aria-hidden="true" tabindex="-1"></a>Y_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(y, <span class="at">dtype =</span> <span class="fu">torch_float32</span>())<span class="sc">$</span><span class="fu">view</span>(<span class="fu">list</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)) </span>
<span id="cb297-8"><a href="#cb297-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb297-9"><a href="#cb297-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Set model into training status.</span></span>
<span id="cb297-10"><a href="#cb297-10" aria-hidden="true" tabindex="-1"></a>model_torch<span class="sc">$</span><span class="fu">train</span>()</span>
<span id="cb297-11"><a href="#cb297-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb297-12"><a href="#cb297-12" aria-hidden="true" tabindex="-1"></a>log_losses <span class="ot">=</span> <span class="cn">NULL</span></span>
<span id="cb297-13"><a href="#cb297-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb297-14"><a href="#cb297-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Training loop.</span></span>
<span id="cb297-15"><a href="#cb297-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>steps){</span>
<span id="cb297-16"><a href="#cb297-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Get batch indices.</span></span>
<span id="cb297-17"><a href="#cb297-17" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(x), batch_size)</span>
<span id="cb297-18"><a href="#cb297-18" aria-hidden="true" tabindex="-1"></a>  X_batch <span class="ot">=</span> X_torch[indices,]</span>
<span id="cb297-19"><a href="#cb297-19" aria-hidden="true" tabindex="-1"></a>  Y_batch <span class="ot">=</span> Y_torch[indices,]</span>
<span id="cb297-20"><a href="#cb297-20" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb297-21"><a href="#cb297-21" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Reset backpropagation.</span></span>
<span id="cb297-22"><a href="#cb297-22" aria-hidden="true" tabindex="-1"></a>  optimizer_torch<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb297-23"><a href="#cb297-23" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb297-24"><a href="#cb297-24" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Predict and calculate loss.</span></span>
<span id="cb297-25"><a href="#cb297-25" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">=</span> <span class="fu">model_torch</span>(X_batch)</span>
<span id="cb297-26"><a href="#cb297-26" aria-hidden="true" tabindex="-1"></a>  loss <span class="ot">=</span> <span class="fu">nnf_mse_loss</span>(pred, Y_batch)</span>
<span id="cb297-27"><a href="#cb297-27" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb297-28"><a href="#cb297-28" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Backpropagation and weight update.</span></span>
<span id="cb297-29"><a href="#cb297-29" aria-hidden="true" tabindex="-1"></a>  loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb297-30"><a href="#cb297-30" aria-hidden="true" tabindex="-1"></a>  optimizer_torch<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb297-31"><a href="#cb297-31" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb297-32"><a href="#cb297-32" aria-hidden="true" tabindex="-1"></a>  log_losses[i] <span class="ot">=</span> <span class="fu">as.numeric</span>(loss)</span>
<span id="cb297-33"><a href="#cb297-33" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>6. Plot training history.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb298"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb298-1"><a href="#cb298-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">y =</span> log_losses, <span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span>steps, <span class="at">xlab =</span> <span class="st">"Epoch"</span>, <span class="at">ylab =</span> <span class="st">"MSE"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>7. Create predictions.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb299"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb299-1"><a href="#cb299-1" aria-hidden="true" tabindex="-1"></a>pred_torch <span class="ot">=</span> <span class="fu">model_torch</span>(X_torch)</span>
<span id="cb299-2"><a href="#cb299-2" aria-hidden="true" tabindex="-1"></a>pred_torch <span class="ot">=</span> <span class="fu">as.numeric</span>(pred_torch) <span class="co"># cast torch to R object </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>8. Compare your Torch model with a linear model:</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb300"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb300-1"><a href="#cb300-1" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">lm</span>(Ozone <span class="sc">~</span> ., <span class="at">data =</span> data)</span>
<span id="cb300-2"><a href="#cb300-2" aria-hidden="true" tabindex="-1"></a>pred_lm <span class="ot">=</span> <span class="fu">predict</span>(fit, data)</span>
<span id="cb300-3"><a href="#cb300-3" aria-hidden="true" tabindex="-1"></a>rmse_lm <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_lm)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb300-4"><a href="#cb300-4" aria-hidden="true" tabindex="-1"></a>rmse_torch <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_torch)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb300-5"><a href="#cb300-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_lm)</span>
<span id="cb300-6"><a href="#cb300-6" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_torch)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<p><strong>Look at this slightly more complex model and compare the loss plot and the accuracy in contrast to the former.</strong></p>
<div class="panelset">
<div class="panel">
<p><span class="panel-name">Keras</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb301"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb301-1"><a href="#cb301-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb301-2"><a href="#cb301-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb301-3"><a href="#cb301-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R's random seed.</span></span>
<span id="cb301-4"><a href="#cb301-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb301-5"><a href="#cb301-5" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb301-6"><a href="#cb301-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb301-7"><a href="#cb301-7" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb301-8"><a href="#cb301-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">"relu"</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(5L)) <span class="sc">%&gt;%</span></span>
<span id="cb301-9"><a href="#cb301-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb301-10"><a href="#cb301-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 30L, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb301-11"><a href="#cb301-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb301-12"><a href="#cb301-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">"linear"</span>)</span>
<span id="cb301-13"><a href="#cb301-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb301-14"><a href="#cb301-14" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb301-15"><a href="#cb301-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.05</span>))</span>
<span id="cb301-16"><a href="#cb301-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb301-17"><a href="#cb301-17" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb301-18"><a href="#cb301-18" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb301-19"><a href="#cb301-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> x, <span class="at">y =</span> <span class="fu">matrix</span>(y, <span class="at">ncol =</span> 1L), <span class="at">epochs =</span> 100L,</span>
<span id="cb301-20"><a href="#cb301-20" aria-hidden="true" tabindex="-1"></a>      <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb301-21"><a href="#cb301-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb301-22"><a href="#cb301-22" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C1-TensorFlow_files/figure-html/chunk_chapter3_task_41-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb302"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb302-1"><a href="#cb302-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb302-2"><a href="#cb302-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">evaluate</span>(x, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    loss 
210.4453 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb304"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb304-1"><a href="#cb304-1" aria-hidden="true" tabindex="-1"></a>pred_keras <span class="ot">=</span> <span class="fu">predict</span>(model, x)</span>
<span id="cb304-2"><a href="#cb304-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb304-3"><a href="#cb304-3" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">lm</span>(Ozone <span class="sc">~</span> ., <span class="at">data =</span> data)</span>
<span id="cb304-4"><a href="#cb304-4" aria-hidden="true" tabindex="-1"></a>pred_lm <span class="ot">=</span> <span class="fu">predict</span>(fit, data)</span>
<span id="cb304-5"><a href="#cb304-5" aria-hidden="true" tabindex="-1"></a>rmse_lm <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_lm)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb304-6"><a href="#cb304-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb304-7"><a href="#cb304-7" aria-hidden="true" tabindex="-1"></a>rmse_keras <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_keras)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb304-8"><a href="#cb304-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb304-9"><a href="#cb304-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_lm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 14.78897</code></pre>
</div>
<div class="sourceCode cell-code" id="cb306"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb306-1"><a href="#cb306-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_keras)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 10.51122</code></pre>
</div>
</div>
</div>
<div class="panel">
<p><span class="panel-name">Torch</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb308"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb308-1"><a href="#cb308-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb308-2"><a href="#cb308-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb308-3"><a href="#cb308-3" aria-hidden="true" tabindex="-1"></a>model_torch <span class="ot">=</span> </span>
<span id="cb308-4"><a href="#cb308-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_sequential</span>(</span>
<span id="cb308-5"><a href="#cb308-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(5L, 20L),</span>
<span id="cb308-6"><a href="#cb308-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb308-7"><a href="#cb308-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 20L),</span>
<span id="cb308-8"><a href="#cb308-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb308-9"><a href="#cb308-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 30L),</span>
<span id="cb308-10"><a href="#cb308-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb308-11"><a href="#cb308-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(30L, 20L),</span>
<span id="cb308-12"><a href="#cb308-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb308-13"><a href="#cb308-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 1L),</span>
<span id="cb308-14"><a href="#cb308-14" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb308-15"><a href="#cb308-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb308-16"><a href="#cb308-16" aria-hidden="true" tabindex="-1"></a>optimizer_torch <span class="ot">=</span> <span class="fu">optim_adam</span>(<span class="at">params =</span> model_torch<span class="sc">$</span>parameters, <span class="at">lr =</span> <span class="fl">0.05</span>)</span>
<span id="cb308-17"><a href="#cb308-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb308-18"><a href="#cb308-18" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> <span class="dv">100</span></span>
<span id="cb308-19"><a href="#cb308-19" aria-hidden="true" tabindex="-1"></a>batch_size <span class="ot">=</span> <span class="dv">32</span></span>
<span id="cb308-20"><a href="#cb308-20" aria-hidden="true" tabindex="-1"></a>steps <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">nrow</span>(x)<span class="sc">/</span>batch_size<span class="sc">*</span>epochs)</span>
<span id="cb308-21"><a href="#cb308-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb308-22"><a href="#cb308-22" aria-hidden="true" tabindex="-1"></a>X_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(x)</span>
<span id="cb308-23"><a href="#cb308-23" aria-hidden="true" tabindex="-1"></a>Y_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(y, <span class="at">dtype =</span> <span class="fu">torch_float32</span>())<span class="sc">$</span><span class="fu">view</span>(<span class="fu">list</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)) </span>
<span id="cb308-24"><a href="#cb308-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb308-25"><a href="#cb308-25" aria-hidden="true" tabindex="-1"></a>model_torch<span class="sc">$</span><span class="fu">train</span>()</span>
<span id="cb308-26"><a href="#cb308-26" aria-hidden="true" tabindex="-1"></a>log_losses <span class="ot">=</span> <span class="cn">NULL</span></span>
<span id="cb308-27"><a href="#cb308-27" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>steps){</span>
<span id="cb308-28"><a href="#cb308-28" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(x), batch_size)</span>
<span id="cb308-29"><a href="#cb308-29" aria-hidden="true" tabindex="-1"></a>  X_batch <span class="ot">=</span> X_torch[indices,]</span>
<span id="cb308-30"><a href="#cb308-30" aria-hidden="true" tabindex="-1"></a>  Y_batch <span class="ot">=</span> Y_torch[indices,]</span>
<span id="cb308-31"><a href="#cb308-31" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Reset backpropagation.</span></span>
<span id="cb308-32"><a href="#cb308-32" aria-hidden="true" tabindex="-1"></a>  optimizer_torch<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb308-33"><a href="#cb308-33" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Predict and calculate loss.</span></span>
<span id="cb308-34"><a href="#cb308-34" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">=</span> <span class="fu">model_torch</span>(X_batch)</span>
<span id="cb308-35"><a href="#cb308-35" aria-hidden="true" tabindex="-1"></a>  loss <span class="ot">=</span> <span class="fu">nnf_mse_loss</span>(pred, Y_batch)</span>
<span id="cb308-36"><a href="#cb308-36" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Backpropagation and weight update.</span></span>
<span id="cb308-37"><a href="#cb308-37" aria-hidden="true" tabindex="-1"></a>  loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb308-38"><a href="#cb308-38" aria-hidden="true" tabindex="-1"></a>  optimizer_torch<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb308-39"><a href="#cb308-39" aria-hidden="true" tabindex="-1"></a>  log_losses[i] <span class="ot">=</span> <span class="fu">as.numeric</span>(loss)</span>
<span id="cb308-40"><a href="#cb308-40" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb308-41"><a href="#cb308-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb308-42"><a href="#cb308-42" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">y =</span> log_losses, <span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span>steps, <span class="at">xlab =</span> <span class="st">"Epoch"</span>, <span class="at">ylab =</span> <span class="st">"MSE"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C1-TensorFlow_files/figure-html/chunk_chapter3_task_41_torch-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb309"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb309-1"><a href="#cb309-1" aria-hidden="true" tabindex="-1"></a>pred_torch <span class="ot">=</span> <span class="fu">model_torch</span>(X_torch)</span>
<span id="cb309-2"><a href="#cb309-2" aria-hidden="true" tabindex="-1"></a>pred_torch <span class="ot">=</span> <span class="fu">as.numeric</span>(pred_torch) <span class="co"># cast torch to R object </span></span>
<span id="cb309-3"><a href="#cb309-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb309-4"><a href="#cb309-4" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">lm</span>(Ozone <span class="sc">~</span> ., <span class="at">data =</span> data)</span>
<span id="cb309-5"><a href="#cb309-5" aria-hidden="true" tabindex="-1"></a>pred_lm <span class="ot">=</span> <span class="fu">predict</span>(fit, data)</span>
<span id="cb309-6"><a href="#cb309-6" aria-hidden="true" tabindex="-1"></a>rmse_lm <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_lm)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb309-7"><a href="#cb309-7" aria-hidden="true" tabindex="-1"></a>rmse_torch <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_torch)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb309-8"><a href="#cb309-8" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_lm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 14.78897</code></pre>
</div>
<div class="sourceCode cell-code" id="cb311"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb311-1"><a href="#cb311-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_torch)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5.12053</code></pre>
</div>
</div>
</div>
</div>
<p>You see, the more complex model works better, because it can learn the functional form between the features and the response better (if necessary). But keep the overfitting problem in mind!</p>
<p><strong>Look at the little change in learning rates for the next 2 models and compare the loss plot and the accuracy in contrast to the former.</strong></p>
<div class="panelset">
<div class="panel">
<p><span class="panel-name">Keras</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb313"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb313-1"><a href="#cb313-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb313-2"><a href="#cb313-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb313-3"><a href="#cb313-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R's random seed.</span></span>
<span id="cb313-4"><a href="#cb313-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb313-5"><a href="#cb313-5" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb313-6"><a href="#cb313-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb313-7"><a href="#cb313-7" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb313-8"><a href="#cb313-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">"relu"</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(5L)) <span class="sc">%&gt;%</span></span>
<span id="cb313-9"><a href="#cb313-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb313-10"><a href="#cb313-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 30L, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb313-11"><a href="#cb313-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb313-12"><a href="#cb313-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">"linear"</span>)</span>
<span id="cb313-13"><a href="#cb313-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb313-14"><a href="#cb313-14" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb313-15"><a href="#cb313-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.1</span>))</span>
<span id="cb313-16"><a href="#cb313-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb313-17"><a href="#cb313-17" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb313-18"><a href="#cb313-18" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb313-19"><a href="#cb313-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> x, <span class="at">y =</span> <span class="fu">matrix</span>(y, <span class="at">ncol =</span> 1L), <span class="at">epochs =</span> 100L,</span>
<span id="cb313-20"><a href="#cb313-20" aria-hidden="true" tabindex="-1"></a>      <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb313-21"><a href="#cb313-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb313-22"><a href="#cb313-22" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C1-TensorFlow_files/figure-html/chunk_chapter3_task_42-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb314"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb314-1"><a href="#cb314-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb314-2"><a href="#cb314-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">evaluate</span>(x, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    loss 
56.70872 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb316"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb316-1"><a href="#cb316-1" aria-hidden="true" tabindex="-1"></a>pred_keras <span class="ot">=</span> <span class="fu">predict</span>(model, x)</span>
<span id="cb316-2"><a href="#cb316-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb316-3"><a href="#cb316-3" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">lm</span>(Ozone <span class="sc">~</span> ., <span class="at">data =</span> data)</span>
<span id="cb316-4"><a href="#cb316-4" aria-hidden="true" tabindex="-1"></a>pred_lm <span class="ot">=</span> <span class="fu">predict</span>(fit, data)</span>
<span id="cb316-5"><a href="#cb316-5" aria-hidden="true" tabindex="-1"></a>rmse_lm <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_lm)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb316-6"><a href="#cb316-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb316-7"><a href="#cb316-7" aria-hidden="true" tabindex="-1"></a>rmse_keras <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_keras)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb316-8"><a href="#cb316-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb316-9"><a href="#cb316-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_lm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 14.78897</code></pre>
</div>
<div class="sourceCode cell-code" id="cb318"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb318-1"><a href="#cb318-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_keras)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5.661808</code></pre>
</div>
</div>
</div>
<div class="panel">
<p><span class="panel-name">Torch</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb320"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb320-1"><a href="#cb320-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb320-2"><a href="#cb320-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb320-3"><a href="#cb320-3" aria-hidden="true" tabindex="-1"></a>model_torch <span class="ot">=</span> </span>
<span id="cb320-4"><a href="#cb320-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_sequential</span>(</span>
<span id="cb320-5"><a href="#cb320-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(5L, 20L),</span>
<span id="cb320-6"><a href="#cb320-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb320-7"><a href="#cb320-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 20L),</span>
<span id="cb320-8"><a href="#cb320-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb320-9"><a href="#cb320-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 30L),</span>
<span id="cb320-10"><a href="#cb320-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb320-11"><a href="#cb320-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(30L, 20L),</span>
<span id="cb320-12"><a href="#cb320-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb320-13"><a href="#cb320-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 1L),</span>
<span id="cb320-14"><a href="#cb320-14" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb320-15"><a href="#cb320-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb320-16"><a href="#cb320-16" aria-hidden="true" tabindex="-1"></a>optimizer_torch <span class="ot">=</span> <span class="fu">optim_adam</span>(<span class="at">params =</span> model_torch<span class="sc">$</span>parameters, <span class="at">lr =</span> <span class="fl">0.1</span>)</span>
<span id="cb320-17"><a href="#cb320-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb320-18"><a href="#cb320-18" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> <span class="dv">100</span></span>
<span id="cb320-19"><a href="#cb320-19" aria-hidden="true" tabindex="-1"></a>batch_size <span class="ot">=</span> <span class="dv">32</span></span>
<span id="cb320-20"><a href="#cb320-20" aria-hidden="true" tabindex="-1"></a>steps <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">nrow</span>(x)<span class="sc">/</span>batch_size<span class="sc">*</span>epochs)</span>
<span id="cb320-21"><a href="#cb320-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb320-22"><a href="#cb320-22" aria-hidden="true" tabindex="-1"></a>X_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(x)</span>
<span id="cb320-23"><a href="#cb320-23" aria-hidden="true" tabindex="-1"></a>Y_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(y, <span class="at">dtype =</span> <span class="fu">torch_float32</span>())<span class="sc">$</span><span class="fu">view</span>(<span class="fu">list</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)) </span>
<span id="cb320-24"><a href="#cb320-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb320-25"><a href="#cb320-25" aria-hidden="true" tabindex="-1"></a>model_torch<span class="sc">$</span><span class="fu">train</span>()</span>
<span id="cb320-26"><a href="#cb320-26" aria-hidden="true" tabindex="-1"></a>log_losses <span class="ot">=</span> <span class="cn">NULL</span></span>
<span id="cb320-27"><a href="#cb320-27" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>steps){</span>
<span id="cb320-28"><a href="#cb320-28" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(x), batch_size)</span>
<span id="cb320-29"><a href="#cb320-29" aria-hidden="true" tabindex="-1"></a>  X_batch <span class="ot">=</span> X_torch[indices,]</span>
<span id="cb320-30"><a href="#cb320-30" aria-hidden="true" tabindex="-1"></a>  Y_batch <span class="ot">=</span> Y_torch[indices,]</span>
<span id="cb320-31"><a href="#cb320-31" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Reset backpropagation.</span></span>
<span id="cb320-32"><a href="#cb320-32" aria-hidden="true" tabindex="-1"></a>  optimizer_torch<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb320-33"><a href="#cb320-33" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Predict and calculate loss.</span></span>
<span id="cb320-34"><a href="#cb320-34" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">=</span> <span class="fu">model_torch</span>(X_batch)</span>
<span id="cb320-35"><a href="#cb320-35" aria-hidden="true" tabindex="-1"></a>  loss <span class="ot">=</span> <span class="fu">nnf_mse_loss</span>(pred, Y_batch)</span>
<span id="cb320-36"><a href="#cb320-36" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Backpropagation and weight update.</span></span>
<span id="cb320-37"><a href="#cb320-37" aria-hidden="true" tabindex="-1"></a>  loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb320-38"><a href="#cb320-38" aria-hidden="true" tabindex="-1"></a>  optimizer_torch<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb320-39"><a href="#cb320-39" aria-hidden="true" tabindex="-1"></a>  log_losses[i] <span class="ot">=</span> <span class="fu">as.numeric</span>(loss)</span>
<span id="cb320-40"><a href="#cb320-40" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb320-41"><a href="#cb320-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb320-42"><a href="#cb320-42" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">y =</span> log_losses, <span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span>steps, <span class="at">xlab =</span> <span class="st">"Epoch"</span>, <span class="at">ylab =</span> <span class="st">"MSE"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C1-TensorFlow_files/figure-html/chunk_chapter3_task_43_torch-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb321"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb321-1"><a href="#cb321-1" aria-hidden="true" tabindex="-1"></a>pred_torch <span class="ot">=</span> <span class="fu">model_torch</span>(X_torch)</span>
<span id="cb321-2"><a href="#cb321-2" aria-hidden="true" tabindex="-1"></a>pred_torch <span class="ot">=</span> <span class="fu">as.numeric</span>(pred_torch) <span class="co"># cast torch to R object </span></span>
<span id="cb321-3"><a href="#cb321-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb321-4"><a href="#cb321-4" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">lm</span>(Ozone <span class="sc">~</span> ., <span class="at">data =</span> data)</span>
<span id="cb321-5"><a href="#cb321-5" aria-hidden="true" tabindex="-1"></a>pred_lm <span class="ot">=</span> <span class="fu">predict</span>(fit, data)</span>
<span id="cb321-6"><a href="#cb321-6" aria-hidden="true" tabindex="-1"></a>rmse_lm <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_lm)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb321-7"><a href="#cb321-7" aria-hidden="true" tabindex="-1"></a>rmse_torch <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_torch)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb321-8"><a href="#cb321-8" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_lm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 14.78897</code></pre>
</div>
<div class="sourceCode cell-code" id="cb323"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb323-1"><a href="#cb323-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_torch)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 6.461597</code></pre>
</div>
</div>
</div>
</div>
<p>You can see, the higher learning rate yields a little bit worse results. The optimum is jumped over.</p>
<div class="panelset">
<div class="panel">
<p><span class="panel-name">Keras</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb325"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb325-1"><a href="#cb325-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb325-2"><a href="#cb325-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb325-3"><a href="#cb325-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R's random seed.</span></span>
<span id="cb325-4"><a href="#cb325-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb325-5"><a href="#cb325-5" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb325-6"><a href="#cb325-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb325-7"><a href="#cb325-7" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb325-8"><a href="#cb325-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">"relu"</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(5L)) <span class="sc">%&gt;%</span></span>
<span id="cb325-9"><a href="#cb325-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb325-10"><a href="#cb325-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 30L, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb325-11"><a href="#cb325-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb325-12"><a href="#cb325-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">"linear"</span>)</span>
<span id="cb325-13"><a href="#cb325-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb325-14"><a href="#cb325-14" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb325-15"><a href="#cb325-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.001</span>))</span>
<span id="cb325-16"><a href="#cb325-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb325-17"><a href="#cb325-17" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb325-18"><a href="#cb325-18" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb325-19"><a href="#cb325-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> x, <span class="at">y =</span> <span class="fu">matrix</span>(y, <span class="at">ncol =</span> 1L), <span class="at">epochs =</span> 100L,</span>
<span id="cb325-20"><a href="#cb325-20" aria-hidden="true" tabindex="-1"></a>      <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb325-21"><a href="#cb325-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb325-22"><a href="#cb325-22" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C1-TensorFlow_files/figure-html/chunk_chapter3_task_43-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb326"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb326-1"><a href="#cb326-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb326-2"><a href="#cb326-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">evaluate</span>(x, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    loss 
340.8205 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb328"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb328-1"><a href="#cb328-1" aria-hidden="true" tabindex="-1"></a>pred_keras <span class="ot">=</span> <span class="fu">predict</span>(model, x)</span>
<span id="cb328-2"><a href="#cb328-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb328-3"><a href="#cb328-3" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">lm</span>(Ozone <span class="sc">~</span> ., <span class="at">data =</span> data)</span>
<span id="cb328-4"><a href="#cb328-4" aria-hidden="true" tabindex="-1"></a>pred_lm <span class="ot">=</span> <span class="fu">predict</span>(fit, data)</span>
<span id="cb328-5"><a href="#cb328-5" aria-hidden="true" tabindex="-1"></a>rmse_lm <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_lm)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb328-6"><a href="#cb328-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb328-7"><a href="#cb328-7" aria-hidden="true" tabindex="-1"></a>rmse_keras <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_keras)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb328-8"><a href="#cb328-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb328-9"><a href="#cb328-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_lm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 14.78897</code></pre>
</div>
<div class="sourceCode cell-code" id="cb330"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb330-1"><a href="#cb330-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_keras)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 13.18632</code></pre>
</div>
</div>
</div>
<div class="panel">
<p><span class="panel-name">Torch</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb332"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb332-1"><a href="#cb332-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb332-2"><a href="#cb332-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb332-3"><a href="#cb332-3" aria-hidden="true" tabindex="-1"></a>model_torch <span class="ot">=</span> </span>
<span id="cb332-4"><a href="#cb332-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_sequential</span>(</span>
<span id="cb332-5"><a href="#cb332-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(5L, 20L),</span>
<span id="cb332-6"><a href="#cb332-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb332-7"><a href="#cb332-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 20L),</span>
<span id="cb332-8"><a href="#cb332-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb332-9"><a href="#cb332-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 30L),</span>
<span id="cb332-10"><a href="#cb332-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb332-11"><a href="#cb332-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(30L, 20L),</span>
<span id="cb332-12"><a href="#cb332-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_relu</span>(),</span>
<span id="cb332-13"><a href="#cb332-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 1L),</span>
<span id="cb332-14"><a href="#cb332-14" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb332-15"><a href="#cb332-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb332-16"><a href="#cb332-16" aria-hidden="true" tabindex="-1"></a>optimizer_torch <span class="ot">=</span> <span class="fu">optim_adam</span>(<span class="at">params =</span> model_torch<span class="sc">$</span>parameters, <span class="at">lr =</span> <span class="fl">0.001</span>)</span>
<span id="cb332-17"><a href="#cb332-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb332-18"><a href="#cb332-18" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> <span class="dv">100</span></span>
<span id="cb332-19"><a href="#cb332-19" aria-hidden="true" tabindex="-1"></a>batch_size <span class="ot">=</span> <span class="dv">32</span></span>
<span id="cb332-20"><a href="#cb332-20" aria-hidden="true" tabindex="-1"></a>steps <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">nrow</span>(x)<span class="sc">/</span>batch_size<span class="sc">*</span>epochs)</span>
<span id="cb332-21"><a href="#cb332-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb332-22"><a href="#cb332-22" aria-hidden="true" tabindex="-1"></a>X_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(x)</span>
<span id="cb332-23"><a href="#cb332-23" aria-hidden="true" tabindex="-1"></a>Y_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(y, <span class="at">dtype =</span> <span class="fu">torch_float32</span>())<span class="sc">$</span><span class="fu">view</span>(<span class="fu">list</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)) </span>
<span id="cb332-24"><a href="#cb332-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb332-25"><a href="#cb332-25" aria-hidden="true" tabindex="-1"></a>model_torch<span class="sc">$</span><span class="fu">train</span>()</span>
<span id="cb332-26"><a href="#cb332-26" aria-hidden="true" tabindex="-1"></a>log_losses <span class="ot">=</span> <span class="cn">NULL</span></span>
<span id="cb332-27"><a href="#cb332-27" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>steps){</span>
<span id="cb332-28"><a href="#cb332-28" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(x), batch_size)</span>
<span id="cb332-29"><a href="#cb332-29" aria-hidden="true" tabindex="-1"></a>  X_batch <span class="ot">=</span> X_torch[indices,]</span>
<span id="cb332-30"><a href="#cb332-30" aria-hidden="true" tabindex="-1"></a>  Y_batch <span class="ot">=</span> Y_torch[indices,]</span>
<span id="cb332-31"><a href="#cb332-31" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Reset backpropagation.</span></span>
<span id="cb332-32"><a href="#cb332-32" aria-hidden="true" tabindex="-1"></a>  optimizer_torch<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb332-33"><a href="#cb332-33" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Predict and calculate loss.</span></span>
<span id="cb332-34"><a href="#cb332-34" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">=</span> <span class="fu">model_torch</span>(X_batch)</span>
<span id="cb332-35"><a href="#cb332-35" aria-hidden="true" tabindex="-1"></a>  loss <span class="ot">=</span> <span class="fu">nnf_mse_loss</span>(pred, Y_batch)</span>
<span id="cb332-36"><a href="#cb332-36" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Backpropagation and weight update.</span></span>
<span id="cb332-37"><a href="#cb332-37" aria-hidden="true" tabindex="-1"></a>  loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb332-38"><a href="#cb332-38" aria-hidden="true" tabindex="-1"></a>  optimizer_torch<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb332-39"><a href="#cb332-39" aria-hidden="true" tabindex="-1"></a>  log_losses[i] <span class="ot">=</span> <span class="fu">as.numeric</span>(loss)</span>
<span id="cb332-40"><a href="#cb332-40" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb332-41"><a href="#cb332-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb332-42"><a href="#cb332-42" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">y =</span> log_losses, <span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span>steps, <span class="at">xlab =</span> <span class="st">"Epoch"</span>, <span class="at">ylab =</span> <span class="st">"MSE"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C1-TensorFlow_files/figure-html/chunk_chapter3_task_442_torch-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb333"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb333-1"><a href="#cb333-1" aria-hidden="true" tabindex="-1"></a>pred_torch <span class="ot">=</span> <span class="fu">model_torch</span>(X_torch)</span>
<span id="cb333-2"><a href="#cb333-2" aria-hidden="true" tabindex="-1"></a>pred_torch <span class="ot">=</span> <span class="fu">as.numeric</span>(pred_torch) <span class="co"># cast torch to R object </span></span>
<span id="cb333-3"><a href="#cb333-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb333-4"><a href="#cb333-4" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">lm</span>(Ozone <span class="sc">~</span> ., <span class="at">data =</span> data)</span>
<span id="cb333-5"><a href="#cb333-5" aria-hidden="true" tabindex="-1"></a>pred_lm <span class="ot">=</span> <span class="fu">predict</span>(fit, data)</span>
<span id="cb333-6"><a href="#cb333-6" aria-hidden="true" tabindex="-1"></a>rmse_lm <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_lm)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb333-7"><a href="#cb333-7" aria-hidden="true" tabindex="-1"></a>rmse_torch <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_torch)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb333-8"><a href="#cb333-8" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_lm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 14.78897</code></pre>
</div>
<div class="sourceCode cell-code" id="cb335"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb335-1"><a href="#cb335-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_torch)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 12.48754</code></pre>
</div>
</div>
</div>
</div>
<p>You can see, that for the lower learning rate, the optimum (compared to the run with learning rate 0.05) is not yet reached (to few epochs have gone by). But also here, mind the overfitting problem. For too many epochs, things might get worse!</p>
    <p></p>
  </details>
  <br>
  <hr>
  <strong><span style="color: #0011AA; font-size:18px;">2. Task</span></strong><br>
<p>The next task differs for Torch and Keras users. Keras users will learn more about the inner working of training while Torch users will learn how to simplify and generalize the training loop.</p>
<div class="panelset">
<div class="panel">
<p><span class="panel-name">Keras</span></p>
<p>Similar to Torch, here we will write the training loop ourselves in the following. The training loop consists of several steps:</p>
<ol type="1">
<li>Sample batches of X and Y data</li>
<li>Open the gradientTape to create a computational graph (autodiff)</li>
<li>Make predictions and calculate loss</li>
<li>Update parameters based on the gradients at the loss (go back to 1. and repeat)</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb337"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb337-1"><a href="#cb337-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb337-2"><a href="#cb337-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb337-3"><a href="#cb337-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R's random seed.</span></span>
<span id="cb337-4"><a href="#cb337-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb337-5"><a href="#cb337-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality</span>
<span id="cb337-6"><a href="#cb337-6" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> data[<span class="fu">complete.cases</span>(data),]  <span class="co"># Remove NAs.</span></span>
<span id="cb337-7"><a href="#cb337-7" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="dv">2</span><span class="sc">:</span><span class="dv">6</span>])</span>
<span id="cb337-8"><a href="#cb337-8" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> data[,<span class="dv">1</span>]</span>
<span id="cb337-9"><a href="#cb337-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb337-10"><a href="#cb337-10" aria-hidden="true" tabindex="-1"></a>layers <span class="ot">=</span> tf<span class="sc">$</span>keras<span class="sc">$</span>layers</span>
<span id="cb337-11"><a href="#cb337-11" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> tf<span class="sc">$</span>keras<span class="sc">$</span>models<span class="sc">$</span><span class="fu">Sequential</span>(</span>
<span id="cb337-12"><a href="#cb337-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>(</span>
<span id="cb337-13"><a href="#cb337-13" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">InputLayer</span>(<span class="at">input_shape =</span> <span class="fu">list</span>(5L)),</span>
<span id="cb337-14"><a href="#cb337-14" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">Dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> tf<span class="sc">$</span>nn<span class="sc">$</span>relu),</span>
<span id="cb337-15"><a href="#cb337-15" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">Dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> tf<span class="sc">$</span>nn<span class="sc">$</span>relu),</span>
<span id="cb337-16"><a href="#cb337-16" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">Dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> tf<span class="sc">$</span>nn<span class="sc">$</span>relu),</span>
<span id="cb337-17"><a href="#cb337-17" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">Dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="cn">NULL</span>) <span class="co"># No activation == "linear".</span></span>
<span id="cb337-18"><a href="#cb337-18" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb337-19"><a href="#cb337-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb337-20"><a href="#cb337-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb337-21"><a href="#cb337-21" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> 200L</span>
<span id="cb337-22"><a href="#cb337-22" aria-hidden="true" tabindex="-1"></a>optimizer <span class="ot">=</span> tf<span class="sc">$</span>keras<span class="sc">$</span>optimizers<span class="sc">$</span><span class="fu">Adamax</span>(<span class="fl">0.01</span>)</span>
<span id="cb337-23"><a href="#cb337-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb337-24"><a href="#cb337-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Stochastic gradient optimization is more efficient</span></span>
<span id="cb337-25"><a href="#cb337-25" aria-hidden="true" tabindex="-1"></a><span class="co"># in each optimization step, we use a random subset of the data.</span></span>
<span id="cb337-26"><a href="#cb337-26" aria-hidden="true" tabindex="-1"></a>get_batch <span class="ot">=</span> <span class="cf">function</span>(<span class="at">batch_size =</span> 32L){</span>
<span id="cb337-27"><a href="#cb337-27" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(x), <span class="at">size =</span> batch_size)</span>
<span id="cb337-28"><a href="#cb337-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">bX =</span> x[indices,], <span class="at">bY =</span> y[indices]))</span>
<span id="cb337-29"><a href="#cb337-29" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb337-30"><a href="#cb337-30" aria-hidden="true" tabindex="-1"></a><span class="fu">get_batch</span>() <span class="co"># Try out this function.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$bX
        Solar.R        Wind        Temp      Month        Day
87  -1.13877323 -0.37654514  0.44147123 -0.1467431  1.1546835
117  0.58361881 -1.83815816  0.33653910  0.5319436  1.0398360
129 -1.01809608  1.56290291  0.65133550  1.2106304 -1.1422676
121  0.44100036 -2.14734553  1.70065685  0.5319436  1.4992262
91   0.74817856 -0.71384046  0.54640337 -0.1467431  1.6140738
137 -1.76410028  0.26993754 -0.71278225  1.2106304 -0.2234871
21  -1.93963068 -0.06735777 -1.97196786 -1.5041165  0.5804458
141 -1.73118833  0.10128988 -0.18812157  1.2106304  0.2359031
78   0.97856221  0.10128988  0.44147123 -0.1467431  0.1210555
15  -1.31430363  0.91642022 -2.07689999 -1.5041165 -0.1086396
38  -0.63412333 -0.06735777  0.44147123 -0.8254298 -1.0274200
49  -1.62148183 -0.20789749 -1.34237505 -0.8254298  0.2359031
123  0.03508631 -1.02302783  1.70065685  0.5319436  1.7289213
136  0.58361881 -1.02302783 -0.08318944  1.2106304 -0.3383347
120  0.19964606 -0.06735777  2.01545325  0.5319436  1.3843787
114 -1.63245248  1.22560759 -0.60785011  0.5319436  0.6952933
145 -1.87380678 -0.20789749 -0.71278225  1.2106304  0.6952933
140  0.43002971  1.08506788 -1.13251078  1.2106304  0.1210555
64   0.56167751 -0.20789749  0.33653910 -0.1467431 -1.4868103
118  0.33129386 -0.54519280  0.86119977  0.5319436  1.1546835
128 -0.98518413 -0.71384046  0.96613190  1.2106304 -1.2571152
62   0.92370896 -1.64140257  0.65133550 -0.1467431 -1.7165054
125  0.13382216 -1.36032314  1.49079258  1.2106304 -1.6016578
4    1.40641756  0.43858520 -1.65717146 -1.5041165 -1.3719627
79   1.09923936 -1.02302783  0.65133550 -0.1467431  0.2359031
82  -1.95060133 -0.85438017 -0.39798584 -0.1467431  0.5804458
149  0.08993956 -0.85438017 -0.81771438  1.2106304  1.1546835
17   1.34059366  0.57912491 -1.23744292 -1.5041165  0.1210555
48   1.08826871  3.02451593 -0.60785011 -0.8254298  0.1210555
130  0.73720791  0.26993754  0.23160696  1.2106304 -1.0274200
132  0.49585361  0.26993754 -0.29305371  1.2106304 -0.7977249
30   0.41905906 -1.19167548  0.12667483 -1.5041165  1.6140738

$bY
 [1]  20 168  32 118  64   9   1  13  35  18  29  20  85  28  76   9  23  18  32
[20]  73  47 135  78  18  61  16  30  34  37  20  21 115</code></pre>
</div>
<div class="sourceCode cell-code" id="cb339"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb339-1"><a href="#cb339-1" aria-hidden="true" tabindex="-1"></a>steps <span class="ot">=</span> <span class="fu">floor</span>(<span class="fu">nrow</span>(x)<span class="sc">/</span><span class="dv">32</span>) <span class="sc">*</span> epochs  <span class="co"># We need nrow(x)/32 steps for each epoch.</span></span>
<span id="cb339-2"><a href="#cb339-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>steps){</span>
<span id="cb339-3"><a href="#cb339-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Get data.</span></span>
<span id="cb339-4"><a href="#cb339-4" aria-hidden="true" tabindex="-1"></a>  batch <span class="ot">=</span> <span class="fu">get_batch</span>()</span>
<span id="cb339-5"><a href="#cb339-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb339-6"><a href="#cb339-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Transform it into tensors.</span></span>
<span id="cb339-7"><a href="#cb339-7" aria-hidden="true" tabindex="-1"></a>  bX <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(batch<span class="sc">$</span>bX)</span>
<span id="cb339-8"><a href="#cb339-8" aria-hidden="true" tabindex="-1"></a>  bY <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(<span class="fu">matrix</span>(batch<span class="sc">$</span>bY, <span class="at">ncol =</span> 1L))</span>
<span id="cb339-9"><a href="#cb339-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb339-10"><a href="#cb339-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Automatic differentiation:</span></span>
<span id="cb339-11"><a href="#cb339-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Record computations with respect to our model variables.</span></span>
<span id="cb339-12"><a href="#cb339-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">with</span>(tf<span class="sc">$</span><span class="fu">GradientTape</span>() <span class="sc">%as%</span> tape,</span>
<span id="cb339-13"><a href="#cb339-13" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb339-14"><a href="#cb339-14" aria-hidden="true" tabindex="-1"></a>      pred <span class="ot">=</span> <span class="fu">model</span>(bX) <span class="co"># We record the operation for our model weights.</span></span>
<span id="cb339-15"><a href="#cb339-15" aria-hidden="true" tabindex="-1"></a>      loss <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">reduce_mean</span>(tf<span class="sc">$</span>keras<span class="sc">$</span>losses<span class="sc">$</span><span class="fu">mean_squared_error</span>(bY, pred))</span>
<span id="cb339-16"><a href="#cb339-16" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb339-17"><a href="#cb339-17" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb339-18"><a href="#cb339-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb339-19"><a href="#cb339-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Calculate the gradients for our model$weights at the loss / backpropagation.</span></span>
<span id="cb339-20"><a href="#cb339-20" aria-hidden="true" tabindex="-1"></a>  gradients <span class="ot">=</span> tape<span class="sc">$</span><span class="fu">gradient</span>(loss, model<span class="sc">$</span>weights) </span>
<span id="cb339-21"><a href="#cb339-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb339-22"><a href="#cb339-22" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Update our model weights with the learning rate specified above.</span></span>
<span id="cb339-23"><a href="#cb339-23" aria-hidden="true" tabindex="-1"></a>  optimizer<span class="sc">$</span><span class="fu">apply_gradients</span>(purrr<span class="sc">::</span><span class="fu">transpose</span>(<span class="fu">list</span>(gradients, model<span class="sc">$</span>weights))) </span>
<span id="cb339-24"><a href="#cb339-24" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="sc">!</span> i<span class="sc">%%</span><span class="dv">30</span>){</span>
<span id="cb339-25"><a href="#cb339-25" aria-hidden="true" tabindex="-1"></a>    <span class="fu">cat</span>(<span class="st">"Loss: "</span>, loss<span class="sc">$</span><span class="fu">numpy</span>(), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>) <span class="co"># Print loss every 30 steps (not epochs!).</span></span>
<span id="cb339-26"><a href="#cb339-26" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb339-27"><a href="#cb339-27" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss:  1444.033 
Loss:  488.953 
Loss:  270.0465 
Loss:  450.0282 
Loss:  138.2488 
Loss:  227.6001 
Loss:  216.2361 
Loss:  109.9781 
Loss:  352.7486 
Loss:  239.2065 
Loss:  234.0703 
Loss:  224.0462 
Loss:  227.475 
Loss:  336.5538 
Loss:  348.1582 
Loss:  158.787 
Loss:  209.5738 
Loss:  321.0661 
Loss:  232.6139 
Loss:  289.6932 </code></pre>
</div>
</div>
</div>
<div class="panel">
<p><span class="panel-name">Torch</span></p>
<p>Keras and Torch use dataloaders to generate the data batches. Dataloaders are objects that return batches of data infinetly. Keras create the dataloader object automatically in the fit function, in Torch we have to write them ourselves:</p>
<ol type="1">
<li>Define a dataset object. This object informs the dataloader function about the inputs, outputs, length (nrow), and how to sample from it.</li>
<li>Create an instance of the dataset object by calling it and passing the actual data to it</li>
<li>Pass the initiated dataset to the dataloader function</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb341"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb341-1"><a href="#cb341-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb341-2"><a href="#cb341-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb341-3"><a href="#cb341-3" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality</span>
<span id="cb341-4"><a href="#cb341-4" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> data[<span class="fu">complete.cases</span>(data),]  <span class="co"># Remove NAs.</span></span>
<span id="cb341-5"><a href="#cb341-5" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="dv">2</span><span class="sc">:</span><span class="dv">6</span>])</span>
<span id="cb341-6"><a href="#cb341-6" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">matrix</span>(data[,<span class="dv">1</span>], <span class="at">ncol =</span> 1L)</span>
<span id="cb341-7"><a href="#cb341-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb341-8"><a href="#cb341-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb341-9"><a href="#cb341-9" aria-hidden="true" tabindex="-1"></a>torch_dataset <span class="ot">=</span> torch<span class="sc">::</span><span class="fu">dataset</span>(</span>
<span id="cb341-10"><a href="#cb341-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">name =</span> <span class="st">"airquality"</span>,</span>
<span id="cb341-11"><a href="#cb341-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">initialize =</span> <span class="cf">function</span>(X,Y) {</span>
<span id="cb341-12"><a href="#cb341-12" aria-hidden="true" tabindex="-1"></a>      self<span class="sc">$</span>X <span class="ot">=</span> torch<span class="sc">::</span><span class="fu">torch_tensor</span>(<span class="fu">as.matrix</span>(X), <span class="at">dtype =</span> <span class="fu">torch_float32</span>())</span>
<span id="cb341-13"><a href="#cb341-13" aria-hidden="true" tabindex="-1"></a>      self<span class="sc">$</span>Y <span class="ot">=</span> torch<span class="sc">::</span><span class="fu">torch_tensor</span>(<span class="fu">as.matrix</span>(Y), <span class="at">dtype =</span> <span class="fu">torch_float32</span>())</span>
<span id="cb341-14"><a href="#cb341-14" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb341-15"><a href="#cb341-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">.getitem =</span> <span class="cf">function</span>(index) {</span>
<span id="cb341-16"><a href="#cb341-16" aria-hidden="true" tabindex="-1"></a>      x <span class="ot">=</span> self<span class="sc">$</span>X[index,]</span>
<span id="cb341-17"><a href="#cb341-17" aria-hidden="true" tabindex="-1"></a>      y <span class="ot">=</span> self<span class="sc">$</span>Y[index,]</span>
<span id="cb341-18"><a href="#cb341-18" aria-hidden="true" tabindex="-1"></a>      <span class="fu">list</span>(x, y)</span>
<span id="cb341-19"><a href="#cb341-19" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb341-20"><a href="#cb341-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">.length =</span> <span class="cf">function</span>() {</span>
<span id="cb341-21"><a href="#cb341-21" aria-hidden="true" tabindex="-1"></a>      self<span class="sc">$</span>Y<span class="sc">$</span><span class="fu">size</span>()[[<span class="dv">1</span>]]</span>
<span id="cb341-22"><a href="#cb341-22" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb341-23"><a href="#cb341-23" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb341-24"><a href="#cb341-24" aria-hidden="true" tabindex="-1"></a>dataset <span class="ot">=</span> <span class="fu">torch_dataset</span>(x,y)</span>
<span id="cb341-25"><a href="#cb341-25" aria-hidden="true" tabindex="-1"></a>dataloader <span class="ot">=</span> torch<span class="sc">::</span><span class="fu">dataloader</span>(dataset, <span class="at">batch_size =</span> 30L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Our dataloader is again an object which has to be initiated. The initiated object returns a list of two elements, batch x and batch y. The initated object stops returning batches when the dataset was completly transversed (no worries, we don’t have to all of this ourselves).</p>
<p>Our training has also changed now:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb342"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb342-1"><a href="#cb342-1" aria-hidden="true" tabindex="-1"></a>model_torch <span class="ot">=</span> <span class="fu">nn_sequential</span>(</span>
<span id="cb342-2"><a href="#cb342-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_linear</span>(5L, 50L),</span>
<span id="cb342-3"><a href="#cb342-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_relu</span>(),</span>
<span id="cb342-4"><a href="#cb342-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_linear</span>(50L, 50L),</span>
<span id="cb342-5"><a href="#cb342-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_relu</span>(), </span>
<span id="cb342-6"><a href="#cb342-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_linear</span>(50L, 50L),</span>
<span id="cb342-7"><a href="#cb342-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_relu</span>(), </span>
<span id="cb342-8"><a href="#cb342-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_linear</span>(50L, 1L)</span>
<span id="cb342-9"><a href="#cb342-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb342-10"><a href="#cb342-10" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> 50L</span>
<span id="cb342-11"><a href="#cb342-11" aria-hidden="true" tabindex="-1"></a>opt <span class="ot">=</span> <span class="fu">optim_adam</span>(model_torch<span class="sc">$</span>parameters, <span class="fl">0.01</span>)</span>
<span id="cb342-12"><a href="#cb342-12" aria-hidden="true" tabindex="-1"></a>train_losses <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb342-13"><a href="#cb342-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(epoch <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>epochs){</span>
<span id="cb342-14"><a href="#cb342-14" aria-hidden="true" tabindex="-1"></a>  train_loss <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb342-15"><a href="#cb342-15" aria-hidden="true" tabindex="-1"></a>  coro<span class="sc">::</span><span class="fu">loop</span>(</span>
<span id="cb342-16"><a href="#cb342-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(batch <span class="cf">in</span> dataloader) { </span>
<span id="cb342-17"><a href="#cb342-17" aria-hidden="true" tabindex="-1"></a>      opt<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb342-18"><a href="#cb342-18" aria-hidden="true" tabindex="-1"></a>      pred <span class="ot">=</span> <span class="fu">model_torch</span>(batch[[<span class="dv">1</span>]])</span>
<span id="cb342-19"><a href="#cb342-19" aria-hidden="true" tabindex="-1"></a>      loss <span class="ot">=</span> <span class="fu">nnf_mse_loss</span>(pred, batch[[<span class="dv">2</span>]])</span>
<span id="cb342-20"><a href="#cb342-20" aria-hidden="true" tabindex="-1"></a>      loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb342-21"><a href="#cb342-21" aria-hidden="true" tabindex="-1"></a>      opt<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb342-22"><a href="#cb342-22" aria-hidden="true" tabindex="-1"></a>      train_loss <span class="ot">=</span> <span class="fu">c</span>(train_loss, loss<span class="sc">$</span><span class="fu">item</span>())</span>
<span id="cb342-23"><a href="#cb342-23" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb342-24"><a href="#cb342-24" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb342-25"><a href="#cb342-25" aria-hidden="true" tabindex="-1"></a>  train_losses <span class="ot">=</span> <span class="fu">c</span>(train_losses, <span class="fu">mean</span>(train_loss))</span>
<span id="cb342-26"><a href="#cb342-26" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="sc">!</span>epoch<span class="sc">%%</span><span class="dv">10</span>) <span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">"Loss at epoch %d: %3f</span><span class="sc">\n</span><span class="st">"</span>, epoch, <span class="fu">mean</span>(train_loss)))</span>
<span id="cb342-27"><a href="#cb342-27" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss at epoch 10: 387.950073
Loss at epoch 20: 282.698288
Loss at epoch 30: 257.855043
Loss at epoch 40: 244.420750
Loss at epoch 50: 217.362108</code></pre>
</div>
<div class="sourceCode cell-code" id="cb344"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb344-1"><a href="#cb344-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(train_losses, <span class="at">type =</span> <span class="st">"o"</span>, <span class="at">pch =</span> <span class="dv">15</span>,</span>
<span id="cb344-2"><a href="#cb344-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">col =</span> <span class="st">"darkblue"</span>, <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">xlab =</span> <span class="st">"Epoch"</span>,</span>
<span id="cb344-3"><a href="#cb344-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">ylab =</span> <span class="st">"Loss"</span>, <span class="at">las =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C1-TensorFlow_files/figure-html/chunk_chapter3_task_45_torch-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The previous sampling wasn’t ideal, why?</p>
</div>
</div>
<p>Now change the code from above for the iris data set. Tip: In tf$keras$losses$… you can find various loss functions.</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:18px;">Solution</span></strong>
    </summary>
    <p>
</p><div class="panelset">
<div class="panel">
<p><span class="panel-name">Keras</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb345"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb345-1"><a href="#cb345-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb345-2"><a href="#cb345-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb345-3"><a href="#cb345-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R's random seed.</span></span>
<span id="cb345-4"><a href="#cb345-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb345-5"><a href="#cb345-5" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">scale</span>(iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span>
<span id="cb345-6"><a href="#cb345-6" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> iris[,<span class="dv">5</span>]</span>
<span id="cb345-7"><a href="#cb345-7" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> keras<span class="sc">::</span><span class="fu">to_categorical</span>(<span class="fu">as.integer</span>(Y)<span class="sc">-</span>1L, <span class="dv">3</span>)</span>
<span id="cb345-8"><a href="#cb345-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb345-9"><a href="#cb345-9" aria-hidden="true" tabindex="-1"></a>layers <span class="ot">=</span> tf<span class="sc">$</span>keras<span class="sc">$</span>layers</span>
<span id="cb345-10"><a href="#cb345-10" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> tf<span class="sc">$</span>keras<span class="sc">$</span>models<span class="sc">$</span><span class="fu">Sequential</span>(</span>
<span id="cb345-11"><a href="#cb345-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>(</span>
<span id="cb345-12"><a href="#cb345-12" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">InputLayer</span>(<span class="at">input_shape =</span> <span class="fu">list</span>(4L)),</span>
<span id="cb345-13"><a href="#cb345-13" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">Dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> tf<span class="sc">$</span>nn<span class="sc">$</span>relu),</span>
<span id="cb345-14"><a href="#cb345-14" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">Dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> tf<span class="sc">$</span>nn<span class="sc">$</span>relu),</span>
<span id="cb345-15"><a href="#cb345-15" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">Dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> tf<span class="sc">$</span>nn<span class="sc">$</span>relu),</span>
<span id="cb345-16"><a href="#cb345-16" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">Dense</span>(<span class="at">units =</span> 3L, <span class="at">activation =</span> tf<span class="sc">$</span>nn<span class="sc">$</span>softmax)</span>
<span id="cb345-17"><a href="#cb345-17" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb345-18"><a href="#cb345-18" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb345-19"><a href="#cb345-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb345-20"><a href="#cb345-20" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> 200L</span>
<span id="cb345-21"><a href="#cb345-21" aria-hidden="true" tabindex="-1"></a>optimizer <span class="ot">=</span> tf<span class="sc">$</span>keras<span class="sc">$</span>optimizers<span class="sc">$</span><span class="fu">Adamax</span>(<span class="fl">0.01</span>)</span>
<span id="cb345-22"><a href="#cb345-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb345-23"><a href="#cb345-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Stochastic gradient optimization is more efficient.</span></span>
<span id="cb345-24"><a href="#cb345-24" aria-hidden="true" tabindex="-1"></a>get_batch <span class="ot">=</span> <span class="cf">function</span>(<span class="at">batch_size =</span> 32L){</span>
<span id="cb345-25"><a href="#cb345-25" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(x), <span class="at">size =</span> batch_size)</span>
<span id="cb345-26"><a href="#cb345-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">bX =</span> x[indices,], <span class="at">bY =</span> y[indices,]))</span>
<span id="cb345-27"><a href="#cb345-27" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb345-28"><a href="#cb345-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb345-29"><a href="#cb345-29" aria-hidden="true" tabindex="-1"></a>steps <span class="ot">=</span> <span class="fu">floor</span>(<span class="fu">nrow</span>(x)<span class="sc">/</span><span class="dv">32</span>) <span class="sc">*</span> epochs <span class="co"># We need nrow(x)/32 steps for each epoch.</span></span>
<span id="cb345-30"><a href="#cb345-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb345-31"><a href="#cb345-31" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>steps){</span>
<span id="cb345-32"><a href="#cb345-32" aria-hidden="true" tabindex="-1"></a>  batch <span class="ot">=</span> <span class="fu">get_batch</span>()</span>
<span id="cb345-33"><a href="#cb345-33" aria-hidden="true" tabindex="-1"></a>  bX <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(batch<span class="sc">$</span>bX)</span>
<span id="cb345-34"><a href="#cb345-34" aria-hidden="true" tabindex="-1"></a>  bY <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(batch<span class="sc">$</span>bY)</span>
<span id="cb345-35"><a href="#cb345-35" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb345-36"><a href="#cb345-36" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Automatic differentiation.</span></span>
<span id="cb345-37"><a href="#cb345-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">with</span>(tf<span class="sc">$</span><span class="fu">GradientTape</span>() <span class="sc">%as%</span> tape,</span>
<span id="cb345-38"><a href="#cb345-38" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb345-39"><a href="#cb345-39" aria-hidden="true" tabindex="-1"></a>      pred <span class="ot">=</span> <span class="fu">model</span>(bX) <span class="co"># we record the operation for our model weights</span></span>
<span id="cb345-40"><a href="#cb345-40" aria-hidden="true" tabindex="-1"></a>      loss <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">reduce_mean</span>(tf<span class="sc">$</span>keras<span class="sc">$</span>losses<span class="sc">$</span><span class="fu">categorical_crossentropy</span>(bY, pred))</span>
<span id="cb345-41"><a href="#cb345-41" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb345-42"><a href="#cb345-42" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb345-43"><a href="#cb345-43" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb345-44"><a href="#cb345-44" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Calculate the gradients for the loss at our model$weights / backpropagation.</span></span>
<span id="cb345-45"><a href="#cb345-45" aria-hidden="true" tabindex="-1"></a>  gradients <span class="ot">=</span> tape<span class="sc">$</span><span class="fu">gradient</span>(loss, model<span class="sc">$</span>weights)</span>
<span id="cb345-46"><a href="#cb345-46" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb345-47"><a href="#cb345-47" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Update our model weights with the learning rate specified above.</span></span>
<span id="cb345-48"><a href="#cb345-48" aria-hidden="true" tabindex="-1"></a>  optimizer<span class="sc">$</span><span class="fu">apply_gradients</span>(purrr<span class="sc">::</span><span class="fu">transpose</span>(<span class="fu">list</span>(gradients, model<span class="sc">$</span>weights)))</span>
<span id="cb345-49"><a href="#cb345-49" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb345-50"><a href="#cb345-50" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="sc">!</span> i<span class="sc">%%</span><span class="dv">30</span>){</span>
<span id="cb345-51"><a href="#cb345-51" aria-hidden="true" tabindex="-1"></a>    <span class="fu">cat</span>(<span class="st">"Loss: "</span>, loss<span class="sc">$</span><span class="fu">numpy</span>(), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>) <span class="co"># Print loss every 30 steps (not epochs!).</span></span>
<span id="cb345-52"><a href="#cb345-52" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb345-53"><a href="#cb345-53" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss:  0.002633849 
Loss:  0.0005500487 
Loss:  0.001006462 
Loss:  0.0001315936 
Loss:  0.0004843124 
Loss:  0.0004023896 
Loss:  0.0004356128 
Loss:  0.000235351 
Loss:  4.823796e-05 
Loss:  0.0001512702 
Loss:  0.0002624761 
Loss:  0.0001274793 
Loss:  7.111725e-05 
Loss:  0.0001509234 
Loss:  0.0002024032 
Loss:  0.0001532886 
Loss:  9.489701e-05 
Loss:  0.0001040314 
Loss:  7.334561e-05 
Loss:  2.743953e-05 
Loss:  9.655961e-05 
Loss:  2.361947e-05 
Loss:  6.918395e-05 
Loss:  1.603245e-05 
Loss:  1.772152e-05 
Loss:  2.512357e-05 </code></pre>
</div>
</div>
</div>
<div class="panel">
<p><span class="panel-name">Torch</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb347"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb347-1"><a href="#cb347-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb347-2"><a href="#cb347-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb347-3"><a href="#cb347-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">scale</span>(iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span>
<span id="cb347-4"><a href="#cb347-4" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> iris[,<span class="dv">5</span>]</span>
<span id="cb347-5"><a href="#cb347-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">as.integer</span>(iris<span class="sc">$</span>Species)</span>
<span id="cb347-6"><a href="#cb347-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb347-7"><a href="#cb347-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb347-8"><a href="#cb347-8" aria-hidden="true" tabindex="-1"></a>torch_dataset <span class="ot">=</span> torch<span class="sc">::</span><span class="fu">dataset</span>(</span>
<span id="cb347-9"><a href="#cb347-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">name =</span> <span class="st">"iris"</span>,</span>
<span id="cb347-10"><a href="#cb347-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">initialize =</span> <span class="cf">function</span>(X,Y) {</span>
<span id="cb347-11"><a href="#cb347-11" aria-hidden="true" tabindex="-1"></a>      self<span class="sc">$</span>X <span class="ot">=</span> torch<span class="sc">::</span><span class="fu">torch_tensor</span>(<span class="fu">as.matrix</span>(X), <span class="at">dtype =</span> <span class="fu">torch_float32</span>())</span>
<span id="cb347-12"><a href="#cb347-12" aria-hidden="true" tabindex="-1"></a>      self<span class="sc">$</span>Y <span class="ot">=</span> torch<span class="sc">::</span><span class="fu">torch_tensor</span>(Y, <span class="at">dtype =</span> <span class="fu">torch_long</span>())</span>
<span id="cb347-13"><a href="#cb347-13" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb347-14"><a href="#cb347-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">.getitem =</span> <span class="cf">function</span>(index) {</span>
<span id="cb347-15"><a href="#cb347-15" aria-hidden="true" tabindex="-1"></a>      x <span class="ot">=</span> self<span class="sc">$</span>X[index,]</span>
<span id="cb347-16"><a href="#cb347-16" aria-hidden="true" tabindex="-1"></a>      y <span class="ot">=</span> self<span class="sc">$</span>Y[index]</span>
<span id="cb347-17"><a href="#cb347-17" aria-hidden="true" tabindex="-1"></a>      <span class="fu">list</span>(x, y)</span>
<span id="cb347-18"><a href="#cb347-18" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb347-19"><a href="#cb347-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">.length =</span> <span class="cf">function</span>() {</span>
<span id="cb347-20"><a href="#cb347-20" aria-hidden="true" tabindex="-1"></a>      self<span class="sc">$</span>Y<span class="sc">$</span><span class="fu">size</span>()[[<span class="dv">1</span>]]</span>
<span id="cb347-21"><a href="#cb347-21" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb347-22"><a href="#cb347-22" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb347-23"><a href="#cb347-23" aria-hidden="true" tabindex="-1"></a>dataset <span class="ot">=</span> <span class="fu">torch_dataset</span>(x,y)</span>
<span id="cb347-24"><a href="#cb347-24" aria-hidden="true" tabindex="-1"></a>dataloader <span class="ot">=</span> torch<span class="sc">::</span><span class="fu">dataloader</span>(dataset, <span class="at">batch_size =</span> 30L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb347-25"><a href="#cb347-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb347-26"><a href="#cb347-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb347-27"><a href="#cb347-27" aria-hidden="true" tabindex="-1"></a>model_torch <span class="ot">=</span> <span class="fu">nn_sequential</span>(</span>
<span id="cb347-28"><a href="#cb347-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_linear</span>(4L, 50L),</span>
<span id="cb347-29"><a href="#cb347-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_relu</span>(),</span>
<span id="cb347-30"><a href="#cb347-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_linear</span>(50L, 50L),</span>
<span id="cb347-31"><a href="#cb347-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_relu</span>(), </span>
<span id="cb347-32"><a href="#cb347-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_linear</span>(50L, 50L),</span>
<span id="cb347-33"><a href="#cb347-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_relu</span>(), </span>
<span id="cb347-34"><a href="#cb347-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_linear</span>(50L, 3L)</span>
<span id="cb347-35"><a href="#cb347-35" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb347-36"><a href="#cb347-36" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> 50L</span>
<span id="cb347-37"><a href="#cb347-37" aria-hidden="true" tabindex="-1"></a>opt <span class="ot">=</span> <span class="fu">optim_adam</span>(model_torch<span class="sc">$</span>parameters, <span class="fl">0.01</span>)</span>
<span id="cb347-38"><a href="#cb347-38" aria-hidden="true" tabindex="-1"></a>train_losses <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb347-39"><a href="#cb347-39" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(epoch <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>epochs){</span>
<span id="cb347-40"><a href="#cb347-40" aria-hidden="true" tabindex="-1"></a>  train_loss</span>
<span id="cb347-41"><a href="#cb347-41" aria-hidden="true" tabindex="-1"></a>  coro<span class="sc">::</span><span class="fu">loop</span>(</span>
<span id="cb347-42"><a href="#cb347-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(batch <span class="cf">in</span> dataloader) { </span>
<span id="cb347-43"><a href="#cb347-43" aria-hidden="true" tabindex="-1"></a>      opt<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb347-44"><a href="#cb347-44" aria-hidden="true" tabindex="-1"></a>      pred <span class="ot">=</span> <span class="fu">model_torch</span>(batch[[<span class="dv">1</span>]])</span>
<span id="cb347-45"><a href="#cb347-45" aria-hidden="true" tabindex="-1"></a>      loss <span class="ot">=</span> <span class="fu">nnf_cross_entropy</span>(pred, batch[[<span class="dv">2</span>]])</span>
<span id="cb347-46"><a href="#cb347-46" aria-hidden="true" tabindex="-1"></a>      loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb347-47"><a href="#cb347-47" aria-hidden="true" tabindex="-1"></a>      opt<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb347-48"><a href="#cb347-48" aria-hidden="true" tabindex="-1"></a>      train_loss <span class="ot">=</span> <span class="fu">c</span>(train_loss, loss<span class="sc">$</span><span class="fu">item</span>())</span>
<span id="cb347-49"><a href="#cb347-49" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb347-50"><a href="#cb347-50" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb347-51"><a href="#cb347-51" aria-hidden="true" tabindex="-1"></a>  train_losses <span class="ot">=</span> <span class="fu">c</span>(train_losses, <span class="fu">mean</span>(train_loss))</span>
<span id="cb347-52"><a href="#cb347-52" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="sc">!</span>epoch<span class="sc">%%</span><span class="dv">10</span>) <span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">"Loss at epoch %d: %3f</span><span class="sc">\n</span><span class="st">"</span>, epoch, <span class="fu">mean</span>(train_loss)))</span>
<span id="cb347-53"><a href="#cb347-53" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss at epoch 10: 16.298814
Loss at epoch 20: 8.492696
Loss at epoch 30: 5.744957
Loss at epoch 40: 4.344102
Loss at epoch 50: 3.493563</code></pre>
</div>
<div class="sourceCode cell-code" id="cb349"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb349-1"><a href="#cb349-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(train_losses, <span class="at">type =</span> <span class="st">"o"</span>, <span class="at">pch =</span> <span class="dv">15</span>,</span>
<span id="cb349-2"><a href="#cb349-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">col =</span> <span class="st">"darkblue"</span>, <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">xlab =</span> <span class="st">"Epoch"</span>,</span>
<span id="cb349-3"><a href="#cb349-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">ylab =</span> <span class="st">"Loss"</span>, <span class="at">las =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C1-TensorFlow_files/figure-html/chunk_chapter3_task_47_torch-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</div>
</div>
<p>Remarks:</p>
<ul>
<li>Mind the different input and output layer numbers.</li>
<li>The loss function increases randomly, because different subsets of the data were drawn. This is a downside of stochastic gradient descent.</li>
<li>A positive thing about stochastic gradient descent is, that local valleys or hills may be left and global ones can be found instead.</li>
</ul>
    <p></p>
  </details>
  <br><hr>
</section>
</section>
<section id="basicMath" class="level2" data-number="8.4">
<h2 data-number="8.4" class="anchored" data-anchor-id="basicMath"><span class="header-section-number">8.4</span> Underlying mathematical concepts - optional</h2>
<p>If are not yet familiar with the underlying concepts of neural networks and want to know more about that, it is suggested to read / view the following videos / sites. Consider the Links and videos with descriptions in parentheses as optional bonus.</p>
<p><em><strong>This might be useful to understand the further concepts in more depth.</strong></em></p>
<ul>
<li><p>(<a href="https://en.wikipedia.org/wiki/Newton%27s_method#Description" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Newton%27s_method#Description</a> (Especially the animated graphic is interesting).)</p></li>
<li><p><a href="https://en.wikipedia.org/wiki/Gradient_descent#Description" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Gradient_descent#Description</a></p></li>
<li><p><a href="https://mlfromscratch.com/neural-networks-explained/#/" target="_blank" rel="noopener">Neural networks (Backpropagation, etc.)</a>.</p></li>
<li><p><a href="https://mlfromscratch.com/activation-functions-explained/#/" target="_blank" rel="noopener">Activation functions in detail</a> (requires the above as prerequisite).</p></li>
</ul>
<p><em><strong>Videos about the topic</strong></em>:</p>
<ul>
<li><strong>Gradient descent explained</strong></li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/sDv4f4s2SB8" frameborder="0" allow="accelerometer; autoplay; clipboard-write;
  encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<ul>
<li>(Stochastic gradient descent explained)</li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/vMh0zPT0tLI" frameborder="0" allow="accelerometer; autoplay; clipboard-write;
  encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<ul>
<li>(Entropy explained)</li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/YtebGVx-Fxw" frameborder="0" allow="accelerometer; autoplay; clipboard-write;
  encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<ul>
<li><strong>Short explanation of entropy, cross entropy and Kullback–Leibler divergence</strong></li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/ErfnhcEV1O8" frameborder="0" allow="accelerometer; autoplay; clipboard-write;
  encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<ul>
<li><strong>Deep Learning (chapter 1)</strong></li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/aircAruvnKk" frameborder="0" allow="accelerometer; autoplay; clipboard-write;
  encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<ul>
<li><strong>How neural networks learn - Deep Learning (chapter 2)</strong></li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/IHZwWFHWa-w" frameborder="0" allow="accelerometer; autoplay; clipboard-write;
  encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<ul>
<li><strong>Backpropagation - Deep Learning (chapter 3)</strong></li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Ilg3gGewQ5U" frameborder="0" allow="accelerometer; autoplay; clipboard-write;
  encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<ul>
<li><strong>Another video about backpropagation (extends the previous one) - Deep Learning (chapter 4)</strong></li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/tIeHLnjs5U8" frameborder="0" allow="accelerometer; autoplay; clipboard-write;
  encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<section id="caveats-of-neural-network-optimization" class="level3" data-number="8.4.1">
<h3 data-number="8.4.1" class="anchored" data-anchor-id="caveats-of-neural-network-optimization"><span class="header-section-number">8.4.1</span> Caveats of neural network optimization</h3>
<p>Depending on activation functions, it might occur that the network won’t get updated, even with high learning rates (called <em>vanishing gradient</em>, especially for “sigmoid” functions). Furthermore, updates might overshoot (called <em>exploding gradients</em>) or activation functions will result in many zeros (especially for “relu”, <em>dying relu</em>).</p>
<p>In general, the first layers of a network tend to learn (much) more slowly than subsequent ones.</p>


</section>
</section>

</main> <!-- /main -->
<script>

/* update total correct if #webex-total_correct exists */
update_total_correct = function() {
  console.log("webex: update total_correct");

  var t = document.getElementsByClassName("webex-total_correct");
  for (var i = 0; i < t.length; i++) {
    p = t[i].parentElement;
    var correct = p.getElementsByClassName("webex-correct").length;
    var solvemes = p.getElementsByClassName("webex-solveme").length;
    var radiogroups = p.getElementsByClassName("webex-radiogroup").length;
    var selects = p.getElementsByClassName("webex-select").length;

    t[i].innerHTML = correct + " of " + (solvemes + radiogroups + selects) + " correct";
  }
}

/* webex-solution button toggling function */
b_func = function() {
  console.log("webex: toggle hide");

  var cl = this.parentElement.classList;
  if (cl.contains('open')) {
    cl.remove("open");
  } else {
    cl.add("open");
  }
}

/* check answers */
check_func = function() {
  console.log("webex: check answers");

  var cl = this.parentElement.classList;
  if (cl.contains('unchecked')) {
    cl.remove("unchecked");
    this.innerHTML = "Hide Answers";
  } else {
    cl.add("unchecked");
    this.innerHTML = "Show Answers";
  }
}

/* function for checking solveme answers */
solveme_func = function(e) {
  console.log("webex: check solveme");

  var real_answers = JSON.parse(this.dataset.answer);
  var my_answer = this.value;
  var cl = this.classList;
  if (cl.contains("ignorecase")) {
    my_answer = my_answer.toLowerCase();
  }
  if (cl.contains("nospaces")) {
    my_answer = my_answer.replace(/ /g, "")
  }

  if (my_answer == "") {
    cl.remove("webex-correct");
    cl.remove("webex-incorrect");
  } else if (real_answers.includes(my_answer)) {
    cl.add("webex-correct");
    cl.remove("webex-incorrect");
  } else {
    cl.add("webex-incorrect");
    cl.remove("webex-correct");
  }

  // match numeric answers within a specified tolerance
  if(this.dataset.tol > 0){
    var tol = JSON.parse(this.dataset.tol);
    var matches = real_answers.map(x => Math.abs(x - my_answer) < tol)
    if (matches.reduce((a, b) => a + b, 0) > 0) {
      cl.add("webex-correct");
    } else {
      cl.remove("webex-correct");
    }
  }

  // added regex bit
  if (cl.contains("regex")){
    answer_regex = RegExp(real_answers.join("|"))
    if (answer_regex.test(my_answer)) {
      cl.add("webex-correct");
    }
  }

  update_total_correct();
}

/* function for checking select answers */
select_func = function(e) {
  console.log("webex: check select");

  var cl = this.classList

  /* add style */
  cl.remove("webex-incorrect");
  cl.remove("webex-correct");
  if (this.value == "answer") {
    cl.add("webex-correct");
  } else if (this.value != "blank") {
    cl.add("webex-incorrect");
  }

  update_total_correct();
}

/* function for checking radiogroups answers */
radiogroups_func = function(e) {
  console.log("webex: check radiogroups");

  var checked_button = document.querySelector('input[name=' + this.id + ']:checked');
  var cl = checked_button.parentElement.classList;
  var labels = checked_button.parentElement.parentElement.children;

  /* get rid of styles */
  for (i = 0; i < labels.length; i++) {
    labels[i].classList.remove("webex-incorrect");
    labels[i].classList.remove("webex-correct");
  }

  /* add style */
  if (checked_button.value == "answer") {
    cl.add("webex-correct");
  } else {
    cl.add("webex-incorrect");
  }

  update_total_correct();
}

window.onload = function() {
  console.log("webex onload");
  /* set up solution buttons */
  var buttons = document.getElementsByTagName("button");

  for (var i = 0; i < buttons.length; i++) {
    if (buttons[i].parentElement.classList.contains('webex-solution')) {
      buttons[i].onclick = b_func;
    }
  }

  var check_sections = document.getElementsByClassName("webex-check");
  console.log("check:", check_sections.length);
  for (var i = 0; i < check_sections.length; i++) {
    check_sections[i].classList.add("unchecked");

    let btn = document.createElement("button");
    btn.innerHTML = "Show Answers";
    btn.classList.add("webex-check-button");
    btn.onclick = check_func;
    check_sections[i].appendChild(btn);

    let spn = document.createElement("span");
    spn.classList.add("webex-total_correct");
    check_sections[i].appendChild(spn);
  }

  /* set up webex-solveme inputs */
  var solveme = document.getElementsByClassName("webex-solveme");

  for (var i = 0; i < solveme.length; i++) {
    /* make sure input boxes don't auto-anything */
    solveme[i].setAttribute("autocomplete","off");
    solveme[i].setAttribute("autocorrect", "off");
    solveme[i].setAttribute("autocapitalize", "off");
    solveme[i].setAttribute("spellcheck", "false");
    solveme[i].value = "";

    /* adjust answer for ignorecase or nospaces */
    var cl = solveme[i].classList;
    var real_answer = solveme[i].dataset.answer;
    if (cl.contains("ignorecase")) {
      real_answer = real_answer.toLowerCase();
    }
    if (cl.contains("nospaces")) {
      real_answer = real_answer.replace(/ /g, "");
    }
    solveme[i].dataset.answer = real_answer;

    /* attach checking function */
    solveme[i].onkeyup = solveme_func;
    solveme[i].onchange = solveme_func;

    solveme[i].insertAdjacentHTML("afterend", " <span class='webex-icon'></span>")
  }

  /* set up radiogroups */
  var radiogroups = document.getElementsByClassName("webex-radiogroup");
  for (var i = 0; i < radiogroups.length; i++) {
    radiogroups[i].onchange = radiogroups_func;
  }

  /* set up selects */
  var selects = document.getElementsByClassName("webex-select");
  for (var i = 0; i < selects.length; i++) {
    selects[i].onchange = select_func;
    selects[i].insertAdjacentHTML("afterend", " <span class='webex-icon'></span>")
  }

  update_total_correct();
}

</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./B3-NeuralNetworks.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Artificial Neural Networks</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./C2-DeepNeuralNetworks.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Deep Neural Networks</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>
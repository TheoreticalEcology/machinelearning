<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5 Explainable AI (xAI), NLP, and RNNs | Machine Learning and AI in TensorFlow and R</title>
  <meta name="description" content="5 Explainable AI (xAI), NLP, and RNNs | Machine Learning and AI in TensorFlow and R" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="5 Explainable AI (xAI), NLP, and RNNs | Machine Learning and AI in TensorFlow and R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="5 Explainable AI (xAI), NLP, and RNNs | Machine Learning and AI in TensorFlow and R" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5 Explainable AI (xAI), NLP, and RNNs | Machine Learning and AI in TensorFlow and R" />
  
  <meta name="twitter:description" content="5 Explainable AI (xAI), NLP, and RNNs | Machine Learning and AI in TensorFlow and R" />
  

<meta name="author" content="Maximilian Pichler and Florian Hartig" />


<meta name="date" content="2021-05-03" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="Deep.html"/>
<link rel="next" href="gans-vaes-and-reinforcement-learning.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #ffffff;
    color: #a0a0a0;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
div.sourceCode
  { color: #1f1c1b; background-color: #ffffff; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span { color: #1f1c1b; } /* Normal */
code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
code span.an { color: #ca60ca; } /* Annotation */
code span.at { color: #0057ae; } /* Attribute */
code span.bn { color: #b08000; } /* BaseN */
code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #924c9d; } /* Char */
code span.cn { color: #aa5500; } /* Constant */
code span.co { color: #898887; } /* Comment */
code span.cv { color: #0095ff; } /* CommentVar */
code span.do { color: #607880; } /* Documentation */
code span.dt { color: #0057ae; } /* DataType */
code span.dv { color: #b08000; } /* DecVal */
code span.er { color: #bf0303; text-decoration: underline; } /* Error */
code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
code span.fl { color: #b08000; } /* Float */
code span.fu { color: #644a9b; } /* Function */
code span.im { color: #ff5500; } /* Import */
code span.in { color: #b08000; } /* Information */
code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
code span.op { color: #1f1c1b; } /* Operator */
code span.ot { color: #006e28; } /* Other */
code span.pp { color: #006e28; } /* Preprocessor */
code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #ff5500; } /* SpecialString */
code span.st { color: #bf0303; } /* String */
code span.va { color: #0057ae; } /* Variable */
code span.vs { color: #bf0303; } /* VerbatimString */
code span.wa { color: #bf0303; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction to Machine Learning</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#unsupervised-learning"><i class="fa fa-check"></i><b>2.1</b> Unsupervised learning</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="introduction.html"><a href="introduction.html#hierarchical-clustering"><i class="fa fa-check"></i><b>2.1.1</b> Hierarchical clustering</a></li>
<li class="chapter" data-level="2.1.2" data-path="introduction.html"><a href="introduction.html#k-means-clustering"><i class="fa fa-check"></i><b>2.1.2</b> k-means clustering</a></li>
<li class="chapter" data-level="2.1.3" data-path="introduction.html"><a href="introduction.html#density-based-clustering"><i class="fa fa-check"></i><b>2.1.3</b> Density-based clustering</a></li>
<li class="chapter" data-level="2.1.4" data-path="introduction.html"><a href="introduction.html#model-based-clustering"><i class="fa fa-check"></i><b>2.1.4</b> Model-based clustering</a></li>
<li class="chapter" data-level="2.1.5" data-path="introduction.html"><a href="introduction.html#ordination"><i class="fa fa-check"></i><b>2.1.5</b> Ordination</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#supervised-learning-regression-and-classification"><i class="fa fa-check"></i><b>2.2</b> Supervised learning: regression and classification</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="introduction.html"><a href="introduction.html#supervised-regression-using-random-forest"><i class="fa fa-check"></i><b>2.2.1</b> Supervised regression using Random Forest</a></li>
<li class="chapter" data-level="2.2.2" data-path="introduction.html"><a href="introduction.html#supervised-classification-using-random-forest"><i class="fa fa-check"></i><b>2.2.2</b> Supervised classification using Random Forest</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#introduction-to-tensorflow"><i class="fa fa-check"></i><b>2.3</b> Introduction to Tensorflow</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="introduction.html"><a href="introduction.html#tensorflow-data-containers"><i class="fa fa-check"></i><b>2.3.1</b> Tensorflow data containers</a></li>
<li class="chapter" data-level="2.3.2" data-path="introduction.html"><a href="introduction.html#tensorflow-data-types---good-practise-with-r-tf"><i class="fa fa-check"></i><b>2.3.2</b> Tensorflow data types - good practise with R-TF</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="introduction.html"><a href="introduction.html#introduction-to-pytorch"><i class="fa fa-check"></i><b>2.4</b> Introduction to PyTorch</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="introduction.html"><a href="introduction.html#pytorch-data-containers"><i class="fa fa-check"></i><b>2.4.1</b> PyTorch data containers</a></li>
<li class="chapter" data-level="2.4.2" data-path="introduction.html"><a href="introduction.html#torch-data-types---good-practise-with-r-tf"><i class="fa fa-check"></i><b>2.4.2</b> Torch data types - good practise with R-TF</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="introduction.html"><a href="introduction.html#first-steps-with-the-keras-framework"><i class="fa fa-check"></i><b>2.5</b> First steps with the keras framework</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="introduction.html"><a href="introduction.html#example-workflow-in-keras"><i class="fa fa-check"></i><b>2.5.1</b> Example workflow in keras</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="fund.html"><a href="fund.html"><i class="fa fa-check"></i><b>3</b> Fundamental principles and techniques</a>
<ul>
<li class="chapter" data-level="3.1" data-path="fund.html"><a href="fund.html#machine-learning-principles"><i class="fa fa-check"></i><b>3.1</b> Machine learning principles</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="fund.html"><a href="fund.html#optimization"><i class="fa fa-check"></i><b>3.1.1</b> Optimization</a></li>
<li class="chapter" data-level="3.1.2" data-path="fund.html"><a href="fund.html#regularization"><i class="fa fa-check"></i><b>3.1.2</b> Regularization</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="fund.html"><a href="fund.html#tree-based-ml-algorithms"><i class="fa fa-check"></i><b>3.2</b> Tree-based ML algorithms</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="fund.html"><a href="fund.html#classification-and-regression-trees"><i class="fa fa-check"></i><b>3.2.1</b> Classification and Regression Trees</a></li>
<li class="chapter" data-level="3.2.2" data-path="fund.html"><a href="fund.html#random-forest"><i class="fa fa-check"></i><b>3.2.2</b> Random Forest</a></li>
<li class="chapter" data-level="3.2.3" data-path="fund.html"><a href="fund.html#boosted-regression-trees"><i class="fa fa-check"></i><b>3.2.3</b> Boosted regression trees</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="fund.html"><a href="fund.html#distance-based-algorithms"><i class="fa fa-check"></i><b>3.3</b> Distance-based algorithms</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="fund.html"><a href="fund.html#k-nearest-neighbor"><i class="fa fa-check"></i><b>3.3.1</b> k-nearest-neighbor</a></li>
<li class="chapter" data-level="3.3.2" data-path="fund.html"><a href="fund.html#support-vector-machines-svm"><i class="fa fa-check"></i><b>3.3.2</b> Support Vector Machines (SVM)</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="fund.html"><a href="fund.html#artificial-neural-networks"><i class="fa fa-check"></i><b>3.4</b> Artificial neural networks</a></li>
<li class="chapter" data-level="3.5" data-path="fund.html"><a href="fund.html#the-standard-ml-pipeline-at-the-example-of-the-titanic-dataset"><i class="fa fa-check"></i><b>3.5</b> The standard ML pipeline at the example of the titanic dataset</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="fund.html"><a href="fund.html#data-cleaning"><i class="fa fa-check"></i><b>3.5.1</b> Data cleaning</a></li>
<li class="chapter" data-level="3.5.2" data-path="fund.html"><a href="fund.html#pre-processing-and-feature-selection"><i class="fa fa-check"></i><b>3.5.2</b> Pre-processing and feature selection</a></li>
<li class="chapter" data-level="3.5.3" data-path="fund.html"><a href="fund.html#split-data-for-training-and-testing"><i class="fa fa-check"></i><b>3.5.3</b> Split data for training and testing</a></li>
<li class="chapter" data-level="3.5.4" data-path="fund.html"><a href="fund.html#model-fitting"><i class="fa fa-check"></i><b>3.5.4</b> Model fitting</a></li>
<li class="chapter" data-level="3.5.5" data-path="fund.html"><a href="fund.html#model-evaluation"><i class="fa fa-check"></i><b>3.5.5</b> Model evaluation</a></li>
<li class="chapter" data-level="3.5.6" data-path="fund.html"><a href="fund.html#predictions-and-submission"><i class="fa fa-check"></i><b>3.5.6</b> Predictions and submission</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="fund.html"><a href="fund.html#bonus---reproducible-ml-pipelines-with-mlr3"><i class="fa fa-check"></i><b>3.6</b> Bonus - Reproducible ML pipelines with mlr3</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="fund.html"><a href="fund.html#mlr3---the-basic-workflow"><i class="fa fa-check"></i><b>3.6.1</b> mlr3 - the basic workflow</a></li>
<li class="chapter" data-level="3.6.2" data-path="fund.html"><a href="fund.html#mlr3---hyper-parameter-tuning"><i class="fa fa-check"></i><b>3.6.2</b> mlr3 - hyper-parameter tuning</a></li>
<li class="chapter" data-level="3.6.3" data-path="fund.html"><a href="fund.html#mlr3---hyper-parameter-tuning-with-oversampling"><i class="fa fa-check"></i><b>3.6.3</b> mlr3 - hyper-parameter tuning with oversampling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Deep.html"><a href="Deep.html"><i class="fa fa-check"></i><b>4</b> Deep learning</a>
<ul>
<li class="chapter" data-level="4.1" data-path="Deep.html"><a href="Deep.html#deep-neural-networks"><i class="fa fa-check"></i><b>4.1</b> Deep Neural Networks</a></li>
<li class="chapter" data-level="4.2" data-path="Deep.html"><a href="Deep.html#convolutional-neural-networks---mnist"><i class="fa fa-check"></i><b>4.2</b> Convolutional Neural Networks - MNIST</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="Deep.html"><a href="Deep.html#data-augmentation"><i class="fa fa-check"></i><b>4.2.1</b> Data Augmentation</a></li>
<li class="chapter" data-level="4.2.2" data-path="Deep.html"><a href="Deep.html#transfer"><i class="fa fa-check"></i><b>4.2.2</b> Transfer learning</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="xAI.html"><a href="xAI.html"><i class="fa fa-check"></i><b>5</b> Explainable AI (xAI), NLP, and RNNs</a>
<ul>
<li class="chapter" data-level="5.1" data-path="xAI.html"><a href="xAI.html#xai-methods"><i class="fa fa-check"></i><b>5.1</b> xAI Methods</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="xAI.html"><a href="xAI.html#variable-importance"><i class="fa fa-check"></i><b>5.1.1</b> Variable Importance</a></li>
<li class="chapter" data-level="5.1.2" data-path="xAI.html"><a href="xAI.html#partial-dependencies"><i class="fa fa-check"></i><b>5.1.2</b> Partial dependencies</a></li>
<li class="chapter" data-level="5.1.3" data-path="xAI.html"><a href="xAI.html#accumulated-local-effects"><i class="fa fa-check"></i><b>5.1.3</b> Accumulated local effects</a></li>
<li class="chapter" data-level="5.1.4" data-path="xAI.html"><a href="xAI.html#friedmans-h-statistic"><i class="fa fa-check"></i><b>5.1.4</b> Friedmans H-statistic</a></li>
<li class="chapter" data-level="5.1.5" data-path="xAI.html"><a href="xAI.html#global-explainer---simplifying-the-ml-model"><i class="fa fa-check"></i><b>5.1.5</b> Global explainer - Simplifying the ML model</a></li>
<li class="chapter" data-level="5.1.6" data-path="xAI.html"><a href="xAI.html#local-explainer---lime-explaining-single-instances-observations"><i class="fa fa-check"></i><b>5.1.6</b> Local explainer - LIME explaining single instances (observations)</a></li>
<li class="chapter" data-level="5.1.7" data-path="xAI.html"><a href="xAI.html#local-explainer---shapley"><i class="fa fa-check"></i><b>5.1.7</b> Local explainer - Shapley</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="xAI.html"><a href="xAI.html#natural-language-processing-nlp"><i class="fa fa-check"></i><b>5.2</b> Natural Language Processing (NLP)</a></li>
<li class="chapter" data-level="5.3" data-path="xAI.html"><a href="xAI.html#recurrent-neural-networks-rnns"><i class="fa fa-check"></i><b>5.3</b> Recurrent neural networks (RNNs)</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="gans-vaes-and-reinforcement-learning.html"><a href="gans-vaes-and-reinforcement-learning.html"><i class="fa fa-check"></i><b>6</b> GANs, VAEs, and Reinforcement learning</a>
<ul>
<li class="chapter" data-level="6.1" data-path="gans-vaes-and-reinforcement-learning.html"><a href="gans-vaes-and-reinforcement-learning.html#generative-adversarial-network-gans"><i class="fa fa-check"></i><b>6.1</b> Generative adversarial network (GANs)</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="gans-vaes-and-reinforcement-learning.html"><a href="gans-vaes-and-reinforcement-learning.html#mnist---gan-based-on-dnns"><i class="fa fa-check"></i><b>6.1.1</b> MNIST - GAN based on DNNs</a></li>
<li class="chapter" data-level="6.1.2" data-path="gans-vaes-and-reinforcement-learning.html"><a href="gans-vaes-and-reinforcement-learning.html#flower---gan"><i class="fa fa-check"></i><b>6.1.2</b> Flower - GAN</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="gans-vaes-and-reinforcement-learning.html"><a href="gans-vaes-and-reinforcement-learning.html#autoencoder"><i class="fa fa-check"></i><b>6.2</b> Autoencoder</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="gans-vaes-and-reinforcement-learning.html"><a href="gans-vaes-and-reinforcement-learning.html#autoencoder---mnist-cnn"><i class="fa fa-check"></i><b>6.2.1</b> Autoencoder - MNIST CNN</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="gans-vaes-and-reinforcement-learning.html"><a href="gans-vaes-and-reinforcement-learning.html#varational-autoencoder"><i class="fa fa-check"></i><b>6.3</b> Varational Autoencoder</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="datasets.html"><a href="datasets.html"><i class="fa fa-check"></i><b>7</b> Datasets</a>
<ul>
<li class="chapter" data-level="7.1" data-path="datasets.html"><a href="datasets.html#titanic"><i class="fa fa-check"></i><b>7.1</b> Titanic</a></li>
<li class="chapter" data-level="7.2" data-path="datasets.html"><a href="datasets.html#plant-pollinator-database"><i class="fa fa-check"></i><b>7.2</b> Plant-pollinator database</a></li>
<li class="chapter" data-level="7.3" data-path="datasets.html"><a href="datasets.html#wine"><i class="fa fa-check"></i><b>7.3</b> Wine</a></li>
<li class="chapter" data-level="7.4" data-path="datasets.html"><a href="datasets.html#nasa"><i class="fa fa-check"></i><b>7.4</b> Nasa</a></li>
<li class="chapter" data-level="7.5" data-path="datasets.html"><a href="datasets.html#flower"><i class="fa fa-check"></i><b>7.5</b> Flower</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning and AI in TensorFlow and R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="xAI" class="section level1" number="5">
<h1><span class="header-section-number">5</span> Explainable AI (xAI), NLP, and RNNs</h1>
<p>The goal of xAI is to explain WHY a fitted ML models makes certain predictions, for example how important different variables are for predictions etc. There are various important applications for this, ranging from a better technical understanding of the models over understanding which data is important to improve predictions to questions of fairness and discrimination (e.g. to understand if an algorithm uses skin color to make a decision).</p>
<p>In general, xAI != causality
Before we discuss xAI methods in more detail, we want to make one thing very clear - in general, xAI methods measure which variables are used by the algorithm for predictions, or how much variables improve predictions.</p>
<p>The important point to note here: if a variable causes something, we could also expect that it helps to predict the very thing. The opposite, however, is not generally true - it is very often possible that a variable that doesn’t cause something can predict something.</p>
<p>In statistics (in particular course: advanced biostatistics), we discuss the issue of causality at length. Here, we don’t want to go into the details, but again, you should in general resist to interpret indicators of importance in xAI as causal effects. They tell you something about what’s going on in the algorithm, not about what’s going on in reality.</p>
<p>Here an example for the variable importance indicators in the RF algorithm. The purpose of this script is to show that RF variable importance will split importance values for collinear variables evenly, even if collinearity is low enough so that variables are sepearable and would be correctly separated by an lm / ANOVA</p>
<p>We simulate a dataset with 2 predictors that are strongly correlated, but only one of them has an effect on the response.</p>
<div class="sourceCode" id="cb318"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb318-1"><a href="xAI.html#cb318-1" aria-hidden="true" tabindex="-1"></a><span class="co"># simulation parameters</span></span>
<span id="cb318-2"><a href="xAI.html#cb318-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="dv">1000</span></span>
<span id="cb318-3"><a href="xAI.html#cb318-3" aria-hidden="true" tabindex="-1"></a>col <span class="ot">=</span> <span class="fl">0.7</span></span>
<span id="cb318-4"><a href="xAI.html#cb318-4" aria-hidden="true" tabindex="-1"></a><span class="co"># create collinear predictors</span></span>
<span id="cb318-5"><a href="xAI.html#cb318-5" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">=</span> <span class="fu">runif</span>(n)</span>
<span id="cb318-6"><a href="xAI.html#cb318-6" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">=</span> col <span class="sc">*</span> x1 <span class="sc">+</span> (<span class="dv">1</span><span class="sc">-</span>col) <span class="sc">*</span> <span class="fu">runif</span>(n)</span>
<span id="cb318-7"><a href="xAI.html#cb318-7" aria-hidden="true" tabindex="-1"></a><span class="co"># response is only influenced by x1</span></span>
<span id="cb318-8"><a href="xAI.html#cb318-8" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> x1 <span class="sc">+</span> <span class="fu">rnorm</span>(n)</span></code></pre></div>
<p>lm / anova correctly identify x1 as causal variable</p>
<div class="sourceCode" id="cb319"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb319-1"><a href="xAI.html#cb319-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2))</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: y
##            Df Sum Sq Mean Sq F value Pr(&gt;F)    
## x1          1  73.59  73.595 74.0440 &lt;2e-16 ***
## x2          1   1.75   1.751  1.7613 0.1848    
## Residuals 997 990.95   0.994                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Fit RF and show variable importance</p>
<div class="sourceCode" id="cb321"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb321-1"><a href="xAI.html#cb321-1" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2, <span class="at">importance=</span><span class="cn">TRUE</span>)</span>
<span id="cb321-2"><a href="xAI.html#cb321-2" aria-hidden="true" tabindex="-1"></a><span class="fu">varImpPlot</span>(fit)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-155-1.png" width="672" />
Variable importance is now split nearly evenly.</p>
<p>Task: understand why this is - remember:</p>
<ul>
<li>How the random forest works - variables are randomly hidden from the regression tree when the trees for the forest are built</li>
<li>Remember that as x1 ~ x2, we can use x2 as a replacement for x1</li>
<li>Remember that the variable importance measures the average contributions of the different variables in the trees of the forest</li>
</ul>
<div id="xai-methods" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> xAI Methods</h2>
<p>In this lecture we will work with another famous dataset, the Boston housing dataset:</p>
<p>We will fit a random forest and use the iml pkg for xAI, see <img src="https://christophm.github.io/interpretable-ml-book/" /></p>
<div class="sourceCode" id="cb322"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb322-1"><a href="xAI.html#cb322-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb322-2"><a href="xAI.html#cb322-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;iml&quot;</span>)</span>
<span id="cb322-3"><a href="xAI.html#cb322-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;randomForest&quot;</span>)</span>
<span id="cb322-4"><a href="xAI.html#cb322-4" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;Boston&quot;</span>, <span class="at">package =</span> <span class="st">&quot;MASS&quot;</span>)</span>
<span id="cb322-5"><a href="xAI.html#cb322-5" aria-hidden="true" tabindex="-1"></a>rf <span class="ot">=</span> <span class="fu">randomForest</span>(medv <span class="sc">~</span> ., <span class="at">data =</span> Boston, <span class="at">ntree =</span> <span class="dv">50</span>)</span></code></pre></div>
<p>xAI packages are generic, i.e. they can handle almost all ML models. First, we have to create a Predictor object, that holds the model and the data. The iml package uses R6 classes: New objects can be created by calling Predictor$new().</p>
<div class="sourceCode" id="cb323"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb323-1"><a href="xAI.html#cb323-1" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> Boston[<span class="fu">which</span>(<span class="fu">names</span>(Boston) <span class="sc">!=</span> <span class="st">&quot;medv&quot;</span>)]</span>
<span id="cb323-2"><a href="xAI.html#cb323-2" aria-hidden="true" tabindex="-1"></a>predictor <span class="ot">=</span> Predictor<span class="sc">$</span><span class="fu">new</span>(rf, <span class="at">data =</span> X, <span class="at">y =</span> Boston<span class="sc">$</span>medv)</span></code></pre></div>
<div id="variable-importance" class="section level3" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Variable Importance</h3>
<p>Importance - not to be mistaken for the RF importance. This importance can be calculated for all ML models and is based on a permutation approach (have a look at the book):</p>
<div class="sourceCode" id="cb324"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb324-1"><a href="xAI.html#cb324-1" aria-hidden="true" tabindex="-1"></a>imp <span class="ot">=</span> FeatureImp<span class="sc">$</span><span class="fu">new</span>(predictor, <span class="at">loss =</span> <span class="st">&quot;mae&quot;</span>)</span>
<span id="cb324-2"><a href="xAI.html#cb324-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(imp)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-158-1.png" width="672" /></p>
<p>It tells us how important the individual variables are for predictions.</p>
</div>
<div id="partial-dependencies" class="section level3" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Partial dependencies</h3>
<p>Partial dependencies are similar to allEffects plot, the idea is to visualize “marginal effects” of predictors (with the feature argument we specify the variable we want to visualize):</p>
<div class="sourceCode" id="cb325"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb325-1"><a href="xAI.html#cb325-1" aria-hidden="true" tabindex="-1"></a>eff <span class="ot">=</span> FeatureEffect<span class="sc">$</span><span class="fu">new</span>(predictor, <span class="at">feature =</span> <span class="st">&quot;rm&quot;</span>, <span class="at">method =</span> <span class="st">&quot;pdp&quot;</span>, <span class="at">grid.size =</span> <span class="dv">30</span>)</span>
<span id="cb325-2"><a href="xAI.html#cb325-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(eff)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-159-1.png" width="672" /></p>
<p>Partial dependencies can be also plotted for single observations:</p>
<div class="sourceCode" id="cb326"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb326-1"><a href="xAI.html#cb326-1" aria-hidden="true" tabindex="-1"></a>eff <span class="ot">=</span> FeatureEffect<span class="sc">$</span><span class="fu">new</span>(predictor, <span class="at">feature =</span> <span class="st">&quot;rm&quot;</span>, <span class="at">method =</span> <span class="st">&quot;pdp+ice&quot;</span>, <span class="at">grid.size =</span> <span class="dv">30</span>)</span>
<span id="cb326-2"><a href="xAI.html#cb326-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(eff)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-160-1.png" width="672" /></p>
<p>One disadvantage of partial dependencies is that they are sensitive to correlated predictors. Accumulated local effects can be used to account for correlation for predictors</p>
</div>
<div id="accumulated-local-effects" class="section level3" number="5.1.3">
<h3><span class="header-section-number">5.1.3</span> Accumulated local effects</h3>
<p>ALE re basically partial dependencies plots but try to correct for correlations between predictors</p>
<div class="sourceCode" id="cb327"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb327-1"><a href="xAI.html#cb327-1" aria-hidden="true" tabindex="-1"></a>ale <span class="ot">=</span> FeatureEffect<span class="sc">$</span><span class="fu">new</span>(predictor, <span class="at">feature =</span> <span class="st">&quot;rm&quot;</span>, <span class="at">method =</span> <span class="st">&quot;ale&quot;</span>)</span>
<span id="cb327-2"><a href="xAI.html#cb327-2" aria-hidden="true" tabindex="-1"></a>ale<span class="sc">$</span><span class="fu">plot</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-161-1.png" width="672" /></p>
<p>If there is no collinearity, you shouldn’t see much difference between partial dependencies and ALE plots.</p>
</div>
<div id="friedmans-h-statistic" class="section level3" number="5.1.4">
<h3><span class="header-section-number">5.1.4</span> Friedmans H-statistic</h3>
<p>The H-statistic can be used to find interactions between predictors. However, again, keep in mind that the H-statistic is sensible to correlation between predictors:</p>
<div class="sourceCode" id="cb328"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb328-1"><a href="xAI.html#cb328-1" aria-hidden="true" tabindex="-1"></a>interact <span class="ot">=</span> Interaction<span class="sc">$</span><span class="fu">new</span>(predictor, <span class="st">&quot;lstat&quot;</span>)</span>
<span id="cb328-2"><a href="xAI.html#cb328-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(interact)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-162-1.png" width="672" /></p>
</div>
<div id="global-explainer---simplifying-the-ml-model" class="section level3" number="5.1.5">
<h3><span class="header-section-number">5.1.5</span> Global explainer - Simplifying the ML model</h3>
<p>Another idea is to simplify the ML model with another simpler model such as a decision tree. We create predictions for a lot of different predictors values and then we will fit a decision tree on the predictions:</p>
<div class="sourceCode" id="cb329"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb329-1"><a href="xAI.html#cb329-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(partykit)</span></code></pre></div>
<pre><code>## Loading required package: libcoin</code></pre>
<pre><code>## Loading required package: mvtnorm</code></pre>
<pre><code>## 
## Attaching package: &#39;mvtnorm&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:mclust&#39;:
## 
##     dmvnorm</code></pre>
<div class="sourceCode" id="cb334"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb334-1"><a href="xAI.html#cb334-1" aria-hidden="true" tabindex="-1"></a>tree <span class="ot">=</span> TreeSurrogate<span class="sc">$</span><span class="fu">new</span>(predictor, <span class="at">maxdepth =</span> <span class="dv">2</span>)</span>
<span id="cb334-2"><a href="xAI.html#cb334-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(tree)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-163-1.png" width="672" /></p>
</div>
<div id="local-explainer---lime-explaining-single-instances-observations" class="section level3" number="5.1.6">
<h3><span class="header-section-number">5.1.6</span> Local explainer - LIME explaining single instances (observations)</h3>
<p>The global approach is to simplify a black-box model via a simpler surrogate Model.</p>
<p>However, sometimes we are only interested in understanding how single observations/predictions are generated. The lime approach explores the feature space around one observations and fits then a simpler model (e.g. a linear model) on the feature space around one observation:</p>
<div class="sourceCode" id="cb335"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb335-1"><a href="xAI.html#cb335-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glmnet)</span></code></pre></div>
<pre><code>## Loaded glmnet 4.1-1</code></pre>
<div class="sourceCode" id="cb337"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb337-1"><a href="xAI.html#cb337-1" aria-hidden="true" tabindex="-1"></a>lime.explain <span class="ot">=</span> LocalModel<span class="sc">$</span><span class="fu">new</span>(predictor, <span class="at">x.interest =</span> X[<span class="dv">1</span>,])</span></code></pre></div>
<pre><code>## Loading required package: gower</code></pre>
<div class="sourceCode" id="cb339"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb339-1"><a href="xAI.html#cb339-1" aria-hidden="true" tabindex="-1"></a>lime.explain<span class="sc">$</span>results</span></code></pre></div>
<pre><code>##               beta x.recoded    effect x.original feature feature.value
## rm       4.1893817     6.575 27.545185      6.575      rm      rm=6.575
## ptratio -0.5307031    15.300 -8.119758       15.3 ptratio  ptratio=15.3
## lstat   -0.4398104     4.980 -2.190256       4.98   lstat    lstat=4.98</code></pre>
<div class="sourceCode" id="cb341"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb341-1"><a href="xAI.html#cb341-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lime.explain)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-164-1.png" width="672" /></p>
</div>
<div id="local-explainer---shapley" class="section level3" number="5.1.7">
<h3><span class="header-section-number">5.1.7</span> Local explainer - Shapley</h3>
<p>Shapley computes feature contributions for single predictions with the Shapley value, an approach from cooperative game theory. The idea is that the features values of an instance cooperate to achieve the prediction. The Shapley value fairly distributes the difference of the instance’s prediction and the datasets average prediction among the features:</p>
<div class="sourceCode" id="cb342"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb342-1"><a href="xAI.html#cb342-1" aria-hidden="true" tabindex="-1"></a>shapley <span class="ot">=</span> Shapley<span class="sc">$</span><span class="fu">new</span>(predictor, <span class="at">x.interest =</span> X[<span class="dv">1</span>,])</span>
<span id="cb342-2"><a href="xAI.html#cb342-2" aria-hidden="true" tabindex="-1"></a>shapley<span class="sc">$</span><span class="fu">plot</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-165-1.png" width="672" /></p>
</div>
</div>
<div id="natural-language-processing-nlp" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Natural Language Processing (NLP)</h2>
<p>What this video to get an idea about what NLP is about</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/UFtXy0KRxVI" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<p>See also the blog post linked with the youtube video with accompanying code to the video. Moreover, here is an article that shows now NLP works with keras, however, written in Python. As a challenge, you can take the code and implement it in R <img src="https://nlpforhackers.io/keras-intro/" /></p>
</div>
<div id="recurrent-neural-networks-rnns" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> Recurrent neural networks (RNNs)</h2>
<p>Recurrent Neural Networks are used to model sequential data, i.e. temporal sequence that exhibits temporal dynamic behavior. Here is a good introduction to the topic:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/SEnXr6v2ifU" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
</iframe>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="Deep.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="gans-vaes-and-reinforcement-learning.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

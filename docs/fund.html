<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Fundamental principles and techniques | Machine Learning and AI in TensorFlow and R</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Fundamental principles and techniques | Machine Learning and AI in TensorFlow and R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Fundamental principles and techniques | Machine Learning and AI in TensorFlow and R" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Maximilian Pichler and Florian Hartig" />


<meta name="date" content="2021-04-29" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introduction.html"/>

<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction to Machine Learning</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#supervised-learning-regression-and-classification"><i class="fa fa-check"></i><b>2.1</b> Supervised learning: regression and classification</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="introduction.html"><a href="introduction.html#supervised-regression-using-random-forest"><i class="fa fa-check"></i><b>2.1.1</b> Supervised regression using Random Forest</a></li>
<li class="chapter" data-level="2.1.2" data-path="introduction.html"><a href="introduction.html#supervised-classification-using-random-forest"><i class="fa fa-check"></i><b>2.1.2</b> Supervised classification using Random Forest</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#unsupervised-learning"><i class="fa fa-check"></i><b>2.2</b> Unsupervised learning</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="introduction.html"><a href="introduction.html#k-means-clustering"><i class="fa fa-check"></i><b>2.2.1</b> k-means clustering</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#introduction-to-tensorflow"><i class="fa fa-check"></i><b>2.3</b> Introduction to Tensorflow</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="introduction.html"><a href="introduction.html#tensorflow-data-containers"><i class="fa fa-check"></i><b>2.3.1</b> Tensorflow data containers</a></li>
<li class="chapter" data-level="2.3.2" data-path="introduction.html"><a href="introduction.html#tensorflow-data-types---good-practise-with-r-tf"><i class="fa fa-check"></i><b>2.3.2</b> Tensorflow data types - good practise with R-TF</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="introduction.html"><a href="introduction.html#first-steps-with-the-keras-framework"><i class="fa fa-check"></i><b>2.4</b> First steps with the keras framework</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="introduction.html"><a href="introduction.html#example-workflow-in-keras"><i class="fa fa-check"></i><b>2.4.1</b> Example workflow in keras</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="fund.html"><a href="fund.html"><i class="fa fa-check"></i><b>3</b> Fundamental principles and techniques</a>
<ul>
<li class="chapter" data-level="3.1" data-path="fund.html"><a href="fund.html#machine-learning-principles"><i class="fa fa-check"></i><b>3.1</b> Machine learning principles</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="fund.html"><a href="fund.html#optimization"><i class="fa fa-check"></i><b>3.1.1</b> Optimization</a></li>
<li class="chapter" data-level="3.1.2" data-path="fund.html"><a href="fund.html#regularization"><i class="fa fa-check"></i><b>3.1.2</b> Regularization</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="fund.html"><a href="fund.html#tree-based-ml-algorithms"><i class="fa fa-check"></i><b>3.2</b> Tree-based ML algorithms</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="fund.html"><a href="fund.html#classification-and-regression-trees"><i class="fa fa-check"></i><b>3.2.1</b> Classification and Regression Trees</a></li>
<li class="chapter" data-level="3.2.2" data-path="fund.html"><a href="fund.html#random-forest"><i class="fa fa-check"></i><b>3.2.2</b> Random Forest</a></li>
<li class="chapter" data-level="3.2.3" data-path="fund.html"><a href="fund.html#boosted-regression-trees"><i class="fa fa-check"></i><b>3.2.3</b> Boosted regression trees</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="fund.html"><a href="fund.html#distance-based-algorithms"><i class="fa fa-check"></i><b>3.3</b> Distance-based algorithms</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="fund.html"><a href="fund.html#k-nearest-neighbor"><i class="fa fa-check"></i><b>3.3.1</b> k-nearest-neighbor</a></li>
<li class="chapter" data-level="3.3.2" data-path="fund.html"><a href="fund.html#support-vector-machines-svm"><i class="fa fa-check"></i><b>3.3.2</b> Support Vector Machines (SVM)</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="fund.html"><a href="fund.html#artificial-neural-networks"><i class="fa fa-check"></i><b>3.4</b> Artificial neural networks</a></li>
<li class="chapter" data-level="3.5" data-path="fund.html"><a href="fund.html#the-standard-ml-pipeline"><i class="fa fa-check"></i><b>3.5</b> The standard ML pipeline</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="fund.html"><a href="fund.html#example-of-the-ml-workflow-with-the-titanic-dataset"><i class="fa fa-check"></i><b>3.5.1</b> Example of the ML workflow with the titanic dataset</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning and AI in TensorFlow and R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="fund" class="section level1" number="3">
<h1><span class="header-section-number">3</span> Fundamental principles and techniques</h1>
<div id="machine-learning-principles" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Machine learning principles</h2>
<div id="optimization" class="section level3" number="3.1.1">
<h3><span class="header-section-number">3.1.1</span> Optimization</h3>
<p>from wikipedia: " an optimization problem is the problem of finding the best solution from all feasible solutions"</p>
<p>Why do we need this “optimization”?</p>
<ul>
<li><p>A loss function (e.g. we tell in each training step the algorithm how many observations were miss-classified) guides the training of ML algorithms</p></li>
<li><p>Based on the loss, the optimizer tries to update the weights of the ML algorithms in a way that the loss function is minimized</p></li>
</ul>
<p>Calculating analytically the global optima of a function is a non-trivial problem and bunch of diverse optimization algorithms evolved</p>
<p>Some optimization algorithms are inspired by biological systemse.g. Ants, Bee, or even slimve algorithms):</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/X-iSQQgOd1A" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<div id="small-optimization-example" class="section level4" number="3.1.1.1">
<h4><span class="header-section-number">3.1.1.1</span> Small optimization example</h4>
<p>We have the following function:</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="fund.html#cb56-1" aria-hidden="true" tabindex="-1"></a>func <span class="ot">=</span> <span class="cf">function</span>(x) <span class="fu">return</span>(x<span class="sc">^</span><span class="dv">2</span>)</span></code></pre></div>
<p>which we want to minimize, we could do this by hand:</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="fund.html#cb57-1" aria-hidden="true" tabindex="-1"></a>a <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="dv">100</span>)</span>
<span id="cb57-2"><a href="fund.html#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(a, <span class="fu">func</span>(a))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
<p>The smallest value is at x = 0 (to be honest, we can calculate this for this simple case analytically)</p>
<p>We can also use an optimizer with the optim(…) function</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="fund.html#cb58-1" aria-hidden="true" tabindex="-1"></a>opt <span class="ot">=</span> <span class="fu">optim</span>(<span class="fl">1.0</span>, func)</span></code></pre></div>
<pre><code>## Warning in optim(1, func): one-dimensional optimization by Nelder-Mead is unreliable:
## use &quot;Brent&quot; or optimize() directly</code></pre>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="fund.html#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(opt<span class="sc">$</span>par)</span></code></pre></div>
<pre><code>## [1] -8.881784e-16</code></pre>
<p>opt$par will return the best values found by the optimizer</p>
</div>
<div id="advanced-optimization-example" class="section level4" number="3.1.1.2">
<h4><span class="header-section-number">3.1.1.2</span> Advanced optimization example</h4>
<p>We will now optimze the weights (slopes) for linear regression model.</p>
<p>Basically, we will implement lm(y~x) on our own:</p>
<p>Load the airquality dataset, remove NAs, split it into predictors and response, and scale the predictors:</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="fund.html#cb62-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality[<span class="fu">complete.cases</span>(airquality<span class="sc">$</span>Ozone) <span class="sc">&amp;</span> <span class="fu">complete.cases</span>(airquality<span class="sc">$</span>Solar.R),]</span>
<span id="cb62-2"><a href="fund.html#cb62-2" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb62-3"><a href="fund.html#cb62-3" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span> data<span class="sc">$</span>Ozone</span></code></pre></div>
<p>The model we want to optimize: <span class="math inline">\(ozone = Solar.R*X1 + Wind*X2 + Temp*X3 + Month*X4 + Day*X5 + X6\)</span></p>
<p>Our loss function: mean(predicted ozone - true ozone)^2)</p>
<p>We found to find the parameters X1-X6 for which the loss function is the smallest:</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="fund.html#cb63-1" aria-hidden="true" tabindex="-1"></a>linear_regression <span class="ot">=</span> <span class="cf">function</span>(w) {</span>
<span id="cb63-2"><a href="fund.html#cb63-2" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">=</span> w[<span class="dv">1</span>]<span class="sc">*</span>X[,<span class="dv">1</span>] <span class="sc">+</span> <span class="co"># Solar.R</span></span>
<span id="cb63-3"><a href="fund.html#cb63-3" aria-hidden="true" tabindex="-1"></a>         w[<span class="dv">2</span>]<span class="sc">*</span>X[,<span class="dv">2</span>] <span class="sc">+</span> <span class="co"># Wind</span></span>
<span id="cb63-4"><a href="fund.html#cb63-4" aria-hidden="true" tabindex="-1"></a>         w[<span class="dv">3</span>]<span class="sc">*</span>X[,<span class="dv">3</span>] <span class="sc">+</span> <span class="co"># Temp</span></span>
<span id="cb63-5"><a href="fund.html#cb63-5" aria-hidden="true" tabindex="-1"></a>         w[<span class="dv">4</span>]<span class="sc">*</span>X[,<span class="dv">4</span>] <span class="sc">+</span> <span class="co"># Month</span></span>
<span id="cb63-6"><a href="fund.html#cb63-6" aria-hidden="true" tabindex="-1"></a>         w[<span class="dv">5</span>]<span class="sc">*</span>X[,<span class="dv">5</span>] <span class="sc">+</span></span>
<span id="cb63-7"><a href="fund.html#cb63-7" aria-hidden="true" tabindex="-1"></a>         w[<span class="dv">6</span>]         <span class="co"># or X %*% w[1:5] + w[6]</span></span>
<span id="cb63-8"><a href="fund.html#cb63-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># loss  = MSE, we want to find the optimal weights </span></span>
<span id="cb63-9"><a href="fund.html#cb63-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># to minimize the sum of squared residuals</span></span>
<span id="cb63-10"><a href="fund.html#cb63-10" aria-hidden="true" tabindex="-1"></a>  loss <span class="ot">=</span> <span class="fu">mean</span>((pred <span class="sc">-</span> Y)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb63-11"><a href="fund.html#cb63-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(loss)</span>
<span id="cb63-12"><a href="fund.html#cb63-12" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>The linear_regression function takes potential solutions for the weights (X1-X6) and will return the loss for these weights:</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="fund.html#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="fu">linear_regression</span>(<span class="fu">runif</span>(<span class="dv">6</span>))</span></code></pre></div>
<pre><code>## [1] 2847.567</code></pre>
<p>Let’s try it bruteforce (which means we will try to find the optimal solution with random a set of random weights):</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="fund.html#cb66-1" aria-hidden="true" tabindex="-1"></a>random_search <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(<span class="dv">6</span><span class="sc">*</span><span class="dv">5000</span>,<span class="sc">-</span><span class="dv">10</span>,<span class="dv">10</span>), <span class="dv">5000</span>, <span class="dv">6</span>)</span>
<span id="cb66-2"><a href="fund.html#cb66-2" aria-hidden="true" tabindex="-1"></a>losses <span class="ot">=</span> <span class="fu">apply</span>(random_search, <span class="dv">1</span>, linear_regression)</span>
<span id="cb66-3"><a href="fund.html#cb66-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(losses, <span class="at">type =</span> <span class="st">&quot;l&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-45-1.png" width="672" /></p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="fund.html#cb67-1" aria-hidden="true" tabindex="-1"></a>random_search[<span class="fu">which.min</span>(losses),]</span></code></pre></div>
<pre><code>## [1]  5.0567712 -7.8550341  7.4573370  0.8109562  2.0097918  9.3807506</code></pre>
<p>Bruteforce isn’t a good approach, it might work well with only a few parameters.</p>
<p>Let’s try it with the optim function:</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="fund.html#cb69-1" aria-hidden="true" tabindex="-1"></a>opt <span class="ot">=</span> <span class="fu">optim</span>(<span class="fu">runif</span>(<span class="dv">6</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>), linear_regression)</span>
<span id="cb69-2"><a href="fund.html#cb69-2" aria-hidden="true" tabindex="-1"></a>opt<span class="sc">$</span>par</span></code></pre></div>
<pre><code>## [1]   4.150032 -15.100683  11.409332  -5.445377  -3.115452  42.502556</code></pre>
<p>Compare the weights the estimated weights of the lm() function:</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="fund.html#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">lm</span>(Y<span class="sc">~</span>X))</span></code></pre></div>
<pre><code>## (Intercept)    XSolar.R       XWind       XTemp      XMonth        XDay 
##   42.099099    4.582620  -11.806072   18.066786   -4.479175    2.384705</code></pre>
</div>
</div>
<div id="regularization" class="section level3" number="3.1.2">
<h3><span class="header-section-number">3.1.2</span> Regularization</h3>
<p>There are several ways to regularize models. In this section we will focus on lasso and ridge regularization for weights in neural networks.</p>
<p>The idea of lasso and ridge regularization is to put some type of rubber band on the weights and pull them to zero, important weights are able to pull away from zero.</p>
<p>Lasso and ridge have slightly different properties:</p>
<ul>
<li>Lasso: abs( sum(Weights))</li>
<li>Ridge: (sum(Weights))^2
Lasso tries to push the weights directly to zero, where as the Ridge allows small values around zero (caused by the difference of the absolute and squared function).</li>
</ul>
<p>Let’s have a look at a keras model with and without regularization (we will use here a network without hidden layers == linear regression model):</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="fund.html#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb73-2"><a href="fund.html#cb73-2" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality[<span class="fu">complete.cases</span>(airquality),]</span>
<span id="cb73-3"><a href="fund.html#cb73-3" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb73-4"><a href="fund.html#cb73-4" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span> data<span class="sc">$</span>Ozone</span>
<span id="cb73-5"><a href="fund.html#cb73-5" aria-hidden="true" tabindex="-1"></a><span class="co"># l1/l2 on linear model</span></span>
<span id="cb73-6"><a href="fund.html#cb73-6" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb73-7"><a href="fund.html#cb73-7" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb73-8"><a href="fund.html#cb73-8" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;linear&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(<span class="fu">dim</span>(X)[<span class="dv">2</span>]))</span>
<span id="cb73-9"><a href="fund.html#cb73-9" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## Model: &quot;sequential_9&quot;
## ____________________________________________________________________________________________________________________________________________
## Layer (type)                                                   Output Shape                                            Param #              
## ============================================================================================================================================
## dense_18 (Dense)                                               (None, 1)                                               6                    
## ============================================================================================================================================
## Total params: 6
## Trainable params: 6
## Non-trainable params: 0
## ____________________________________________________________________________________________________________________________________________</code></pre>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="fund.html#cb75-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb75-2"><a href="fund.html#cb75-2" aria-hidden="true" tabindex="-1"></a> <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">lr =</span> <span class="fl">0.5</span>))</span>
<span id="cb75-3"><a href="fund.html#cb75-3" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb75-4"><a href="fund.html#cb75-4" aria-hidden="true" tabindex="-1"></a> model <span class="sc">%&gt;%</span></span>
<span id="cb75-5"><a href="fund.html#cb75-5" aria-hidden="true" tabindex="-1"></a> <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, <span class="at">epochs =</span> 50L, <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb75-6"><a href="fund.html#cb75-6" aria-hidden="true" tabindex="-1"></a>unconstrained <span class="ot">=</span> model<span class="sc">$</span><span class="fu">get_weights</span>()</span>
<span id="cb75-7"><a href="fund.html#cb75-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(Y<span class="sc">~</span>X))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Y ~ X)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -37.014 -12.284  -3.302   8.454  95.348 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   42.099      1.980  21.264  &lt; 2e-16 ***
## XSolar.R       4.583      2.135   2.147   0.0341 *  
## XWind        -11.806      2.293  -5.149 1.23e-06 ***
## XTemp         18.067      2.610   6.922 3.66e-10 ***
## XMonth        -4.479      2.230  -2.009   0.0471 *  
## XDay           2.385      2.000   1.192   0.2358    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 20.86 on 105 degrees of freedom
## Multiple R-squared:  0.6249, Adjusted R-squared:  0.6071 
## F-statistic: 34.99 on 5 and 105 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="fund.html#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">lm</span>(Y<span class="sc">~</span>X))</span></code></pre></div>
<pre><code>## (Intercept)    XSolar.R       XWind       XTemp      XMonth        XDay 
##   42.099099    4.582620  -11.806072   18.066786   -4.479175    2.384705</code></pre>
<p>Now we will put a l1 (lasso) regularization on the weights:</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="fund.html#cb79-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb79-2"><a href="fund.html#cb79-2" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb79-3"><a href="fund.html#cb79-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;linear&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(<span class="fu">dim</span>(X)[<span class="dv">2</span>]), </span>
<span id="cb79-4"><a href="fund.html#cb79-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1</span>(<span class="dv">10</span>), <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l1</span>(<span class="dv">10</span>))</span>
<span id="cb79-5"><a href="fund.html#cb79-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## Model: &quot;sequential_10&quot;
## ____________________________________________________________________________________________________________________________________________
## Layer (type)                                                   Output Shape                                            Param #              
## ============================================================================================================================================
## dense_19 (Dense)                                               (None, 1)                                               6                    
## ============================================================================================================================================
## Total params: 6
## Trainable params: 6
## Non-trainable params: 0
## ____________________________________________________________________________________________________________________________________________</code></pre>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="fund.html#cb81-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb81-2"><a href="fund.html#cb81-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">lr =</span> <span class="fl">0.5</span>), <span class="at">metrics =</span> <span class="fu">c</span>(metric_mean_squared_error))</span>
<span id="cb81-3"><a href="fund.html#cb81-3" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb81-4"><a href="fund.html#cb81-4" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb81-5"><a href="fund.html#cb81-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, <span class="at">epochs =</span> 30L, <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb81-6"><a href="fund.html#cb81-6" aria-hidden="true" tabindex="-1"></a>l1 <span class="ot">=</span> model<span class="sc">$</span><span class="fu">get_weights</span>()</span>
<span id="cb81-7"><a href="fund.html#cb81-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(Y<span class="sc">~</span>X))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Y ~ X)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -37.014 -12.284  -3.302   8.454  95.348 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   42.099      1.980  21.264  &lt; 2e-16 ***
## XSolar.R       4.583      2.135   2.147   0.0341 *  
## XWind        -11.806      2.293  -5.149 1.23e-06 ***
## XTemp         18.067      2.610   6.922 3.66e-10 ***
## XMonth        -4.479      2.230  -2.009   0.0471 *  
## XDay           2.385      2.000   1.192   0.2358    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 20.86 on 105 degrees of freedom
## Multiple R-squared:  0.6249, Adjusted R-squared:  0.6071 
## F-statistic: 34.99 on 5 and 105 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="fund.html#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">lm</span>(Y<span class="sc">~</span>X))</span></code></pre></div>
<pre><code>## (Intercept)    XSolar.R       XWind       XTemp      XMonth        XDay 
##   42.099099    4.582620  -11.806072   18.066786   -4.479175    2.384705</code></pre>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="fund.html#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(<span class="fu">unlist</span>(l1), <span class="fu">unlist</span>(unconstrained))</span></code></pre></div>
<pre><code>##              [,1]       [,2]
## [1,]  1.335416317   4.758992
## [2,] -8.142886162 -12.199446
## [3,] 13.692774773  16.987839
## [4,]  0.015733831  -3.922871
## [5,] -0.002944823   2.305355
## [6,] 33.569160461  41.365257</code></pre>
</div>
</div>
<div id="tree-based-ml-algorithms" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Tree-based ML algorithms</h2>
<p>Famous ML algorithms such as random Forest and gradient boosted trees are based on classification and regression trees.</p>
<div id="classification-and-regression-trees" class="section level3" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> Classification and Regression Trees</h3>
<p>In this lecture we will explore regression and classifaction trees at the example of the airquality data set:</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="fund.html#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb87-2"><a href="fund.html#cb87-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart.plot)</span>
<span id="cb87-3"><a href="fund.html#cb87-3" aria-hidden="true" tabindex="-1"></a>data<span class="ot">=</span>airquality[<span class="fu">complete.cases</span>(airquality),]</span></code></pre></div>
<p>Fit and visualize a regression tree:</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="fund.html#cb88-1" aria-hidden="true" tabindex="-1"></a>rt <span class="ot">=</span> <span class="fu">rpart</span>(Ozone<span class="sc">~</span>., <span class="at">data =</span> data,<span class="at">control =</span> <span class="fu">rpart.control</span>(<span class="at">minsplit =</span> <span class="dv">10</span>))</span>
<span id="cb88-2"><a href="fund.html#cb88-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(rt)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-51-1.png" width="672" /></p>
<p>Visualize the predictions:</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="fund.html#cb89-1" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">predict</span>(rt, data)</span>
<span id="cb89-2"><a href="fund.html#cb89-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(data<span class="sc">$</span>Temp, data<span class="sc">$</span>Ozone)</span>
<span id="cb89-3"><a href="fund.html#cb89-3" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(data<span class="sc">$</span>Temp[<span class="fu">order</span>(data<span class="sc">$</span>Temp)], pred[<span class="fu">order</span>(data<span class="sc">$</span>Temp)], <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-52-1.png" width="672" /></p>
<p>The angular form of the prediction line is typical for regression trees.</p>
<p>There is one important hyper-parameter for regression trees: minsplit</p>
<ul>
<li>controls the depth of tree (see the help of tree for a description)</li>
<li>controls the complexity of the tree and can be seen also as a regularization parameter</li>
</ul>
</div>
<div id="random-forest" class="section level3" number="3.2.2">
<h3><span class="header-section-number">3.2.2</span> Random Forest</h3>
<p>Random Forest creates an ensemble of regression/classification trees.</p>
<p>However, there are two randomization steps with the RF that are responsible for the success of RF:</p>
<ul>
<li>bootstrap sample for each tree (we will sample observations with replacement from the dataset)</li>
<li>at each split, we will sample a subset of predictors which are then considered as potential splitting criterion</li>
</ul>
<p>Fit a RF and visualize the predictions:</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="fund.html#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span>
<span id="cb90-2"><a href="fund.html#cb90-2" aria-hidden="true" tabindex="-1"></a>rf <span class="ot">=</span> <span class="fu">randomForest</span>(Ozone<span class="sc">~</span>., <span class="at">data =</span> data)</span>
<span id="cb90-3"><a href="fund.html#cb90-3" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">predict</span>(rf, data)</span>
<span id="cb90-4"><a href="fund.html#cb90-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(Ozone<span class="sc">~</span>Temp, <span class="at">data =</span> data)</span>
<span id="cb90-5"><a href="fund.html#cb90-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(data<span class="sc">$</span>Temp[<span class="fu">order</span>(data<span class="sc">$</span>Temp)], pred[<span class="fu">order</span>(data<span class="sc">$</span>Temp)], <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-53-1.png" width="672" /></p>
<p>One advantage of RF is that we will get a variable importance:</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="fund.html#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="fu">importance</span>(rf)</span></code></pre></div>
<pre><code>##         IncNodePurity
## Solar.R      18441.43
## Wind         31140.89
## Temp         33965.21
## Month        11031.51
## Day          15610.66</code></pre>
<p>Important hyperparameters:</p>
<ul>
<li>Similar to regression and classification trees, the hyper parameter nodesize controls for complexity. -&gt; Minimum size of terminal nodes. Setting this number larger causes smaller trees to be grown (and thus take less time). Note that the default values are different for classification (1) and regression (5).</li>
<li>mtry - Number of trees to grow. This should not be set to too small a number, to ensure that every input row gets predicted at least a few times.</li>
</ul>
</div>
<div id="boosted-regression-trees" class="section level3" number="3.2.3">
<h3><span class="header-section-number">3.2.3</span> Boosted regression trees</h3>
<p>RF fits hundreds of trees independent of each other.</p>
<p>In boosted regression trees, we will start with a weak learner (weak learner == regression tree) and then fit sequentially additional weak learners.</p>
<p>There are two different approaches to enhance the performance:</p>
<ul>
<li>AdaBoost, wrong classified observations (by the previous tree) will get a higher weight, the chain of trees will focus on difficult/missclassified observations</li>
<li>Gradient boosting (state of the art), each sequential model will be fit on the residual errors of the previous model</li>
</ul>
<p>Fit a BRT using xgboost:</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="fund.html#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(xgboost)</span>
<span id="cb93-2"><a href="fund.html#cb93-2" aria-hidden="true" tabindex="-1"></a>data_xg <span class="ot">=</span> <span class="fu">xgb.DMatrix</span>(<span class="at">data =</span> <span class="fu">as.matrix</span>(<span class="fu">scale</span>(data[,<span class="sc">-</span><span class="dv">1</span>])), <span class="at">label =</span> data<span class="sc">$</span>Ozone)</span>
<span id="cb93-3"><a href="fund.html#cb93-3" aria-hidden="true" tabindex="-1"></a>brt <span class="ot">=</span> <span class="fu">xgboost</span>(data_xg, <span class="at">nrounds =</span> 16L, <span class="at">nthreads =</span> 4L)</span></code></pre></div>
<pre><code>## [19:01:14] WARNING: amalgamation/../src/learner.cc:516: 
## Parameters: { nthreads } might not be used.
## 
##   This may not be accurate due to some parameters are only used in language bindings but
##   passed down to XGBoost core.  Or some parameters are not used but slip through this
##   verification. Please open an issue if you find above cases.
## 
## 
## [1]  train-rmse:39.724625 
## [2]  train-rmse:30.225761 
## [3]  train-rmse:23.134838 
## [4]  train-rmse:17.899178 
## [5]  train-rmse:14.097785 
## [6]  train-rmse:11.375458 
## [7]  train-rmse:9.391275 
## [8]  train-rmse:7.889690 
## [9]  train-rmse:6.646585 
## [10] train-rmse:5.804859 
## [11] train-rmse:5.128437 
## [12] train-rmse:4.456416 
## [13] train-rmse:4.069464 
## [14] train-rmse:3.674615 
## [15] train-rmse:3.424578 
## [16] train-rmse:3.191301</code></pre>
<p>xgboost has a weird syntax, we have to transform our data into a xgb.DMatrix object to be able to fit the model. We will do 500 rounds which means we will fit 500 sequential models:</p>
<p>Let us visualize the predictions for different number of trees:</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="fund.html#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb95-2"><a href="fund.html#cb95-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>){</span>
<span id="cb95-3"><a href="fund.html#cb95-3" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">=</span> <span class="fu">predict</span>(brt, <span class="at">newdata =</span> data_xg, <span class="at">ntreelimit =</span> i)</span>
<span id="cb95-4"><a href="fund.html#cb95-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(data<span class="sc">$</span>Temp, data<span class="sc">$</span>Ozone, <span class="at">main =</span> i)</span>
<span id="cb95-5"><a href="fund.html#cb95-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(data<span class="sc">$</span>Temp[<span class="fu">order</span>(data<span class="sc">$</span>Temp)], pred[<span class="fu">order</span>(data<span class="sc">$</span>Temp)], <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb95-6"><a href="fund.html#cb95-6" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p><img src="_main_files/figure-html/BRT2-1.png" width="672" /></p>
<p>xgboost also provides an variable importance:</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="fund.html#cb96-1" aria-hidden="true" tabindex="-1"></a>xgboost<span class="sc">::</span><span class="fu">xgb.importance</span>(<span class="at">model =</span> brt)</span></code></pre></div>
<pre><code>##    Feature        Gain     Cover  Frequency
## 1:    Temp 0.570071875 0.2958229 0.24836601
## 2:    Wind 0.348230710 0.3419576 0.24183007
## 3: Solar.R 0.058795559 0.1571072 0.30718954
## 4:     Day 0.019530002 0.1779925 0.16993464
## 5:   Month 0.003371853 0.0271197 0.03267974</code></pre>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="fund.html#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">mean</span>((data<span class="sc">$</span>Ozone <span class="sc">-</span> pred)<span class="sc">^</span><span class="dv">2</span>)) <span class="co"># RMSE</span></span></code></pre></div>
<pre><code>## [1] 17.89918</code></pre>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="fund.html#cb100-1" aria-hidden="true" tabindex="-1"></a>data_xg <span class="ot">=</span> <span class="fu">xgb.DMatrix</span>(<span class="at">data =</span> <span class="fu">as.matrix</span>(<span class="fu">scale</span>(data[,<span class="sc">-</span><span class="dv">1</span>])), <span class="at">label =</span> data<span class="sc">$</span>Ozone)</span></code></pre></div>
<p>xgboost has an argument to do cross-validation:</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="fund.html#cb101-1" aria-hidden="true" tabindex="-1"></a>brt <span class="ot">=</span> <span class="fu">xgboost</span>(data_xg, <span class="at">nrounds =</span> 5L)</span></code></pre></div>
<pre><code>## [1]  train-rmse:39.724625 
## [2]  train-rmse:30.225760 
## [3]  train-rmse:23.134840 
## [4]  train-rmse:17.899178 
## [5]  train-rmse:14.097784</code></pre>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb103-1"><a href="fund.html#cb103-1" aria-hidden="true" tabindex="-1"></a>brt_cv <span class="ot">=</span> xgboost<span class="sc">::</span><span class="fu">xgb.cv</span>(<span class="at">data =</span> data_xg, <span class="at">nfold =</span> 3L, <span class="at">nrounds =</span> 3L, <span class="at">nthreads =</span> 4L)</span></code></pre></div>
<pre><code>## [1]  train-rmse:39.978896+0.286917   test-rmse:40.933159+0.927615 
## [2]  train-rmse:30.598419+0.425074   test-rmse:33.257562+1.932902 
## [3]  train-rmse:23.706882+0.437096   test-rmse:27.806431+2.435702</code></pre>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb105-1"><a href="fund.html#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(brt_cv)</span></code></pre></div>
<pre><code>## ##### xgb.cv 3-folds
##  iter train_rmse_mean train_rmse_std test_rmse_mean test_rmse_std
##     1        39.97890      0.2869171       40.93316     0.9276147
##     2        30.59842      0.4250742       33.25756     1.9329018
##     3        23.70688      0.4370956       27.80643     2.4357021</code></pre>
<p>There are different ways to control for complexity:</p>
<ul>
<li>max_depth, depth of each tree</li>
<li>shrinkage (each tree will get a weight and the weight will decrease with the number of trees)</li>
</ul>
</div>
</div>
<div id="distance-based-algorithms" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Distance-based algorithms</h2>
<p>In this chapter, we introduce support-vector machines (SVMs) and other distance-based methods.</p>
<div id="k-nearest-neighbor" class="section level3" number="3.3.1">
<h3><span class="header-section-number">3.3.1</span> k-nearest-neighbor</h3>
<p>k-nearest-neighbor classifies new observations by calculating the nearest n neighbors.</p>
<p>The labels of the n nearest neighbors decide the class of the new point:</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="fund.html#cb107-1" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">scale</span>(iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span>
<span id="cb107-2"><a href="fund.html#cb107-2" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span> iris[,<span class="dv">5</span>]</span>
<span id="cb107-3"><a href="fund.html#cb107-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(X[<span class="sc">-</span><span class="dv">100</span>,<span class="dv">1</span>], X[<span class="sc">-</span><span class="dv">100</span>,<span class="dv">3</span>], <span class="at">col =</span> Y)</span>
<span id="cb107-4"><a href="fund.html#cb107-4" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(X[<span class="dv">100</span>,<span class="dv">1</span>], X[<span class="dv">100</span>,<span class="dv">3</span>], <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">pch =</span> <span class="dv">18</span>, <span class="at">cex =</span> <span class="fl">1.3</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-55-1.png" width="672" /></p>
<p>Which class would you decide for the blue point? What are the classes of the nearest points?… well this procedure is used by the kNN:</p>
<p>Scaling is very important when dealing with distances (we also split the dataset into a training and a testing dataset):</p>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="fund.html#cb108-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> iris</span>
<span id="cb108-2"><a href="fund.html#cb108-2" aria-hidden="true" tabindex="-1"></a>data[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>] <span class="ot">=</span> <span class="fu">apply</span>(data[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>],<span class="dv">2</span>, scale)</span>
<span id="cb108-3"><a href="fund.html#cb108-3" aria-hidden="true" tabindex="-1"></a>indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(data), <span class="fl">0.7</span><span class="sc">*</span><span class="fu">nrow</span>(data))</span>
<span id="cb108-4"><a href="fund.html#cb108-4" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> data[indices,]</span>
<span id="cb108-5"><a href="fund.html#cb108-5" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> data[<span class="sc">-</span>indices,]</span></code></pre></div>
<p>Fit model and create predictions:</p>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb109-1"><a href="fund.html#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(kknn)</span>
<span id="cb109-2"><a href="fund.html#cb109-2" aria-hidden="true" tabindex="-1"></a>knn <span class="ot">=</span> <span class="fu">kknn</span>(Species<span class="sc">~</span>., <span class="at">train =</span> train, <span class="at">test =</span> test)</span>
<span id="cb109-3"><a href="fund.html#cb109-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(knn)</span></code></pre></div>
<pre><code>## 
## Call:
## kknn(formula = Species ~ ., train = train, test = test)
## 
## Response: &quot;nominal&quot;
##           fit prob.setosa prob.versicolor prob.virginica
## 1      setosa           1       0.0000000     0.00000000
## 2      setosa           1       0.0000000     0.00000000
## 3      setosa           1       0.0000000     0.00000000
## 4      setosa           1       0.0000000     0.00000000
## 5      setosa           1       0.0000000     0.00000000
## 6      setosa           1       0.0000000     0.00000000
## 7      setosa           1       0.0000000     0.00000000
## 8      setosa           1       0.0000000     0.00000000
## 9      setosa           1       0.0000000     0.00000000
## 10     setosa           1       0.0000000     0.00000000
## 11     setosa           1       0.0000000     0.00000000
## 12     setosa           1       0.0000000     0.00000000
## 13     setosa           1       0.0000000     0.00000000
## 14     setosa           1       0.0000000     0.00000000
## 15     setosa           1       0.0000000     0.00000000
## 16     setosa           1       0.0000000     0.00000000
## 17 versicolor           0       0.9354939     0.06450608
## 18 versicolor           0       0.6349387     0.36506134
## 19 versicolor           0       1.0000000     0.00000000
## 20 versicolor           0       0.7783044     0.22169561
## 21 versicolor           0       1.0000000     0.00000000
## 22 versicolor           0       1.0000000     0.00000000
## 23 versicolor           0       0.6430958     0.35690421
## 24 versicolor           0       1.0000000     0.00000000
## 25  virginica           0       0.2580081     0.74199187
## 26 versicolor           0       0.9148730     0.08512700
## 27 versicolor           0       1.0000000     0.00000000
## 28 versicolor           0       0.7245826     0.27541743
## 29 versicolor           0       1.0000000     0.00000000
## 30 versicolor           0       1.0000000     0.00000000
## 31 versicolor           0       0.7890886     0.21091135
## 32 versicolor           0       1.0000000     0.00000000
## 33 versicolor           0       0.9511855     0.04881448
## 34 versicolor           0       1.0000000     0.00000000
## 35  virginica           0       0.0000000     1.00000000
## 36  virginica           0       0.0851270     0.91487300
## 37  virginica           0       0.0000000     1.00000000
## 38  virginica           0       0.0000000     1.00000000
## 39  virginica           0       0.0000000     1.00000000
## 40 versicolor           0       0.7013345     0.29866548
## 41  virginica           0       0.2109114     0.78908865
## 42  virginica           0       0.0000000     1.00000000
## 43  virginica           0       0.0000000     1.00000000
## 44  virginica           0       0.0000000     1.00000000
## 45  virginica           0       0.0156916     0.98430840</code></pre>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="fund.html#cb111-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(test<span class="sc">$</span>Species, <span class="fu">fitted</span>(knn))</span></code></pre></div>
<pre><code>##             
##              setosa versicolor virginica
##   setosa         16          0         0
##   versicolor      0         17         1
##   virginica       0          1        10</code></pre>
<p>Actually, there is no “real” learning in a kNN.</p>
</div>
<div id="support-vector-machines-svm" class="section level3" number="3.3.2">
<h3><span class="header-section-number">3.3.2</span> Support Vector Machines (SVM)</h3>
<p>Support vectors machine try to find a hyperplane in the predictor space which separates the classes in the best way.</p>
<p>Fitting a SVM:</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="fund.html#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(e1071)</span>
<span id="cb113-2"><a href="fund.html#cb113-2" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> iris</span>
<span id="cb113-3"><a href="fund.html#cb113-3" aria-hidden="true" tabindex="-1"></a>data[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>] <span class="ot">=</span> <span class="fu">apply</span>(data[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>],<span class="dv">2</span>, scale)</span>
<span id="cb113-4"><a href="fund.html#cb113-4" aria-hidden="true" tabindex="-1"></a>indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(data), <span class="fl">0.7</span><span class="sc">*</span><span class="fu">nrow</span>(data))</span>
<span id="cb113-5"><a href="fund.html#cb113-5" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> data[indices,]</span>
<span id="cb113-6"><a href="fund.html#cb113-6" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> data[<span class="sc">-</span>indices,]</span>
<span id="cb113-7"><a href="fund.html#cb113-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb113-8"><a href="fund.html#cb113-8" aria-hidden="true" tabindex="-1"></a>sm <span class="ot">=</span> <span class="fu">svm</span>(Species<span class="sc">~</span>., <span class="at">data =</span> train, <span class="at">kernel =</span> <span class="st">&quot;linear&quot;</span>)</span>
<span id="cb113-9"><a href="fund.html#cb113-9" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">predict</span>(sm, <span class="at">newdata =</span> test)</span></code></pre></div>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="fund.html#cb114-1" aria-hidden="true" tabindex="-1"></a>oldpar <span class="ot">=</span> <span class="fu">par</span>()</span>
<span id="cb114-2"><a href="fund.html#cb114-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb114-3"><a href="fund.html#cb114-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(test<span class="sc">$</span>Sepal.Length, test<span class="sc">$</span>Petal.Length, <span class="at">col =</span>  pred, <span class="at">main =</span> <span class="st">&quot;predicted&quot;</span>)</span>
<span id="cb114-4"><a href="fund.html#cb114-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(test<span class="sc">$</span>Sepal.Length, test<span class="sc">$</span>Petal.Length, <span class="at">col =</span>  test<span class="sc">$</span>Species, <span class="at">main =</span> <span class="st">&quot;observed&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-59-1.png" width="672" /></p>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="fund.html#cb115-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(oldpar)</span></code></pre></div>
<pre><code>## Warning in par(oldpar): graphical parameter &quot;cin&quot; cannot be set</code></pre>
<pre><code>## Warning in par(oldpar): graphical parameter &quot;cra&quot; cannot be set</code></pre>
<pre><code>## Warning in par(oldpar): graphical parameter &quot;csi&quot; cannot be set</code></pre>
<pre><code>## Warning in par(oldpar): graphical parameter &quot;cxy&quot; cannot be set</code></pre>
<pre><code>## Warning in par(oldpar): graphical parameter &quot;din&quot; cannot be set</code></pre>
<pre><code>## Warning in par(oldpar): graphical parameter &quot;page&quot; cannot be set</code></pre>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="fund.html#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(pred<span class="sc">==</span>test<span class="sc">$</span>Species) <span class="co"># accuracy</span></span></code></pre></div>
<pre><code>## [1] 0.9777778</code></pre>
<p>SVM can only work on linear separable problems. ( A problem is called linearly separable if there exists at least one line in the plane with all of the points of one group on one side of the line and all the points of the others group on the other side).</p>
<p>However, there is a trick, the so called kernel trick.</p>
<p>The kernel trick maps the predictor space into a (higher dimensional) space in which the problem is linear separable:</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="fund.html#cb124-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb124-2"><a href="fund.html#cb124-2" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb124-3"><a href="fund.html#cb124-3" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb124-4"><a href="fund.html#cb124-4" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">expand.grid</span>(x1, x2)</span>
<span id="cb124-5"><a href="fund.html#cb124-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">apply</span>(X, <span class="dv">1</span>, <span class="cf">function</span>(x) <span class="fu">exp</span>(<span class="sc">-</span>x[<span class="dv">1</span>]<span class="sc">^</span><span class="dv">2</span> <span class="sc">-</span> x[<span class="dv">2</span>]<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb124-6"><a href="fund.html#cb124-6" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">ifelse</span>(<span class="dv">1</span><span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(<span class="sc">-</span>y)) <span class="sc">&lt;</span> <span class="fl">0.62</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb124-7"><a href="fund.html#cb124-7" aria-hidden="true" tabindex="-1"></a><span class="fu">image</span>(<span class="fu">matrix</span>(y, <span class="dv">100</span>, <span class="dv">100</span>))</span>
<span id="cb124-8"><a href="fund.html#cb124-8" aria-hidden="true" tabindex="-1"></a>animation<span class="sc">::</span><span class="fu">saveGIF</span>({</span>
<span id="cb124-9"><a href="fund.html#cb124-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">c</span>(<span class="st">&quot;truth&quot;</span>,<span class="st">&quot;linear&quot;</span>, <span class="st">&quot;radial&quot;</span>, <span class="st">&quot;sigmoid&quot;</span>)) {</span>
<span id="cb124-10"><a href="fund.html#cb124-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(i <span class="sc">==</span> <span class="st">&quot;truth&quot;</span>){</span>
<span id="cb124-11"><a href="fund.html#cb124-11" aria-hidden="true" tabindex="-1"></a>      <span class="fu">image</span>(<span class="fu">matrix</span>(y, <span class="dv">100</span>,<span class="dv">100</span>),<span class="at">main =</span> <span class="st">&quot;Ground truth&quot;</span>,<span class="at">axes =</span> <span class="cn">FALSE</span>, <span class="at">las =</span> <span class="dv">2</span>)</span>
<span id="cb124-12"><a href="fund.html#cb124-12" aria-hidden="true" tabindex="-1"></a>    }<span class="cf">else</span>{</span>
<span id="cb124-13"><a href="fund.html#cb124-13" aria-hidden="true" tabindex="-1"></a>      sv <span class="ot">=</span> e1071<span class="sc">::</span><span class="fu">svm</span>(<span class="at">x =</span> X, <span class="at">y =</span> <span class="fu">factor</span>(y), <span class="at">kernel =</span> i)</span>
<span id="cb124-14"><a href="fund.html#cb124-14" aria-hidden="true" tabindex="-1"></a>      <span class="fu">image</span>(<span class="fu">matrix</span>(<span class="fu">as.numeric</span>(<span class="fu">as.character</span>(<span class="fu">predict</span>(sv, X))), <span class="dv">100</span>,<span class="dv">100</span>),<span class="at">main =</span> <span class="fu">paste0</span>(<span class="st">&quot;Kernel: &quot;</span>, i),<span class="at">axes =</span> <span class="cn">FALSE</span>, <span class="at">las =</span> <span class="dv">2</span>)</span>
<span id="cb124-15"><a href="fund.html#cb124-15" aria-hidden="true" tabindex="-1"></a>      <span class="fu">axis</span>(<span class="dv">1</span>, <span class="at">at =</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">10</span>), <span class="at">labels =</span> <span class="fu">round</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>,<span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">10</span>), <span class="dv">1</span>))</span>
<span id="cb124-16"><a href="fund.html#cb124-16" aria-hidden="true" tabindex="-1"></a>      <span class="fu">axis</span>(<span class="dv">2</span>, <span class="at">at =</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">10</span>), <span class="at">labels =</span> <span class="fu">round</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>,<span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">10</span>), <span class="dv">1</span>), <span class="at">las =</span> <span class="dv">2</span>)</span>
<span id="cb124-17"><a href="fund.html#cb124-17" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb124-18"><a href="fund.html#cb124-18" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb124-19"><a href="fund.html#cb124-19" aria-hidden="true" tabindex="-1"></a>},<span class="at">movie.name =</span> <span class="st">&quot;svm.gif&quot;</span>, <span class="at">autobrowse =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="images/svm.gif" /><!-- --></p>
</div>
</div>
<div id="artificial-neural-networks" class="section level2" number="3.4">
<h2><span class="header-section-number">3.4</span> Artificial neural networks</h2>
<p>Regularization in ANNs</p>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="fund.html#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb125-2"><a href="fund.html#cb125-2" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality</span>
<span id="cb125-3"><a href="fund.html#cb125-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(data)</span></code></pre></div>
<pre><code>##      Ozone           Solar.R           Wind             Temp           Month            Day      
##  Min.   :  1.00   Min.   :  7.0   Min.   : 1.700   Min.   :56.00   Min.   :5.000   Min.   : 1.0  
##  1st Qu.: 18.00   1st Qu.:115.8   1st Qu.: 7.400   1st Qu.:72.00   1st Qu.:6.000   1st Qu.: 8.0  
##  Median : 31.50   Median :205.0   Median : 9.700   Median :79.00   Median :7.000   Median :16.0  
##  Mean   : 42.13   Mean   :185.9   Mean   : 9.958   Mean   :77.88   Mean   :6.993   Mean   :15.8  
##  3rd Qu.: 63.25   3rd Qu.:258.8   3rd Qu.:11.500   3rd Qu.:85.00   3rd Qu.:8.000   3rd Qu.:23.0  
##  Max.   :168.00   Max.   :334.0   Max.   :20.700   Max.   :97.00   Max.   :9.000   Max.   :31.0  
##  NA&#39;s   :37       NA&#39;s   :7</code></pre>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="fund.html#cb127-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> data[<span class="fu">complete.cases</span>(data),] <span class="co"># remove NAs</span></span>
<span id="cb127-2"><a href="fund.html#cb127-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(data)</span></code></pre></div>
<pre><code>##      Ozone          Solar.R           Wind            Temp           Month            Day       
##  Min.   :  1.0   Min.   :  7.0   Min.   : 2.30   Min.   :57.00   Min.   :5.000   Min.   : 1.00  
##  1st Qu.: 18.0   1st Qu.:113.5   1st Qu.: 7.40   1st Qu.:71.00   1st Qu.:6.000   1st Qu.: 9.00  
##  Median : 31.0   Median :207.0   Median : 9.70   Median :79.00   Median :7.000   Median :16.00  
##  Mean   : 42.1   Mean   :184.8   Mean   : 9.94   Mean   :77.79   Mean   :7.216   Mean   :15.95  
##  3rd Qu.: 62.0   3rd Qu.:255.5   3rd Qu.:11.50   3rd Qu.:84.50   3rd Qu.:9.000   3rd Qu.:22.50  
##  Max.   :168.0   Max.   :334.0   Max.   :20.70   Max.   :97.00   Max.   :9.000   Max.   :31.00</code></pre>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="fund.html#cb129-1" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="dv">2</span><span class="sc">:</span><span class="dv">6</span>])</span>
<span id="cb129-2"><a href="fund.html#cb129-2" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span> data[,<span class="dv">1</span>]</span>
<span id="cb129-3"><a href="fund.html#cb129-3" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb129-4"><a href="fund.html#cb129-4" aria-hidden="true" tabindex="-1"></a>penalty <span class="ot">=</span> <span class="fl">0.01</span></span>
<span id="cb129-5"><a href="fund.html#cb129-5" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb129-6"><a href="fund.html#cb129-6" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(5L), <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1</span>(penalty)) <span class="sc">%&gt;%</span></span>
<span id="cb129-7"><a href="fund.html#cb129-7" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1</span>(penalty) ) <span class="sc">%&gt;%</span></span>
<span id="cb129-8"><a href="fund.html#cb129-8" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1</span>(penalty)) <span class="sc">%&gt;%</span></span>
<span id="cb129-9"><a href="fund.html#cb129-9" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;linear&quot;</span>, <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1</span>(penalty)) <span class="co"># one output dimension with a linear activation function</span></span>
<span id="cb129-10"><a href="fund.html#cb129-10" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## Model: &quot;sequential_2&quot;
## ______________________________________________________________________________________________________________________________________________________________
## Layer (type)                                                           Output Shape                                                   Param #                 
## ==============================================================================================================================================================
## dense_8 (Dense)                                                        (None, 100)                                                    600                     
## ______________________________________________________________________________________________________________________________________________________________
## dense_9 (Dense)                                                        (None, 100)                                                    10100                   
## ______________________________________________________________________________________________________________________________________________________________
## dense_10 (Dense)                                                       (None, 100)                                                    10100                   
## ______________________________________________________________________________________________________________________________________________________________
## dense_11 (Dense)                                                       (None, 1)                                                      101                     
## ==============================================================================================================================================================
## Total params: 20,901
## Trainable params: 20,901
## Non-trainable params: 0
## ______________________________________________________________________________________________________________________________________________________________</code></pre>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="fund.html#cb131-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb131-2"><a href="fund.html#cb131-2" aria-hidden="true" tabindex="-1"></a> <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="fl">0.1</span>))</span>
<span id="cb131-3"><a href="fund.html#cb131-3" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb131-4"><a href="fund.html#cb131-4" aria-hidden="true" tabindex="-1"></a> model <span class="sc">%&gt;%</span></span>
<span id="cb131-5"><a href="fund.html#cb131-5" aria-hidden="true" tabindex="-1"></a> <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> <span class="fu">matrix</span>(Y, <span class="at">ncol =</span> 1L), <span class="at">epochs =</span> 100L, <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>, <span class="at">validation_split =</span> <span class="fl">0.2</span>)</span>
<span id="cb131-6"><a href="fund.html#cb131-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-62-1.png" width="672" /></p>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb133-1"><a href="fund.html#cb133-1" aria-hidden="true" tabindex="-1"></a>weights <span class="ot">=</span> <span class="fu">lapply</span>(model<span class="sc">$</span>weights, <span class="cf">function</span>(w) w<span class="sc">$</span><span class="fu">numpy</span>() )</span>
<span id="cb133-2"><a href="fund.html#cb133-2" aria-hidden="true" tabindex="-1"></a>fields<span class="sc">::</span><span class="fu">image.plot</span>(weights[[<span class="dv">1</span>]])</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-62-2.png" width="672" /></p>
</div>
<div id="the-standard-ml-pipeline" class="section level2" number="3.5">
<h2><span class="header-section-number">3.5</span> The standard ML pipeline</h2>
<p>The typical ML workflow consist of:</p>
<ul>
<li>Data cleaning and exploration (EDA=explorative data analysis) with tidyverse</li>
<li>Pre-processing and feature selection</li>
<li>Splitting dataset into train and test set for evaluation</li>
<li>Model fitting</li>
<li>Model evaluation</li>
<li>New predictions
Here is an (optional) video that explains the entire pipeline from a slightly different perspective</li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/nKW8Ndu7Mjw" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<p>In the following example, we use tidyverse, a collection of R packages for data science / data manipulation mainly developed by Hadley Wickham. A video that explains the basics here</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/nRtp7wSEtJA" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<p>A good reference is R for data science by Hadley <a href="https://r4ds.had.co.nz/"></a></p>
<div id="example-of-the-ml-workflow-with-the-titanic-dataset" class="section level3" number="3.5.1">
<h3><span class="header-section-number">3.5.1</span> Example of the ML workflow with the titanic dataset</h3>
<p>For this lecture you need the titanic dataset provided by us. You can find it in GRIPS (datasets.RData in the dataset and submission section) or at <a href="http://rhsbio6.uni-regensburg.de:8500"></a>.</p>
<p>We have split the dataset already into training and testing datasets (the test split has one column less than the train split, why?)</p>
<div id="data-cleaning" class="section level4" number="3.5.1.1">
<h4><span class="header-section-number">3.5.1.1</span> Data cleaning</h4>
<p>Load necessary libraries:</p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="fund.html#cb134-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb134-2"><a href="fund.html#cb134-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb134-3"><a href="fund.html#cb134-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code></pre></div>
<p>Load dataset:</p>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb135-1"><a href="fund.html#cb135-1" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">&quot;datasets.RData&quot;</span>)</span>
<span id="cb135-2"><a href="fund.html#cb135-2" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> titanic<span class="sc">$</span>train</span>
<span id="cb135-3"><a href="fund.html#cb135-3" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> titanic<span class="sc">$</span>test</span></code></pre></div>
<p>For cleaning and exploration we will combine the datasets together (if we change a predictor in the train set, we have also to change it in the test set…).</p>
<p>But we will create a new variable “subset” that tells us whether an observation belongs to the train or test split:</p>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="fund.html#cb136-1" aria-hidden="true" tabindex="-1"></a>test<span class="sc">$</span>survived <span class="ot">=</span> <span class="cn">NA</span></span>
<span id="cb136-2"><a href="fund.html#cb136-2" aria-hidden="true" tabindex="-1"></a>train<span class="sc">$</span>subset <span class="ot">=</span> <span class="st">&quot;train&quot;</span></span>
<span id="cb136-3"><a href="fund.html#cb136-3" aria-hidden="true" tabindex="-1"></a>test<span class="sc">$</span>subset <span class="ot">=</span> <span class="st">&quot;test&quot;</span></span>
<span id="cb136-4"><a href="fund.html#cb136-4" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">rbind</span>(train,test)</span></code></pre></div>
<p>Standard summaries:</p>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb137-1"><a href="fund.html#cb137-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(data)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    111 obs. of  6 variables:
##  $ Ozone  : int  41 36 12 18 23 19 8 16 11 14 ...
##  $ Solar.R: int  190 118 149 313 299 99 19 256 290 274 ...
##  $ Wind   : num  7.4 8 12.6 11.5 8.6 13.8 20.1 9.7 9.2 10.9 ...
##  $ Temp   : int  67 72 74 62 65 59 61 69 66 68 ...
##  $ Month  : int  5 5 5 5 5 5 5 5 5 5 ...
##  $ Day    : int  1 2 3 4 7 8 9 12 13 14 ...</code></pre>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="fund.html#cb139-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(data)</span></code></pre></div>
<pre><code>##      Ozone          Solar.R           Wind            Temp           Month            Day       
##  Min.   :  1.0   Min.   :  7.0   Min.   : 2.30   Min.   :57.00   Min.   :5.000   Min.   : 1.00  
##  1st Qu.: 18.0   1st Qu.:113.5   1st Qu.: 7.40   1st Qu.:71.00   1st Qu.:6.000   1st Qu.: 9.00  
##  Median : 31.0   Median :207.0   Median : 9.70   Median :79.00   Median :7.000   Median :16.00  
##  Mean   : 42.1   Mean   :184.8   Mean   : 9.94   Mean   :77.79   Mean   :7.216   Mean   :15.95  
##  3rd Qu.: 62.0   3rd Qu.:255.5   3rd Qu.:11.50   3rd Qu.:84.50   3rd Qu.:9.000   3rd Qu.:22.50  
##  Max.   :168.0   Max.   :334.0   Max.   :20.70   Max.   :97.00   Max.   :9.000   Max.   :31.00</code></pre>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="fund.html#cb141-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(data)</span></code></pre></div>
<pre><code>##   Ozone Solar.R Wind Temp Month Day
## 1    41     190  7.4   67     5   1
## 2    36     118  8.0   72     5   2
## 3    12     149 12.6   74     5   3
## 4    18     313 11.5   62     5   4
## 7    23     299  8.6   65     5   7
## 8    19      99 13.8   59     5   8</code></pre>

</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Fundamental principles and techniques | Machine Learning and AI in TensorFlow and R</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Fundamental principles and techniques | Machine Learning and AI in TensorFlow and R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Fundamental principles and techniques | Machine Learning and AI in TensorFlow and R" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Maximilian Pichler and Florian Hartig" />


<meta name="date" content="2021-04-30" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introduction.html"/>
<link rel="next" href="Deep.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction to Machine Learning</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#supervised-learning-regression-and-classification"><i class="fa fa-check"></i><b>2.1</b> Supervised learning: regression and classification</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="introduction.html"><a href="introduction.html#supervised-regression-using-random-forest"><i class="fa fa-check"></i><b>2.1.1</b> Supervised regression using Random Forest</a></li>
<li class="chapter" data-level="2.1.2" data-path="introduction.html"><a href="introduction.html#supervised-classification-using-random-forest"><i class="fa fa-check"></i><b>2.1.2</b> Supervised classification using Random Forest</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#unsupervised-learning"><i class="fa fa-check"></i><b>2.2</b> Unsupervised learning</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="introduction.html"><a href="introduction.html#k-means-clustering"><i class="fa fa-check"></i><b>2.2.1</b> k-means clustering</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#introduction-to-tensorflow"><i class="fa fa-check"></i><b>2.3</b> Introduction to Tensorflow</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="introduction.html"><a href="introduction.html#tensorflow-data-containers"><i class="fa fa-check"></i><b>2.3.1</b> Tensorflow data containers</a></li>
<li class="chapter" data-level="2.3.2" data-path="introduction.html"><a href="introduction.html#tensorflow-data-types---good-practise-with-r-tf"><i class="fa fa-check"></i><b>2.3.2</b> Tensorflow data types - good practise with R-TF</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="introduction.html"><a href="introduction.html#first-steps-with-the-keras-framework"><i class="fa fa-check"></i><b>2.4</b> First steps with the keras framework</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="introduction.html"><a href="introduction.html#example-workflow-in-keras"><i class="fa fa-check"></i><b>2.4.1</b> Example workflow in keras</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="fund.html"><a href="fund.html"><i class="fa fa-check"></i><b>3</b> Fundamental principles and techniques</a>
<ul>
<li class="chapter" data-level="3.1" data-path="fund.html"><a href="fund.html#machine-learning-principles"><i class="fa fa-check"></i><b>3.1</b> Machine learning principles</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="fund.html"><a href="fund.html#optimization"><i class="fa fa-check"></i><b>3.1.1</b> Optimization</a></li>
<li class="chapter" data-level="3.1.2" data-path="fund.html"><a href="fund.html#regularization"><i class="fa fa-check"></i><b>3.1.2</b> Regularization</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="fund.html"><a href="fund.html#tree-based-ml-algorithms"><i class="fa fa-check"></i><b>3.2</b> Tree-based ML algorithms</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="fund.html"><a href="fund.html#classification-and-regression-trees"><i class="fa fa-check"></i><b>3.2.1</b> Classification and Regression Trees</a></li>
<li class="chapter" data-level="3.2.2" data-path="fund.html"><a href="fund.html#random-forest"><i class="fa fa-check"></i><b>3.2.2</b> Random Forest</a></li>
<li class="chapter" data-level="3.2.3" data-path="fund.html"><a href="fund.html#boosted-regression-trees"><i class="fa fa-check"></i><b>3.2.3</b> Boosted regression trees</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="fund.html"><a href="fund.html#distance-based-algorithms"><i class="fa fa-check"></i><b>3.3</b> Distance-based algorithms</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="fund.html"><a href="fund.html#k-nearest-neighbor"><i class="fa fa-check"></i><b>3.3.1</b> k-nearest-neighbor</a></li>
<li class="chapter" data-level="3.3.2" data-path="fund.html"><a href="fund.html#support-vector-machines-svm"><i class="fa fa-check"></i><b>3.3.2</b> Support Vector Machines (SVM)</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="fund.html"><a href="fund.html#artificial-neural-networks"><i class="fa fa-check"></i><b>3.4</b> Artificial neural networks</a></li>
<li class="chapter" data-level="3.5" data-path="fund.html"><a href="fund.html#the-standard-ml-pipeline-at-the-example-of-the-titanic-dataset"><i class="fa fa-check"></i><b>3.5</b> The standard ML pipeline at the example of the titanic dataset</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="fund.html"><a href="fund.html#data-cleaning"><i class="fa fa-check"></i><b>3.5.1</b> Data cleaning</a></li>
<li class="chapter" data-level="3.5.2" data-path="fund.html"><a href="fund.html#pre-processing-and-feature-selection"><i class="fa fa-check"></i><b>3.5.2</b> Pre-processing and feature selection</a></li>
<li class="chapter" data-level="3.5.3" data-path="fund.html"><a href="fund.html#split-data-for-training-and-testing"><i class="fa fa-check"></i><b>3.5.3</b> Split data for training and testing</a></li>
<li class="chapter" data-level="3.5.4" data-path="fund.html"><a href="fund.html#model-fitting"><i class="fa fa-check"></i><b>3.5.4</b> Model fitting</a></li>
<li class="chapter" data-level="3.5.5" data-path="fund.html"><a href="fund.html#model-evaluation"><i class="fa fa-check"></i><b>3.5.5</b> Model evaluation</a></li>
<li class="chapter" data-level="3.5.6" data-path="fund.html"><a href="fund.html#predictions-and-submission"><i class="fa fa-check"></i><b>3.5.6</b> Predictions and submission</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Deep.html"><a href="Deep.html"><i class="fa fa-check"></i><b>4</b> Deep learning</a>
<ul>
<li class="chapter" data-level="4.1" data-path="Deep.html"><a href="Deep.html#deep-neural-networks"><i class="fa fa-check"></i><b>4.1</b> Deep Neural Networks</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="Deep.html"><a href="Deep.html#dropout-and-early-stopping"><i class="fa fa-check"></i><b>4.1.1</b> Dropout and Early stopping</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="Deep.html"><a href="Deep.html#convolutional-neural-networks---mnist"><i class="fa fa-check"></i><b>4.2</b> Convolutional Neural Networks - MNIST</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="Deep.html"><a href="Deep.html#data-augmentation"><i class="fa fa-check"></i><b>4.2.1</b> Data Augmentation</a></li>
<li class="chapter" data-level="4.2.2" data-path="Deep.html"><a href="Deep.html#transfer-learning"><i class="fa fa-check"></i><b>4.2.2</b> Transfer learning</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="Deep.html"><a href="Deep.html#flower-dataset"><i class="fa fa-check"></i><b>4.3</b> Flower dataset</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="xAI.html"><a href="xAI.html"><i class="fa fa-check"></i><b>5</b> Explainable AI (xAI), NLP, and RNNs</a>
<ul>
<li class="chapter" data-level="5.1" data-path="xAI.html"><a href="xAI.html#xai-methods"><i class="fa fa-check"></i><b>5.1</b> xAI Methods</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="xAI.html"><a href="xAI.html#variable-importance"><i class="fa fa-check"></i><b>5.1.1</b> Variable Importance</a></li>
<li class="chapter" data-level="5.1.2" data-path="xAI.html"><a href="xAI.html#partial-dependencies"><i class="fa fa-check"></i><b>5.1.2</b> Partial dependencies</a></li>
<li class="chapter" data-level="5.1.3" data-path="xAI.html"><a href="xAI.html#accumulated-local-effects"><i class="fa fa-check"></i><b>5.1.3</b> Accumulated local effects</a></li>
<li class="chapter" data-level="5.1.4" data-path="xAI.html"><a href="xAI.html#friedmans-h-statistic"><i class="fa fa-check"></i><b>5.1.4</b> Friedmans H-statistic</a></li>
<li class="chapter" data-level="5.1.5" data-path="xAI.html"><a href="xAI.html#global-explainer---simplifying-the-ml-model"><i class="fa fa-check"></i><b>5.1.5</b> Global explainer - Simplifying the ML model</a></li>
<li class="chapter" data-level="5.1.6" data-path="xAI.html"><a href="xAI.html#local-explainer---lime-explaining-single-instances-observations"><i class="fa fa-check"></i><b>5.1.6</b> Local explainer - LIME explaining single instances (observations)</a></li>
<li class="chapter" data-level="5.1.7" data-path="xAI.html"><a href="xAI.html#local-explainer---shapley"><i class="fa fa-check"></i><b>5.1.7</b> Local explainer - Shapley</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="xAI.html"><a href="xAI.html#natural-language-processing-nlp"><i class="fa fa-check"></i><b>5.2</b> Natural Language Processing (NLP)</a></li>
<li class="chapter" data-level="5.3" data-path="xAI.html"><a href="xAI.html#recurrent-neural-networks-rnns"><i class="fa fa-check"></i><b>5.3</b> Recurrent neural networks (RNNs)</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="gans-vaes-and-reinforcement-learning.html"><a href="gans-vaes-and-reinforcement-learning.html"><i class="fa fa-check"></i><b>6</b> GANs, VAEs, and Reinforcement learning</a>
<ul>
<li class="chapter" data-level="6.1" data-path="gans-vaes-and-reinforcement-learning.html"><a href="gans-vaes-and-reinforcement-learning.html#generative-adversarial-network-gans"><i class="fa fa-check"></i><b>6.1</b> Generative adversarial network (GANs)</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning and AI in TensorFlow and R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="fund" class="section level1" number="3">
<h1><span class="header-section-number">3</span> Fundamental principles and techniques</h1>
<div id="machine-learning-principles" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Machine learning principles</h2>
<div id="optimization" class="section level3" number="3.1.1">
<h3><span class="header-section-number">3.1.1</span> Optimization</h3>
<p>from wikipedia: " an optimization problem is the problem of finding the best solution from all feasible solutions"</p>
<p>Why do we need this “optimization”?</p>
<ul>
<li><p>A loss function (e.g. we tell in each training step the algorithm how many observations were miss-classified) guides the training of ML algorithms</p></li>
<li><p>Based on the loss, the optimizer tries to update the weights of the ML algorithms in a way that the loss function is minimized</p></li>
</ul>
<p>Calculating analytically the global optima of a function is a non-trivial problem and bunch of diverse optimization algorithms evolved</p>
<p>Some optimization algorithms are inspired by biological systemse.g. Ants, Bee, or even slimve algorithms):</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/X-iSQQgOd1A" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<div id="small-optimization-example" class="section level4" number="3.1.1.1">
<h4><span class="header-section-number">3.1.1.1</span> Small optimization example</h4>
<p>We have the following function:</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="fund.html#cb56-1" aria-hidden="true" tabindex="-1"></a>func <span class="ot">=</span> <span class="cf">function</span>(x) <span class="fu">return</span>(x<span class="sc">^</span><span class="dv">2</span>)</span></code></pre></div>
<p>which we want to minimize, we could do this by hand:</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="fund.html#cb57-1" aria-hidden="true" tabindex="-1"></a>a <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="dv">100</span>)</span>
<span id="cb57-2"><a href="fund.html#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(a, <span class="fu">func</span>(a))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
<p>The smallest value is at x = 0 (to be honest, we can calculate this for this simple case analytically)</p>
<p>We can also use an optimizer with the optim(…) function</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="fund.html#cb58-1" aria-hidden="true" tabindex="-1"></a>opt <span class="ot">=</span> <span class="fu">optim</span>(<span class="fl">1.0</span>, func)</span></code></pre></div>
<pre><code>## Warning in optim(1, func): one-dimensional optimization by Nelder-Mead is unreliable:
## use &quot;Brent&quot; or optimize() directly</code></pre>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="fund.html#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(opt<span class="sc">$</span>par)</span></code></pre></div>
<pre><code>## [1] -8.881784e-16</code></pre>
<p>opt$par will return the best values found by the optimizer</p>
</div>
<div id="advanced-optimization-example" class="section level4" number="3.1.1.2">
<h4><span class="header-section-number">3.1.1.2</span> Advanced optimization example</h4>
<p>We will now optimze the weights (slopes) for linear regression model.</p>
<p>Basically, we will implement lm(y~x) on our own:</p>
<p>Load the airquality dataset, remove NAs, split it into predictors and response, and scale the predictors:</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="fund.html#cb62-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality[<span class="fu">complete.cases</span>(airquality<span class="sc">$</span>Ozone) <span class="sc">&amp;</span> <span class="fu">complete.cases</span>(airquality<span class="sc">$</span>Solar.R),]</span>
<span id="cb62-2"><a href="fund.html#cb62-2" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb62-3"><a href="fund.html#cb62-3" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span> data<span class="sc">$</span>Ozone</span></code></pre></div>
<p>The model we want to optimize: <span class="math inline">\(ozone = Solar.R*X1 + Wind*X2 + Temp*X3 + Month*X4 + Day*X5 + X6\)</span></p>
<p>Our loss function: mean(predicted ozone - true ozone)^2)</p>
<p>We found to find the parameters X1-X6 for which the loss function is the smallest:</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="fund.html#cb63-1" aria-hidden="true" tabindex="-1"></a>linear_regression <span class="ot">=</span> <span class="cf">function</span>(w) {</span>
<span id="cb63-2"><a href="fund.html#cb63-2" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">=</span> w[<span class="dv">1</span>]<span class="sc">*</span>X[,<span class="dv">1</span>] <span class="sc">+</span> <span class="co"># Solar.R</span></span>
<span id="cb63-3"><a href="fund.html#cb63-3" aria-hidden="true" tabindex="-1"></a>         w[<span class="dv">2</span>]<span class="sc">*</span>X[,<span class="dv">2</span>] <span class="sc">+</span> <span class="co"># Wind</span></span>
<span id="cb63-4"><a href="fund.html#cb63-4" aria-hidden="true" tabindex="-1"></a>         w[<span class="dv">3</span>]<span class="sc">*</span>X[,<span class="dv">3</span>] <span class="sc">+</span> <span class="co"># Temp</span></span>
<span id="cb63-5"><a href="fund.html#cb63-5" aria-hidden="true" tabindex="-1"></a>         w[<span class="dv">4</span>]<span class="sc">*</span>X[,<span class="dv">4</span>] <span class="sc">+</span> <span class="co"># Month</span></span>
<span id="cb63-6"><a href="fund.html#cb63-6" aria-hidden="true" tabindex="-1"></a>         w[<span class="dv">5</span>]<span class="sc">*</span>X[,<span class="dv">5</span>] <span class="sc">+</span></span>
<span id="cb63-7"><a href="fund.html#cb63-7" aria-hidden="true" tabindex="-1"></a>         w[<span class="dv">6</span>]         <span class="co"># or X %*% w[1:5] + w[6]</span></span>
<span id="cb63-8"><a href="fund.html#cb63-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># loss  = MSE, we want to find the optimal weights </span></span>
<span id="cb63-9"><a href="fund.html#cb63-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># to minimize the sum of squared residuals</span></span>
<span id="cb63-10"><a href="fund.html#cb63-10" aria-hidden="true" tabindex="-1"></a>  loss <span class="ot">=</span> <span class="fu">mean</span>((pred <span class="sc">-</span> Y)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb63-11"><a href="fund.html#cb63-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(loss)</span>
<span id="cb63-12"><a href="fund.html#cb63-12" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>The linear_regression function takes potential solutions for the weights (X1-X6) and will return the loss for these weights:</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="fund.html#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="fu">linear_regression</span>(<span class="fu">runif</span>(<span class="dv">6</span>))</span></code></pre></div>
<pre><code>## [1] 2847.567</code></pre>
<p>Let’s try it bruteforce (which means we will try to find the optimal solution with random a set of random weights):</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="fund.html#cb66-1" aria-hidden="true" tabindex="-1"></a>random_search <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(<span class="dv">6</span><span class="sc">*</span><span class="dv">5000</span>,<span class="sc">-</span><span class="dv">10</span>,<span class="dv">10</span>), <span class="dv">5000</span>, <span class="dv">6</span>)</span>
<span id="cb66-2"><a href="fund.html#cb66-2" aria-hidden="true" tabindex="-1"></a>losses <span class="ot">=</span> <span class="fu">apply</span>(random_search, <span class="dv">1</span>, linear_regression)</span>
<span id="cb66-3"><a href="fund.html#cb66-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(losses, <span class="at">type =</span> <span class="st">&quot;l&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-45-1.png" width="672" /></p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="fund.html#cb67-1" aria-hidden="true" tabindex="-1"></a>random_search[<span class="fu">which.min</span>(losses),]</span></code></pre></div>
<pre><code>## [1]  5.0567712 -7.8550341  7.4573370  0.8109562  2.0097918  9.3807506</code></pre>
<p>Bruteforce isn’t a good approach, it might work well with only a few parameters.</p>
<p>Let’s try it with the optim function:</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="fund.html#cb69-1" aria-hidden="true" tabindex="-1"></a>opt <span class="ot">=</span> <span class="fu">optim</span>(<span class="fu">runif</span>(<span class="dv">6</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>), linear_regression)</span>
<span id="cb69-2"><a href="fund.html#cb69-2" aria-hidden="true" tabindex="-1"></a>opt<span class="sc">$</span>par</span></code></pre></div>
<pre><code>## [1]   4.150032 -15.100683  11.409332  -5.445377  -3.115452  42.502556</code></pre>
<p>Compare the weights the estimated weights of the lm() function:</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="fund.html#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">lm</span>(Y<span class="sc">~</span>X))</span></code></pre></div>
<pre><code>## (Intercept)    XSolar.R       XWind       XTemp      XMonth        XDay 
##   42.099099    4.582620  -11.806072   18.066786   -4.479175    2.384705</code></pre>
</div>
</div>
<div id="regularization" class="section level3" number="3.1.2">
<h3><span class="header-section-number">3.1.2</span> Regularization</h3>
<p>There are several ways to regularize models. In this section we will focus on lasso and ridge regularization for weights in neural networks.</p>
<p>The idea of lasso and ridge regularization is to put some type of rubber band on the weights and pull them to zero, important weights are able to pull away from zero.</p>
<p>Lasso and ridge have slightly different properties:</p>
<ul>
<li>Lasso: abs( sum(Weights))</li>
<li>Ridge: (sum(Weights))^2
Lasso tries to push the weights directly to zero, where as the Ridge allows small values around zero (caused by the difference of the absolute and squared function).</li>
</ul>
<p>Let’s have a look at a keras model with and without regularization (we will use here a network without hidden layers == linear regression model):</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="fund.html#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb73-2"><a href="fund.html#cb73-2" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality[<span class="fu">complete.cases</span>(airquality),]</span>
<span id="cb73-3"><a href="fund.html#cb73-3" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb73-4"><a href="fund.html#cb73-4" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span> data<span class="sc">$</span>Ozone</span>
<span id="cb73-5"><a href="fund.html#cb73-5" aria-hidden="true" tabindex="-1"></a><span class="co"># l1/l2 on linear model</span></span>
<span id="cb73-6"><a href="fund.html#cb73-6" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb73-7"><a href="fund.html#cb73-7" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb73-8"><a href="fund.html#cb73-8" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;linear&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(<span class="fu">dim</span>(X)[<span class="dv">2</span>]))</span>
<span id="cb73-9"><a href="fund.html#cb73-9" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## Model: &quot;sequential_15&quot;
## _________________________________________________________________________________________________________________________________________
## Layer (type)                                                 Output Shape                                           Param #              
## =========================================================================================================================================
## dense_41 (Dense)                                             (None, 1)                                              6                    
## =========================================================================================================================================
## Total params: 6
## Trainable params: 6
## Non-trainable params: 0
## _________________________________________________________________________________________________________________________________________</code></pre>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="fund.html#cb75-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb75-2"><a href="fund.html#cb75-2" aria-hidden="true" tabindex="-1"></a> <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">lr =</span> <span class="fl">0.5</span>))</span>
<span id="cb75-3"><a href="fund.html#cb75-3" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb75-4"><a href="fund.html#cb75-4" aria-hidden="true" tabindex="-1"></a> model <span class="sc">%&gt;%</span></span>
<span id="cb75-5"><a href="fund.html#cb75-5" aria-hidden="true" tabindex="-1"></a> <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, <span class="at">epochs =</span> 50L, <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb75-6"><a href="fund.html#cb75-6" aria-hidden="true" tabindex="-1"></a>unconstrained <span class="ot">=</span> model<span class="sc">$</span><span class="fu">get_weights</span>()</span>
<span id="cb75-7"><a href="fund.html#cb75-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(Y<span class="sc">~</span>X))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Y ~ X)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -37.014 -12.284  -3.302   8.454  95.348 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   42.099      1.980  21.264  &lt; 2e-16 ***
## XSolar.R       4.583      2.135   2.147   0.0341 *  
## XWind        -11.806      2.293  -5.149 1.23e-06 ***
## XTemp         18.067      2.610   6.922 3.66e-10 ***
## XMonth        -4.479      2.230  -2.009   0.0471 *  
## XDay           2.385      2.000   1.192   0.2358    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 20.86 on 105 degrees of freedom
## Multiple R-squared:  0.6249, Adjusted R-squared:  0.6071 
## F-statistic: 34.99 on 5 and 105 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="fund.html#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">lm</span>(Y<span class="sc">~</span>X))</span></code></pre></div>
<pre><code>## (Intercept)    XSolar.R       XWind       XTemp      XMonth        XDay 
##   42.099099    4.582620  -11.806072   18.066786   -4.479175    2.384705</code></pre>
<p>Now we will put a l1 (lasso) regularization on the weights:</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="fund.html#cb79-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb79-2"><a href="fund.html#cb79-2" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb79-3"><a href="fund.html#cb79-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;linear&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(<span class="fu">dim</span>(X)[<span class="dv">2</span>]), </span>
<span id="cb79-4"><a href="fund.html#cb79-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1</span>(<span class="dv">10</span>), <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l1</span>(<span class="dv">10</span>))</span>
<span id="cb79-5"><a href="fund.html#cb79-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## Model: &quot;sequential_16&quot;
## _________________________________________________________________________________________________________________________________________
## Layer (type)                                                 Output Shape                                           Param #              
## =========================================================================================================================================
## dense_42 (Dense)                                             (None, 1)                                              6                    
## =========================================================================================================================================
## Total params: 6
## Trainable params: 6
## Non-trainable params: 0
## _________________________________________________________________________________________________________________________________________</code></pre>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="fund.html#cb81-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb81-2"><a href="fund.html#cb81-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">lr =</span> <span class="fl">0.5</span>), <span class="at">metrics =</span> <span class="fu">c</span>(metric_mean_squared_error))</span>
<span id="cb81-3"><a href="fund.html#cb81-3" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb81-4"><a href="fund.html#cb81-4" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb81-5"><a href="fund.html#cb81-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, <span class="at">epochs =</span> 30L, <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb81-6"><a href="fund.html#cb81-6" aria-hidden="true" tabindex="-1"></a>l1 <span class="ot">=</span> model<span class="sc">$</span><span class="fu">get_weights</span>()</span>
<span id="cb81-7"><a href="fund.html#cb81-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(Y<span class="sc">~</span>X))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Y ~ X)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -37.014 -12.284  -3.302   8.454  95.348 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   42.099      1.980  21.264  &lt; 2e-16 ***
## XSolar.R       4.583      2.135   2.147   0.0341 *  
## XWind        -11.806      2.293  -5.149 1.23e-06 ***
## XTemp         18.067      2.610   6.922 3.66e-10 ***
## XMonth        -4.479      2.230  -2.009   0.0471 *  
## XDay           2.385      2.000   1.192   0.2358    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 20.86 on 105 degrees of freedom
## Multiple R-squared:  0.6249, Adjusted R-squared:  0.6071 
## F-statistic: 34.99 on 5 and 105 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="fund.html#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">lm</span>(Y<span class="sc">~</span>X))</span></code></pre></div>
<pre><code>## (Intercept)    XSolar.R       XWind       XTemp      XMonth        XDay 
##   42.099099    4.582620  -11.806072   18.066786   -4.479175    2.384705</code></pre>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="fund.html#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(<span class="fu">unlist</span>(l1), <span class="fu">unlist</span>(unconstrained))</span></code></pre></div>
<pre><code>##              [,1]       [,2]
## [1,]  1.767281771   4.825849
## [2,] -8.808810234 -12.174186
## [3,] 12.964618683  17.419437
## [4,] -0.001905646  -4.348501
## [5,]  0.044293262   2.311703
## [6,] 33.291839600  41.056118</code></pre>
</div>
</div>
<div id="tree-based-ml-algorithms" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Tree-based ML algorithms</h2>
<p>Famous ML algorithms such as random Forest and gradient boosted trees are based on classification and regression trees.</p>
<div id="classification-and-regression-trees" class="section level3" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> Classification and Regression Trees</h3>
<p>In this lecture we will explore regression and classifaction trees at the example of the airquality data set:</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="fund.html#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb87-2"><a href="fund.html#cb87-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart.plot)</span>
<span id="cb87-3"><a href="fund.html#cb87-3" aria-hidden="true" tabindex="-1"></a>data<span class="ot">=</span>airquality[<span class="fu">complete.cases</span>(airquality),]</span></code></pre></div>
<p>Fit and visualize a regression tree:</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="fund.html#cb88-1" aria-hidden="true" tabindex="-1"></a>rt <span class="ot">=</span> <span class="fu">rpart</span>(Ozone<span class="sc">~</span>., <span class="at">data =</span> data,<span class="at">control =</span> <span class="fu">rpart.control</span>(<span class="at">minsplit =</span> <span class="dv">10</span>))</span>
<span id="cb88-2"><a href="fund.html#cb88-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(rt)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-51-1.png" width="672" /></p>
<p>Visualize the predictions:</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="fund.html#cb89-1" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">predict</span>(rt, data)</span>
<span id="cb89-2"><a href="fund.html#cb89-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(data<span class="sc">$</span>Temp, data<span class="sc">$</span>Ozone)</span>
<span id="cb89-3"><a href="fund.html#cb89-3" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(data<span class="sc">$</span>Temp[<span class="fu">order</span>(data<span class="sc">$</span>Temp)], pred[<span class="fu">order</span>(data<span class="sc">$</span>Temp)], <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-52-1.png" width="672" /></p>
<p>The angular form of the prediction line is typical for regression trees.</p>
<p>There is one important hyper-parameter for regression trees: minsplit</p>
<ul>
<li>controls the depth of tree (see the help of tree for a description)</li>
<li>controls the complexity of the tree and can be seen also as a regularization parameter</li>
</ul>
</div>
<div id="random-forest" class="section level3" number="3.2.2">
<h3><span class="header-section-number">3.2.2</span> Random Forest</h3>
<p>Random Forest creates an ensemble of regression/classification trees.</p>
<p>However, there are two randomization steps with the RF that are responsible for the success of RF:</p>
<ul>
<li>bootstrap sample for each tree (we will sample observations with replacement from the dataset)</li>
<li>at each split, we will sample a subset of predictors which are then considered as potential splitting criterion</li>
</ul>
<p>Fit a RF and visualize the predictions:</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="fund.html#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span>
<span id="cb90-2"><a href="fund.html#cb90-2" aria-hidden="true" tabindex="-1"></a>rf <span class="ot">=</span> <span class="fu">randomForest</span>(Ozone<span class="sc">~</span>., <span class="at">data =</span> data)</span>
<span id="cb90-3"><a href="fund.html#cb90-3" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">predict</span>(rf, data)</span>
<span id="cb90-4"><a href="fund.html#cb90-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(Ozone<span class="sc">~</span>Temp, <span class="at">data =</span> data)</span>
<span id="cb90-5"><a href="fund.html#cb90-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(data<span class="sc">$</span>Temp[<span class="fu">order</span>(data<span class="sc">$</span>Temp)], pred[<span class="fu">order</span>(data<span class="sc">$</span>Temp)], <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-53-1.png" width="672" /></p>
<p>One advantage of RF is that we will get a variable importance:</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="fund.html#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="fu">importance</span>(rf)</span></code></pre></div>
<pre><code>##         IncNodePurity
## Solar.R      18441.43
## Wind         31140.89
## Temp         33965.21
## Month        11031.51
## Day          15610.66</code></pre>
<p>Important hyperparameters:</p>
<ul>
<li>Similar to regression and classification trees, the hyper parameter nodesize controls for complexity. -&gt; Minimum size of terminal nodes. Setting this number larger causes smaller trees to be grown (and thus take less time). Note that the default values are different for classification (1) and regression (5).</li>
<li>mtry - Number of trees to grow. This should not be set to too small a number, to ensure that every input row gets predicted at least a few times.</li>
</ul>
</div>
<div id="boosted-regression-trees" class="section level3" number="3.2.3">
<h3><span class="header-section-number">3.2.3</span> Boosted regression trees</h3>
<p>RF fits hundreds of trees independent of each other.</p>
<p>In boosted regression trees, we will start with a weak learner (weak learner == regression tree) and then fit sequentially additional weak learners.</p>
<p>There are two different approaches to enhance the performance:</p>
<ul>
<li>AdaBoost, wrong classified observations (by the previous tree) will get a higher weight, the chain of trees will focus on difficult/missclassified observations</li>
<li>Gradient boosting (state of the art), each sequential model will be fit on the residual errors of the previous model</li>
</ul>
<p>Fit a BRT using xgboost:</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="fund.html#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(xgboost)</span>
<span id="cb93-2"><a href="fund.html#cb93-2" aria-hidden="true" tabindex="-1"></a>data_xg <span class="ot">=</span> <span class="fu">xgb.DMatrix</span>(<span class="at">data =</span> <span class="fu">as.matrix</span>(<span class="fu">scale</span>(data[,<span class="sc">-</span><span class="dv">1</span>])), <span class="at">label =</span> data<span class="sc">$</span>Ozone)</span>
<span id="cb93-3"><a href="fund.html#cb93-3" aria-hidden="true" tabindex="-1"></a>brt <span class="ot">=</span> <span class="fu">xgboost</span>(data_xg, <span class="at">nrounds =</span> 16L, <span class="at">nthreads =</span> 4L)</span></code></pre></div>
<pre><code>## [11:39:36] WARNING: amalgamation/../src/learner.cc:516: 
## Parameters: { nthreads } might not be used.
## 
##   This may not be accurate due to some parameters are only used in language bindings but
##   passed down to XGBoost core.  Or some parameters are not used but slip through this
##   verification. Please open an issue if you find above cases.
## 
## 
## [1]  train-rmse:39.724625 
## [2]  train-rmse:30.225761 
## [3]  train-rmse:23.134842 
## [4]  train-rmse:17.899178 
## [5]  train-rmse:14.097785 
## [6]  train-rmse:11.375458 
## [7]  train-rmse:9.391275 
## [8]  train-rmse:7.889690 
## [9]  train-rmse:6.646585 
## [10] train-rmse:5.804860 
## [11] train-rmse:5.128438 
## [12] train-rmse:4.456416 
## [13] train-rmse:4.069464 
## [14] train-rmse:3.674615 
## [15] train-rmse:3.424578 
## [16] train-rmse:3.191302</code></pre>
<p>xgboost has a weird syntax, we have to transform our data into a xgb.DMatrix object to be able to fit the model. We will do 500 rounds which means we will fit 500 sequential models:</p>
<p>Let us visualize the predictions for different number of trees:</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="fund.html#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb95-2"><a href="fund.html#cb95-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>){</span>
<span id="cb95-3"><a href="fund.html#cb95-3" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">=</span> <span class="fu">predict</span>(brt, <span class="at">newdata =</span> data_xg, <span class="at">ntreelimit =</span> i)</span>
<span id="cb95-4"><a href="fund.html#cb95-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(data<span class="sc">$</span>Temp, data<span class="sc">$</span>Ozone, <span class="at">main =</span> i)</span>
<span id="cb95-5"><a href="fund.html#cb95-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(data<span class="sc">$</span>Temp[<span class="fu">order</span>(data<span class="sc">$</span>Temp)], pred[<span class="fu">order</span>(data<span class="sc">$</span>Temp)], <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb95-6"><a href="fund.html#cb95-6" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p><img src="_main_files/figure-html/BRT2-1.png" width="672" /></p>
<p>xgboost also provides an variable importance:</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="fund.html#cb96-1" aria-hidden="true" tabindex="-1"></a>xgboost<span class="sc">::</span><span class="fu">xgb.importance</span>(<span class="at">model =</span> brt)</span></code></pre></div>
<pre><code>##    Feature        Gain     Cover  Frequency
## 1:    Temp 0.570071875 0.2958229 0.24836601
## 2:    Wind 0.348230710 0.3419576 0.24183007
## 3: Solar.R 0.058795559 0.1571072 0.30718954
## 4:     Day 0.019530002 0.1779925 0.16993464
## 5:   Month 0.003371853 0.0271197 0.03267974</code></pre>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="fund.html#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">mean</span>((data<span class="sc">$</span>Ozone <span class="sc">-</span> pred)<span class="sc">^</span><span class="dv">2</span>)) <span class="co"># RMSE</span></span></code></pre></div>
<pre><code>## [1] 17.89918</code></pre>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="fund.html#cb100-1" aria-hidden="true" tabindex="-1"></a>data_xg <span class="ot">=</span> <span class="fu">xgb.DMatrix</span>(<span class="at">data =</span> <span class="fu">as.matrix</span>(<span class="fu">scale</span>(data[,<span class="sc">-</span><span class="dv">1</span>])), <span class="at">label =</span> data<span class="sc">$</span>Ozone)</span></code></pre></div>
<p>xgboost has an argument to do cross-validation:</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="fund.html#cb101-1" aria-hidden="true" tabindex="-1"></a>brt <span class="ot">=</span> <span class="fu">xgboost</span>(data_xg, <span class="at">nrounds =</span> 5L)</span></code></pre></div>
<pre><code>## [1]  train-rmse:39.724625 
## [2]  train-rmse:30.225761 
## [3]  train-rmse:23.134842 
## [4]  train-rmse:17.899178 
## [5]  train-rmse:14.097785</code></pre>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb103-1"><a href="fund.html#cb103-1" aria-hidden="true" tabindex="-1"></a>brt_cv <span class="ot">=</span> xgboost<span class="sc">::</span><span class="fu">xgb.cv</span>(<span class="at">data =</span> data_xg, <span class="at">nfold =</span> 3L, <span class="at">nrounds =</span> 3L, <span class="at">nthreads =</span> 4L)</span></code></pre></div>
<pre><code>## [1]  train-rmse:39.978896+0.286917   test-rmse:40.933159+0.927614 
## [2]  train-rmse:30.598420+0.425075   test-rmse:33.257564+1.932901 
## [3]  train-rmse:23.706881+0.437094   test-rmse:27.806431+2.435701</code></pre>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb105-1"><a href="fund.html#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(brt_cv)</span></code></pre></div>
<pre><code>## ##### xgb.cv 3-folds
##  iter train_rmse_mean train_rmse_std test_rmse_mean test_rmse_std
##     1        39.97890      0.2869171       40.93316     0.9276142
##     2        30.59842      0.4250749       33.25756     1.9329006
##     3        23.70688      0.4370938       27.80643     2.4357008</code></pre>
<p>There are different ways to control for complexity:</p>
<ul>
<li>max_depth, depth of each tree</li>
<li>shrinkage (each tree will get a weight and the weight will decrease with the number of trees)</li>
</ul>
</div>
</div>
<div id="distance-based-algorithms" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Distance-based algorithms</h2>
<p>In this chapter, we introduce support-vector machines (SVMs) and other distance-based methods.</p>
<div id="k-nearest-neighbor" class="section level3" number="3.3.1">
<h3><span class="header-section-number">3.3.1</span> k-nearest-neighbor</h3>
<p>k-nearest-neighbor classifies new observations by calculating the nearest n neighbors.</p>
<p>The labels of the n nearest neighbors decide the class of the new point:</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="fund.html#cb107-1" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">scale</span>(iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span>
<span id="cb107-2"><a href="fund.html#cb107-2" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span> iris[,<span class="dv">5</span>]</span>
<span id="cb107-3"><a href="fund.html#cb107-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(X[<span class="sc">-</span><span class="dv">100</span>,<span class="dv">1</span>], X[<span class="sc">-</span><span class="dv">100</span>,<span class="dv">3</span>], <span class="at">col =</span> Y)</span>
<span id="cb107-4"><a href="fund.html#cb107-4" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(X[<span class="dv">100</span>,<span class="dv">1</span>], X[<span class="dv">100</span>,<span class="dv">3</span>], <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">pch =</span> <span class="dv">18</span>, <span class="at">cex =</span> <span class="fl">1.3</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-55-1.png" width="672" /></p>
<p>Which class would you decide for the blue point? What are the classes of the nearest points?… well this procedure is used by the kNN:</p>
<p>Scaling is very important when dealing with distances (we also split the dataset into a training and a testing dataset):</p>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="fund.html#cb108-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> iris</span>
<span id="cb108-2"><a href="fund.html#cb108-2" aria-hidden="true" tabindex="-1"></a>data[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>] <span class="ot">=</span> <span class="fu">apply</span>(data[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>],<span class="dv">2</span>, scale)</span>
<span id="cb108-3"><a href="fund.html#cb108-3" aria-hidden="true" tabindex="-1"></a>indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(data), <span class="fl">0.7</span><span class="sc">*</span><span class="fu">nrow</span>(data))</span>
<span id="cb108-4"><a href="fund.html#cb108-4" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> data[indices,]</span>
<span id="cb108-5"><a href="fund.html#cb108-5" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> data[<span class="sc">-</span>indices,]</span></code></pre></div>
<p>Fit model and create predictions:</p>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb109-1"><a href="fund.html#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(kknn)</span>
<span id="cb109-2"><a href="fund.html#cb109-2" aria-hidden="true" tabindex="-1"></a>knn <span class="ot">=</span> <span class="fu">kknn</span>(Species<span class="sc">~</span>., <span class="at">train =</span> train, <span class="at">test =</span> test)</span>
<span id="cb109-3"><a href="fund.html#cb109-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(knn)</span></code></pre></div>
<pre><code>## 
## Call:
## kknn(formula = Species ~ ., train = train, test = test)
## 
## Response: &quot;nominal&quot;
##           fit prob.setosa prob.versicolor prob.virginica
## 1      setosa           1       0.0000000     0.00000000
## 2      setosa           1       0.0000000     0.00000000
## 3      setosa           1       0.0000000     0.00000000
## 4      setosa           1       0.0000000     0.00000000
## 5      setosa           1       0.0000000     0.00000000
## 6      setosa           1       0.0000000     0.00000000
## 7      setosa           1       0.0000000     0.00000000
## 8      setosa           1       0.0000000     0.00000000
## 9      setosa           1       0.0000000     0.00000000
## 10     setosa           1       0.0000000     0.00000000
## 11     setosa           1       0.0000000     0.00000000
## 12     setosa           1       0.0000000     0.00000000
## 13     setosa           1       0.0000000     0.00000000
## 14     setosa           1       0.0000000     0.00000000
## 15     setosa           1       0.0000000     0.00000000
## 16     setosa           1       0.0000000     0.00000000
## 17 versicolor           0       0.9354939     0.06450608
## 18 versicolor           0       0.6349387     0.36506134
## 19 versicolor           0       1.0000000     0.00000000
## 20 versicolor           0       0.7783044     0.22169561
## 21 versicolor           0       1.0000000     0.00000000
## 22 versicolor           0       1.0000000     0.00000000
## 23 versicolor           0       0.6430958     0.35690421
## 24 versicolor           0       1.0000000     0.00000000
## 25  virginica           0       0.2580081     0.74199187
## 26 versicolor           0       0.9148730     0.08512700
## 27 versicolor           0       1.0000000     0.00000000
## 28 versicolor           0       0.7245826     0.27541743
## 29 versicolor           0       1.0000000     0.00000000
## 30 versicolor           0       1.0000000     0.00000000
## 31 versicolor           0       0.7890886     0.21091135
## 32 versicolor           0       1.0000000     0.00000000
## 33 versicolor           0       0.9511855     0.04881448
## 34 versicolor           0       1.0000000     0.00000000
## 35  virginica           0       0.0000000     1.00000000
## 36  virginica           0       0.0851270     0.91487300
## 37  virginica           0       0.0000000     1.00000000
## 38  virginica           0       0.0000000     1.00000000
## 39  virginica           0       0.0000000     1.00000000
## 40 versicolor           0       0.7013345     0.29866548
## 41  virginica           0       0.2109114     0.78908865
## 42  virginica           0       0.0000000     1.00000000
## 43  virginica           0       0.0000000     1.00000000
## 44  virginica           0       0.0000000     1.00000000
## 45  virginica           0       0.0156916     0.98430840</code></pre>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="fund.html#cb111-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(test<span class="sc">$</span>Species, <span class="fu">fitted</span>(knn))</span></code></pre></div>
<pre><code>##             
##              setosa versicolor virginica
##   setosa         16          0         0
##   versicolor      0         17         1
##   virginica       0          1        10</code></pre>
<p>Actually, there is no “real” learning in a kNN.</p>
</div>
<div id="support-vector-machines-svm" class="section level3" number="3.3.2">
<h3><span class="header-section-number">3.3.2</span> Support Vector Machines (SVM)</h3>
<p>Support vectors machine try to find a hyperplane in the predictor space which separates the classes in the best way.</p>
<p>Fitting a SVM:</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="fund.html#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(e1071)</span>
<span id="cb113-2"><a href="fund.html#cb113-2" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> iris</span>
<span id="cb113-3"><a href="fund.html#cb113-3" aria-hidden="true" tabindex="-1"></a>data[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>] <span class="ot">=</span> <span class="fu">apply</span>(data[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>],<span class="dv">2</span>, scale)</span>
<span id="cb113-4"><a href="fund.html#cb113-4" aria-hidden="true" tabindex="-1"></a>indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(data), <span class="fl">0.7</span><span class="sc">*</span><span class="fu">nrow</span>(data))</span>
<span id="cb113-5"><a href="fund.html#cb113-5" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> data[indices,]</span>
<span id="cb113-6"><a href="fund.html#cb113-6" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> data[<span class="sc">-</span>indices,]</span>
<span id="cb113-7"><a href="fund.html#cb113-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb113-8"><a href="fund.html#cb113-8" aria-hidden="true" tabindex="-1"></a>sm <span class="ot">=</span> <span class="fu">svm</span>(Species<span class="sc">~</span>., <span class="at">data =</span> train, <span class="at">kernel =</span> <span class="st">&quot;linear&quot;</span>)</span>
<span id="cb113-9"><a href="fund.html#cb113-9" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">predict</span>(sm, <span class="at">newdata =</span> test)</span></code></pre></div>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="fund.html#cb114-1" aria-hidden="true" tabindex="-1"></a>oldpar <span class="ot">=</span> <span class="fu">par</span>()</span>
<span id="cb114-2"><a href="fund.html#cb114-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb114-3"><a href="fund.html#cb114-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(test<span class="sc">$</span>Sepal.Length, test<span class="sc">$</span>Petal.Length, <span class="at">col =</span>  pred, <span class="at">main =</span> <span class="st">&quot;predicted&quot;</span>)</span>
<span id="cb114-4"><a href="fund.html#cb114-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(test<span class="sc">$</span>Sepal.Length, test<span class="sc">$</span>Petal.Length, <span class="at">col =</span>  test<span class="sc">$</span>Species, <span class="at">main =</span> <span class="st">&quot;observed&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-59-1.png" width="672" /></p>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="fund.html#cb115-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(oldpar)</span></code></pre></div>
<pre><code>## Warning in par(oldpar): graphical parameter &quot;cin&quot; cannot be set</code></pre>
<pre><code>## Warning in par(oldpar): graphical parameter &quot;cra&quot; cannot be set</code></pre>
<pre><code>## Warning in par(oldpar): graphical parameter &quot;csi&quot; cannot be set</code></pre>
<pre><code>## Warning in par(oldpar): graphical parameter &quot;cxy&quot; cannot be set</code></pre>
<pre><code>## Warning in par(oldpar): graphical parameter &quot;din&quot; cannot be set</code></pre>
<pre><code>## Warning in par(oldpar): graphical parameter &quot;page&quot; cannot be set</code></pre>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="fund.html#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(pred<span class="sc">==</span>test<span class="sc">$</span>Species) <span class="co"># accuracy</span></span></code></pre></div>
<pre><code>## [1] 0.9777778</code></pre>
<p>SVM can only work on linear separable problems. ( A problem is called linearly separable if there exists at least one line in the plane with all of the points of one group on one side of the line and all the points of the others group on the other side).</p>
<p>However, there is a trick, the so called kernel trick.</p>
<p>The kernel trick maps the predictor space into a (higher dimensional) space in which the problem is linear separable:</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="fund.html#cb124-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb124-2"><a href="fund.html#cb124-2" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb124-3"><a href="fund.html#cb124-3" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb124-4"><a href="fund.html#cb124-4" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">expand.grid</span>(x1, x2)</span>
<span id="cb124-5"><a href="fund.html#cb124-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">apply</span>(X, <span class="dv">1</span>, <span class="cf">function</span>(x) <span class="fu">exp</span>(<span class="sc">-</span>x[<span class="dv">1</span>]<span class="sc">^</span><span class="dv">2</span> <span class="sc">-</span> x[<span class="dv">2</span>]<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb124-6"><a href="fund.html#cb124-6" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">ifelse</span>(<span class="dv">1</span><span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(<span class="sc">-</span>y)) <span class="sc">&lt;</span> <span class="fl">0.62</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb124-7"><a href="fund.html#cb124-7" aria-hidden="true" tabindex="-1"></a><span class="fu">image</span>(<span class="fu">matrix</span>(y, <span class="dv">100</span>, <span class="dv">100</span>))</span>
<span id="cb124-8"><a href="fund.html#cb124-8" aria-hidden="true" tabindex="-1"></a>animation<span class="sc">::</span><span class="fu">saveGIF</span>({</span>
<span id="cb124-9"><a href="fund.html#cb124-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">c</span>(<span class="st">&quot;truth&quot;</span>,<span class="st">&quot;linear&quot;</span>, <span class="st">&quot;radial&quot;</span>, <span class="st">&quot;sigmoid&quot;</span>)) {</span>
<span id="cb124-10"><a href="fund.html#cb124-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(i <span class="sc">==</span> <span class="st">&quot;truth&quot;</span>){</span>
<span id="cb124-11"><a href="fund.html#cb124-11" aria-hidden="true" tabindex="-1"></a>      <span class="fu">image</span>(<span class="fu">matrix</span>(y, <span class="dv">100</span>,<span class="dv">100</span>),<span class="at">main =</span> <span class="st">&quot;Ground truth&quot;</span>,<span class="at">axes =</span> <span class="cn">FALSE</span>, <span class="at">las =</span> <span class="dv">2</span>)</span>
<span id="cb124-12"><a href="fund.html#cb124-12" aria-hidden="true" tabindex="-1"></a>    }<span class="cf">else</span>{</span>
<span id="cb124-13"><a href="fund.html#cb124-13" aria-hidden="true" tabindex="-1"></a>      sv <span class="ot">=</span> e1071<span class="sc">::</span><span class="fu">svm</span>(<span class="at">x =</span> X, <span class="at">y =</span> <span class="fu">factor</span>(y), <span class="at">kernel =</span> i)</span>
<span id="cb124-14"><a href="fund.html#cb124-14" aria-hidden="true" tabindex="-1"></a>      <span class="fu">image</span>(<span class="fu">matrix</span>(<span class="fu">as.numeric</span>(<span class="fu">as.character</span>(<span class="fu">predict</span>(sv, X))), <span class="dv">100</span>,<span class="dv">100</span>),<span class="at">main =</span> <span class="fu">paste0</span>(<span class="st">&quot;Kernel: &quot;</span>, i),<span class="at">axes =</span> <span class="cn">FALSE</span>, <span class="at">las =</span> <span class="dv">2</span>)</span>
<span id="cb124-15"><a href="fund.html#cb124-15" aria-hidden="true" tabindex="-1"></a>      <span class="fu">axis</span>(<span class="dv">1</span>, <span class="at">at =</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">10</span>), <span class="at">labels =</span> <span class="fu">round</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>,<span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">10</span>), <span class="dv">1</span>))</span>
<span id="cb124-16"><a href="fund.html#cb124-16" aria-hidden="true" tabindex="-1"></a>      <span class="fu">axis</span>(<span class="dv">2</span>, <span class="at">at =</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">10</span>), <span class="at">labels =</span> <span class="fu">round</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>,<span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">10</span>), <span class="dv">1</span>), <span class="at">las =</span> <span class="dv">2</span>)</span>
<span id="cb124-17"><a href="fund.html#cb124-17" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb124-18"><a href="fund.html#cb124-18" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb124-19"><a href="fund.html#cb124-19" aria-hidden="true" tabindex="-1"></a>},<span class="at">movie.name =</span> <span class="st">&quot;svm.gif&quot;</span>, <span class="at">autobrowse =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="images/svm.gif" /><!-- --></p>
</div>
</div>
<div id="artificial-neural-networks" class="section level2" number="3.4">
<h2><span class="header-section-number">3.4</span> Artificial neural networks</h2>
<p>Regularization in ANNs</p>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="fund.html#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb125-2"><a href="fund.html#cb125-2" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality</span>
<span id="cb125-3"><a href="fund.html#cb125-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(data)</span></code></pre></div>
<pre><code>##      Ozone           Solar.R           Wind             Temp           Month            Day      
##  Min.   :  1.00   Min.   :  7.0   Min.   : 1.700   Min.   :56.00   Min.   :5.000   Min.   : 1.0  
##  1st Qu.: 18.00   1st Qu.:115.8   1st Qu.: 7.400   1st Qu.:72.00   1st Qu.:6.000   1st Qu.: 8.0  
##  Median : 31.50   Median :205.0   Median : 9.700   Median :79.00   Median :7.000   Median :16.0  
##  Mean   : 42.13   Mean   :185.9   Mean   : 9.958   Mean   :77.88   Mean   :6.993   Mean   :15.8  
##  3rd Qu.: 63.25   3rd Qu.:258.8   3rd Qu.:11.500   3rd Qu.:85.00   3rd Qu.:8.000   3rd Qu.:23.0  
##  Max.   :168.00   Max.   :334.0   Max.   :20.700   Max.   :97.00   Max.   :9.000   Max.   :31.0  
##  NA&#39;s   :37       NA&#39;s   :7</code></pre>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="fund.html#cb127-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> data[<span class="fu">complete.cases</span>(data),] <span class="co"># remove NAs</span></span>
<span id="cb127-2"><a href="fund.html#cb127-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(data)</span></code></pre></div>
<pre><code>##      Ozone          Solar.R           Wind            Temp           Month            Day       
##  Min.   :  1.0   Min.   :  7.0   Min.   : 2.30   Min.   :57.00   Min.   :5.000   Min.   : 1.00  
##  1st Qu.: 18.0   1st Qu.:113.5   1st Qu.: 7.40   1st Qu.:71.00   1st Qu.:6.000   1st Qu.: 9.00  
##  Median : 31.0   Median :207.0   Median : 9.70   Median :79.00   Median :7.000   Median :16.00  
##  Mean   : 42.1   Mean   :184.8   Mean   : 9.94   Mean   :77.79   Mean   :7.216   Mean   :15.95  
##  3rd Qu.: 62.0   3rd Qu.:255.5   3rd Qu.:11.50   3rd Qu.:84.50   3rd Qu.:9.000   3rd Qu.:22.50  
##  Max.   :168.0   Max.   :334.0   Max.   :20.70   Max.   :97.00   Max.   :9.000   Max.   :31.00</code></pre>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="fund.html#cb129-1" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="dv">2</span><span class="sc">:</span><span class="dv">6</span>])</span>
<span id="cb129-2"><a href="fund.html#cb129-2" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span> data[,<span class="dv">1</span>]</span>
<span id="cb129-3"><a href="fund.html#cb129-3" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb129-4"><a href="fund.html#cb129-4" aria-hidden="true" tabindex="-1"></a>penalty <span class="ot">=</span> <span class="fl">0.01</span></span>
<span id="cb129-5"><a href="fund.html#cb129-5" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb129-6"><a href="fund.html#cb129-6" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(5L), <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1</span>(penalty)) <span class="sc">%&gt;%</span></span>
<span id="cb129-7"><a href="fund.html#cb129-7" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1</span>(penalty) ) <span class="sc">%&gt;%</span></span>
<span id="cb129-8"><a href="fund.html#cb129-8" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1</span>(penalty)) <span class="sc">%&gt;%</span></span>
<span id="cb129-9"><a href="fund.html#cb129-9" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;linear&quot;</span>, <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1</span>(penalty)) <span class="co"># one output dimension with a linear activation function</span></span>
<span id="cb129-10"><a href="fund.html#cb129-10" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## Model: &quot;sequential_17&quot;
## _________________________________________________________________________________________________________________________________________
## Layer (type)                                                 Output Shape                                           Param #              
## =========================================================================================================================================
## dense_43 (Dense)                                             (None, 100)                                            600                  
## _________________________________________________________________________________________________________________________________________
## dense_44 (Dense)                                             (None, 100)                                            10100                
## _________________________________________________________________________________________________________________________________________
## dense_45 (Dense)                                             (None, 100)                                            10100                
## _________________________________________________________________________________________________________________________________________
## dense_46 (Dense)                                             (None, 1)                                              101                  
## =========================================================================================================================================
## Total params: 20,901
## Trainable params: 20,901
## Non-trainable params: 0
## _________________________________________________________________________________________________________________________________________</code></pre>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="fund.html#cb131-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb131-2"><a href="fund.html#cb131-2" aria-hidden="true" tabindex="-1"></a> <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="fl">0.1</span>))</span>
<span id="cb131-3"><a href="fund.html#cb131-3" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb131-4"><a href="fund.html#cb131-4" aria-hidden="true" tabindex="-1"></a> model <span class="sc">%&gt;%</span></span>
<span id="cb131-5"><a href="fund.html#cb131-5" aria-hidden="true" tabindex="-1"></a> <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> <span class="fu">matrix</span>(Y, <span class="at">ncol =</span> 1L), <span class="at">epochs =</span> 100L, <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>, <span class="at">validation_split =</span> <span class="fl">0.2</span>)</span>
<span id="cb131-6"><a href="fund.html#cb131-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-62-1.png" width="672" /></p>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb133-1"><a href="fund.html#cb133-1" aria-hidden="true" tabindex="-1"></a>weights <span class="ot">=</span> <span class="fu">lapply</span>(model<span class="sc">$</span>weights, <span class="cf">function</span>(w) w<span class="sc">$</span><span class="fu">numpy</span>() )</span>
<span id="cb133-2"><a href="fund.html#cb133-2" aria-hidden="true" tabindex="-1"></a>fields<span class="sc">::</span><span class="fu">image.plot</span>(weights[[<span class="dv">1</span>]])</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-62-2.png" width="672" /></p>
</div>
<div id="the-standard-ml-pipeline-at-the-example-of-the-titanic-dataset" class="section level2" number="3.5">
<h2><span class="header-section-number">3.5</span> The standard ML pipeline at the example of the titanic dataset</h2>
<p>The typical ML workflow consist of:</p>
<ul>
<li>Data cleaning and exploration (EDA=explorative data analysis) with tidyverse</li>
<li>Pre-processing and feature selection</li>
<li>Splitting dataset into train and test set for evaluation</li>
<li>Model fitting</li>
<li>Model evaluation</li>
<li>New predictions
Here is an (optional) video that explains the entire pipeline from a slightly different perspective</li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/nKW8Ndu7Mjw" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<p>In the following example, we use tidyverse, a collection of R packages for data science / data manipulation mainly developed by Hadley Wickham. A video that explains the basics here</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/nRtp7wSEtJA" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<p>A good reference is R for data science by Hadley <a href="https://r4ds.had.co.nz/"></a></p>
<p>For this lecture you need the titanic dataset provided by us. You can find it in GRIPS (datasets.RData in the dataset and submission section) or at <a href="http://rhsbio6.uni-regensburg.de:8500"></a>.</p>
<p>We have split the dataset already into training and testing datasets (the test split has one column less than the train split, why?)</p>
<div id="data-cleaning" class="section level3" number="3.5.1">
<h3><span class="header-section-number">3.5.1</span> Data cleaning</h3>
<p>Load necessary libraries:</p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="fund.html#cb134-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb134-2"><a href="fund.html#cb134-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb134-3"><a href="fund.html#cb134-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code></pre></div>
<p>Load dataset:</p>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb135-1"><a href="fund.html#cb135-1" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">&quot;datasets.RData&quot;</span>)</span>
<span id="cb135-2"><a href="fund.html#cb135-2" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> titanic<span class="sc">$</span>train</span>
<span id="cb135-3"><a href="fund.html#cb135-3" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> titanic<span class="sc">$</span>test</span></code></pre></div>
<p>For cleaning and exploration we will combine the datasets together (if we change a predictor in the train set, we have also to change it in the test set…).</p>
<p>But we will create a new variable “subset” that tells us whether an observation belongs to the train or test split:</p>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="fund.html#cb136-1" aria-hidden="true" tabindex="-1"></a>test<span class="sc">$</span>survived <span class="ot">=</span> <span class="cn">NA</span></span>
<span id="cb136-2"><a href="fund.html#cb136-2" aria-hidden="true" tabindex="-1"></a>train<span class="sc">$</span>subset <span class="ot">=</span> <span class="st">&quot;train&quot;</span></span>
<span id="cb136-3"><a href="fund.html#cb136-3" aria-hidden="true" tabindex="-1"></a>test<span class="sc">$</span>subset <span class="ot">=</span> <span class="st">&quot;test&quot;</span></span>
<span id="cb136-4"><a href="fund.html#cb136-4" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">rbind</span>(train,test)</span></code></pre></div>
<p>Standard summaries:</p>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb137-1"><a href="fund.html#cb137-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(data)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    1309 obs. of  15 variables:
##  $ pclass   : int  2 1 3 3 3 3 3 1 3 1 ...
##  $ survived : int  1 1 0 0 0 0 0 1 0 1 ...
##  $ name     : chr  &quot;Sinkkonen, Miss. Anna&quot; &quot;Woolner, Mr. Hugh&quot; &quot;Sage, Mr. Douglas Bullen&quot; &quot;Palsson, Master. Paul Folke&quot; ...
##  $ sex      : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 1 2 2 2 2 2 2 1 1 1 ...
##  $ age      : num  30 NA NA 6 30.5 38.5 20 53 NA 42 ...
##  $ sibsp    : int  0 0 8 3 0 0 0 0 0 0 ...
##  $ parch    : int  0 0 2 1 0 0 0 0 0 0 ...
##  $ ticket   : Factor w/ 929 levels &quot;110152&quot;,&quot;110413&quot;,..: 221 123 779 542 589 873 472 823 588 834 ...
##  $ fare     : num  13 35.5 69.55 21.07 8.05 ...
##  $ cabin    : Factor w/ 187 levels &quot;&quot;,&quot;A10&quot;,&quot;A11&quot;,..: 1 94 1 1 1 1 1 1 1 1 ...
##  $ embarked : Factor w/ 4 levels &quot;&quot;,&quot;C&quot;,&quot;Q&quot;,&quot;S&quot;: 4 4 4 4 4 4 4 2 4 2 ...
##  $ boat     : Factor w/ 28 levels &quot;&quot;,&quot;1&quot;,&quot;10&quot;,&quot;11&quot;,..: 3 28 1 1 1 1 1 19 1 15 ...
##  $ body     : int  NA NA NA NA 50 32 NA NA NA NA ...
##  $ home.dest: Factor w/ 370 levels &quot;&quot;,&quot;?Havana, Cuba&quot;,..: 121 213 1 1 1 1 322 350 1 1 ...
##  $ subset   : chr  &quot;train&quot; &quot;train&quot; &quot;train&quot; &quot;train&quot; ...</code></pre>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="fund.html#cb139-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(data)</span></code></pre></div>
<pre><code>##      pclass         survived          name               sex           age              sibsp            parch            ticket    
##  Min.   :1.000   Min.   :0.0000   Length:1309        female:466   Min.   : 0.1667   Min.   :0.0000   Min.   :0.000   CA. 2343:  11  
##  1st Qu.:2.000   1st Qu.:0.0000   Class :character   male  :843   1st Qu.:21.0000   1st Qu.:0.0000   1st Qu.:0.000   1601    :   8  
##  Median :3.000   Median :0.0000   Mode  :character                Median :28.0000   Median :0.0000   Median :0.000   CA 2144 :   8  
##  Mean   :2.295   Mean   :0.3853                                   Mean   :29.8811   Mean   :0.4989   Mean   :0.385   3101295 :   7  
##  3rd Qu.:3.000   3rd Qu.:1.0000                                   3rd Qu.:39.0000   3rd Qu.:1.0000   3rd Qu.:0.000   347077  :   7  
##  Max.   :3.000   Max.   :1.0000                                   Max.   :80.0000   Max.   :8.0000   Max.   :9.000   347082  :   7  
##                  NA&#39;s   :655                                      NA&#39;s   :263                                        (Other) :1261  
##       fare                     cabin      embarked      boat          body                      home.dest      subset         
##  Min.   :  0.000                  :1014    :  2           :823   Min.   :  1.0                       :564   Length:1309       
##  1st Qu.:  7.896   C23 C25 C27    :   6   C:270    13     : 39   1st Qu.: 72.0   New York, NY        : 64   Class :character  
##  Median : 14.454   B57 B59 B63 B66:   5   Q:123    C      : 38   Median :155.0   London              : 14   Mode  :character  
##  Mean   : 33.295   G6             :   5   S:914    15     : 37   Mean   :160.8   Montreal, PQ        : 10                     
##  3rd Qu.: 31.275   B96 B98        :   4            14     : 33   3rd Qu.:256.0   Cornwall / Akron, OH:  9                     
##  Max.   :512.329   C22 C26        :   4            4      : 31   Max.   :328.0   Paris, France       :  9                     
##  NA&#39;s   :1         (Other)        : 271            (Other):308   NA&#39;s   :1188    (Other)             :639</code></pre>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="fund.html#cb141-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(data)</span></code></pre></div>
<pre><code>##      pclass survived                         name    sex  age sibsp parch             ticket   fare cabin embarked boat body
## 561       2        1        Sinkkonen, Miss. Anna female 30.0     0     0             250648 13.000              S   10   NA
## 321       1        1            Woolner, Mr. Hugh   male   NA     0     0              19947 35.500   C52        S    D   NA
## 1177      3        0     Sage, Mr. Douglas Bullen   male   NA     8     2           CA. 2343 69.550              S        NA
## 1098      3        0  Palsson, Master. Paul Folke   male  6.0     3     1             349909 21.075              S        NA
## 1252      3        0   Tomlin, Mr. Ernest Portage   male 30.5     0     0             364499  8.050              S        50
## 1170      3        0 Saether, Mr. Simon Sivertsen   male 38.5     0     0 SOTON/O.Q. 3101262  7.250              S        32
##                     home.dest subset
## 561  Finland / Washington, DC  train
## 321           London, England  train
## 1177                           train
## 1098                           train
## 1252                           train
## 1170                           train</code></pre>
<p>The name variable consists of 1309 unique factors (there are 1309 observations…):</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="fund.html#cb143-1" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(<span class="fu">unique</span>(data<span class="sc">$</span>name))</span></code></pre></div>
<pre><code>## [1] 1307</code></pre>
<p>However, there is a title in each name. Let’s extract the titles:</p>
<ol style="list-style-type: decimal">
<li>we will extract all names and split each name after each comma “,”</li>
<li>we will split the second split of the name after a point “.” and extract the titles</li>
</ol>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb145-1"><a href="fund.html#cb145-1" aria-hidden="true" tabindex="-1"></a>first_split <span class="ot">=</span> <span class="fu">sapply</span>(data<span class="sc">$</span>name, <span class="cf">function</span>(x) stringr<span class="sc">::</span><span class="fu">str_split</span>(x, <span class="at">pattern =</span> <span class="st">&quot;,&quot;</span>)[[<span class="dv">1</span>]][<span class="dv">2</span>])</span>
<span id="cb145-2"><a href="fund.html#cb145-2" aria-hidden="true" tabindex="-1"></a>titles <span class="ot">=</span> <span class="fu">sapply</span>(first_split, <span class="cf">function</span>(x) <span class="fu">strsplit</span>(x, <span class="st">&quot;.&quot;</span>,<span class="at">fixed =</span> <span class="cn">TRUE</span>)[[<span class="dv">1</span>]][<span class="dv">1</span>])</span></code></pre></div>
<p>We get 18 unique titles:</p>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="fund.html#cb146-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(titles)</span></code></pre></div>
<pre><code>## titles
##          Capt           Col           Don          Dona            Dr      Jonkheer          Lady         Major        Master 
##             1             4             1             1             8             1             1             2            61 
##          Miss          Mlle           Mme            Mr           Mrs            Ms           Rev           Sir  the Countess 
##           260             2             1           757           197             2             8             1             1</code></pre>
<p>With the forcats package we can easily handle and mutate factor variables.</p>
<p>A few titles have a very low occurrence rate:</p>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="fund.html#cb148-1" aria-hidden="true" tabindex="-1"></a>titles <span class="ot">=</span> stringr<span class="sc">::</span><span class="fu">str_trim</span>((titles))</span>
<span id="cb148-2"><a href="fund.html#cb148-2" aria-hidden="true" tabindex="-1"></a>titles <span class="sc">%&gt;%</span></span>
<span id="cb148-3"><a href="fund.html#cb148-3" aria-hidden="true" tabindex="-1"></a> <span class="fu">fct_count</span>()</span></code></pre></div>
<pre><code>## # A tibble: 18 x 2
##    f                n
##    &lt;fct&gt;        &lt;int&gt;
##  1 Capt             1
##  2 Col              4
##  3 Don              1
##  4 Dona             1
##  5 Dr               8
##  6 Jonkheer         1
##  7 Lady             1
##  8 Major            2
##  9 Master          61
## 10 Miss           260
## 11 Mlle             2
## 12 Mme              1
## 13 Mr             757
## 14 Mrs            197
## 15 Ms               2
## 16 Rev              8
## 17 Sir              1
## 18 the Countess     1</code></pre>
<p>We will collapse titles with low occurrences into one title:</p>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb150-1"><a href="fund.html#cb150-1" aria-hidden="true" tabindex="-1"></a>titles2 <span class="ot">=</span></span>
<span id="cb150-2"><a href="fund.html#cb150-2" aria-hidden="true" tabindex="-1"></a>  forcats<span class="sc">::</span><span class="fu">fct_collapse</span>(titles,</span>
<span id="cb150-3"><a href="fund.html#cb150-3" aria-hidden="true" tabindex="-1"></a>                        <span class="at">officer =</span> <span class="fu">c</span>(<span class="st">&quot;Capt&quot;</span>, <span class="st">&quot;Col&quot;</span>, <span class="st">&quot;Major&quot;</span>, <span class="st">&quot;Dr&quot;</span>, <span class="st">&quot;Rev&quot;</span>),</span>
<span id="cb150-4"><a href="fund.html#cb150-4" aria-hidden="true" tabindex="-1"></a>                        <span class="at">royal =</span> <span class="fu">c</span>(<span class="st">&quot;Jonkheer&quot;</span>, <span class="st">&quot;Don&quot;</span>, <span class="st">&quot;Sir&quot;</span>, <span class="st">&quot;the Countess&quot;</span>, <span class="st">&quot;Dona&quot;</span>, <span class="st">&quot;Lady&quot;</span>),</span>
<span id="cb150-5"><a href="fund.html#cb150-5" aria-hidden="true" tabindex="-1"></a>                        <span class="at">miss =</span> <span class="fu">c</span>(<span class="st">&quot;Miss&quot;</span>, <span class="st">&quot;Mlle&quot;</span>),</span>
<span id="cb150-6"><a href="fund.html#cb150-6" aria-hidden="true" tabindex="-1"></a>                        <span class="at">mrs =</span> <span class="fu">c</span>(<span class="st">&quot;Mrs&quot;</span>, <span class="st">&quot;Mme&quot;</span>, <span class="st">&quot;Ms&quot;</span>)</span>
<span id="cb150-7"><a href="fund.html#cb150-7" aria-hidden="true" tabindex="-1"></a>                        )</span>
<span id="cb150-8"><a href="fund.html#cb150-8" aria-hidden="true" tabindex="-1"></a>titles <span class="ot">=</span> stringr<span class="sc">::</span><span class="fu">str_trim</span>((titles))</span>
<span id="cb150-9"><a href="fund.html#cb150-9" aria-hidden="true" tabindex="-1"></a>titles <span class="sc">%&gt;%</span></span>
<span id="cb150-10"><a href="fund.html#cb150-10" aria-hidden="true" tabindex="-1"></a> <span class="fu">fct_count</span>()</span></code></pre></div>
<pre><code>## # A tibble: 18 x 2
##    f                n
##    &lt;fct&gt;        &lt;int&gt;
##  1 Capt             1
##  2 Col              4
##  3 Don              1
##  4 Dona             1
##  5 Dr               8
##  6 Jonkheer         1
##  7 Lady             1
##  8 Major            2
##  9 Master          61
## 10 Miss           260
## 11 Mlle             2
## 12 Mme              1
## 13 Mr             757
## 14 Mrs            197
## 15 Ms               2
## 16 Rev              8
## 17 Sir              1
## 18 the Countess     1</code></pre>
<p>We will collapse titles with low occurrences into one title:</p>
<div class="sourceCode" id="cb152"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb152-1"><a href="fund.html#cb152-1" aria-hidden="true" tabindex="-1"></a>titles2 <span class="ot">=</span></span>
<span id="cb152-2"><a href="fund.html#cb152-2" aria-hidden="true" tabindex="-1"></a>  forcats<span class="sc">::</span><span class="fu">fct_collapse</span>(titles,</span>
<span id="cb152-3"><a href="fund.html#cb152-3" aria-hidden="true" tabindex="-1"></a>                        <span class="at">officer =</span> <span class="fu">c</span>(<span class="st">&quot;Capt&quot;</span>, <span class="st">&quot;Col&quot;</span>, <span class="st">&quot;Major&quot;</span>, <span class="st">&quot;Dr&quot;</span>, <span class="st">&quot;Rev&quot;</span>),</span>
<span id="cb152-4"><a href="fund.html#cb152-4" aria-hidden="true" tabindex="-1"></a>                        <span class="at">royal =</span> <span class="fu">c</span>(<span class="st">&quot;Jonkheer&quot;</span>, <span class="st">&quot;Don&quot;</span>, <span class="st">&quot;Sir&quot;</span>, <span class="st">&quot;the Countess&quot;</span>, <span class="st">&quot;Dona&quot;</span>, <span class="st">&quot;Lady&quot;</span>),</span>
<span id="cb152-5"><a href="fund.html#cb152-5" aria-hidden="true" tabindex="-1"></a>                        <span class="at">miss =</span> <span class="fu">c</span>(<span class="st">&quot;Miss&quot;</span>, <span class="st">&quot;Mlle&quot;</span>),</span>
<span id="cb152-6"><a href="fund.html#cb152-6" aria-hidden="true" tabindex="-1"></a>                        <span class="at">mrs =</span> <span class="fu">c</span>(<span class="st">&quot;Mrs&quot;</span>, <span class="st">&quot;Mme&quot;</span>, <span class="st">&quot;Ms&quot;</span>)</span>
<span id="cb152-7"><a href="fund.html#cb152-7" aria-hidden="true" tabindex="-1"></a>                        )</span></code></pre></div>
<p>Count titles again:</p>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb153-1"><a href="fund.html#cb153-1" aria-hidden="true" tabindex="-1"></a>titles2 <span class="sc">%&gt;%</span>  </span>
<span id="cb153-2"><a href="fund.html#cb153-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">fct_count</span>()</span></code></pre></div>
<pre><code>## # A tibble: 6 x 2
##   f           n
##   &lt;fct&gt;   &lt;int&gt;
## 1 officer    23
## 2 royal       6
## 3 Master     61
## 4 miss      262
## 5 mrs       200
## 6 Mr        757</code></pre>
<p>Add new title variable to dataset:</p>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb155-1"><a href="fund.html#cb155-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span></span>
<span id="cb155-2"><a href="fund.html#cb155-2" aria-hidden="true" tabindex="-1"></a>  data <span class="sc">%&gt;%</span></span>
<span id="cb155-3"><a href="fund.html#cb155-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">title =</span> titles2)</span></code></pre></div>
<p>As a second example, we will explore and clean the numeric “age” variable:</p>
<p>Explore the variable:</p>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb156-1"><a href="fund.html#cb156-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(data)</span></code></pre></div>
<pre><code>##      pclass         survived          name               sex           age              sibsp            parch            ticket    
##  Min.   :1.000   Min.   :0.0000   Length:1309        female:466   Min.   : 0.1667   Min.   :0.0000   Min.   :0.000   CA. 2343:  11  
##  1st Qu.:2.000   1st Qu.:0.0000   Class :character   male  :843   1st Qu.:21.0000   1st Qu.:0.0000   1st Qu.:0.000   1601    :   8  
##  Median :3.000   Median :0.0000   Mode  :character                Median :28.0000   Median :0.0000   Median :0.000   CA 2144 :   8  
##  Mean   :2.295   Mean   :0.3853                                   Mean   :29.8811   Mean   :0.4989   Mean   :0.385   3101295 :   7  
##  3rd Qu.:3.000   3rd Qu.:1.0000                                   3rd Qu.:39.0000   3rd Qu.:1.0000   3rd Qu.:0.000   347077  :   7  
##  Max.   :3.000   Max.   :1.0000                                   Max.   :80.0000   Max.   :8.0000   Max.   :9.000   347082  :   7  
##                  NA&#39;s   :655                                      NA&#39;s   :263                                        (Other) :1261  
##       fare                     cabin      embarked      boat          body                      home.dest      subset         
##  Min.   :  0.000                  :1014    :  2           :823   Min.   :  1.0                       :564   Length:1309       
##  1st Qu.:  7.896   C23 C25 C27    :   6   C:270    13     : 39   1st Qu.: 72.0   New York, NY        : 64   Class :character  
##  Median : 14.454   B57 B59 B63 B66:   5   Q:123    C      : 38   Median :155.0   London              : 14   Mode  :character  
##  Mean   : 33.295   G6             :   5   S:914    15     : 37   Mean   :160.8   Montreal, PQ        : 10                     
##  3rd Qu.: 31.275   B96 B98        :   4            14     : 33   3rd Qu.:256.0   Cornwall / Akron, OH:  9                     
##  Max.   :512.329   C22 C26        :   4            4      : 31   Max.   :328.0   Paris, France       :  9                     
##  NA&#39;s   :1         (Other)        : 271            (Other):308   NA&#39;s   :1188    (Other)             :639                     
##      title    
##  officer: 23  
##  royal  :  6  
##  Master : 61  
##  miss   :262  
##  mrs    :200  
##  Mr     :757  
## </code></pre>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb158-1"><a href="fund.html#cb158-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">is.na</span>(data<span class="sc">$</span>age))<span class="sc">/</span><span class="fu">nrow</span>(data)</span></code></pre></div>
<pre><code>## [1] 0.2009167</code></pre>
<p>20% NAs!
Either we remove all observations with NAs, or we impute (fill) the missing values, e.g. with the median age:</p>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb160-1"><a href="fund.html#cb160-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span></span>
<span id="cb160-2"><a href="fund.html#cb160-2" aria-hidden="true" tabindex="-1"></a>  data <span class="sc">%&gt;%</span></span>
<span id="cb160-3"><a href="fund.html#cb160-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(sex, pclass, title) <span class="sc">%&gt;%</span></span>
<span id="cb160-4"><a href="fund.html#cb160-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">age2 =</span> <span class="fu">ifelse</span>(<span class="fu">is.na</span>(age), <span class="fu">median</span>(age, <span class="at">na.rm =</span> <span class="cn">TRUE</span>), age)) <span class="sc">%&gt;%</span></span>
<span id="cb160-5"><a href="fund.html#cb160-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ungroup</span>()</span></code></pre></div>
<p>However, age itself might depend on other variables such as sex, class and title. We want to fill the NAs with the median age of these groups.
In tidyverse we can easily “group” the data, i.e. we will nest the observations (here: group_by after sex, pclass and title).
After grouping, all operations (such as our median(age….)) will be done within the specified groups.</p>
</div>
<div id="pre-processing-and-feature-selection" class="section level3" number="3.5.2">
<h3><span class="header-section-number">3.5.2</span> Pre-processing and feature selection</h3>
<p>Keras cannot handle factors and we have to scale the data.</p>
<p>For now we will sub-select a batch of predictors and:</p>
<ul>
<li>scale the numeric predictors</li>
<li>change the factors with only two groups/levels into integer</li>
</ul>
<div class="sourceCode" id="cb161"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb161-1"><a href="fund.html#cb161-1" aria-hidden="true" tabindex="-1"></a>data_sub <span class="ot">=</span></span>
<span id="cb161-2"><a href="fund.html#cb161-2" aria-hidden="true" tabindex="-1"></a>  data <span class="sc">%&gt;%</span></span>
<span id="cb161-3"><a href="fund.html#cb161-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">select</span>(survived, sex, age2, fare, title, pclass) <span class="sc">%&gt;%</span></span>
<span id="cb161-4"><a href="fund.html#cb161-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">age2 =</span> scales<span class="sc">::</span><span class="fu">rescale</span>(age2, <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>)), <span class="at">fare =</span> scales<span class="sc">::</span><span class="fu">rescale</span>(fare, <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>))) <span class="sc">%&gt;%</span></span>
<span id="cb161-5"><a href="fund.html#cb161-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">sex =</span> <span class="fu">as.integer</span>(sex) <span class="sc">-</span> 1L, <span class="at">title =</span> <span class="fu">as.integer</span>(title) <span class="sc">-</span> 1L, <span class="at">pclass =</span> <span class="fu">as.integer</span>(pclass <span class="sc">-</span> 1L))</span></code></pre></div>
<p>One hot encoding of factors with &gt; 2 levels:</p>
<div class="sourceCode" id="cb162"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb162-1"><a href="fund.html#cb162-1" aria-hidden="true" tabindex="-1"></a>one_title <span class="ot">=</span> <span class="fu">k_one_hot</span>(data_sub<span class="sc">$</span>title, <span class="fu">length</span>(<span class="fu">unique</span>(data<span class="sc">$</span>title)))<span class="sc">$</span><span class="fu">numpy</span>()</span>
<span id="cb162-2"><a href="fund.html#cb162-2" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(one_title) <span class="ot">=</span> <span class="fu">levels</span>(data<span class="sc">$</span>title)</span>
<span id="cb162-3"><a href="fund.html#cb162-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb162-4"><a href="fund.html#cb162-4" aria-hidden="true" tabindex="-1"></a>one_sex <span class="ot">=</span> <span class="fu">k_one_hot</span>(data_sub<span class="sc">$</span>sex, <span class="fu">length</span>(<span class="fu">unique</span>(data<span class="sc">$</span>sex)))<span class="sc">$</span><span class="fu">numpy</span>()</span>
<span id="cb162-5"><a href="fund.html#cb162-5" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(one_sex) <span class="ot">=</span> <span class="fu">levels</span>(data<span class="sc">$</span>sex)</span>
<span id="cb162-6"><a href="fund.html#cb162-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb162-7"><a href="fund.html#cb162-7" aria-hidden="true" tabindex="-1"></a>one_pclass <span class="ot">=</span> <span class="fu">k_one_hot</span>(data_sub<span class="sc">$</span>pclass,  <span class="fu">length</span>(<span class="fu">unique</span>(data<span class="sc">$</span>pclass)))<span class="sc">$</span><span class="fu">numpy</span>()</span>
<span id="cb162-8"><a href="fund.html#cb162-8" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(one_pclass) <span class="ot">=</span> <span class="fu">paste0</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(<span class="fu">unique</span>(data<span class="sc">$</span>pclass)), <span class="st">&quot;pclass&quot;</span>)</span></code></pre></div>
<p>Add the dummy encoded variables to the dataset:</p>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb163-1"><a href="fund.html#cb163-1" aria-hidden="true" tabindex="-1"></a>data_sub <span class="ot">=</span> <span class="fu">cbind</span>(<span class="fu">data.frame</span>(<span class="at">survived=</span> data_sub<span class="sc">$</span>survived, <span class="at">subset =</span> data<span class="sc">$</span>subset), one_title, one_sex, <span class="at">age =</span> data_sub<span class="sc">$</span>age2, <span class="at">fare =</span> data_sub<span class="sc">$</span>fare, one_pclass)</span>
<span id="cb163-2"><a href="fund.html#cb163-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(data_sub)</span></code></pre></div>
<pre><code>##   survived subset officer royal Master miss mrs Mr female male        age       fare 1pclass 2pclass 3pclass
## 1        1  train       0     0      0    1   0  0      1    0 0.37369494 0.02537431       0       1       0
## 2        1  train       0     0      0    0   0  1      0    1 0.51774510 0.06929139       1       0       0
## 3        0  train       0     0      0    0   0  1      0    1 0.32359053 0.13575256       0       0       1
## 4        0  train       0     0      1    0   0  0      0    1 0.07306851 0.04113566       0       0       1
## 5        0  train       0     0      0    0   0  1      0    1 0.37995799 0.01571255       0       0       1
## 6        0  train       0     0      0    0   0  1      0    1 0.48016680 0.01415106       0       0       1</code></pre>
</div>
<div id="split-data-for-training-and-testing" class="section level3" number="3.5.3">
<h3><span class="header-section-number">3.5.3</span> Split data for training and testing</h3>
<p>The splitting consists of two splits:</p>
<ul>
<li>an outer split (the original split, remember we got a train and test split without the response “survived”)</li>
<li>an inner split (we will split further the train dataset into another train and test split with known response)
The inner split is important because to assess the model’s performance and potential overfitting</li>
</ul>
<p>Outer split:</p>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb165-1"><a href="fund.html#cb165-1" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> data_sub <span class="sc">%&gt;%</span> </span>
<span id="cb165-2"><a href="fund.html#cb165-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(subset <span class="sc">==</span> <span class="st">&quot;train&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb165-3"><a href="fund.html#cb165-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="sc">!</span><span class="fu">is.na</span>(fare)) <span class="sc">%&gt;%</span> </span>
<span id="cb165-4"><a href="fund.html#cb165-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>subset)</span></code></pre></div>
<p>Inner split:</p>
<div class="sourceCode" id="cb166"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb166-1"><a href="fund.html#cb166-1" aria-hidden="true" tabindex="-1"></a>indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(train), <span class="fl">0.7</span><span class="sc">*</span><span class="fu">nrow</span>(train))</span>
<span id="cb166-2"><a href="fund.html#cb166-2" aria-hidden="true" tabindex="-1"></a>sub_train <span class="ot">=</span> train[indices,]</span>
<span id="cb166-3"><a href="fund.html#cb166-3" aria-hidden="true" tabindex="-1"></a>sub_test <span class="ot">=</span> train[<span class="sc">-</span>indices,]</span></code></pre></div>
<p>What is the difference between the two splits? (Tip: have a look at the variable survived)</p>
</div>
<div id="model-fitting" class="section level3" number="3.5.4">
<h3><span class="header-section-number">3.5.4</span> Model fitting</h3>
<p>In the next step we will fit a keras model on the train split of the inner split:</p>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb167-1"><a href="fund.html#cb167-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb167-2"><a href="fund.html#cb167-2" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb167-3"><a href="fund.html#cb167-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">input_shape =</span> <span class="fu">ncol</span>(sub_train) <span class="sc">-</span> 1L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb167-4"><a href="fund.html#cb167-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb167-5"><a href="fund.html#cb167-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb167-6"><a href="fund.html#cb167-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 2L, <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>)</span>
<span id="cb167-7"><a href="fund.html#cb167-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## Model: &quot;sequential_18&quot;
## _________________________________________________________________________________________________________________________________________
## Layer (type)                                                 Output Shape                                           Param #              
## =========================================================================================================================================
## dense_47 (Dense)                                             (None, 20)                                             280                  
## _________________________________________________________________________________________________________________________________________
## dense_48 (Dense)                                             (None, 20)                                             420                  
## _________________________________________________________________________________________________________________________________________
## dense_49 (Dense)                                             (None, 20)                                             420                  
## _________________________________________________________________________________________________________________________________________
## dense_50 (Dense)                                             (None, 2)                                              42                   
## =========================================================================================================================================
## Total params: 1,162
## Trainable params: 1,162
## Non-trainable params: 0
## _________________________________________________________________________________________________________________________________________</code></pre>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb169-1"><a href="fund.html#cb169-1" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb169-2"><a href="fund.html#cb169-2" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb169-3"><a href="fund.html#cb169-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy, <span class="at">optimizer =</span> <span class="fu">optimizer_adamax</span>(<span class="fl">0.01</span>))</span>
<span id="cb169-4"><a href="fund.html#cb169-4" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb169-5"><a href="fund.html#cb169-5" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb169-6"><a href="fund.html#cb169-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(<span class="at">x =</span> <span class="fu">as.matrix</span>(sub_train[,<span class="sc">-</span><span class="dv">1</span>]), <span class="at">y =</span> <span class="fu">to_categorical</span>(sub_train[,<span class="dv">1</span>],<span class="at">num_classes =</span> 2L), <span class="at">epochs =</span> 100L, <span class="at">batch_size =</span> 32L, <span class="at">validation_split =</span> <span class="fl">0.2</span>, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb169-7"><a href="fund.html#cb169-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb169-8"><a href="fund.html#cb169-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-84-1.png" width="672" /></p>
</div>
<div id="model-evaluation" class="section level3" number="3.5.5">
<h3><span class="header-section-number">3.5.5</span> Model evaluation</h3>
<p>We will predict survived for the test set of the inner split and calculate the accuracy:</p>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb171-1"><a href="fund.html#cb171-1" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">=</span></span>
<span id="cb171-2"><a href="fund.html#cb171-2" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb171-3"><a href="fund.html#cb171-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">predict</span>(<span class="at">x =</span> <span class="fu">as.matrix</span>(sub_test[,<span class="sc">-</span><span class="dv">1</span>]))</span>
<span id="cb171-4"><a href="fund.html#cb171-4" aria-hidden="true" tabindex="-1"></a>predicted <span class="ot">=</span> <span class="fu">ifelse</span>(preds[,<span class="dv">2</span>] <span class="sc">&lt;</span> <span class="fl">0.5</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb171-5"><a href="fund.html#cb171-5" aria-hidden="true" tabindex="-1"></a>observed <span class="ot">=</span> sub_test[,<span class="dv">1</span>]</span>
<span id="cb171-6"><a href="fund.html#cb171-6" aria-hidden="true" tabindex="-1"></a>(<span class="at">accuracy =</span> <span class="fu">mean</span>(predicted <span class="sc">==</span> observed))</span></code></pre></div>
<pre><code>## [1] 0.7704082</code></pre>
</div>
<div id="predictions-and-submission" class="section level3" number="3.5.6">
<h3><span class="header-section-number">3.5.6</span> Predictions and submission</h3>
<p>When we are satisfied with the performance of our model in the inner split, we will create predictions for the test split of the outer split:</p>
<p>select all observations that belong to the outer test split (the filter function)
remove the subset and survived (NAs) columns</p>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb173-1"><a href="fund.html#cb173-1" aria-hidden="true" tabindex="-1"></a>submit<span class="ot">=</span> </span>
<span id="cb173-2"><a href="fund.html#cb173-2" aria-hidden="true" tabindex="-1"></a>  data_sub <span class="sc">%&gt;%</span> </span>
<span id="cb173-3"><a href="fund.html#cb173-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(subset <span class="sc">==</span> <span class="st">&quot;test&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb173-4"><a href="fund.html#cb173-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">select</span>(<span class="sc">-</span>subset, <span class="sc">-</span>survived)</span></code></pre></div>
<p>We cannot assess the performance on the test split because the true survived ratio is unknown, however, we can now submit our predictions to the submission server at
<a href="http://rhsbio6.uni-regensburg.de:8500" class="uri">http://rhsbio6.uni-regensburg.de:8500</a>
To do so, we have to transform our survived probablities into actual 0/1 predictions (probablities are not allowed) and create a csv:</p>
<div class="sourceCode" id="cb174"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb174-1"><a href="fund.html#cb174-1" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> model <span class="sc">%&gt;%</span> </span>
<span id="cb174-2"><a href="fund.html#cb174-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">predict</span>(<span class="fu">as.matrix</span>(submit))</span>
<span id="cb174-3"><a href="fund.html#cb174-3" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">ifelse</span>(pred[,<span class="dv">2</span>] <span class="sc">&lt;</span> <span class="fl">0.5</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span></code></pre></div>
<p>All values &gt; 0.5 will be set to 1 and values &lt; 0.5 to zero.
For the submission it is critical to change the predictions into a data.frame and save it with the write.csv function:</p>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb175-1"><a href="fund.html#cb175-1" aria-hidden="true" tabindex="-1"></a><span class="fu">write.csv</span>(<span class="fu">data.frame</span>(<span class="at">y=</span>pred), <span class="at">file =</span> <span class="st">&quot;Max_1.csv&quot;</span>)</span></code></pre></div>
<p>The file name is used as the ID on the submission server, so change it to whatever you want as long as you can identify yourself.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="Deep.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

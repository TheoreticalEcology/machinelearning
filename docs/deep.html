<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5 Deep Learning | Machine Learning and AI in TensorFlow and R</title>
  <meta name="description" content="5 Deep Learning | Machine Learning and AI in TensorFlow and R" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="5 Deep Learning | Machine Learning and AI in TensorFlow and R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="5 Deep Learning | Machine Learning and AI in TensorFlow and R" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5 Deep Learning | Machine Learning and AI in TensorFlow and R" />
  
  <meta name="twitter:description" content="5 Deep Learning | Machine Learning and AI in TensorFlow and R" />
  

<meta name="author" content="Maximilian Pichler and Florian Hartig" />


<meta name="date" content="2021-11-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="fundamental.html"/>
<link rel="next" href="interpretation.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/viz-1.8.2/viz.js"></script>
<link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="libs/grViz-binding-1.0.6.1/grViz.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #ffffff;
    color: #a0a0a0;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
div.sourceCode
  { color: #1f1c1b; background-color: #ffffff; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span { color: #1f1c1b; } /* Normal */
code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
code span.an { color: #ca60ca; } /* Annotation */
code span.at { color: #0057ae; } /* Attribute */
code span.bn { color: #b08000; } /* BaseN */
code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #924c9d; } /* Char */
code span.cn { color: #aa5500; } /* Constant */
code span.co { color: #898887; } /* Comment */
code span.cv { color: #0095ff; } /* CommentVar */
code span.do { color: #607880; } /* Documentation */
code span.dt { color: #0057ae; } /* DataType */
code span.dv { color: #b08000; } /* DecVal */
code span.er { color: #bf0303; text-decoration: underline; } /* Error */
code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
code span.fl { color: #b08000; } /* Float */
code span.fu { color: #644a9b; } /* Function */
code span.im { color: #ff5500; } /* Import */
code span.in { color: #b08000; } /* Information */
code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
code span.op { color: #1f1c1b; } /* Operator */
code span.ot { color: #006e28; } /* Other */
code span.pp { color: #006e28; } /* Preprocessor */
code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #ff5500; } /* SpecialString */
code span.st { color: #bf0303; } /* String */
code span.va { color: #0057ae; } /* Variable */
code span.vs { color: #bf0303; } /* VerbatimString */
code span.wa { color: #bf0303; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#r-system"><i class="fa fa-check"></i><b>1.1</b> R System</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#tensorflow-and-keras"><i class="fa fa-check"></i><b>1.2</b> TensorFlow and Keras</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#torch-for-r"><i class="fa fa-check"></i><b>1.3</b> Torch for R</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#ecodata"><i class="fa fa-check"></i><b>1.4</b> EcoData</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#further-used-libraries"><i class="fa fa-check"></i><b>1.5</b> Further Used Libraries</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#linuxunix-systems-have-to-fulfill-some-durther-dependencies"><i class="fa fa-check"></i><b>1.6</b> Linux/UNIX systems have to fulfill some durther dependencies</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="reminder.html"><a href="reminder.html"><i class="fa fa-check"></i><b>2</b> Reminders About Basic Operations in R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="reminder.html"><a href="reminder.html#your-r-system"><i class="fa fa-check"></i><b>2.1</b> Your R System</a></li>
<li class="chapter" data-level="2.2" data-path="reminder.html"><a href="reminder.html#data-types-in-r"><i class="fa fa-check"></i><b>2.2</b> Data types in R</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="reminder.html"><a href="reminder.html#test-your-knowledge"><i class="fa fa-check"></i><b>2.2.1</b> Test Your Knowledge</a></li>
<li class="chapter" data-level="2.2.2" data-path="reminder.html"><a href="reminder.html#iris-data"><i class="fa fa-check"></i><b>2.2.2</b> Iris Data</a></li>
<li class="chapter" data-level="2.2.3" data-path="reminder.html"><a href="reminder.html#dynamic-typing"><i class="fa fa-check"></i><b>2.2.3</b> Dynamic typing</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="reminder.html"><a href="reminder.html#data-selection-slicing-and-subsetting"><i class="fa fa-check"></i><b>2.3</b> Data selection, Slicing and Subsetting</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="reminder.html"><a href="reminder.html#subsetting-and-slicing-for-single-data-types"><i class="fa fa-check"></i><b>2.3.1</b> Subsetting and Slicing for Single Data Types</a></li>
<li class="chapter" data-level="2.3.2" data-path="reminder.html"><a href="reminder.html#logic-and-slicing"><i class="fa fa-check"></i><b>2.3.2</b> Logic and Slicing</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="reminder.html"><a href="reminder.html#applying-functions-and-aggregates-across-a-data-set"><i class="fa fa-check"></i><b>2.4</b> Applying Functions and Aggregates Across a Data set</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="reminder.html"><a href="reminder.html#functions"><i class="fa fa-check"></i><b>2.4.1</b> Functions</a></li>
<li class="chapter" data-level="2.4.2" data-path="reminder.html"><a href="reminder.html#the-apply-function"><i class="fa fa-check"></i><b>2.4.2</b> The apply() Function</a></li>
<li class="chapter" data-level="2.4.3" data-path="reminder.html"><a href="reminder.html#the-aggregate-function"><i class="fa fa-check"></i><b>2.4.3</b> The aggregate() Function</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="reminder.html"><a href="reminder.html#plotting"><i class="fa fa-check"></i><b>2.5</b> Plotting</a></li>
<li class="chapter" data-level="2.6" data-path="reminder.html"><a href="reminder.html#additional-resources"><i class="fa fa-check"></i><b>2.6</b> Additional Resources</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="reminder.html"><a href="reminder.html#books"><i class="fa fa-check"></i><b>2.6.1</b> Books</a></li>
<li class="chapter" data-level="2.6.2" data-path="reminder.html"><a href="reminder.html#instructional-videos"><i class="fa fa-check"></i><b>2.6.2</b> Instructional videos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>3</b> Introduction to Machine Learning</a>
<ul>
<li class="chapter" data-level="3.1" data-path="introduction.html"><a href="introduction.html#unsupervised-learning"><i class="fa fa-check"></i><b>3.1</b> Unsupervised Learning</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="introduction.html"><a href="introduction.html#hierarchical-clustering"><i class="fa fa-check"></i><b>3.1.1</b> Hierarchical Clustering</a></li>
<li class="chapter" data-level="3.1.2" data-path="introduction.html"><a href="introduction.html#k-means-clustering"><i class="fa fa-check"></i><b>3.1.2</b> K-means Clustering</a></li>
<li class="chapter" data-level="3.1.3" data-path="introduction.html"><a href="introduction.html#density-based-clustering"><i class="fa fa-check"></i><b>3.1.3</b> Density-based Clustering</a></li>
<li class="chapter" data-level="3.1.4" data-path="introduction.html"><a href="introduction.html#model-based-clustering"><i class="fa fa-check"></i><b>3.1.4</b> Model-based Clustering</a></li>
<li class="chapter" data-level="3.1.5" data-path="introduction.html"><a href="introduction.html#ordination"><i class="fa fa-check"></i><b>3.1.5</b> Ordination</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="introduction.html"><a href="introduction.html#supervised-learning-regression-and-classification"><i class="fa fa-check"></i><b>3.2</b> Supervised Learning: Regression and Classification</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="introduction.html"><a href="introduction.html#supervised-regression-using-random-forest"><i class="fa fa-check"></i><b>3.2.1</b> Supervised Regression Using Random Forest</a></li>
<li class="chapter" data-level="3.2.2" data-path="introduction.html"><a href="introduction.html#supervised-classification-using-random-forest"><i class="fa fa-check"></i><b>3.2.2</b> Supervised Classification Using Random Forest</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="introduction.html"><a href="introduction.html#basicMath"><i class="fa fa-check"></i><b>3.3</b> Small Introduction Into the Underlying Mathematical Concepts of all Following Lessons - Optional</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="introduction.html"><a href="introduction.html#caveat-about-learning-rates-and-activation-functions"><i class="fa fa-check"></i><b>3.3.1</b> Caveat About Learning Rates and Activation Functions</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="introduction.html"><a href="introduction.html#introduction-to-tensorflow"><i class="fa fa-check"></i><b>3.4</b> Introduction to TensorFlow</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="introduction.html"><a href="introduction.html#tensorflow-data-containers"><i class="fa fa-check"></i><b>3.4.1</b> TensorFlow Data Containers</a></li>
<li class="chapter" data-level="3.4.2" data-path="introduction.html"><a href="introduction.html#basic-operations"><i class="fa fa-check"></i><b>3.4.2</b> Basic Operations</a></li>
<li class="chapter" data-level="3.4.3" data-path="introduction.html"><a href="introduction.html#tensorflow-data-types---good-practice-with-r-tensorflow"><i class="fa fa-check"></i><b>3.4.3</b> TensorFlow Data Types - Good Practice With R-TensorFlow</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="introduction.html"><a href="introduction.html#introduction-to-pytorch"><i class="fa fa-check"></i><b>3.5</b> Introduction to PyTorch</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="introduction.html"><a href="introduction.html#pytorch-data-containers"><i class="fa fa-check"></i><b>3.5.1</b> PyTorch Data Containers</a></li>
<li class="chapter" data-level="3.5.2" data-path="introduction.html"><a href="introduction.html#basic-operations-1"><i class="fa fa-check"></i><b>3.5.2</b> Basic Operations</a></li>
<li class="chapter" data-level="3.5.3" data-path="introduction.html"><a href="introduction.html#torch-data-types---good-practice-with-r-torch"><i class="fa fa-check"></i><b>3.5.3</b> Torch Data Types - Good Practice With R-Torch</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="introduction.html"><a href="introduction.html#first-steps-with-the-keras-framework"><i class="fa fa-check"></i><b>3.6</b> First Steps With the Keras Framework</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="introduction.html"><a href="introduction.html#example-workflow-in-keras"><i class="fa fa-check"></i><b>3.6.1</b> Example Workflow in Keras</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="fundamental.html"><a href="fundamental.html"><i class="fa fa-check"></i><b>4</b> Fundamental Principles and Techniques</a>
<ul>
<li class="chapter" data-level="4.1" data-path="fundamental.html"><a href="fundamental.html#machine-learning-principles"><i class="fa fa-check"></i><b>4.1</b> Machine Learning Principles</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="fundamental.html"><a href="fundamental.html#optimization"><i class="fa fa-check"></i><b>4.1.1</b> Optimization</a></li>
<li class="chapter" data-level="4.1.2" data-path="fundamental.html"><a href="fundamental.html#advanced-optimization-example"><i class="fa fa-check"></i><b>4.1.2</b> Advanced Optimization Example</a></li>
<li class="chapter" data-level="4.1.3" data-path="fundamental.html"><a href="fundamental.html#regularization"><i class="fa fa-check"></i><b>4.1.3</b> Regularization</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="fundamental.html"><a href="fundamental.html#artificial-neural-networks"><i class="fa fa-check"></i><b>4.2</b> Artificial Neural Networks</a></li>
<li class="chapter" data-level="4.3" data-path="fundamental.html"><a href="fundamental.html#tree-based-machine-learning-algorithms"><i class="fa fa-check"></i><b>4.3</b> Tree-based Machine Learning Algorithms</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="fundamental.html"><a href="fundamental.html#classification-and-regression-trees"><i class="fa fa-check"></i><b>4.3.1</b> Classification and Regression Trees</a></li>
<li class="chapter" data-level="4.3.2" data-path="fundamental.html"><a href="fundamental.html#random-forest"><i class="fa fa-check"></i><b>4.3.2</b> Random Forest</a></li>
<li class="chapter" data-level="4.3.3" data-path="fundamental.html"><a href="fundamental.html#boosted-regression-trees"><i class="fa fa-check"></i><b>4.3.3</b> Boosted Regression Trees</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="fundamental.html"><a href="fundamental.html#distance-based-algorithms"><i class="fa fa-check"></i><b>4.4</b> Distance-based Algorithms</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="fundamental.html"><a href="fundamental.html#k-nearest-neighbor"><i class="fa fa-check"></i><b>4.4.1</b> K-Nearest-Neighbor</a></li>
<li class="chapter" data-level="4.4.2" data-path="fundamental.html"><a href="fundamental.html#support-vector-machines-svms"><i class="fa fa-check"></i><b>4.4.2</b> Support Vector Machines (SVMs)</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="fundamental.html"><a href="fundamental.html#the-standard-machine-learning-pipeline-at-the-eexample-of-the-titanic-data-set"><i class="fa fa-check"></i><b>4.5</b> The Standard Machine Learning Pipeline at the Eexample of the Titanic Data set</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="fundamental.html"><a href="fundamental.html#data-cleaning"><i class="fa fa-check"></i><b>4.5.1</b> Data Cleaning</a></li>
<li class="chapter" data-level="4.5.2" data-path="fundamental.html"><a href="fundamental.html#preprocessing-and-feature-selection"><i class="fa fa-check"></i><b>4.5.2</b> Preprocessing and Feature Selection</a></li>
<li class="chapter" data-level="4.5.3" data-path="fundamental.html"><a href="fundamental.html#split-data-for-training-and-testing"><i class="fa fa-check"></i><b>4.5.3</b> Split Data for Training and Testing</a></li>
<li class="chapter" data-level="4.5.4" data-path="fundamental.html"><a href="fundamental.html#model-fitting"><i class="fa fa-check"></i><b>4.5.4</b> Model Fitting</a></li>
<li class="chapter" data-level="4.5.5" data-path="fundamental.html"><a href="fundamental.html#model-evaluation"><i class="fa fa-check"></i><b>4.5.5</b> Model Evaluation</a></li>
<li class="chapter" data-level="4.5.6" data-path="fundamental.html"><a href="fundamental.html#predictions-and-submission"><i class="fa fa-check"></i><b>4.5.6</b> Predictions and Submission</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="fundamental.html"><a href="fundamental.html#mlr"><i class="fa fa-check"></i><b>4.6</b> Bonus - Machine Learning Pipelines with mlr3</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="fundamental.html"><a href="fundamental.html#mlr3---the-basic-workflow"><i class="fa fa-check"></i><b>4.6.1</b> mlr3 - The Basic Workflow</a></li>
<li class="chapter" data-level="4.6.2" data-path="fundamental.html"><a href="fundamental.html#mlr3---hyperparameter-tuning"><i class="fa fa-check"></i><b>4.6.2</b> mlr3 - Hyperparameter Tuning</a></li>
<li class="chapter" data-level="4.6.3" data-path="fundamental.html"><a href="fundamental.html#mlr3---hyperparameter-tuning-with-oversampling"><i class="fa fa-check"></i><b>4.6.3</b> mlr3 - Hyperparameter Tuning with Oversampling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="deep.html"><a href="deep.html"><i class="fa fa-check"></i><b>5</b> Deep Learning</a>
<ul>
<li class="chapter" data-level="5.1" data-path="deep.html"><a href="deep.html#network-architectures"><i class="fa fa-check"></i><b>5.1</b> Network Architectures</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="deep.html"><a href="deep.html#deep-neural-networks-dnns"><i class="fa fa-check"></i><b>5.1.1</b> Deep Neural Networks (DNNs)</a></li>
<li class="chapter" data-level="5.1.2" data-path="deep.html"><a href="deep.html#convolutional-neural-networks-cnns"><i class="fa fa-check"></i><b>5.1.2</b> Convolutional Neural Networks (CNNs)</a></li>
<li class="chapter" data-level="5.1.3" data-path="deep.html"><a href="deep.html#recurrent-neural-networks-rnns"><i class="fa fa-check"></i><b>5.1.3</b> Recurrent Neural Networks (RNNs)</a></li>
<li class="chapter" data-level="5.1.4" data-path="deep.html"><a href="deep.html#natural-language-processing-nlp"><i class="fa fa-check"></i><b>5.1.4</b> Natural Language Processing (NLP)</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="deep.html"><a href="deep.html#case-study-dropout-and-early-stopping-in-a-deep-neural-network"><i class="fa fa-check"></i><b>5.2</b> Case Study: Dropout and Early Stopping in a Deep Neural Network</a></li>
<li class="chapter" data-level="5.3" data-path="deep.html"><a href="deep.html#case-study-fitting-a-convolutional-neural-network-on-mnist"><i class="fa fa-check"></i><b>5.3</b> Case Study: Fitting a Convolutional Neural Network on MNIST</a></li>
<li class="chapter" data-level="5.4" data-path="deep.html"><a href="deep.html#advanced-training-techniques"><i class="fa fa-check"></i><b>5.4</b> Advanced Training Techniques</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="deep.html"><a href="deep.html#data-augmentation"><i class="fa fa-check"></i><b>5.4.1</b> Data Augmentation</a></li>
<li class="chapter" data-level="5.4.2" data-path="deep.html"><a href="deep.html#transfer"><i class="fa fa-check"></i><b>5.4.2</b> Transfer Learning</a></li>
<li class="chapter" data-level="5.4.3" data-path="deep.html"><a href="deep.html#influence-of-batch-size-and-learning-rate"><i class="fa fa-check"></i><b>5.4.3</b> Influence of Batch Size and Learning Rate</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="interpretation.html"><a href="interpretation.html"><i class="fa fa-check"></i><b>6</b> Interpretation and Causality With Machine Learning</a>
<ul>
<li class="chapter" data-level="6.1" data-path="interpretation.html"><a href="interpretation.html#explainable-ai"><i class="fa fa-check"></i><b>6.1</b> Explainable AI</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="interpretation.html"><a href="interpretation.html#a-practical-example"><i class="fa fa-check"></i><b>6.1.1</b> A Practical Example</a></li>
<li class="chapter" data-level="6.1.2" data-path="interpretation.html"><a href="interpretation.html#feature-importance"><i class="fa fa-check"></i><b>6.1.2</b> Feature Importance</a></li>
<li class="chapter" data-level="6.1.3" data-path="interpretation.html"><a href="interpretation.html#partial-dependencies"><i class="fa fa-check"></i><b>6.1.3</b> Partial Dependencies</a></li>
<li class="chapter" data-level="6.1.4" data-path="interpretation.html"><a href="interpretation.html#accumulated-local-effects"><i class="fa fa-check"></i><b>6.1.4</b> Accumulated Local Effects</a></li>
<li class="chapter" data-level="6.1.5" data-path="interpretation.html"><a href="interpretation.html#friedmans-h-statistic"><i class="fa fa-check"></i><b>6.1.5</b> Friedman’s H-statistic</a></li>
<li class="chapter" data-level="6.1.6" data-path="interpretation.html"><a href="interpretation.html#global-explainer---simplifying-the-machine-learning-model"><i class="fa fa-check"></i><b>6.1.6</b> Global Explainer - Simplifying the Machine Learning Model</a></li>
<li class="chapter" data-level="6.1.7" data-path="interpretation.html"><a href="interpretation.html#local-explainer---lime-explaining-single-instances-observations"><i class="fa fa-check"></i><b>6.1.7</b> Local Explainer - LIME Explaining Single Instances (observations)</a></li>
<li class="chapter" data-level="6.1.8" data-path="interpretation.html"><a href="interpretation.html#local-explainer---shapley"><i class="fa fa-check"></i><b>6.1.8</b> Local Explainer - Shapley</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="interpretation.html"><a href="interpretation.html#causal-inference-and-machine-learning"><i class="fa fa-check"></i><b>6.2</b> Causal Inference and Machine Learning</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="interpretation.html"><a href="interpretation.html#causalInference"><i class="fa fa-check"></i><b>6.2.1</b> Causal Inference on Static Data</a></li>
<li class="chapter" data-level="6.2.2" data-path="interpretation.html"><a href="interpretation.html#structural-equation-models"><i class="fa fa-check"></i><b>6.2.2</b> Structural Equation Models</a></li>
<li class="chapter" data-level="6.2.3" data-path="interpretation.html"><a href="interpretation.html#automatic-causal-discovery"><i class="fa fa-check"></i><b>6.2.3</b> Automatic Causal Discovery</a></li>
<li class="chapter" data-level="6.2.4" data-path="interpretation.html"><a href="interpretation.html#causal-inference-on-dynamic-data"><i class="fa fa-check"></i><b>6.2.4</b> Causal Inference on Dynamic Data</a></li>
<li class="chapter" data-level="6.2.5" data-path="interpretation.html"><a href="interpretation.html#outlook-for-machine-learning"><i class="fa fa-check"></i><b>6.2.5</b> Outlook for Machine Learning</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="gan.html"><a href="gan.html"><i class="fa fa-check"></i><b>7</b> Generative Modeling and Reinforcement Learning</a>
<ul>
<li class="chapter" data-level="7.1" data-path="gan.html"><a href="gan.html#autoencoder"><i class="fa fa-check"></i><b>7.1</b> Autoencoder</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="gan.html"><a href="gan.html#autoencoder---deep-neural-network-mnist"><i class="fa fa-check"></i><b>7.1.1</b> Autoencoder - Deep Neural Network MNIST</a></li>
<li class="chapter" data-level="7.1.2" data-path="gan.html"><a href="gan.html#autoencoder---mnist-convolutional-neural-networks"><i class="fa fa-check"></i><b>7.1.2</b> Autoencoder - MNIST Convolutional Neural Networks</a></li>
<li class="chapter" data-level="7.1.3" data-path="gan.html"><a href="gan.html#VAE"><i class="fa fa-check"></i><b>7.1.3</b> Variational Autoencoder (VAE)</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="gan.html"><a href="gan.html#GANS"><i class="fa fa-check"></i><b>7.2</b> Generative Adversarial Networks (GANs)</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="gan.html"><a href="gan.html#mnist---generative-adversarial-networks-based-on-deep-neural-networks"><i class="fa fa-check"></i><b>7.2.1</b> MNIST - Generative Adversarial Networks Based on Deep Neural Networks</a></li>
<li class="chapter" data-level="7.2.2" data-path="gan.html"><a href="gan.html#flower---gan"><i class="fa fa-check"></i><b>7.2.2</b> Flower - GAN</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="gan.html"><a href="gan.html#reinforcement-learning"><i class="fa fa-check"></i><b>7.3</b> Reinforcement learning</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="datasets.html"><a href="datasets.html"><i class="fa fa-check"></i><b>8</b> Data sets</a>
<ul>
<li class="chapter" data-level="8.1" data-path="datasets.html"><a href="datasets.html#titanic"><i class="fa fa-check"></i><b>8.1</b> Titanic</a></li>
<li class="chapter" data-level="8.2" data-path="datasets.html"><a href="datasets.html#plant-pollinator-database"><i class="fa fa-check"></i><b>8.2</b> Plant-pollinator Database</a></li>
<li class="chapter" data-level="8.3" data-path="datasets.html"><a href="datasets.html#wine"><i class="fa fa-check"></i><b>8.3</b> Wine</a></li>
<li class="chapter" data-level="8.4" data-path="datasets.html"><a href="datasets.html#nasa"><i class="fa fa-check"></i><b>8.4</b> Nasa</a></li>
<li class="chapter" data-level="8.5" data-path="datasets.html"><a href="datasets.html#flower"><i class="fa fa-check"></i><b>8.5</b> Flower</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning and AI in TensorFlow and R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="deep" class="section level1" number="5">
<h1><span class="header-section-number">5</span> Deep Learning</h1>
<!-- Put this here (right after the first markdown headline) and only here for each document! -->
<script src="./scripts/multipleChoice.js"></script>
<p>In this section, we will discuss both, different (deep) network architectures and different means to regularize and improve those deep architectures.</p>
<div id="network-architectures" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Network Architectures</h2>
<div id="deep-neural-networks-dnns" class="section level3" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Deep Neural Networks (DNNs)</h3>
<p>Deep neural networks are basically the same as simple artificial neural networks, only that they have more hidden layers.</p>
</div>
<div id="convolutional-neural-networks-cnns" class="section level3" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Convolutional Neural Networks (CNNs)</h3>
<p>The main purpose of convolutional neural networks is image recognition. (Sound can be understood as an image as well!)
In a convolutional neural network, we have at least one convolution layer, additional to the normal, fully connected deep neural network layers.</p>
<p>Neurons in a convolution layer are connected only to a small spatially contiguous area of the input layer (<em>receptive field</em>). We use this structure (<em>feature map</em>) to scan the <strong>entire</strong> features / neurons (e.g. picture). Think of the feature map as a <em>kernel</em> or <em>filter</em> (or imagine a sliding window with weighted pixels) that is used to scan the image. As the name is already indicating, this operation is a convolution in mathematics.
The kernel weights are optimized, but we use the same weights across the entire input neurons (<em>shared weights</em>).</p>
<p>The resulting (hidden) convolutional layer after training is called a <em>feature map</em>. You can think of the feature map as a map that shows you where the “shapes” expressed by the kernel appear in the input. One kernel / feature map will not be enough, we typically have many shapes that we want to recognize. Thus, the input layer is typically connected to several feature maps, which can be aggregated and followed by a second layer of feature maps, and so on.</p>
<p>You get one convolution map/layer for each kernel of one convolutional layer.</p>
</div>
<div id="recurrent-neural-networks-rnns" class="section level3" number="5.1.3">
<h3><span class="header-section-number">5.1.3</span> Recurrent Neural Networks (RNNs)</h3>
<p>Recurrent neural networks are used to model sequential data, i.e. a temporal sequence that exhibits temporal dynamic behavior. Here is a good introduction to the topic:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/SEnXr6v2ifU" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<p>The following code snippet shows you many (technical) things you need for building more complex network structures, even with memory cells:</p>
<div class="sourceCode" id="cb674"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb674-1"><a href="deep.html#cb674-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(deepviz)</span>
<span id="cb674-2"><a href="deep.html#cb674-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb674-3"><a href="deep.html#cb674-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb674-4"><a href="deep.html#cb674-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb674-5"><a href="deep.html#cb674-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb674-6"><a href="deep.html#cb674-6" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span>keras<span class="sc">$</span>backend<span class="sc">$</span><span class="fu">clear_session</span>()  <span class="co"># Resets especially layer counter.</span></span>
<span id="cb674-7"><a href="deep.html#cb674-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb674-8"><a href="deep.html#cb674-8" aria-hidden="true" tabindex="-1"></a>inputDimension1 <span class="ot">=</span> 50L</span>
<span id="cb674-9"><a href="deep.html#cb674-9" aria-hidden="true" tabindex="-1"></a>inputDimension2 <span class="ot">=</span> 10L</span>
<span id="cb674-10"><a href="deep.html#cb674-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb674-11"><a href="deep.html#cb674-11" aria-hidden="true" tabindex="-1"></a>input1 <span class="ot">=</span> <span class="fu">layer_input</span>(<span class="at">shape =</span> inputDimension1)</span>
<span id="cb674-12"><a href="deep.html#cb674-12" aria-hidden="true" tabindex="-1"></a>input2 <span class="ot">=</span> <span class="fu">layer_input</span>(<span class="at">shape =</span> inputDimension2)</span>
<span id="cb674-13"><a href="deep.html#cb674-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb674-14"><a href="deep.html#cb674-14" aria-hidden="true" tabindex="-1"></a>modelInput2 <span class="ot">=</span> input2 <span class="sc">%&gt;%</span></span>
<span id="cb674-15"><a href="deep.html#cb674-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="at">rate =</span> <span class="fl">0.5</span>) <span class="sc">%&gt;%</span></span>
<span id="cb674-16"><a href="deep.html#cb674-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> inputDimension2, <span class="at">activation =</span> <span class="st">&quot;gelu&quot;</span>)</span>
<span id="cb674-17"><a href="deep.html#cb674-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb674-18"><a href="deep.html#cb674-18" aria-hidden="true" tabindex="-1"></a>modelMemory <span class="ot">=</span> input1 <span class="sc">%&gt;%</span></span>
<span id="cb674-19"><a href="deep.html#cb674-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_embedding</span>(<span class="at">input_dim =</span> inputDimension1, <span class="at">output_dim =</span> 64L) <span class="sc">%&gt;%</span></span>
<span id="cb674-20"><a href="deep.html#cb674-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_lstm</span>(<span class="at">units =</span> 64L) <span class="sc">%&gt;%</span></span>
<span id="cb674-21"><a href="deep.html#cb674-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="at">rate =</span> <span class="fl">0.5</span>) <span class="sc">%&gt;%</span></span>
<span id="cb674-22"><a href="deep.html#cb674-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 2L, <span class="at">activation =</span> <span class="st">&quot;sigmoid&quot;</span>)</span>
<span id="cb674-23"><a href="deep.html#cb674-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb674-24"><a href="deep.html#cb674-24" aria-hidden="true" tabindex="-1"></a>modelDeep <span class="ot">=</span> input1 <span class="sc">%&gt;%</span></span>
<span id="cb674-25"><a href="deep.html#cb674-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="at">rate =</span> <span class="fl">0.5</span>) <span class="sc">%&gt;%</span></span>
<span id="cb674-26"><a href="deep.html#cb674-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 64L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb674-27"><a href="deep.html#cb674-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="at">rate =</span> <span class="fl">0.3</span>) <span class="sc">%&gt;%</span></span>
<span id="cb674-28"><a href="deep.html#cb674-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 64L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb674-29"><a href="deep.html#cb674-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 64L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb674-30"><a href="deep.html#cb674-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 5L, <span class="at">activation =</span> <span class="st">&quot;sigmoid&quot;</span>)</span>
<span id="cb674-31"><a href="deep.html#cb674-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb674-32"><a href="deep.html#cb674-32" aria-hidden="true" tabindex="-1"></a>modelMain <span class="ot">=</span> <span class="fu">layer_concatenate</span>(<span class="fu">c</span>(modelMemory, modelDeep, modelInput2)) <span class="sc">%&gt;%</span></span>
<span id="cb674-33"><a href="deep.html#cb674-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="at">rate =</span> <span class="fl">0.25</span>) <span class="sc">%&gt;%</span></span>
<span id="cb674-34"><a href="deep.html#cb674-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 64L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb674-35"><a href="deep.html#cb674-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="at">rate =</span> <span class="fl">0.3</span>) <span class="sc">%&gt;%</span></span>
<span id="cb674-36"><a href="deep.html#cb674-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 64L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb674-37"><a href="deep.html#cb674-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 2L, <span class="at">activation =</span> <span class="st">&quot;sigmoid&quot;</span>)</span>
<span id="cb674-38"><a href="deep.html#cb674-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb674-39"><a href="deep.html#cb674-39" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model</span>(</span>
<span id="cb674-40"><a href="deep.html#cb674-40" aria-hidden="true" tabindex="-1"></a>  <span class="at">inputs =</span> <span class="fu">c</span>(input1, input2),</span>
<span id="cb674-41"><a href="deep.html#cb674-41" aria-hidden="true" tabindex="-1"></a>  <span class="at">outputs =</span> <span class="fu">c</span>(modelMain)  <span class="co"># Use the whole modelMain (resp. its output) as output.</span></span>
<span id="cb674-42"><a href="deep.html#cb674-42" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb674-43"><a href="deep.html#cb674-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb674-44"><a href="deep.html#cb674-44" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## Model: &quot;model&quot;
## _________________________________________________________________________________________________________________
##  Layer (type)                        Output Shape             Param #      Connected to                          
## =================================================================================================================
##  input_1 (InputLayer)                [(None, 50)]             0            []                                    
##                                                                                                                  
##  dropout_3 (Dropout)                 (None, 50)               0            [&#39;input_1[0][0]&#39;]                     
##                                                                                                                  
##  dense_5 (Dense)                     (None, 64)               3264         [&#39;dropout_3[0][0]&#39;]                   
##                                                                                                                  
##  embedding (Embedding)               (None, 50, 64)           3200         [&#39;input_1[0][0]&#39;]                     
##                                                                                                                  
##  dropout_2 (Dropout)                 (None, 64)               0            [&#39;dense_5[0][0]&#39;]                     
##                                                                                                                  
##  lstm (LSTM)                         (None, 64)               33024        [&#39;embedding[0][0]&#39;]                   
##                                                                                                                  
##  dense_4 (Dense)                     (None, 64)               4160         [&#39;dropout_2[0][0]&#39;]                   
##                                                                                                                  
##  input_2 (InputLayer)                [(None, 10)]             0            []                                    
##                                                                                                                  
##  dropout_1 (Dropout)                 (None, 64)               0            [&#39;lstm[0][0]&#39;]                        
##                                                                                                                  
##  dense_3 (Dense)                     (None, 64)               4160         [&#39;dense_4[0][0]&#39;]                     
##                                                                                                                  
##  dropout (Dropout)                   (None, 10)               0            [&#39;input_2[0][0]&#39;]                     
##                                                                                                                  
##  dense_1 (Dense)                     (None, 2)                130          [&#39;dropout_1[0][0]&#39;]                   
##                                                                                                                  
##  dense_2 (Dense)                     (None, 5)                325          [&#39;dense_3[0][0]&#39;]                     
##                                                                                                                  
##  dense (Dense)                       (None, 10)               110          [&#39;dropout[0][0]&#39;]                     
##                                                                                                                  
##  concatenate (Concatenate)           (None, 17)               0            [&#39;dense_1[0][0]&#39;,                     
##                                                                             &#39;dense_2[0][0]&#39;,                     
##                                                                             &#39;dense[0][0]&#39;]                       
##                                                                                                                  
##  dropout_5 (Dropout)                 (None, 17)               0            [&#39;concatenate[0][0]&#39;]                 
##                                                                                                                  
##  dense_8 (Dense)                     (None, 64)               1152         [&#39;dropout_5[0][0]&#39;]                   
##                                                                                                                  
##  dropout_4 (Dropout)                 (None, 64)               0            [&#39;dense_8[0][0]&#39;]                     
##                                                                                                                  
##  dense_7 (Dense)                     (None, 64)               4160         [&#39;dropout_4[0][0]&#39;]                   
##                                                                                                                  
##  dense_6 (Dense)                     (None, 2)                130          [&#39;dense_7[0][0]&#39;]                     
##                                                                                                                  
## =================================================================================================================
## Total params: 53,815
## Trainable params: 53,815
## Non-trainable params: 0
## _________________________________________________________________________________________________________________</code></pre>
<div class="sourceCode" id="cb676"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb676-1"><a href="deep.html#cb676-1" aria-hidden="true" tabindex="-1"></a><span class="co"># model %&gt;% plot_model()</span></span></code></pre></div>
</div>
<div id="natural-language-processing-nlp" class="section level3" number="5.1.4">
<h3><span class="header-section-number">5.1.4</span> Natural Language Processing (NLP)</h3>
<p>Natural language processing is actually more of a task than a network structure, but in the area of deep learning for natural language processing, particular network structures are used. The following video should give you an idea about what NLP is about.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/UFtXy0KRxVI" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<p>See also the blog post linked with the Youtube video with accompanying code. Moreover, here is an <a href="https://nlpforhackers.io/keras-intro/" target="_blank" rel="noopener">article</a> that shows how natural language processing works with Keras, however, written in Python. As a challenge, you can take the code and implement it in R.</p>
</div>
</div>
<div id="case-study-dropout-and-early-stopping-in-a-deep-neural-network" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Case Study: Dropout and Early Stopping in a Deep Neural Network</h2>
<p>Regularization in deep neural networks is very important because of the problem of overfitting. Standard regularization from statistics like <span class="math inline">\(L1\)</span> and <span class="math inline">\(L2\)</span> regularization are often fuzzy and require a lot of tuning. There are more stable and robust methods:</p>
<ul>
<li>Early stopping: Early stopping allows us to stop the training when for instance the test loss does not decrease anymore or the validation loss starts increasing.</li>
<li>Dropout: The Dropout layer randomly sets input units to 0 with a frequency of a given rate at each step during training time, which helps prevent overfitting. Dropout is more robust than <span class="math inline">\(L1\)</span> and <span class="math inline">\(L2\)</span>, and tuning of the dropout rate can be beneficial but a rate between <span class="math inline">\(0.2-0.5\)</span> often works quite well.</li>
</ul>
<p><strong>Data preparation</strong></p>
<p>See <a href="fundamental.html#mlr">4.6</a> for explanation about the preprocessing pipeline.</p>
<div class="sourceCode" id="cb677"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb677-1"><a href="deep.html#cb677-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(EcoData)</span>
<span id="cb677-2"><a href="deep.html#cb677-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(nasa)</span>
<span id="cb677-3"><a href="deep.html#cb677-3" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(nasa)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    4687 obs. of  40 variables:
##  $ Neo.Reference.ID            : int  3449084 3702322 3406893 NA 2363305 3017307 2438430 3653917 3519490 2066391 ...
##  $ Name                        : int  NA 3702322 3406893 3082923 2363305 3017307 2438430 3653917 3519490 NA ...
##  $ Absolute.Magnitude          : num  18.7 22.1 24.8 21.6 21.4 18.2 20 21 20.9 16.5 ...
##  $ Est.Dia.in.KM.min.          : num  0.4837 0.1011 0.0291 0.1272 0.1395 ...
##  $ Est.Dia.in.KM.max.          : num  1.0815 0.226 0.0652 0.2845 0.3119 ...
##  $ Est.Dia.in.M.min.           : num  483.7 NA 29.1 127.2 139.5 ...
##  $ Est.Dia.in.M.max.           : num  1081.5 226 65.2 284.5 311.9 ...
##  $ Est.Dia.in.Miles.min.       : num  0.3005 0.0628 NA 0.0791 0.0867 ...
##  $ Est.Dia.in.Miles.max.       : num  0.672 0.1404 0.0405 0.1768 0.1938 ...
##  $ Est.Dia.in.Feet.min.        : num  1586.9 331.5 95.6 417.4 457.7 ...
##  $ Est.Dia.in.Feet.max.        : num  3548 741 214 933 1023 ...
##  $ Close.Approach.Date         : Factor w/ 777 levels &quot;1995-01-01&quot;,&quot;1995-01-08&quot;,..: 511 712 472 239 273 145 428 694 87 732 ...
##  $ Epoch.Date.Close.Approach   : num  NA 1.42e+12 1.21e+12 1.00e+12 1.03e+12 ...
##  $ Relative.Velocity.km.per.sec: num  11.22 13.57 5.75 13.84 4.61 ...
##  $ Relative.Velocity.km.per.hr : num  40404 48867 20718 49821 16583 ...
##  $ Miles.per.hour              : num  25105 30364 12873 30957 10304 ...
##  $ Miss.Dist..Astronomical.    : num  NA 0.0671 0.013 0.0583 0.0381 ...
##  $ Miss.Dist..lunar.           : num  112.7 26.1 NA 22.7 14.8 ...
##  $ Miss.Dist..kilometers.      : num  43348668 10030753 1949933 NA 5694558 ...
##  $ Miss.Dist..miles.           : num  26935614 6232821 1211632 5418692 3538434 ...
##  $ Orbiting.Body               : Factor w/ 1 level &quot;Earth&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ Orbit.ID                    : int  NA 8 12 12 91 NA 24 NA NA 212 ...
##  $ Orbit.Determination.Date    : Factor w/ 2680 levels &quot;2014-06-13 15:20:44&quot;,..: 69 NA 1377 1774 2275 2554 1919 731 1178 2520 ...
##  $ Orbit.Uncertainity          : int  0 8 6 0 0 0 1 1 1 0 ...
##  $ Minimum.Orbit.Intersection  : num  NA 0.05594 0.00553 NA 0.0281 ...
##  $ Jupiter.Tisserand.Invariant : num  5.58 3.61 4.44 5.5 NA ...
##  $ Epoch.Osculation            : num  2457800 2457010 NA 2458000 2458000 ...
##  $ Eccentricity                : num  0.276 0.57 0.344 0.255 0.22 ...
##  $ Semi.Major.Axis             : num  1.1 NA 1.52 1.11 1.24 ...
##  $ Inclination                 : num  20.06 4.39 5.44 23.9 3.5 ...
##  $ Asc.Node.Longitude          : num  29.85 1.42 170.68 356.18 183.34 ...
##  $ Orbital.Period              : num  419 1040 682 427 503 ...
##  $ Perihelion.Distance         : num  0.794 0.864 0.994 0.828 0.965 ...
##  $ Perihelion.Arg              : num  41.8 359.3 350 268.2 179.2 ...
##  $ Aphelion.Dist               : num  1.4 3.15 2.04 1.39 1.51 ...
##  $ Perihelion.Time             : num  2457736 2456941 2457937 NA 2458070 ...
##  $ Mean.Anomaly                : num  55.1 NA NA 297.4 310.5 ...
##  $ Mean.Motion                 : num  0.859 0.346 0.528 0.843 0.716 ...
##  $ Equinox                     : Factor w/ 1 level &quot;J2000&quot;: 1 1 NA 1 1 1 1 1 1 1 ...
##  $ Hazardous                   : int  0 0 0 1 1 0 0 0 1 1 ...</code></pre>
<div class="sourceCode" id="cb679"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb679-1"><a href="deep.html#cb679-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb679-2"><a href="deep.html#cb679-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3)</span>
<span id="cb679-3"><a href="deep.html#cb679-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3pipelines)</span>
<span id="cb679-4"><a href="deep.html#cb679-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb679-5"><a href="deep.html#cb679-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb679-6"><a href="deep.html#cb679-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb679-7"><a href="deep.html#cb679-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb679-8"><a href="deep.html#cb679-8" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> nasa <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>Orbit.Determination.Date,</span>
<span id="cb679-9"><a href="deep.html#cb679-9" aria-hidden="true" tabindex="-1"></a>                       <span class="sc">-</span>Close.Approach.Date, <span class="sc">-</span>Name, <span class="sc">-</span>Neo.Reference.ID)</span>
<span id="cb679-10"><a href="deep.html#cb679-10" aria-hidden="true" tabindex="-1"></a>data<span class="sc">$</span>Hazardous <span class="ot">=</span> <span class="fu">as.factor</span>(data<span class="sc">$</span>Hazardous)</span>
<span id="cb679-11"><a href="deep.html#cb679-11" aria-hidden="true" tabindex="-1"></a>task <span class="ot">=</span> TaskClassif<span class="sc">$</span><span class="fu">new</span>(<span class="at">id =</span> <span class="st">&quot;nasa&quot;</span>, <span class="at">backend =</span> data,</span>
<span id="cb679-12"><a href="deep.html#cb679-12" aria-hidden="true" tabindex="-1"></a>                       <span class="at">target =</span> <span class="st">&quot;Hazardous&quot;</span>, <span class="at">positive =</span> <span class="st">&quot;1&quot;</span>)</span>
<span id="cb679-13"><a href="deep.html#cb679-13" aria-hidden="true" tabindex="-1"></a>preprocessing <span class="ot">=</span> <span class="fu">po</span>(<span class="st">&quot;imputeoor&quot;</span>) <span class="sc">%&gt;&gt;%</span> <span class="fu">po</span>(<span class="st">&quot;scale&quot;</span>) <span class="sc">%&gt;&gt;%</span> <span class="fu">po</span>(<span class="st">&quot;encode&quot;</span>) </span>
<span id="cb679-14"><a href="deep.html#cb679-14" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> preprocessing<span class="sc">$</span><span class="fu">train</span>(task)[[<span class="dv">1</span>]]<span class="sc">$</span><span class="fu">data</span>()</span>
<span id="cb679-15"><a href="deep.html#cb679-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb679-16"><a href="deep.html#cb679-16" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> data[<span class="sc">!</span><span class="fu">is.na</span>(data<span class="sc">$</span>Hazardous),]</span>
<span id="cb679-17"><a href="deep.html#cb679-17" aria-hidden="true" tabindex="-1"></a>submit <span class="ot">=</span> data[<span class="fu">is.na</span>(data<span class="sc">$</span>Hazardous),]</span>
<span id="cb679-18"><a href="deep.html#cb679-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb679-19"><a href="deep.html#cb679-19" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">scale</span>(train <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>Hazardous))</span>
<span id="cb679-20"><a href="deep.html#cb679-20" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span> train <span class="sc">%&gt;%</span> <span class="fu">select</span>(Hazardous)</span>
<span id="cb679-21"><a href="deep.html#cb679-21" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span> <span class="fu">to_categorical</span>(<span class="fu">as.matrix</span>(Y), <span class="dv">2</span>)</span></code></pre></div>
<p><strong>Early stopping</strong></p>
<div class="sourceCode" id="cb680"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb680-1"><a href="deep.html#cb680-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb680-2"><a href="deep.html#cb680-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb680-3"><a href="deep.html#cb680-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb680-4"><a href="deep.html#cb680-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb680-5"><a href="deep.html#cb680-5" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb680-6"><a href="deep.html#cb680-6" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb680-7"><a href="deep.html#cb680-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 50L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">input_shape =</span> <span class="fu">ncol</span>(X)) <span class="sc">%&gt;%</span></span>
<span id="cb680-8"><a href="deep.html#cb680-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 50L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb680-9"><a href="deep.html#cb680-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 50L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb680-10"><a href="deep.html#cb680-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="fu">ncol</span>(Y), <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>) </span>
<span id="cb680-11"><a href="deep.html#cb680-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb680-12"><a href="deep.html#cb680-12" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb680-13"><a href="deep.html#cb680-13" aria-hidden="true" tabindex="-1"></a>  keras<span class="sc">::</span><span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb680-14"><a href="deep.html#cb680-14" aria-hidden="true" tabindex="-1"></a>                 keras<span class="sc">::</span><span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.001</span>))</span>
<span id="cb680-15"><a href="deep.html#cb680-15" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## Model: &quot;sequential_1&quot;
## _____________________________________________________________________
##  Layer (type)                  Output Shape               Param #    
## =====================================================================
##  dense_16 (Dense)              (None, 50)                 1900       
##                                                                      
##  dense_15 (Dense)              (None, 50)                 2550       
##                                                                      
##  dense_14 (Dense)              (None, 50)                 2550       
##                                                                      
##  dense_13 (Dense)              (None, 2)                  102        
##                                                                      
## =====================================================================
## Total params: 7,102
## Trainable params: 7,102
## Non-trainable params: 0
## _____________________________________________________________________</code></pre>
<div class="sourceCode" id="cb682"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb682-1"><a href="deep.html#cb682-1" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb682-2"><a href="deep.html#cb682-2" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb682-3"><a href="deep.html#cb682-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, </span>
<span id="cb682-4"><a href="deep.html#cb682-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">epochs =</span> 50L, <span class="at">batch_size =</span> 20L, </span>
<span id="cb682-5"><a href="deep.html#cb682-5" aria-hidden="true" tabindex="-1"></a>        <span class="at">shuffle =</span> <span class="cn">TRUE</span>, <span class="at">validation_split =</span> <span class="fl">0.4</span>)</span>
<span id="cb682-6"><a href="deep.html#cb682-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="_main_files/figure-html/chunk_chapter5_4-1.png" width="672" /></p>
<p>The validation loss first decreases but then starts increasing again, can you explain this behavior?
<span class="math inline">\(\rightarrow\)</span> Overfitting!</p>
<p>Let’s try an <span class="math inline">\(L1+L2\)</span> regularization:</p>
<div class="sourceCode" id="cb684"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb684-1"><a href="deep.html#cb684-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb684-2"><a href="deep.html#cb684-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb684-3"><a href="deep.html#cb684-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb684-4"><a href="deep.html#cb684-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb684-5"><a href="deep.html#cb684-5" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb684-6"><a href="deep.html#cb684-6" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb684-7"><a href="deep.html#cb684-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 50L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">input_shape =</span> <span class="fu">ncol</span>(X),</span>
<span id="cb684-8"><a href="deep.html#cb684-8" aria-hidden="true" tabindex="-1"></a>              <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1_l2</span>(<span class="fl">0.001</span>, <span class="fl">0.001</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb684-9"><a href="deep.html#cb684-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 50L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>,</span>
<span id="cb684-10"><a href="deep.html#cb684-10" aria-hidden="true" tabindex="-1"></a>              <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1_l2</span>(<span class="fl">0.001</span>, <span class="fl">0.001</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb684-11"><a href="deep.html#cb684-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 50L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>,</span>
<span id="cb684-12"><a href="deep.html#cb684-12" aria-hidden="true" tabindex="-1"></a>              <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1_l2</span>(<span class="fl">0.001</span>, <span class="fl">0.001</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb684-13"><a href="deep.html#cb684-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="fu">ncol</span>(Y), <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>,</span>
<span id="cb684-14"><a href="deep.html#cb684-14" aria-hidden="true" tabindex="-1"></a>              <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1_l2</span>(<span class="fl">0.001</span>, <span class="fl">0.001</span>)) </span>
<span id="cb684-15"><a href="deep.html#cb684-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb684-16"><a href="deep.html#cb684-16" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb684-17"><a href="deep.html#cb684-17" aria-hidden="true" tabindex="-1"></a>  keras<span class="sc">::</span><span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb684-18"><a href="deep.html#cb684-18" aria-hidden="true" tabindex="-1"></a>                 keras<span class="sc">::</span><span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.001</span>))</span>
<span id="cb684-19"><a href="deep.html#cb684-19" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## Model: &quot;sequential_4&quot;
## _____________________________________________________________________
##  Layer (type)                  Output Shape               Param #    
## =====================================================================
##  dense_28 (Dense)              (None, 50)                 1900       
##                                                                      
##  dense_27 (Dense)              (None, 50)                 2550       
##                                                                      
##  dense_26 (Dense)              (None, 50)                 2550       
##                                                                      
##  dense_25 (Dense)              (None, 2)                  102        
##                                                                      
## =====================================================================
## Total params: 7,102
## Trainable params: 7,102
## Non-trainable params: 0
## _____________________________________________________________________</code></pre>
<div class="sourceCode" id="cb686"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb686-1"><a href="deep.html#cb686-1" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb686-2"><a href="deep.html#cb686-2" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb686-3"><a href="deep.html#cb686-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, </span>
<span id="cb686-4"><a href="deep.html#cb686-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">epochs =</span> 100L, <span class="at">batch_size =</span> 20L, </span>
<span id="cb686-5"><a href="deep.html#cb686-5" aria-hidden="true" tabindex="-1"></a>        <span class="at">shuffle =</span> <span class="cn">TRUE</span>, <span class="at">validation_split =</span> <span class="fl">0.4</span>)</span>
<span id="cb686-6"><a href="deep.html#cb686-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="_main_files/figure-html/chunk_chapter5_5-1.png" width="672" /></p>
<p>Better, but the validation loss still starts increasing after 40 epochs. We can use early stopping to end the training before the validation loss starts increasing again!</p>
<div class="sourceCode" id="cb688"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb688-1"><a href="deep.html#cb688-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb688-2"><a href="deep.html#cb688-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb688-3"><a href="deep.html#cb688-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb688-4"><a href="deep.html#cb688-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb688-5"><a href="deep.html#cb688-5" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb688-6"><a href="deep.html#cb688-6" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb688-7"><a href="deep.html#cb688-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 50L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">input_shape =</span> <span class="fu">ncol</span>(X),</span>
<span id="cb688-8"><a href="deep.html#cb688-8" aria-hidden="true" tabindex="-1"></a>              <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1_l2</span>( <span class="fl">0.001</span>, <span class="fl">0.001</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb688-9"><a href="deep.html#cb688-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 50L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>,</span>
<span id="cb688-10"><a href="deep.html#cb688-10" aria-hidden="true" tabindex="-1"></a>              <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1_l2</span>(<span class="fl">0.001</span>, <span class="fl">0.001</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb688-11"><a href="deep.html#cb688-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 50L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>,</span>
<span id="cb688-12"><a href="deep.html#cb688-12" aria-hidden="true" tabindex="-1"></a>              <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1_l2</span>(<span class="fl">0.001</span>, <span class="fl">0.001</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb688-13"><a href="deep.html#cb688-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="fu">ncol</span>(Y), <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>,</span>
<span id="cb688-14"><a href="deep.html#cb688-14" aria-hidden="true" tabindex="-1"></a>              <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1_l2</span>(<span class="fl">0.001</span>, <span class="fl">0.001</span>)) </span>
<span id="cb688-15"><a href="deep.html#cb688-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb688-16"><a href="deep.html#cb688-16" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb688-17"><a href="deep.html#cb688-17" aria-hidden="true" tabindex="-1"></a>  keras<span class="sc">::</span><span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb688-18"><a href="deep.html#cb688-18" aria-hidden="true" tabindex="-1"></a>                 keras<span class="sc">::</span><span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.001</span>))</span>
<span id="cb688-19"><a href="deep.html#cb688-19" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## Model: &quot;sequential_6&quot;
## ____________________________________________________________________________________________________________________
##  Layer (type)                                       Output Shape                                  Param #           
## ====================================================================================================================
##  dense_36 (Dense)                                   (None, 50)                                    1900              
##                                                                                                                     
##  dense_35 (Dense)                                   (None, 50)                                    2550              
##                                                                                                                     
##  dense_34 (Dense)                                   (None, 50)                                    2550              
##                                                                                                                     
##  dense_33 (Dense)                                   (None, 2)                                     102               
##                                                                                                                     
## ====================================================================================================================
## Total params: 7,102
## Trainable params: 7,102
## Non-trainable params: 0
## ____________________________________________________________________________________________________________________</code></pre>
<div class="sourceCode" id="cb690"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb690-1"><a href="deep.html#cb690-1" aria-hidden="true" tabindex="-1"></a>early <span class="ot">=</span> keras<span class="sc">::</span><span class="fu">callback_early_stopping</span>(<span class="at">patience =</span> 5L)</span>
<span id="cb690-2"><a href="deep.html#cb690-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb690-3"><a href="deep.html#cb690-3" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb690-4"><a href="deep.html#cb690-4" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb690-5"><a href="deep.html#cb690-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, </span>
<span id="cb690-6"><a href="deep.html#cb690-6" aria-hidden="true" tabindex="-1"></a>        <span class="at">epochs =</span> 100L, <span class="at">batch_size =</span> 20L, </span>
<span id="cb690-7"><a href="deep.html#cb690-7" aria-hidden="true" tabindex="-1"></a>        <span class="at">shuffle =</span> <span class="cn">TRUE</span>, <span class="at">validation_split =</span> <span class="fl">0.4</span>, <span class="at">callbacks =</span> <span class="fu">c</span>(early))</span>
<span id="cb690-8"><a href="deep.html#cb690-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb690-9"><a href="deep.html#cb690-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="_main_files/figure-html/chunk_chapter5_6-1.png" width="672" /></p>
<p>Patience is the number of epochs to wait before aborting the training.</p>
<p><strong>Dropout - another type of regularization</strong></p>
<p><span class="citation"><a href="#ref-dropout" role="doc-biblioref">Srivastava et al.</a> (<a href="#ref-dropout" role="doc-biblioref">2014</a>)</span> suggests a dropout rate of 50% for internal hidden layers and 20% for the input layer. One advantage of dropout is that the training is more independent of the number of epochs i.e. the validation loss usually doesn’t start to increase after several epochs.</p>
<div class="sourceCode" id="cb692"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb692-1"><a href="deep.html#cb692-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb692-2"><a href="deep.html#cb692-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb692-3"><a href="deep.html#cb692-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb692-4"><a href="deep.html#cb692-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb692-5"><a href="deep.html#cb692-5" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb692-6"><a href="deep.html#cb692-6" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb692-7"><a href="deep.html#cb692-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="fl">0.2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb692-8"><a href="deep.html#cb692-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 50L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">input_shape =</span> <span class="fu">ncol</span>(X)) <span class="sc">%&gt;%</span></span>
<span id="cb692-9"><a href="deep.html#cb692-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="fl">0.5</span>) <span class="sc">%&gt;%</span></span>
<span id="cb692-10"><a href="deep.html#cb692-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 50L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb692-11"><a href="deep.html#cb692-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="fl">0.5</span>) <span class="sc">%&gt;%</span></span>
<span id="cb692-12"><a href="deep.html#cb692-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 50L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb692-13"><a href="deep.html#cb692-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="fl">0.5</span>) <span class="sc">%&gt;%</span></span>
<span id="cb692-14"><a href="deep.html#cb692-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="fu">ncol</span>(Y), <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>) </span>
<span id="cb692-15"><a href="deep.html#cb692-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb692-16"><a href="deep.html#cb692-16" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb692-17"><a href="deep.html#cb692-17" aria-hidden="true" tabindex="-1"></a>  keras<span class="sc">::</span><span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb692-18"><a href="deep.html#cb692-18" aria-hidden="true" tabindex="-1"></a>                 keras<span class="sc">::</span><span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.001</span>))</span>
<span id="cb692-19"><a href="deep.html#cb692-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb692-20"><a href="deep.html#cb692-20" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb692-21"><a href="deep.html#cb692-21" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb692-22"><a href="deep.html#cb692-22" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, </span>
<span id="cb692-23"><a href="deep.html#cb692-23" aria-hidden="true" tabindex="-1"></a>        <span class="at">epochs =</span> 100L, <span class="at">batch_size =</span> 20L, </span>
<span id="cb692-24"><a href="deep.html#cb692-24" aria-hidden="true" tabindex="-1"></a>        <span class="at">shuffle =</span> <span class="cn">TRUE</span>, <span class="at">validation_split =</span> <span class="fl">0.4</span>)</span>
<span id="cb692-25"><a href="deep.html#cb692-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb692-26"><a href="deep.html#cb692-26" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="_main_files/figure-html/chunk_chapter5_7-1.png" width="672" /></p>
<p>Of course, you can still combine early stopping and dropout, which is normally a good idea since it improves training efficiency (e.g. you could start with 1000 epochs and you know training will be aborted if it doesn’t improve anymore).</p>
<details>
<summary>
<strong><span style="color: #CC2FAA;">Torch</span></strong>
</summary>
<p>
<p>Dropout and early stopping with Torch:</p>
<div class="sourceCode" id="cb694"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb694-1"><a href="deep.html#cb694-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb694-2"><a href="deep.html#cb694-2" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_manual_seed</span>(321L)</span>
<span id="cb694-3"><a href="deep.html#cb694-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb694-4"><a href="deep.html#cb694-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb694-5"><a href="deep.html#cb694-5" aria-hidden="true" tabindex="-1"></a>model_torch <span class="ot">=</span> <span class="fu">nn_sequential</span>(</span>
<span id="cb694-6"><a href="deep.html#cb694-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_dropout</span>(<span class="fl">0.2</span>),</span>
<span id="cb694-7"><a href="deep.html#cb694-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_linear</span>(<span class="fu">ncol</span>(X), 50L),</span>
<span id="cb694-8"><a href="deep.html#cb694-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_relu</span>(),</span>
<span id="cb694-9"><a href="deep.html#cb694-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_dropout</span>(<span class="fl">0.5</span>),</span>
<span id="cb694-10"><a href="deep.html#cb694-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_linear</span>(50L, 50L),</span>
<span id="cb694-11"><a href="deep.html#cb694-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_relu</span>(), </span>
<span id="cb694-12"><a href="deep.html#cb694-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_dropout</span>(<span class="fl">0.5</span>),</span>
<span id="cb694-13"><a href="deep.html#cb694-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_linear</span>(50L, 50L),</span>
<span id="cb694-14"><a href="deep.html#cb694-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_relu</span>(), </span>
<span id="cb694-15"><a href="deep.html#cb694-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_dropout</span>(<span class="fl">0.5</span>),</span>
<span id="cb694-16"><a href="deep.html#cb694-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_linear</span>(50L, 2L)</span>
<span id="cb694-17"><a href="deep.html#cb694-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb694-18"><a href="deep.html#cb694-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb694-19"><a href="deep.html#cb694-19" aria-hidden="true" tabindex="-1"></a>YT <span class="ot">=</span> <span class="fu">apply</span>(Y, <span class="dv">1</span>, which.max)</span>
<span id="cb694-20"><a href="deep.html#cb694-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb694-21"><a href="deep.html#cb694-21" aria-hidden="true" tabindex="-1"></a>dataset_nasa <span class="ot">=</span> <span class="fu">dataset</span>(</span>
<span id="cb694-22"><a href="deep.html#cb694-22" aria-hidden="true" tabindex="-1"></a>  <span class="at">name =</span> <span class="st">&quot;nasa&quot;</span>,</span>
<span id="cb694-23"><a href="deep.html#cb694-23" aria-hidden="true" tabindex="-1"></a>  <span class="at">initialize =</span> <span class="cf">function</span>(nasa){</span>
<span id="cb694-24"><a href="deep.html#cb694-24" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>X <span class="ot">=</span> nasa<span class="sc">$</span>X</span>
<span id="cb694-25"><a href="deep.html#cb694-25" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>Y <span class="ot">=</span> nasa<span class="sc">$</span>Y</span>
<span id="cb694-26"><a href="deep.html#cb694-26" aria-hidden="true" tabindex="-1"></a>  },</span>
<span id="cb694-27"><a href="deep.html#cb694-27" aria-hidden="true" tabindex="-1"></a>  <span class="at">.getitem =</span> <span class="cf">function</span>(i){</span>
<span id="cb694-28"><a href="deep.html#cb694-28" aria-hidden="true" tabindex="-1"></a>    X <span class="ot">=</span> self<span class="sc">$</span>X[i,,drop <span class="ot">=</span> <span class="cn">FALSE</span>] <span class="sc">%&gt;%</span> <span class="fu">torch_tensor</span>()</span>
<span id="cb694-29"><a href="deep.html#cb694-29" aria-hidden="true" tabindex="-1"></a>    Y <span class="ot">=</span> self<span class="sc">$</span>Y[i] <span class="sc">%&gt;%</span> <span class="fu">torch_tensor</span>()</span>
<span id="cb694-30"><a href="deep.html#cb694-30" aria-hidden="true" tabindex="-1"></a>    <span class="fu">list</span>(X, Y)</span>
<span id="cb694-31"><a href="deep.html#cb694-31" aria-hidden="true" tabindex="-1"></a>  },</span>
<span id="cb694-32"><a href="deep.html#cb694-32" aria-hidden="true" tabindex="-1"></a>  <span class="at">.length =</span> <span class="cf">function</span>(){</span>
<span id="cb694-33"><a href="deep.html#cb694-33" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nrow</span>(self<span class="sc">$</span>X)</span>
<span id="cb694-34"><a href="deep.html#cb694-34" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb694-35"><a href="deep.html#cb694-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb694-36"><a href="deep.html#cb694-36" aria-hidden="true" tabindex="-1"></a>train_dl <span class="ot">=</span> <span class="fu">dataloader</span>(<span class="fu">dataset_nasa</span>(<span class="fu">list</span>(<span class="at">X =</span> X[<span class="dv">1</span><span class="sc">:</span><span class="dv">400</span>,], <span class="at">Y =</span> YT[<span class="dv">1</span><span class="sc">:</span><span class="dv">400</span>])), </span>
<span id="cb694-37"><a href="deep.html#cb694-37" aria-hidden="true" tabindex="-1"></a>                      <span class="at">batch_size =</span> <span class="dv">32</span>, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb694-38"><a href="deep.html#cb694-38" aria-hidden="true" tabindex="-1"></a>test_dl <span class="ot">=</span> <span class="fu">dataloader</span>(<span class="fu">dataset_nasa</span>(<span class="fu">list</span>(<span class="at">X =</span> X[<span class="dv">101</span><span class="sc">:</span><span class="dv">500</span>,], <span class="at">Y =</span> YT[<span class="dv">101</span><span class="sc">:</span><span class="dv">500</span>])), </span>
<span id="cb694-39"><a href="deep.html#cb694-39" aria-hidden="true" tabindex="-1"></a>                      <span class="at">batch_size =</span> <span class="dv">32</span>)</span>
<span id="cb694-40"><a href="deep.html#cb694-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb694-41"><a href="deep.html#cb694-41" aria-hidden="true" tabindex="-1"></a>model_torch<span class="sc">$</span><span class="fu">train</span>()</span>
<span id="cb694-42"><a href="deep.html#cb694-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb694-43"><a href="deep.html#cb694-43" aria-hidden="true" tabindex="-1"></a>opt <span class="ot">=</span> <span class="fu">optim_adam</span>(model_torch<span class="sc">$</span>parameters, <span class="fl">0.01</span>)</span>
<span id="cb694-44"><a href="deep.html#cb694-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb694-45"><a href="deep.html#cb694-45" aria-hidden="true" tabindex="-1"></a>train_losses <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb694-46"><a href="deep.html#cb694-46" aria-hidden="true" tabindex="-1"></a>test_losses <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb694-47"><a href="deep.html#cb694-47" aria-hidden="true" tabindex="-1"></a>early_epoch <span class="ot">=</span> <span class="dv">0</span></span>
<span id="cb694-48"><a href="deep.html#cb694-48" aria-hidden="true" tabindex="-1"></a>min_loss <span class="ot">=</span> <span class="cn">Inf</span></span>
<span id="cb694-49"><a href="deep.html#cb694-49" aria-hidden="true" tabindex="-1"></a>patience <span class="ot">=</span> <span class="dv">5</span></span>
<span id="cb694-50"><a href="deep.html#cb694-50" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(epoch <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">50</span>){</span>
<span id="cb694-51"><a href="deep.html#cb694-51" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(early_epoch <span class="sc">&gt;=</span> patience){ <span class="cf">break</span> }</span>
<span id="cb694-52"><a href="deep.html#cb694-52" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb694-53"><a href="deep.html#cb694-53" aria-hidden="true" tabindex="-1"></a>  train_loss <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb694-54"><a href="deep.html#cb694-54" aria-hidden="true" tabindex="-1"></a>  test_loss <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb694-55"><a href="deep.html#cb694-55" aria-hidden="true" tabindex="-1"></a>  coro<span class="sc">::</span><span class="fu">loop</span>(</span>
<span id="cb694-56"><a href="deep.html#cb694-56" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(batch <span class="cf">in</span> train_dl){</span>
<span id="cb694-57"><a href="deep.html#cb694-57" aria-hidden="true" tabindex="-1"></a>      opt<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb694-58"><a href="deep.html#cb694-58" aria-hidden="true" tabindex="-1"></a>      pred <span class="ot">=</span> <span class="fu">model_torch</span>(batch[[<span class="dv">1</span>]]<span class="sc">$</span><span class="fu">squeeze</span>())</span>
<span id="cb694-59"><a href="deep.html#cb694-59" aria-hidden="true" tabindex="-1"></a>      loss <span class="ot">=</span> <span class="fu">nnf_cross_entropy</span>(pred, batch[[<span class="dv">2</span>]]<span class="sc">$</span><span class="fu">squeeze</span>(), <span class="at">reduction =</span> <span class="st">&quot;mean&quot;</span>)</span>
<span id="cb694-60"><a href="deep.html#cb694-60" aria-hidden="true" tabindex="-1"></a>      loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb694-61"><a href="deep.html#cb694-61" aria-hidden="true" tabindex="-1"></a>      opt<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb694-62"><a href="deep.html#cb694-62" aria-hidden="true" tabindex="-1"></a>      train_loss <span class="ot">=</span> <span class="fu">c</span>(train_loss, loss<span class="sc">$</span><span class="fu">item</span>())</span>
<span id="cb694-63"><a href="deep.html#cb694-63" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb694-64"><a href="deep.html#cb694-64" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb694-65"><a href="deep.html#cb694-65" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb694-66"><a href="deep.html#cb694-66" aria-hidden="true" tabindex="-1"></a>  coro<span class="sc">::</span><span class="fu">loop</span>(</span>
<span id="cb694-67"><a href="deep.html#cb694-67" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(batch <span class="cf">in</span> test_dl){</span>
<span id="cb694-68"><a href="deep.html#cb694-68" aria-hidden="true" tabindex="-1"></a>      pred <span class="ot">=</span> <span class="fu">model_torch</span>(batch[[<span class="dv">1</span>]]<span class="sc">$</span><span class="fu">squeeze</span>())</span>
<span id="cb694-69"><a href="deep.html#cb694-69" aria-hidden="true" tabindex="-1"></a>      loss <span class="ot">=</span> <span class="fu">nnf_cross_entropy</span>(pred, batch[[<span class="dv">2</span>]]<span class="sc">$</span><span class="fu">squeeze</span>(), <span class="at">reduction =</span> <span class="st">&quot;mean&quot;</span>)</span>
<span id="cb694-70"><a href="deep.html#cb694-70" aria-hidden="true" tabindex="-1"></a>      test_loss <span class="ot">=</span> <span class="fu">c</span>(test_loss, loss<span class="sc">$</span><span class="fu">item</span>())</span>
<span id="cb694-71"><a href="deep.html#cb694-71" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb694-72"><a href="deep.html#cb694-72" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb694-73"><a href="deep.html#cb694-73" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb694-74"><a href="deep.html#cb694-74" aria-hidden="true" tabindex="-1"></a>  <span class="do">### Early stopping </span><span class="al">###</span></span>
<span id="cb694-75"><a href="deep.html#cb694-75" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="fu">mean</span>(test_loss) <span class="sc">&lt;</span> min_loss){</span>
<span id="cb694-76"><a href="deep.html#cb694-76" aria-hidden="true" tabindex="-1"></a>    min_loss <span class="ot">=</span> <span class="fu">mean</span>(test_loss)</span>
<span id="cb694-77"><a href="deep.html#cb694-77" aria-hidden="true" tabindex="-1"></a>    early_epoch <span class="ot">=</span> <span class="dv">0</span></span>
<span id="cb694-78"><a href="deep.html#cb694-78" aria-hidden="true" tabindex="-1"></a>  } <span class="cf">else</span> {</span>
<span id="cb694-79"><a href="deep.html#cb694-79" aria-hidden="true" tabindex="-1"></a>    early_epoch <span class="ot">=</span> early_epoch <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb694-80"><a href="deep.html#cb694-80" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb694-81"><a href="deep.html#cb694-81" aria-hidden="true" tabindex="-1"></a>  <span class="do">###</span></span>
<span id="cb694-82"><a href="deep.html#cb694-82" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb694-83"><a href="deep.html#cb694-83" aria-hidden="true" tabindex="-1"></a>  train_losses <span class="ot">=</span> <span class="fu">c</span>(train_losses, <span class="fu">mean</span>(train_loss))</span>
<span id="cb694-84"><a href="deep.html#cb694-84" aria-hidden="true" tabindex="-1"></a>  test_losses <span class="ot">=</span> <span class="fu">c</span>(test_losses, <span class="fu">mean</span>(test_loss))</span>
<span id="cb694-85"><a href="deep.html#cb694-85" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">&quot;Loss at epoch %d: %3f</span><span class="sc">\n</span><span class="st">&quot;</span>, epoch, <span class="fu">mean</span>(train_loss)))</span>
<span id="cb694-86"><a href="deep.html#cb694-86" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<pre><code>## Loss at epoch 1: 0.557363
## Loss at epoch 2: 0.478059
## Loss at epoch 3: 0.454506
## Loss at epoch 4: 0.469278
## Loss at epoch 5: 0.414451
## Loss at epoch 6: 0.420797
## Loss at epoch 7: 0.429624
## Loss at epoch 8: 0.439022
## Loss at epoch 9: 0.418324
## Loss at epoch 10: 0.398850
## Loss at epoch 11: 0.420840
## Loss at epoch 12: 0.412696
## Loss at epoch 13: 0.397618
## Loss at epoch 14: 0.428140
## Loss at epoch 15: 0.368084
## Loss at epoch 16: 0.394033</code></pre>
<div class="sourceCode" id="cb696"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb696-1"><a href="deep.html#cb696-1" aria-hidden="true" tabindex="-1"></a><span class="fu">matplot</span>(<span class="fu">cbind</span>(train_losses, test_losses), <span class="at">type =</span> <span class="st">&quot;o&quot;</span>, <span class="at">pch =</span> <span class="fu">c</span>(<span class="dv">15</span>, <span class="dv">16</span>),</span>
<span id="cb696-2"><a href="deep.html#cb696-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;darkblue&quot;</span>, <span class="st">&quot;darkred&quot;</span>), <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">xlab =</span> <span class="st">&quot;Epoch&quot;</span>,</span>
<span id="cb696-3"><a href="deep.html#cb696-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">ylab =</span> <span class="st">&quot;Loss&quot;</span>, <span class="at">las =</span> <span class="dv">1</span>)</span>
<span id="cb696-4"><a href="deep.html#cb696-4" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="at">bty =</span> <span class="st">&quot;n&quot;</span>, <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;darkblue&quot;</span>, <span class="st">&quot;darkred&quot;</span>),</span>
<span id="cb696-5"><a href="deep.html#cb696-5" aria-hidden="true" tabindex="-1"></a>       <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">pch =</span> <span class="fu">c</span>(<span class="dv">15</span>, <span class="dv">16</span>), <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">&quot;Train loss&quot;</span>, <span class="st">&quot;Val loss&quot;</span>) )</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter5_8-1.png" width="672" /></p>
</p>
</details>
<p><br/></p>
  <hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<p>In this section, we will go through tuning a “deep” neural network, using the NASA data set from kaggle (available via EcoData, see data description via help). You can start immediately, or get inspiration by reading section above (“Case study: dropout and early stopping in a deep neural network”).</p>
<p>A basic network for this problem follows:</p>
<div class="sourceCode" id="cb697"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb697-1"><a href="deep.html#cb697-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb697-2"><a href="deep.html#cb697-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb697-3"><a href="deep.html#cb697-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb697-4"><a href="deep.html#cb697-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(missRanger)</span>
<span id="cb697-5"><a href="deep.html#cb697-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(Metrics)</span>
<span id="cb697-6"><a href="deep.html#cb697-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(EcoData)</span>
<span id="cb697-7"><a href="deep.html#cb697-7" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb697-8"><a href="deep.html#cb697-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb697-9"><a href="deep.html#cb697-9" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;nasa&quot;</span>)</span>
<span id="cb697-10"><a href="deep.html#cb697-10" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> nasa</span>
<span id="cb697-11"><a href="deep.html#cb697-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb697-12"><a href="deep.html#cb697-12" aria-hidden="true" tabindex="-1"></a>data<span class="sc">$</span>subset <span class="ot">=</span> <span class="fu">ifelse</span>(<span class="fu">is.na</span>(data<span class="sc">$</span>Hazardous), <span class="st">&quot;test&quot;</span>, <span class="st">&quot;train&quot;</span>)</span>
<span id="cb697-13"><a href="deep.html#cb697-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb697-14"><a href="deep.html#cb697-14" aria-hidden="true" tabindex="-1"></a><span class="do">## Explore and clean data.</span></span>
<span id="cb697-15"><a href="deep.html#cb697-15" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(data)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    4687 obs. of  41 variables:
##  $ Neo.Reference.ID            : int  3449084 3702322 3406893 NA 2363305 3017307 2438430 3653917 3519490 2066391 ...
##  $ Name                        : int  NA 3702322 3406893 3082923 2363305 3017307 2438430 3653917 3519490 NA ...
##  $ Absolute.Magnitude          : num  18.7 22.1 24.8 21.6 21.4 18.2 20 21 20.9 16.5 ...
##  $ Est.Dia.in.KM.min.          : num  0.4837 0.1011 0.0291 0.1272 0.1395 ...
##  $ Est.Dia.in.KM.max.          : num  1.0815 0.226 0.0652 0.2845 0.3119 ...
##  $ Est.Dia.in.M.min.           : num  483.7 NA 29.1 127.2 139.5 ...
##  $ Est.Dia.in.M.max.           : num  1081.5 226 65.2 284.5 311.9 ...
##  $ Est.Dia.in.Miles.min.       : num  0.3005 0.0628 NA 0.0791 0.0867 ...
##  $ Est.Dia.in.Miles.max.       : num  0.672 0.1404 0.0405 0.1768 0.1938 ...
##  $ Est.Dia.in.Feet.min.        : num  1586.9 331.5 95.6 417.4 457.7 ...
##  $ Est.Dia.in.Feet.max.        : num  3548 741 214 933 1023 ...
##  $ Close.Approach.Date         : Factor w/ 777 levels &quot;1995-01-01&quot;,&quot;1995-01-08&quot;,..: 511 712 472 239 273 145 428 694 87 732 ...
##  $ Epoch.Date.Close.Approach   : num  NA 1.42e+12 1.21e+12 1.00e+12 1.03e+12 ...
##  $ Relative.Velocity.km.per.sec: num  11.22 13.57 5.75 13.84 4.61 ...
##  $ Relative.Velocity.km.per.hr : num  40404 48867 20718 49821 16583 ...
##  $ Miles.per.hour              : num  25105 30364 12873 30957 10304 ...
##  $ Miss.Dist..Astronomical.    : num  NA 0.0671 0.013 0.0583 0.0381 ...
##  $ Miss.Dist..lunar.           : num  112.7 26.1 NA 22.7 14.8 ...
##  $ Miss.Dist..kilometers.      : num  43348668 10030753 1949933 NA 5694558 ...
##  $ Miss.Dist..miles.           : num  26935614 6232821 1211632 5418692 3538434 ...
##  $ Orbiting.Body               : Factor w/ 1 level &quot;Earth&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ Orbit.ID                    : int  NA 8 12 12 91 NA 24 NA NA 212 ...
##  $ Orbit.Determination.Date    : Factor w/ 2680 levels &quot;2014-06-13 15:20:44&quot;,..: 69 NA 1377 1774 2275 2554 1919 731 1178 2520 ...
##  $ Orbit.Uncertainity          : int  0 8 6 0 0 0 1 1 1 0 ...
##  $ Minimum.Orbit.Intersection  : num  NA 0.05594 0.00553 NA 0.0281 ...
##  $ Jupiter.Tisserand.Invariant : num  5.58 3.61 4.44 5.5 NA ...
##  $ Epoch.Osculation            : num  2457800 2457010 NA 2458000 2458000 ...
##  $ Eccentricity                : num  0.276 0.57 0.344 0.255 0.22 ...
##  $ Semi.Major.Axis             : num  1.1 NA 1.52 1.11 1.24 ...
##  $ Inclination                 : num  20.06 4.39 5.44 23.9 3.5 ...
##  $ Asc.Node.Longitude          : num  29.85 1.42 170.68 356.18 183.34 ...
##  $ Orbital.Period              : num  419 1040 682 427 503 ...
##  $ Perihelion.Distance         : num  0.794 0.864 0.994 0.828 0.965 ...
##  $ Perihelion.Arg              : num  41.8 359.3 350 268.2 179.2 ...
##  $ Aphelion.Dist               : num  1.4 3.15 2.04 1.39 1.51 ...
##  $ Perihelion.Time             : num  2457736 2456941 2457937 NA 2458070 ...
##  $ Mean.Anomaly                : num  55.1 NA NA 297.4 310.5 ...
##  $ Mean.Motion                 : num  0.859 0.346 0.528 0.843 0.716 ...
##  $ Equinox                     : Factor w/ 1 level &quot;J2000&quot;: 1 1 NA 1 1 1 1 1 1 1 ...
##  $ Hazardous                   : int  0 0 0 1 1 0 0 0 1 1 ...
##  $ subset                      : chr  &quot;train&quot; &quot;train&quot; &quot;train&quot; &quot;train&quot; ...</code></pre>
<div class="sourceCode" id="cb699"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb699-1"><a href="deep.html#cb699-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(data)</span></code></pre></div>
<pre><code>##  Neo.Reference.ID       Name         Absolute.Magnitude Est.Dia.in.KM.min. Est.Dia.in.KM.max. Est.Dia.in.M.min.  
##  Min.   :2000433   Min.   :2000433   Min.   :11.16      Min.   : 0.00101   Min.   : 0.00226   Min.   :    1.011  
##  1st Qu.:3102682   1st Qu.:3102683   1st Qu.:20.10      1st Qu.: 0.03346   1st Qu.: 0.07482   1st Qu.:   33.462  
##  Median :3514800   Median :3514800   Median :21.90      Median : 0.11080   Median : 0.24777   Median :  110.804  
##  Mean   :3272675   Mean   :3273113   Mean   :22.27      Mean   : 0.20523   Mean   : 0.45754   Mean   :  204.649  
##  3rd Qu.:3690987   3rd Qu.:3690385   3rd Qu.:24.50      3rd Qu.: 0.25384   3rd Qu.: 0.56760   3rd Qu.:  253.837  
##  Max.   :3781897   Max.   :3781897   Max.   :32.10      Max.   :15.57955   Max.   :34.83694   Max.   :15579.552  
##  NA&#39;s   :53        NA&#39;s   :57        NA&#39;s   :36         NA&#39;s   :60         NA&#39;s   :23         NA&#39;s   :29         
##  Est.Dia.in.M.max.  Est.Dia.in.Miles.min. Est.Dia.in.Miles.max. Est.Dia.in.Feet.min. Est.Dia.in.Feet.max.
##  Min.   :    2.26   Min.   :0.00063       Min.   : 0.00140      Min.   :    3.32     Min.   :     7.41   
##  1st Qu.:   74.82   1st Qu.:0.02079       1st Qu.: 0.04649      1st Qu.:  109.78     1st Qu.:   245.49   
##  Median :  247.77   Median :0.06885       Median : 0.15395      Median :  363.53     Median :   812.88   
##  Mean   :  458.45   Mean   :0.12734       Mean   : 0.28486      Mean   :  670.44     Mean   :  1500.77   
##  3rd Qu.:  567.60   3rd Qu.:0.15773       3rd Qu.: 0.35269      3rd Qu.:  832.80     3rd Qu.:  1862.19   
##  Max.   :34836.94   Max.   :9.68068       Max.   :21.64666      Max.   :51114.02     Max.   :114294.42   
##  NA&#39;s   :46         NA&#39;s   :42            NA&#39;s   :50            NA&#39;s   :21           NA&#39;s   :46          
##  Close.Approach.Date Epoch.Date.Close.Approach Relative.Velocity.km.per.sec Relative.Velocity.km.per.hr
##  2016-07-22:  18     Min.   :7.889e+11         Min.   : 0.3355              Min.   :  1208             
##  2015-01-15:  17     1st Qu.:1.016e+12         1st Qu.: 8.4497              1st Qu.: 30399             
##  2015-02-15:  16     Median :1.203e+12         Median :12.9370              Median : 46532             
##  2007-11-08:  15     Mean   :1.180e+12         Mean   :13.9848              Mean   : 50298             
##  2012-01-15:  15     3rd Qu.:1.356e+12         3rd Qu.:18.0774              3rd Qu.: 65068             
##  (Other)   :4577     Max.   :1.473e+12         Max.   :44.6337              Max.   :160681             
##  NA&#39;s      :  29     NA&#39;s   :43                NA&#39;s   :27                   NA&#39;s   :28                 
##  Miles.per.hour    Miss.Dist..Astronomical. Miss.Dist..lunar.   Miss.Dist..kilometers. Miss.Dist..miles. 
##  Min.   :  750.5   Min.   :0.00018          Min.   :  0.06919   Min.   :   26610       Min.   :   16535  
##  1st Qu.:18846.7   1st Qu.:0.13341          1st Qu.: 51.89874   1st Qu.:19964907       1st Qu.:12454813  
##  Median :28893.7   Median :0.26497          Median :103.19415   Median :39685408       Median :24662435  
##  Mean   :31228.0   Mean   :0.25690          Mean   : 99.91366   Mean   :38436154       Mean   :23885560  
##  3rd Qu.:40436.9   3rd Qu.:0.38506          3rd Qu.:149.59244   3rd Qu.:57540318       3rd Qu.:35714721  
##  Max.   :99841.2   Max.   :0.49988          Max.   :194.45491   Max.   :74781600       Max.   :46467132  
##  NA&#39;s   :38        NA&#39;s   :60               NA&#39;s   :30          NA&#39;s   :56             NA&#39;s   :27        
##  Orbiting.Body    Orbit.ID             Orbit.Determination.Date Orbit.Uncertainity Minimum.Orbit.Intersection
##  Earth:4665    Min.   :  1.00   2017-06-21 06:17:20:   9        Min.   :0.000      Min.   :0.00000           
##  NA&#39;s :  22    1st Qu.:  9.00   2017-04-06 08:57:13:   8        1st Qu.:0.000      1st Qu.:0.01435           
##                Median : 16.00   2017-04-06 09:24:24:   8        Median :3.000      Median :0.04653           
##                Mean   : 28.34   2017-04-06 08:24:13:   7        Mean   :3.521      Mean   :0.08191           
##                3rd Qu.: 31.00   2017-04-06 08:26:19:   7        3rd Qu.:6.000      3rd Qu.:0.12150           
##                Max.   :611.00   (Other)            :4622        Max.   :9.000      Max.   :0.47789           
##                NA&#39;s   :33       NA&#39;s               :  26        NA&#39;s   :49         NA&#39;s   :137               
##  Jupiter.Tisserand.Invariant Epoch.Osculation   Eccentricity     Semi.Major.Axis   Inclination      
##  Min.   :2.196               Min.   :2450164   Min.   :0.00752   Min.   :0.6159   Min.   : 0.01451  
##  1st Qu.:4.047               1st Qu.:2458000   1st Qu.:0.24086   1st Qu.:1.0012   1st Qu.: 4.93290  
##  Median :5.071               Median :2458000   Median :0.37251   Median :1.2422   Median :10.27694  
##  Mean   :5.056               Mean   :2457723   Mean   :0.38267   Mean   :1.4009   Mean   :13.36159  
##  3rd Qu.:6.017               3rd Qu.:2458000   3rd Qu.:0.51256   3rd Qu.:1.6782   3rd Qu.:19.47848  
##  Max.   :9.025               Max.   :2458020   Max.   :0.96026   Max.   :5.0720   Max.   :75.40667  
##  NA&#39;s   :56                  NA&#39;s   :60        NA&#39;s   :39        NA&#39;s   :53       NA&#39;s   :42        
##  Asc.Node.Longitude Orbital.Period   Perihelion.Distance Perihelion.Arg     Aphelion.Dist    Perihelion.Time  
##  Min.   :  0.0019   Min.   : 176.6   Min.   :0.08074     Min.   :  0.0069   Min.   :0.8038   Min.   :2450100  
##  1st Qu.: 83.1849   1st Qu.: 365.9   1st Qu.:0.63038     1st Qu.: 95.6430   1st Qu.:1.2661   1st Qu.:2457815  
##  Median :172.6347   Median : 504.9   Median :0.83288     Median :189.7729   Median :1.6182   Median :2457972  
##  Mean   :172.1717   Mean   : 635.5   Mean   :0.81316     Mean   :184.0185   Mean   :1.9864   Mean   :2457726  
##  3rd Qu.:254.8804   3rd Qu.: 793.1   3rd Qu.:0.99718     3rd Qu.:271.9535   3rd Qu.:2.4497   3rd Qu.:2458108  
##  Max.   :359.9059   Max.   :4172.2   Max.   :1.29983     Max.   :359.9931   Max.   :8.9839   Max.   :2458839  
##  NA&#39;s   :60         NA&#39;s   :46       NA&#39;s   :22          NA&#39;s   :48         NA&#39;s   :38       NA&#39;s   :59       
##   Mean.Anomaly       Mean.Motion       Equinox       Hazardous        subset         
##  Min.   :  0.0032   Min.   :0.08628   J2000:4663   Min.   :0.000   Length:4687       
##  1st Qu.: 87.0069   1st Qu.:0.45147   NA&#39;s :  24   1st Qu.:0.000   Class :character  
##  Median :186.0219   Median :0.71137                Median :0.000   Mode  :character  
##  Mean   :181.2882   Mean   :0.73732                Mean   :0.176                     
##  3rd Qu.:276.6418   3rd Qu.:0.98379                3rd Qu.:0.000                     
##  Max.   :359.9180   Max.   :2.03900                Max.   :1.000                     
##  NA&#39;s   :40         NA&#39;s   :48                     NA&#39;s   :4187</code></pre>
<div class="sourceCode" id="cb701"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb701-1"><a href="deep.html#cb701-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove Equinox and other features.</span></span>
<span id="cb701-2"><a href="deep.html#cb701-2" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> data <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>Equinox, <span class="sc">-</span>Orbiting.Body,</span>
<span id="cb701-3"><a href="deep.html#cb701-3" aria-hidden="true" tabindex="-1"></a>                       <span class="sc">-</span>Orbit.Determination.Date, <span class="sc">-</span>Close.Approach.Date)</span>
<span id="cb701-4"><a href="deep.html#cb701-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb701-5"><a href="deep.html#cb701-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Impute missing values using a random forest.</span></span>
<span id="cb701-6"><a href="deep.html#cb701-6" aria-hidden="true" tabindex="-1"></a>imputed <span class="ot">=</span> data <span class="sc">%&gt;%</span></span>
<span id="cb701-7"><a href="deep.html#cb701-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>Hazardous) <span class="sc">%&gt;%</span></span>
<span id="cb701-8"><a href="deep.html#cb701-8" aria-hidden="true" tabindex="-1"></a>    missRanger<span class="sc">::</span><span class="fu">missRanger</span>(<span class="at">maxiter =</span> 5L, <span class="at">num.trees =</span> 20L)</span></code></pre></div>
<pre><code>## 
## Missing value imputation by random forests
## 
##   Variables to impute:       Neo.Reference.ID, Name, Absolute.Magnitude, Est.Dia.in.KM.min., Est.Dia.in.KM.max., Est.Dia.in.M.min., Est.Dia.in.M.max., Est.Dia.in.Miles.min., Est.Dia.in.Miles.max., Est.Dia.in.Feet.min., Est.Dia.in.Feet.max., Epoch.Date.Close.Approach, Relative.Velocity.km.per.sec, Relative.Velocity.km.per.hr, Miles.per.hour, Miss.Dist..Astronomical., Miss.Dist..lunar., Miss.Dist..kilometers., Miss.Dist..miles., Orbit.ID, Orbit.Uncertainity, Minimum.Orbit.Intersection, Jupiter.Tisserand.Invariant, Epoch.Osculation, Eccentricity, Semi.Major.Axis, Inclination, Asc.Node.Longitude, Orbital.Period, Perihelion.Distance, Perihelion.Arg, Aphelion.Dist, Perihelion.Time, Mean.Anomaly, Mean.Motion
##   Variables used to impute:  Neo.Reference.ID, Name, Absolute.Magnitude, Est.Dia.in.KM.min., Est.Dia.in.KM.max., Est.Dia.in.M.min., Est.Dia.in.M.max., Est.Dia.in.Miles.min., Est.Dia.in.Miles.max., Est.Dia.in.Feet.min., Est.Dia.in.Feet.max., Epoch.Date.Close.Approach, Relative.Velocity.km.per.sec, Relative.Velocity.km.per.hr, Miles.per.hour, Miss.Dist..Astronomical., Miss.Dist..lunar., Miss.Dist..kilometers., Miss.Dist..miles., Orbit.ID, Orbit.Uncertainity, Minimum.Orbit.Intersection, Jupiter.Tisserand.Invariant, Epoch.Osculation, Eccentricity, Semi.Major.Axis, Inclination, Asc.Node.Longitude, Orbital.Period, Perihelion.Distance, Perihelion.Arg, Aphelion.Dist, Perihelion.Time, Mean.Anomaly, Mean.Motion, subset
## iter 1:  ...................................
## iter 2:  ...................................
## iter 3:  ...................................
## iter 4:  ...................................</code></pre>
<div class="sourceCode" id="cb703"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb703-1"><a href="deep.html#cb703-1" aria-hidden="true" tabindex="-1"></a><span class="co"># See the usual function call:</span></span>
<span id="cb703-2"><a href="deep.html#cb703-2" aria-hidden="true" tabindex="-1"></a><span class="co"># data_impute = data %&gt;% select(-Hazardous)</span></span>
<span id="cb703-3"><a href="deep.html#cb703-3" aria-hidden="true" tabindex="-1"></a><span class="co"># imputed = missRanger::missRanger(data_impute, maxiter = 5L, num.trees = 20L)</span></span>
<span id="cb703-4"><a href="deep.html#cb703-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb703-5"><a href="deep.html#cb703-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Scale data.</span></span>
<span id="cb703-6"><a href="deep.html#cb703-6" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">cbind</span>(</span>
<span id="cb703-7"><a href="deep.html#cb703-7" aria-hidden="true" tabindex="-1"></a>  data <span class="sc">%&gt;%</span> <span class="fu">select</span>(Hazardous),</span>
<span id="cb703-8"><a href="deep.html#cb703-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale</span>(imputed <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>subset)),</span>
<span id="cb703-9"><a href="deep.html#cb703-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.frame</span>(<span class="st">&quot;subset&quot;</span> <span class="ot">=</span> data<span class="sc">$</span>subset)</span>
<span id="cb703-10"><a href="deep.html#cb703-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb703-11"><a href="deep.html#cb703-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb703-12"><a href="deep.html#cb703-12" aria-hidden="true" tabindex="-1"></a><span class="do">## Outer split.</span></span>
<span id="cb703-13"><a href="deep.html#cb703-13" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> data[data<span class="sc">$</span>subset <span class="sc">==</span> <span class="st">&quot;train&quot;</span>, ]</span>
<span id="cb703-14"><a href="deep.html#cb703-14" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> data[data<span class="sc">$</span>subset <span class="sc">==</span> <span class="st">&quot;test&quot;</span>, ]</span>
<span id="cb703-15"><a href="deep.html#cb703-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb703-16"><a href="deep.html#cb703-16" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> train <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>subset)</span>
<span id="cb703-17"><a href="deep.html#cb703-17" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> test <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>subset)</span>
<span id="cb703-18"><a href="deep.html#cb703-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb703-19"><a href="deep.html#cb703-19" aria-hidden="true" tabindex="-1"></a><span class="do">## 10-fold cross-validation:</span></span>
<span id="cb703-20"><a href="deep.html#cb703-20" aria-hidden="true" tabindex="-1"></a>len <span class="ot">=</span> <span class="fu">nrow</span>(train)</span>
<span id="cb703-21"><a href="deep.html#cb703-21" aria-hidden="true" tabindex="-1"></a>ord <span class="ot">=</span> <span class="fu">sample.int</span>(len)</span>
<span id="cb703-22"><a href="deep.html#cb703-22" aria-hidden="true" tabindex="-1"></a>k <span class="ot">=</span> <span class="dv">10</span></span>
<span id="cb703-23"><a href="deep.html#cb703-23" aria-hidden="true" tabindex="-1"></a>cv_indices <span class="ot">=</span> <span class="fu">lapply</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">9</span>, <span class="cf">function</span>(i) <span class="fu">sort</span>(ord[(i<span class="sc">*</span>len<span class="sc">/</span>k <span class="sc">+</span> <span class="dv">1</span>)<span class="sc">:</span>((i<span class="sc">+</span><span class="dv">1</span>)<span class="sc">*</span>len<span class="sc">/</span>k)]))</span>
<span id="cb703-24"><a href="deep.html#cb703-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb703-25"><a href="deep.html#cb703-25" aria-hidden="true" tabindex="-1"></a>result <span class="ot">=</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, 10L, 2L)</span>
<span id="cb703-26"><a href="deep.html#cb703-26" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(result) <span class="ot">=</span> <span class="fu">c</span>(<span class="st">&quot;train_auc&quot;</span>, <span class="st">&quot;test_auc&quot;</span>)</span>
<span id="cb703-27"><a href="deep.html#cb703-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb703-28"><a href="deep.html#cb703-28" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>) {</span>
<span id="cb703-29"><a href="deep.html#cb703-29" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">=</span> cv_indices[[i]]</span>
<span id="cb703-30"><a href="deep.html#cb703-30" aria-hidden="true" tabindex="-1"></a>  sub_train <span class="ot">=</span> train[<span class="sc">-</span>indices,] <span class="co"># Leave one &quot;bucket&quot; out.</span></span>
<span id="cb703-31"><a href="deep.html#cb703-31" aria-hidden="true" tabindex="-1"></a>  sub_test <span class="ot">=</span> train[indices,]</span>
<span id="cb703-32"><a href="deep.html#cb703-32" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb703-33"><a href="deep.html#cb703-33" aria-hidden="true" tabindex="-1"></a>  <span class="co"># &quot;Deep&quot; neural networks and regularization:</span></span>
<span id="cb703-34"><a href="deep.html#cb703-34" aria-hidden="true" tabindex="-1"></a>  model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb703-35"><a href="deep.html#cb703-35" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb703-36"><a href="deep.html#cb703-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>,</span>
<span id="cb703-37"><a href="deep.html#cb703-37" aria-hidden="true" tabindex="-1"></a>             <span class="at">input_shape =</span> <span class="fu">ncol</span>(sub_train) <span class="sc">-</span> 1L) <span class="sc">%&gt;%</span></span>
<span id="cb703-38"><a href="deep.html#cb703-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb703-39"><a href="deep.html#cb703-39" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;sigmoid&quot;</span>)</span>
<span id="cb703-40"><a href="deep.html#cb703-40" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb703-41"><a href="deep.html#cb703-41" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb703-42"><a href="deep.html#cb703-42" aria-hidden="true" tabindex="-1"></a>  keras<span class="sc">::</span><span class="fu">compile</span>(<span class="at">loss =</span> loss_binary_crossentropy, </span>
<span id="cb703-43"><a href="deep.html#cb703-43" aria-hidden="true" tabindex="-1"></a>                 <span class="at">optimizer =</span> <span class="fu">optimizer_adamax</span>(<span class="fl">0.01</span>))</span>
<span id="cb703-44"><a href="deep.html#cb703-44" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb703-45"><a href="deep.html#cb703-45" aria-hidden="true" tabindex="-1"></a>  model_history <span class="ot">=</span> </span>
<span id="cb703-46"><a href="deep.html#cb703-46" aria-hidden="true" tabindex="-1"></a>   model <span class="sc">%&gt;%</span></span>
<span id="cb703-47"><a href="deep.html#cb703-47" aria-hidden="true" tabindex="-1"></a>     <span class="fu">fit</span>(</span>
<span id="cb703-48"><a href="deep.html#cb703-48" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="fu">as.matrix</span>(sub_train <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>Hazardous)),</span>
<span id="cb703-49"><a href="deep.html#cb703-49" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="fu">as.matrix</span>(sub_train <span class="sc">%&gt;%</span> <span class="fu">select</span>(Hazardous)),</span>
<span id="cb703-50"><a href="deep.html#cb703-50" aria-hidden="true" tabindex="-1"></a>       <span class="at">validation_split =</span> <span class="fl">0.2</span>,</span>
<span id="cb703-51"><a href="deep.html#cb703-51" aria-hidden="true" tabindex="-1"></a>       <span class="at">epochs =</span> 35L, <span class="at">batch =</span> 50L, <span class="at">shuffle =</span> <span class="cn">TRUE</span></span>
<span id="cb703-52"><a href="deep.html#cb703-52" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb703-53"><a href="deep.html#cb703-53" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb703-54"><a href="deep.html#cb703-54" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(model_history)</span>
<span id="cb703-55"><a href="deep.html#cb703-55" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb703-56"><a href="deep.html#cb703-56" aria-hidden="true" tabindex="-1"></a>  pred_train <span class="ot">=</span> <span class="fu">predict</span>(model, <span class="fu">as.matrix</span>(sub_train <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>Hazardous)))</span>
<span id="cb703-57"><a href="deep.html#cb703-57" aria-hidden="true" tabindex="-1"></a>  pred_test <span class="ot">=</span> <span class="fu">predict</span>(model, <span class="fu">as.matrix</span>(sub_test <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>Hazardous)))</span>
<span id="cb703-58"><a href="deep.html#cb703-58" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb703-59"><a href="deep.html#cb703-59" aria-hidden="true" tabindex="-1"></a>  <span class="co"># AUC: Area under the (ROC) curve, this is a performance measure [0, 1].</span></span>
<span id="cb703-60"><a href="deep.html#cb703-60" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 0.5 is worst for a binary classifier.</span></span>
<span id="cb703-61"><a href="deep.html#cb703-61" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 1 perfectly classifies all samples, 0 perfectly misclassifies all samples.</span></span>
<span id="cb703-62"><a href="deep.html#cb703-62" aria-hidden="true" tabindex="-1"></a>  result[i, <span class="dv">1</span>] <span class="ot">=</span> Metrics<span class="sc">::</span><span class="fu">auc</span>(sub_train<span class="sc">$</span>Hazardous, pred_train)</span>
<span id="cb703-63"><a href="deep.html#cb703-63" aria-hidden="true" tabindex="-1"></a>  result[i, <span class="dv">2</span>] <span class="ot">=</span> Metrics<span class="sc">::</span><span class="fu">auc</span>(sub_test<span class="sc">$</span>Hazardous, pred_test)</span>
<span id="cb703-64"><a href="deep.html#cb703-64" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb703-65"><a href="deep.html#cb703-65" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(result)</span></code></pre></div>
<pre><code>##       train_auc  test_auc
##  [1,] 0.9981234 0.9268293
##  [2,] 0.9984570 0.9866667
##  [3,] 0.9960277 0.9822222
##  [4,] 0.9965881 0.9650000
##  [5,] 0.9987838 0.9017857
##  [6,] 0.9976351 0.8809524
##  [7,] 0.9932803 0.9824561
##  [8,] 0.9933126 0.9972900
##  [9,] 0.9944652 0.9484127
## [10,] 0.9968919 0.9642857</code></pre>
<div class="sourceCode" id="cb705"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb705-1"><a href="deep.html#cb705-1" aria-hidden="true" tabindex="-1"></a>(<span class="fu">colMeans</span>(result))</span></code></pre></div>
<pre><code>## train_auc  test_auc 
## 0.9963565 0.9535901</code></pre>
<div class="sourceCode" id="cb707"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb707-1"><a href="deep.html#cb707-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The model setup seems to be fine.</span></span>
<span id="cb707-2"><a href="deep.html#cb707-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb707-3"><a href="deep.html#cb707-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Train and predict for outer validation split (on the complete training data):</span></span>
<span id="cb707-4"><a href="deep.html#cb707-4" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb707-5"><a href="deep.html#cb707-5" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb707-6"><a href="deep.html#cb707-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>,</span>
<span id="cb707-7"><a href="deep.html#cb707-7" aria-hidden="true" tabindex="-1"></a>              <span class="at">input_shape =</span> <span class="fu">ncol</span>(sub_train) <span class="sc">-</span> 1L) <span class="sc">%&gt;%</span></span>
<span id="cb707-8"><a href="deep.html#cb707-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb707-9"><a href="deep.html#cb707-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;sigmoid&quot;</span>)</span>
<span id="cb707-10"><a href="deep.html#cb707-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb707-11"><a href="deep.html#cb707-11" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb707-12"><a href="deep.html#cb707-12" aria-hidden="true" tabindex="-1"></a>  keras<span class="sc">::</span><span class="fu">compile</span>(<span class="at">loss =</span> loss_binary_crossentropy, </span>
<span id="cb707-13"><a href="deep.html#cb707-13" aria-hidden="true" tabindex="-1"></a>                 <span class="at">optimizer =</span> <span class="fu">optimizer_adamax</span>(<span class="fl">0.01</span>))</span>
<span id="cb707-14"><a href="deep.html#cb707-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb707-15"><a href="deep.html#cb707-15" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span> </span>
<span id="cb707-16"><a href="deep.html#cb707-16" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb707-17"><a href="deep.html#cb707-17" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(</span>
<span id="cb707-18"><a href="deep.html#cb707-18" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> <span class="fu">as.matrix</span>(train <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>Hazardous)),</span>
<span id="cb707-19"><a href="deep.html#cb707-19" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> <span class="fu">as.matrix</span>(train <span class="sc">%&gt;%</span> <span class="fu">select</span>(Hazardous)),</span>
<span id="cb707-20"><a href="deep.html#cb707-20" aria-hidden="true" tabindex="-1"></a>      <span class="at">validation_split =</span> <span class="fl">0.2</span>,</span>
<span id="cb707-21"><a href="deep.html#cb707-21" aria-hidden="true" tabindex="-1"></a>      <span class="at">epochs =</span> 35L, <span class="at">batch =</span> 50L, <span class="at">shuffle =</span> <span class="cn">TRUE</span></span>
<span id="cb707-22"><a href="deep.html#cb707-22" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb707-23"><a href="deep.html#cb707-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb707-24"><a href="deep.html#cb707-24" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">predict</span>(model, <span class="fu">as.matrix</span>(test[,<span class="sc">-</span><span class="dv">1</span>])))</span>
<span id="cb707-25"><a href="deep.html#cb707-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb707-26"><a href="deep.html#cb707-26" aria-hidden="true" tabindex="-1"></a><span class="fu">write.csv</span>(<span class="fu">data.frame</span>(<span class="at">y =</span> pred), <span class="at">file =</span> <span class="st">&quot;submission_DNN.csv&quot;</span>)</span></code></pre></div>
<p>Go trough the code line by line and try to understand it. Especially have a focus on the general machine learning workflow (remember the general steps), the new type of imputation and the hand coded 10-fold cross-validation (the for loop).</p>
  <hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<p>Use early stopping and dropout (i.e. use these options, we explained in the book now) within the same algorithm from above and compare them.
Try to tune the network (play around with the number of layers, the width of the layers, dropout layers, early stopping and other regularization and so on) to make better predicitons (monitor the the training and validation loss).</p>
<p>In the end, submit predictions to the <a href="http://rhsbio7.uni-regensburg.de:8500/" target="_blank" rel="noopener">submission server</a> (if you have time you can also transfer your new knowledge to the titanic data set)!</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<div class="sourceCode" id="cb708"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb708-1"><a href="deep.html#cb708-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb708-2"><a href="deep.html#cb708-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb708-3"><a href="deep.html#cb708-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb708-4"><a href="deep.html#cb708-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(missRanger)</span>
<span id="cb708-5"><a href="deep.html#cb708-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(Metrics)</span>
<span id="cb708-6"><a href="deep.html#cb708-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(EcoData)</span>
<span id="cb708-7"><a href="deep.html#cb708-7" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb708-8"><a href="deep.html#cb708-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb708-9"><a href="deep.html#cb708-9" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;nasa&quot;</span>)</span>
<span id="cb708-10"><a href="deep.html#cb708-10" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> nasa</span>
<span id="cb708-11"><a href="deep.html#cb708-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb708-12"><a href="deep.html#cb708-12" aria-hidden="true" tabindex="-1"></a>data<span class="sc">$</span>subset <span class="ot">=</span> <span class="fu">ifelse</span>(<span class="fu">is.na</span>(data<span class="sc">$</span>Hazardous), <span class="st">&quot;test&quot;</span>, <span class="st">&quot;train&quot;</span>)</span>
<span id="cb708-13"><a href="deep.html#cb708-13" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> data <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>Equinox, <span class="sc">-</span>Orbiting.Body,</span>
<span id="cb708-14"><a href="deep.html#cb708-14" aria-hidden="true" tabindex="-1"></a>                       <span class="sc">-</span>Orbit.Determination.Date, <span class="sc">-</span>Close.Approach.Date)</span>
<span id="cb708-15"><a href="deep.html#cb708-15" aria-hidden="true" tabindex="-1"></a>imputed <span class="ot">=</span> data <span class="sc">%&gt;%</span></span>
<span id="cb708-16"><a href="deep.html#cb708-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>Hazardous) <span class="sc">%&gt;%</span></span>
<span id="cb708-17"><a href="deep.html#cb708-17" aria-hidden="true" tabindex="-1"></a>  missRanger<span class="sc">::</span><span class="fu">missRanger</span>(<span class="at">maxiter =</span> 5L, <span class="at">num.trees =</span> 20L)</span></code></pre></div>
<pre><code>## 
## Missing value imputation by random forests
## 
##   Variables to impute:       Neo.Reference.ID, Name, Absolute.Magnitude, Est.Dia.in.KM.min., Est.Dia.in.KM.max., Est.Dia.in.M.min., Est.Dia.in.M.max., Est.Dia.in.Miles.min., Est.Dia.in.Miles.max., Est.Dia.in.Feet.min., Est.Dia.in.Feet.max., Epoch.Date.Close.Approach, Relative.Velocity.km.per.sec, Relative.Velocity.km.per.hr, Miles.per.hour, Miss.Dist..Astronomical., Miss.Dist..lunar., Miss.Dist..kilometers., Miss.Dist..miles., Orbit.ID, Orbit.Uncertainity, Minimum.Orbit.Intersection, Jupiter.Tisserand.Invariant, Epoch.Osculation, Eccentricity, Semi.Major.Axis, Inclination, Asc.Node.Longitude, Orbital.Period, Perihelion.Distance, Perihelion.Arg, Aphelion.Dist, Perihelion.Time, Mean.Anomaly, Mean.Motion
##   Variables used to impute:  Neo.Reference.ID, Name, Absolute.Magnitude, Est.Dia.in.KM.min., Est.Dia.in.KM.max., Est.Dia.in.M.min., Est.Dia.in.M.max., Est.Dia.in.Miles.min., Est.Dia.in.Miles.max., Est.Dia.in.Feet.min., Est.Dia.in.Feet.max., Epoch.Date.Close.Approach, Relative.Velocity.km.per.sec, Relative.Velocity.km.per.hr, Miles.per.hour, Miss.Dist..Astronomical., Miss.Dist..lunar., Miss.Dist..kilometers., Miss.Dist..miles., Orbit.ID, Orbit.Uncertainity, Minimum.Orbit.Intersection, Jupiter.Tisserand.Invariant, Epoch.Osculation, Eccentricity, Semi.Major.Axis, Inclination, Asc.Node.Longitude, Orbital.Period, Perihelion.Distance, Perihelion.Arg, Aphelion.Dist, Perihelion.Time, Mean.Anomaly, Mean.Motion, subset
## iter 1:  ...................................
## iter 2:  ...................................
## iter 3:  ...................................
## iter 4:  ...................................</code></pre>
<div class="sourceCode" id="cb710"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb710-1"><a href="deep.html#cb710-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">cbind</span>(</span>
<span id="cb710-2"><a href="deep.html#cb710-2" aria-hidden="true" tabindex="-1"></a>  data <span class="sc">%&gt;%</span> <span class="fu">select</span>(Hazardous),</span>
<span id="cb710-3"><a href="deep.html#cb710-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale</span>(imputed <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>subset)),</span>
<span id="cb710-4"><a href="deep.html#cb710-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.frame</span>(<span class="st">&quot;subset&quot;</span> <span class="ot">=</span> data<span class="sc">$</span>subset)</span>
<span id="cb710-5"><a href="deep.html#cb710-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb710-6"><a href="deep.html#cb710-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb710-7"><a href="deep.html#cb710-7" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> data[data<span class="sc">$</span>subset <span class="sc">==</span> <span class="st">&quot;train&quot;</span>, ]</span>
<span id="cb710-8"><a href="deep.html#cb710-8" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> data[data<span class="sc">$</span>subset <span class="sc">==</span> <span class="st">&quot;test&quot;</span>, ]</span>
<span id="cb710-9"><a href="deep.html#cb710-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb710-10"><a href="deep.html#cb710-10" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> train <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>subset)</span>
<span id="cb710-11"><a href="deep.html#cb710-11" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> test <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>subset)</span>
<span id="cb710-12"><a href="deep.html#cb710-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb710-13"><a href="deep.html#cb710-13" aria-hidden="true" tabindex="-1"></a>len <span class="ot">=</span> <span class="fu">nrow</span>(train)</span>
<span id="cb710-14"><a href="deep.html#cb710-14" aria-hidden="true" tabindex="-1"></a>ord <span class="ot">=</span> <span class="fu">sample.int</span>(len)</span>
<span id="cb710-15"><a href="deep.html#cb710-15" aria-hidden="true" tabindex="-1"></a>k <span class="ot">=</span> <span class="dv">10</span></span>
<span id="cb710-16"><a href="deep.html#cb710-16" aria-hidden="true" tabindex="-1"></a>cv_indices <span class="ot">=</span> <span class="fu">lapply</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">9</span>, <span class="cf">function</span>(i) <span class="fu">sort</span>(ord[(i<span class="sc">*</span>len<span class="sc">/</span>k <span class="sc">+</span> <span class="dv">1</span>)<span class="sc">:</span>((i<span class="sc">+</span><span class="dv">1</span>)<span class="sc">*</span>len<span class="sc">/</span>k)]))</span>
<span id="cb710-17"><a href="deep.html#cb710-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb710-18"><a href="deep.html#cb710-18" aria-hidden="true" tabindex="-1"></a>result <span class="ot">=</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, 10L, 2L)</span>
<span id="cb710-19"><a href="deep.html#cb710-19" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(result) <span class="ot">=</span> <span class="fu">c</span>(<span class="st">&quot;train_auc&quot;</span>, <span class="st">&quot;test_auc&quot;</span>)</span>
<span id="cb710-20"><a href="deep.html#cb710-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb710-21"><a href="deep.html#cb710-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>) {</span>
<span id="cb710-22"><a href="deep.html#cb710-22" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">=</span> cv_indices[[i]]</span>
<span id="cb710-23"><a href="deep.html#cb710-23" aria-hidden="true" tabindex="-1"></a>  sub_train <span class="ot">=</span> train[<span class="sc">-</span>indices,]</span>
<span id="cb710-24"><a href="deep.html#cb710-24" aria-hidden="true" tabindex="-1"></a>  sub_test <span class="ot">=</span> train[indices,]</span>
<span id="cb710-25"><a href="deep.html#cb710-25" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb710-26"><a href="deep.html#cb710-26" aria-hidden="true" tabindex="-1"></a>  <span class="co"># &quot;Deep&quot; neural networks and regularization:</span></span>
<span id="cb710-27"><a href="deep.html#cb710-27" aria-hidden="true" tabindex="-1"></a>  model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb710-28"><a href="deep.html#cb710-28" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb710-29"><a href="deep.html#cb710-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>,</span>
<span id="cb710-30"><a href="deep.html#cb710-30" aria-hidden="true" tabindex="-1"></a>             <span class="at">input_shape =</span> <span class="fu">ncol</span>(sub_train) <span class="sc">-</span> 1L) <span class="sc">%&gt;%</span></span>
<span id="cb710-31"><a href="deep.html#cb710-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="at">rate =</span> <span class="fl">0.3</span>) <span class="sc">%&gt;%</span></span>
<span id="cb710-32"><a href="deep.html#cb710-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb710-33"><a href="deep.html#cb710-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="at">rate =</span> <span class="fl">0.3</span>) <span class="sc">%&gt;%</span></span>
<span id="cb710-34"><a href="deep.html#cb710-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;sigmoid&quot;</span>)</span>
<span id="cb710-35"><a href="deep.html#cb710-35" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb710-36"><a href="deep.html#cb710-36" aria-hidden="true" tabindex="-1"></a>  early_stopping <span class="ot">=</span> <span class="fu">callback_early_stopping</span>(<span class="at">monitor =</span> <span class="st">&quot;val_loss&quot;</span>, <span class="at">patience =</span> 5L)</span>
<span id="cb710-37"><a href="deep.html#cb710-37" aria-hidden="true" tabindex="-1"></a>  <span class="co"># You need a validation split for this!</span></span>
<span id="cb710-38"><a href="deep.html#cb710-38" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb710-39"><a href="deep.html#cb710-39" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb710-40"><a href="deep.html#cb710-40" aria-hidden="true" tabindex="-1"></a>  keras<span class="sc">::</span><span class="fu">compile</span>(<span class="at">loss =</span> loss_binary_crossentropy, </span>
<span id="cb710-41"><a href="deep.html#cb710-41" aria-hidden="true" tabindex="-1"></a>                 <span class="at">optimizer =</span> <span class="fu">optimizer_adamax</span>(<span class="fl">0.01</span>))</span>
<span id="cb710-42"><a href="deep.html#cb710-42" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb710-43"><a href="deep.html#cb710-43" aria-hidden="true" tabindex="-1"></a>  model_history <span class="ot">=</span> </span>
<span id="cb710-44"><a href="deep.html#cb710-44" aria-hidden="true" tabindex="-1"></a>   model <span class="sc">%&gt;%</span></span>
<span id="cb710-45"><a href="deep.html#cb710-45" aria-hidden="true" tabindex="-1"></a>     <span class="fu">fit</span>(</span>
<span id="cb710-46"><a href="deep.html#cb710-46" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="fu">as.matrix</span>(sub_train <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>Hazardous)),</span>
<span id="cb710-47"><a href="deep.html#cb710-47" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="fu">as.matrix</span>(sub_train <span class="sc">%&gt;%</span> <span class="fu">select</span>(Hazardous)),</span>
<span id="cb710-48"><a href="deep.html#cb710-48" aria-hidden="true" tabindex="-1"></a>       <span class="at">callbacks =</span> <span class="fu">c</span>(early_stopping),</span>
<span id="cb710-49"><a href="deep.html#cb710-49" aria-hidden="true" tabindex="-1"></a>       <span class="at">validation_split =</span> <span class="fl">0.2</span>,</span>
<span id="cb710-50"><a href="deep.html#cb710-50" aria-hidden="true" tabindex="-1"></a>       <span class="at">epochs =</span> 35L, <span class="at">batch =</span> 50L, <span class="at">shuffle =</span> <span class="cn">TRUE</span></span>
<span id="cb710-51"><a href="deep.html#cb710-51" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb710-52"><a href="deep.html#cb710-52" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb710-53"><a href="deep.html#cb710-53" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(model_history)</span>
<span id="cb710-54"><a href="deep.html#cb710-54" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb710-55"><a href="deep.html#cb710-55" aria-hidden="true" tabindex="-1"></a>  pred_train <span class="ot">=</span> <span class="fu">predict</span>(model, <span class="fu">as.matrix</span>(sub_train <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>Hazardous)))</span>
<span id="cb710-56"><a href="deep.html#cb710-56" aria-hidden="true" tabindex="-1"></a>  pred_test <span class="ot">=</span> <span class="fu">predict</span>(model, <span class="fu">as.matrix</span>(sub_test <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>Hazardous)))</span>
<span id="cb710-57"><a href="deep.html#cb710-57" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb710-58"><a href="deep.html#cb710-58" aria-hidden="true" tabindex="-1"></a>  result[i, <span class="dv">1</span>] <span class="ot">=</span> Metrics<span class="sc">::</span><span class="fu">auc</span>(sub_train<span class="sc">$</span>Hazardous, pred_train)</span>
<span id="cb710-59"><a href="deep.html#cb710-59" aria-hidden="true" tabindex="-1"></a>  result[i, <span class="dv">2</span>] <span class="ot">=</span> Metrics<span class="sc">::</span><span class="fu">auc</span>(sub_test<span class="sc">$</span>Hazardous, pred_test)</span>
<span id="cb710-60"><a href="deep.html#cb710-60" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb710-61"><a href="deep.html#cb710-61" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(result)</span></code></pre></div>
<pre><code>##       train_auc  test_auc
##  [1,] 0.9956669 0.9376694
##  [2,] 0.9939923 0.9911111
##  [3,] 0.9859492 0.9422222
##  [4,] 0.9965536 0.9500000
##  [5,] 0.9976351 0.9107143
##  [6,] 0.9961486 0.8809524
##  [7,] 0.9894807 0.9868421
##  [8,] 0.9908902 1.0000000
##  [9,] 0.9936386 0.9583333
## [10,] 0.9947297 0.9642857</code></pre>
<div class="sourceCode" id="cb712"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb712-1"><a href="deep.html#cb712-1" aria-hidden="true" tabindex="-1"></a>(<span class="fu">colMeans</span>(result))</span></code></pre></div>
<pre><code>## train_auc  test_auc 
## 0.9934685 0.9522131</code></pre>
<div class="sourceCode" id="cb714"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb714-1"><a href="deep.html#cb714-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The model setup seems to be fine.</span></span>
<span id="cb714-2"><a href="deep.html#cb714-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb714-3"><a href="deep.html#cb714-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Train and predict for outer validation split (on the complete training data):</span></span>
<span id="cb714-4"><a href="deep.html#cb714-4" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb714-5"><a href="deep.html#cb714-5" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb714-6"><a href="deep.html#cb714-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>,</span>
<span id="cb714-7"><a href="deep.html#cb714-7" aria-hidden="true" tabindex="-1"></a>              <span class="at">input_shape =</span> <span class="fu">ncol</span>(sub_train) <span class="sc">-</span> 1L) <span class="sc">%&gt;%</span></span>
<span id="cb714-8"><a href="deep.html#cb714-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="at">rate =</span> <span class="fl">0.3</span>) <span class="sc">%&gt;%</span></span>
<span id="cb714-9"><a href="deep.html#cb714-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb714-10"><a href="deep.html#cb714-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="at">rate =</span> <span class="fl">0.3</span>) <span class="sc">%&gt;%</span></span>
<span id="cb714-11"><a href="deep.html#cb714-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;sigmoid&quot;</span>)</span>
<span id="cb714-12"><a href="deep.html#cb714-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb714-13"><a href="deep.html#cb714-13" aria-hidden="true" tabindex="-1"></a>early_stopping <span class="ot">=</span> <span class="fu">callback_early_stopping</span>(<span class="at">monitor =</span> <span class="st">&quot;val_loss&quot;</span>, <span class="at">patience =</span> 5L)</span>
<span id="cb714-14"><a href="deep.html#cb714-14" aria-hidden="true" tabindex="-1"></a><span class="co"># You need a validation split for this!</span></span>
<span id="cb714-15"><a href="deep.html#cb714-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb714-16"><a href="deep.html#cb714-16" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb714-17"><a href="deep.html#cb714-17" aria-hidden="true" tabindex="-1"></a>  keras<span class="sc">::</span><span class="fu">compile</span>(<span class="at">loss =</span> loss_binary_crossentropy, </span>
<span id="cb714-18"><a href="deep.html#cb714-18" aria-hidden="true" tabindex="-1"></a>                 <span class="at">optimizer =</span> <span class="fu">optimizer_adamax</span>(<span class="fl">0.01</span>))</span>
<span id="cb714-19"><a href="deep.html#cb714-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb714-20"><a href="deep.html#cb714-20" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span> </span>
<span id="cb714-21"><a href="deep.html#cb714-21" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb714-22"><a href="deep.html#cb714-22" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(</span>
<span id="cb714-23"><a href="deep.html#cb714-23" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> <span class="fu">as.matrix</span>(train <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>Hazardous)),</span>
<span id="cb714-24"><a href="deep.html#cb714-24" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> <span class="fu">as.matrix</span>(train <span class="sc">%&gt;%</span> <span class="fu">select</span>(Hazardous)),</span>
<span id="cb714-25"><a href="deep.html#cb714-25" aria-hidden="true" tabindex="-1"></a>      <span class="at">callbacks =</span> <span class="fu">c</span>(early_stopping),</span>
<span id="cb714-26"><a href="deep.html#cb714-26" aria-hidden="true" tabindex="-1"></a>      <span class="at">validation_split =</span> <span class="fl">0.2</span>,</span>
<span id="cb714-27"><a href="deep.html#cb714-27" aria-hidden="true" tabindex="-1"></a>      <span class="at">epochs =</span> 35L, <span class="at">batch =</span> 50L, <span class="at">shuffle =</span> <span class="cn">TRUE</span></span>
<span id="cb714-28"><a href="deep.html#cb714-28" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb714-29"><a href="deep.html#cb714-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb714-30"><a href="deep.html#cb714-30" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">predict</span>(model, <span class="fu">as.matrix</span>(test[,<span class="sc">-</span><span class="dv">1</span>])))</span>
<span id="cb714-31"><a href="deep.html#cb714-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb714-32"><a href="deep.html#cb714-32" aria-hidden="true" tabindex="-1"></a><span class="fu">write.csv</span>(<span class="fu">data.frame</span>(<span class="at">y =</span> pred), <span class="at">file =</span> <span class="st">&quot;submission_DNN_dropout_early.csv&quot;</span>)</span></code></pre></div>
    </p>
  </details>
  <br/><hr/>
<p>Better predictions:</p>
<div class="sourceCode" id="cb715"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb715-1"><a href="deep.html#cb715-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb715-2"><a href="deep.html#cb715-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb715-3"><a href="deep.html#cb715-3" aria-hidden="true" tabindex="-1"></a>result <span class="ot">=</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, 10L, 2L)</span>
<span id="cb715-4"><a href="deep.html#cb715-4" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(result) <span class="ot">=</span> <span class="fu">c</span>(<span class="st">&quot;train_auc&quot;</span>, <span class="st">&quot;test_auc&quot;</span>)</span>
<span id="cb715-5"><a href="deep.html#cb715-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb715-6"><a href="deep.html#cb715-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>) {</span>
<span id="cb715-7"><a href="deep.html#cb715-7" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">=</span> cv_indices[[i]]</span>
<span id="cb715-8"><a href="deep.html#cb715-8" aria-hidden="true" tabindex="-1"></a>  sub_train <span class="ot">=</span> train[<span class="sc">-</span>indices,]</span>
<span id="cb715-9"><a href="deep.html#cb715-9" aria-hidden="true" tabindex="-1"></a>  sub_test <span class="ot">=</span> train[indices,]</span>
<span id="cb715-10"><a href="deep.html#cb715-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb715-11"><a href="deep.html#cb715-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># &quot;Deep&quot; neural networks and regularization:</span></span>
<span id="cb715-12"><a href="deep.html#cb715-12" aria-hidden="true" tabindex="-1"></a>  model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb715-13"><a href="deep.html#cb715-13" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb715-14"><a href="deep.html#cb715-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>,</span>
<span id="cb715-15"><a href="deep.html#cb715-15" aria-hidden="true" tabindex="-1"></a>             <span class="at">input_shape =</span> <span class="fu">ncol</span>(sub_train) <span class="sc">-</span> 1L) <span class="sc">%&gt;%</span></span>
<span id="cb715-16"><a href="deep.html#cb715-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="at">rate =</span> <span class="fl">0.45</span>) <span class="sc">%&gt;%</span></span>
<span id="cb715-17"><a href="deep.html#cb715-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 50L, <span class="at">activation =</span> <span class="st">&quot;gelu&quot;</span>,</span>
<span id="cb715-18"><a href="deep.html#cb715-18" aria-hidden="true" tabindex="-1"></a>              <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1</span>(.<span class="dv">00125</span>),</span>
<span id="cb715-19"><a href="deep.html#cb715-19" aria-hidden="true" tabindex="-1"></a>              <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l1_l2</span>(.<span class="dv">25</span>)</span>
<span id="cb715-20"><a href="deep.html#cb715-20" aria-hidden="true" tabindex="-1"></a>              ) <span class="sc">%&gt;%</span></span>
<span id="cb715-21"><a href="deep.html#cb715-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="at">rate =</span> <span class="fl">0.35</span>) <span class="sc">%&gt;%</span></span>
<span id="cb715-22"><a href="deep.html#cb715-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 30L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb715-23"><a href="deep.html#cb715-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="at">rate =</span> <span class="fl">0.3</span>) <span class="sc">%&gt;%</span></span>
<span id="cb715-24"><a href="deep.html#cb715-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;sigmoid&quot;</span>)</span>
<span id="cb715-25"><a href="deep.html#cb715-25" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb715-26"><a href="deep.html#cb715-26" aria-hidden="true" tabindex="-1"></a>  early_stopping <span class="ot">=</span> <span class="fu">callback_early_stopping</span>(<span class="at">monitor =</span> <span class="st">&quot;val_loss&quot;</span>, <span class="at">patience =</span> 8L)</span>
<span id="cb715-27"><a href="deep.html#cb715-27" aria-hidden="true" tabindex="-1"></a>  <span class="co"># You need a validation split for this!</span></span>
<span id="cb715-28"><a href="deep.html#cb715-28" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb715-29"><a href="deep.html#cb715-29" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb715-30"><a href="deep.html#cb715-30" aria-hidden="true" tabindex="-1"></a>  keras<span class="sc">::</span><span class="fu">compile</span>(<span class="at">loss =</span> loss_binary_crossentropy, </span>
<span id="cb715-31"><a href="deep.html#cb715-31" aria-hidden="true" tabindex="-1"></a>                 <span class="at">optimizer =</span> <span class="fu">optimizer_adamax</span>(<span class="fl">0.0072</span>))</span>
<span id="cb715-32"><a href="deep.html#cb715-32" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb715-33"><a href="deep.html#cb715-33" aria-hidden="true" tabindex="-1"></a>  model_history <span class="ot">=</span> </span>
<span id="cb715-34"><a href="deep.html#cb715-34" aria-hidden="true" tabindex="-1"></a>   model <span class="sc">%&gt;%</span></span>
<span id="cb715-35"><a href="deep.html#cb715-35" aria-hidden="true" tabindex="-1"></a>     <span class="fu">fit</span>(</span>
<span id="cb715-36"><a href="deep.html#cb715-36" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="fu">as.matrix</span>(sub_train <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>Hazardous)),</span>
<span id="cb715-37"><a href="deep.html#cb715-37" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="fu">as.matrix</span>(sub_train <span class="sc">%&gt;%</span> <span class="fu">select</span>(Hazardous)), </span>
<span id="cb715-38"><a href="deep.html#cb715-38" aria-hidden="true" tabindex="-1"></a>       <span class="at">callbacks =</span> <span class="fu">c</span>(early_stopping),</span>
<span id="cb715-39"><a href="deep.html#cb715-39" aria-hidden="true" tabindex="-1"></a>       <span class="at">validation_split =</span> <span class="fl">0.2</span>,</span>
<span id="cb715-40"><a href="deep.html#cb715-40" aria-hidden="true" tabindex="-1"></a>       <span class="at">epochs =</span> 50L, <span class="at">batch =</span> 50L, <span class="at">shuffle =</span> <span class="cn">TRUE</span></span>
<span id="cb715-41"><a href="deep.html#cb715-41" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb715-42"><a href="deep.html#cb715-42" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb715-43"><a href="deep.html#cb715-43" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(model_history)</span>
<span id="cb715-44"><a href="deep.html#cb715-44" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb715-45"><a href="deep.html#cb715-45" aria-hidden="true" tabindex="-1"></a>  pred_train <span class="ot">=</span> <span class="fu">predict</span>(model, <span class="fu">as.matrix</span>(sub_train <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>Hazardous)))</span>
<span id="cb715-46"><a href="deep.html#cb715-46" aria-hidden="true" tabindex="-1"></a>  pred_test <span class="ot">=</span> <span class="fu">predict</span>(model, <span class="fu">as.matrix</span>(sub_test <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>Hazardous)))</span>
<span id="cb715-47"><a href="deep.html#cb715-47" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb715-48"><a href="deep.html#cb715-48" aria-hidden="true" tabindex="-1"></a>  result[i, <span class="dv">1</span>] <span class="ot">=</span> Metrics<span class="sc">::</span><span class="fu">auc</span>(sub_train<span class="sc">$</span>Hazardous, pred_train)</span>
<span id="cb715-49"><a href="deep.html#cb715-49" aria-hidden="true" tabindex="-1"></a>  result[i, <span class="dv">2</span>] <span class="ot">=</span> Metrics<span class="sc">::</span><span class="fu">auc</span>(sub_test<span class="sc">$</span>Hazardous, pred_test)</span>
<span id="cb715-50"><a href="deep.html#cb715-50" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb715-51"><a href="deep.html#cb715-51" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(result)</span></code></pre></div>
<pre><code>##       train_auc  test_auc
##  [1,] 0.9971340 0.9620596
##  [2,] 0.9906766 0.9955556
##  [3,] 0.9927448 0.9866667
##  [4,] 0.9953474 0.9625000
##  [5,] 0.9927027 0.9285714
##  [6,] 0.9948311 0.8839286
##  [7,] 0.9900084 0.9912281
##  [8,] 0.9926644 1.0000000
##  [9,] 0.9923088 0.9543651
## [10,] 0.9901014 0.9821429</code></pre>
<div class="sourceCode" id="cb717"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb717-1"><a href="deep.html#cb717-1" aria-hidden="true" tabindex="-1"></a>(<span class="fu">colMeans</span>(result))</span></code></pre></div>
<pre><code>## train_auc  test_auc 
## 0.9928520 0.9647018</code></pre>
<div class="sourceCode" id="cb719"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb719-1"><a href="deep.html#cb719-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb719-2"><a href="deep.html#cb719-2" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb719-3"><a href="deep.html#cb719-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>,</span>
<span id="cb719-4"><a href="deep.html#cb719-4" aria-hidden="true" tabindex="-1"></a>             <span class="at">input_shape =</span> <span class="fu">ncol</span>(sub_train) <span class="sc">-</span> 1L) <span class="sc">%&gt;%</span></span>
<span id="cb719-5"><a href="deep.html#cb719-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="at">rate =</span> <span class="fl">0.45</span>) <span class="sc">%&gt;%</span></span>
<span id="cb719-6"><a href="deep.html#cb719-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 50L, <span class="at">activation =</span> <span class="st">&quot;gelu&quot;</span>,</span>
<span id="cb719-7"><a href="deep.html#cb719-7" aria-hidden="true" tabindex="-1"></a>              <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1</span>(.<span class="dv">00125</span>),</span>
<span id="cb719-8"><a href="deep.html#cb719-8" aria-hidden="true" tabindex="-1"></a>              <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l1_l2</span>(.<span class="dv">25</span>)</span>
<span id="cb719-9"><a href="deep.html#cb719-9" aria-hidden="true" tabindex="-1"></a>              ) <span class="sc">%&gt;%</span></span>
<span id="cb719-10"><a href="deep.html#cb719-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="at">rate =</span> <span class="fl">0.35</span>) <span class="sc">%&gt;%</span></span>
<span id="cb719-11"><a href="deep.html#cb719-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 30L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb719-12"><a href="deep.html#cb719-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="at">rate =</span> <span class="fl">0.3</span>) <span class="sc">%&gt;%</span></span>
<span id="cb719-13"><a href="deep.html#cb719-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;sigmoid&quot;</span>)</span>
<span id="cb719-14"><a href="deep.html#cb719-14" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb719-15"><a href="deep.html#cb719-15" aria-hidden="true" tabindex="-1"></a>  early_stopping <span class="ot">=</span> <span class="fu">callback_early_stopping</span>(<span class="at">monitor =</span> <span class="st">&quot;val_loss&quot;</span>, <span class="at">patience =</span> 8L)</span>
<span id="cb719-16"><a href="deep.html#cb719-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># You need a validation split for this!</span></span>
<span id="cb719-17"><a href="deep.html#cb719-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb719-18"><a href="deep.html#cb719-18" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb719-19"><a href="deep.html#cb719-19" aria-hidden="true" tabindex="-1"></a>  keras<span class="sc">::</span><span class="fu">compile</span>(<span class="at">loss =</span> loss_binary_crossentropy, </span>
<span id="cb719-20"><a href="deep.html#cb719-20" aria-hidden="true" tabindex="-1"></a>                 <span class="at">optimizer =</span> <span class="fu">optimizer_adamax</span>(<span class="fl">0.0072</span>))</span>
<span id="cb719-21"><a href="deep.html#cb719-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb719-22"><a href="deep.html#cb719-22" aria-hidden="true" tabindex="-1"></a>  model_history <span class="ot">=</span> </span>
<span id="cb719-23"><a href="deep.html#cb719-23" aria-hidden="true" tabindex="-1"></a>   model <span class="sc">%&gt;%</span></span>
<span id="cb719-24"><a href="deep.html#cb719-24" aria-hidden="true" tabindex="-1"></a>     <span class="fu">fit</span>(</span>
<span id="cb719-25"><a href="deep.html#cb719-25" aria-hidden="true" tabindex="-1"></a>        <span class="at">x =</span> <span class="fu">as.matrix</span>(train <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>Hazardous)),</span>
<span id="cb719-26"><a href="deep.html#cb719-26" aria-hidden="true" tabindex="-1"></a>        <span class="at">y =</span> <span class="fu">as.matrix</span>(train <span class="sc">%&gt;%</span> <span class="fu">select</span>(Hazardous)),</span>
<span id="cb719-27"><a href="deep.html#cb719-27" aria-hidden="true" tabindex="-1"></a>        <span class="at">callbacks =</span> <span class="fu">c</span>(early_stopping),</span>
<span id="cb719-28"><a href="deep.html#cb719-28" aria-hidden="true" tabindex="-1"></a>        <span class="at">validation_split =</span> <span class="fl">0.2</span>,</span>
<span id="cb719-29"><a href="deep.html#cb719-29" aria-hidden="true" tabindex="-1"></a>        <span class="at">epochs =</span> 50L, <span class="at">batch =</span> 50L, <span class="at">shuffle =</span> <span class="cn">TRUE</span></span>
<span id="cb719-30"><a href="deep.html#cb719-30" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb719-31"><a href="deep.html#cb719-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb719-32"><a href="deep.html#cb719-32" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">predict</span>(model, <span class="fu">as.matrix</span>(test[,<span class="sc">-</span><span class="dv">1</span>])))</span>
<span id="cb719-33"><a href="deep.html#cb719-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb719-34"><a href="deep.html#cb719-34" aria-hidden="true" tabindex="-1"></a><span class="fu">write.csv</span>(<span class="fu">data.frame</span>(<span class="at">y =</span> pred), <span class="at">file =</span> <span class="st">&quot;submission_DNN_optimal.csv&quot;</span>)</span></code></pre></div>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
</div>
<div id="case-study-fitting-a-convolutional-neural-network-on-mnist" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> Case Study: Fitting a Convolutional Neural Network on MNIST</h2>
<p>We will show the use of convolutional neural networks with the MNIST data set. This data set is maybe one of the most famous image data sets. It consists of 60,000 handwritten digits from 0-9.</p>
<p>To do so, we define a few helper functions:</p>
<div class="sourceCode" id="cb720"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb720-1"><a href="deep.html#cb720-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb720-2"><a href="deep.html#cb720-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb720-3"><a href="deep.html#cb720-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb720-4"><a href="deep.html#cb720-4" aria-hidden="true" tabindex="-1"></a>rotate <span class="ot">=</span> <span class="cf">function</span>(x){ <span class="fu">t</span>(<span class="fu">apply</span>(x, <span class="dv">2</span>, rev)) }</span>
<span id="cb720-5"><a href="deep.html#cb720-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb720-6"><a href="deep.html#cb720-6" aria-hidden="true" tabindex="-1"></a>imgPlot <span class="ot">=</span> <span class="cf">function</span>(img, <span class="at">title =</span> <span class="st">&quot;&quot;</span>){</span>
<span id="cb720-7"><a href="deep.html#cb720-7" aria-hidden="true" tabindex="-1"></a>  col <span class="ot">=</span> <span class="fu">grey.colors</span>(<span class="dv">255</span>)</span>
<span id="cb720-8"><a href="deep.html#cb720-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">image</span>(<span class="fu">rotate</span>(img), <span class="at">col =</span> col, <span class="at">xlab =</span> <span class="st">&quot;&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;&quot;</span>, <span class="at">axes =</span> <span class="cn">FALSE</span>,</span>
<span id="cb720-9"><a href="deep.html#cb720-9" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="fu">paste0</span>(<span class="st">&quot;Label: &quot;</span>, <span class="fu">as.character</span>(title)))</span>
<span id="cb720-10"><a href="deep.html#cb720-10" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>The MNIST data set is so famous that there is an automatic download function in Keras:</p>
<div class="sourceCode" id="cb721"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb721-1"><a href="deep.html#cb721-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">dataset_mnist</span>()</span>
<span id="cb721-2"><a href="deep.html#cb721-2" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> data<span class="sc">$</span>train</span>
<span id="cb721-3"><a href="deep.html#cb721-3" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> data<span class="sc">$</span>test</span></code></pre></div>
<p>Let’s visualize a few digits:</p>
<div class="sourceCode" id="cb722"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb722-1"><a href="deep.html#cb722-1" aria-hidden="true" tabindex="-1"></a>oldpar <span class="ot">=</span> <span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb722-2"><a href="deep.html#cb722-2" aria-hidden="true" tabindex="-1"></a>.n <span class="ot">=</span> <span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="cf">function</span>(x) <span class="fu">imgPlot</span>(train<span class="sc">$</span>x[x,,], train<span class="sc">$</span>y[x]))</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter5_11-1.png" width="672" /></p>
<div class="sourceCode" id="cb723"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb723-1"><a href="deep.html#cb723-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(oldpar)</span></code></pre></div>
<p>Similar to the normal machine learning workflow, we have to scale the pixels (from 0-255) to the range of <span class="math inline">\([0, 1]\)</span> and one hot encode the response. For scaling the pixels, we will use arrays instead of matrices. Arrays are called tensors in mathematics and a 2D array/tensor is typically called a matrix.</p>
<div class="sourceCode" id="cb724"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb724-1"><a href="deep.html#cb724-1" aria-hidden="true" tabindex="-1"></a>train_x <span class="ot">=</span> <span class="fu">array</span>(train<span class="sc">$</span>x<span class="sc">/</span><span class="dv">255</span>, <span class="fu">c</span>(<span class="fu">dim</span>(train<span class="sc">$</span>x), <span class="dv">1</span>))</span>
<span id="cb724-2"><a href="deep.html#cb724-2" aria-hidden="true" tabindex="-1"></a>test_x <span class="ot">=</span> <span class="fu">array</span>(test<span class="sc">$</span>x<span class="sc">/</span><span class="dv">255</span>, <span class="fu">c</span>(<span class="fu">dim</span>(test<span class="sc">$</span>x), <span class="dv">1</span>))</span>
<span id="cb724-3"><a href="deep.html#cb724-3" aria-hidden="true" tabindex="-1"></a>train_y <span class="ot">=</span> <span class="fu">to_categorical</span>(train<span class="sc">$</span>y, <span class="dv">10</span>)</span>
<span id="cb724-4"><a href="deep.html#cb724-4" aria-hidden="true" tabindex="-1"></a>test_y <span class="ot">=</span> <span class="fu">to_categorical</span>(test<span class="sc">$</span>y, <span class="dv">10</span>)</span></code></pre></div>
<p>The last dimension denotes the number of channels in the image. In our case we have only one channel because the images are black and white.</p>
<p>Most times, we would have at least 3 color channels, for example RGB (red, green, blue) or HSV (hue, saturation, value), sometimes with several additional dimensions like transparency.</p>
<p>To build our convolutional model, we have to specify a kernel. In our case, we will use 16 convolutional kernels (filters) of size <span class="math inline">\(2\times2\)</span>. These are 2D kernels because our images are 2D. For movies for example, one would use 3D kernels (the third dimension would correspond to time and not to the color channels).</p>
<div class="sourceCode" id="cb725"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb725-1"><a href="deep.html#cb725-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb725-2"><a href="deep.html#cb725-2" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb725-3"><a href="deep.html#cb725-3" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_conv_2d</span>(<span class="at">input_shape =</span> <span class="fu">c</span>(28L, 28L, 1L), <span class="at">filters =</span> 16L,</span>
<span id="cb725-4"><a href="deep.html#cb725-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">kernel_size =</span> <span class="fu">c</span>(2L, 2L), <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb725-5"><a href="deep.html#cb725-5" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span></span>
<span id="cb725-6"><a href="deep.html#cb725-6" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> 16L, <span class="at">kernel_size =</span> <span class="fu">c</span>(3L, 3L), <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb725-7"><a href="deep.html#cb725-7" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span></span>
<span id="cb725-8"><a href="deep.html#cb725-8" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_flatten</span>() <span class="sc">%&gt;%</span></span>
<span id="cb725-9"><a href="deep.html#cb725-9" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_dense</span>(100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb725-10"><a href="deep.html#cb725-10" aria-hidden="true" tabindex="-1"></a> <span class="fu">layer_dense</span>(10L, <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>)</span>
<span id="cb725-11"><a href="deep.html#cb725-11" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## Model: &quot;sequential_41&quot;
## ____________________________________________________________________________________________________________________
##  Layer (type)                                       Output Shape                                  Param #           
## ====================================================================================================================
##  conv2d_1 (Conv2D)                                  (None, 27, 27, 16)                            80                
##                                                                                                                     
##  max_pooling2d_1 (MaxPooling2D)                     (None, 13, 13, 16)                            0                 
##                                                                                                                     
##  conv2d (Conv2D)                                    (None, 11, 11, 16)                            2320              
##                                                                                                                     
##  max_pooling2d (MaxPooling2D)                       (None, 5, 5, 16)                              0                 
##                                                                                                                     
##  flatten (Flatten)                                  (None, 400)                                   0                 
##                                                                                                                     
##  dense_152 (Dense)                                  (None, 100)                                   40100             
##                                                                                                                     
##  dense_151 (Dense)                                  (None, 10)                                    1010              
##                                                                                                                     
## ====================================================================================================================
## Total params: 43,510
## Trainable params: 43,510
## Non-trainable params: 0
## ____________________________________________________________________________________________________________________</code></pre>
<p>We additionally used a pooling layer for downsizing the resulting feature maps.
Without further specification, a <span class="math inline">\(2\times2\)</span> pooling layer is taken automatically.
Pooling layers take the input feature map and divide it into (in our case) parts of <span class="math inline">\(2\times2\)</span> size. Then the respective pooling operation is executed.
For every input map/layer, you get one (downsized) output map/layer.</p>
<p>As we are using the max pooling layer (there are sever other methods like the mean pooling), only the maximum value of these 4 parts is taken and forwarded further.
Example input:</p>
<pre><code>1   2   |   5   8   |   3   6
6   5   |   2   4   |   8   1
------------------------------
9   4   |   3   7   |   2   5
0   3   |   2   7   |   4   9</code></pre>
<p>We use max pooling for every field:</p>
<pre><code>max(1, 2, 6, 5)   |   max(5, 8, 2, 4)   |   max(3, 6, 8, 1)
-----------------------------------------------------------
max(9, 4, 0, 3)   |   max(3, 7, 2, 7)   |   max(2, 5, 4, 9)</code></pre>
<p>So the resulting pooled information is:</p>
<pre><code>6   |   8   |   8
------------------
9   |   7   |   9</code></pre>
<p>In this example, a <span class="math inline">\(4\times6\)</span> layer was transformed to a <span class="math inline">\(2\times3\)</span> layer and thus downsized.
This is similar to the biological process called <em>lateral inhibition</em> where active neurons inhibit the activity of neighboring neurons.
It’s a loss of information but often very useful for aggregating information and prevent overfitting.</p>
<p>After another convolutional and pooling layer we flatten the output. That means the following dense layer treats the previous layer as a full layer (so the dense layer is connected to all weights from the last feature maps). You can imagine that like reshaping a matrix (2D) to a simple 1D vector. Then the full vector is used.
Having flattened the layer, we can simply use our typical output layer.</p>
<details>
<summary>
<strong><span style="color: #CC2FAA;">Torch</span></strong>
</summary>
<p>
<p>Prepare/download data:</p>
<div class="sourceCode" id="cb730"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb730-1"><a href="deep.html#cb730-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb730-2"><a href="deep.html#cb730-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torchvision)</span>
<span id="cb730-3"><a href="deep.html#cb730-3" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_manual_seed</span>(321L)</span>
<span id="cb730-4"><a href="deep.html#cb730-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb730-5"><a href="deep.html#cb730-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb730-6"><a href="deep.html#cb730-6" aria-hidden="true" tabindex="-1"></a>train_ds <span class="ot">=</span> <span class="fu">mnist_dataset</span>(</span>
<span id="cb730-7"><a href="deep.html#cb730-7" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;.&quot;</span>,</span>
<span id="cb730-8"><a href="deep.html#cb730-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">download =</span> <span class="cn">TRUE</span>,</span>
<span id="cb730-9"><a href="deep.html#cb730-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">train =</span> <span class="cn">TRUE</span>,</span>
<span id="cb730-10"><a href="deep.html#cb730-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">transform =</span> transform_to_tensor</span>
<span id="cb730-11"><a href="deep.html#cb730-11" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## Processing...</code></pre>
<pre><code>## Done!</code></pre>
<div class="sourceCode" id="cb733"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb733-1"><a href="deep.html#cb733-1" aria-hidden="true" tabindex="-1"></a>test_ds <span class="ot">=</span> <span class="fu">mnist_dataset</span>(</span>
<span id="cb733-2"><a href="deep.html#cb733-2" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;.&quot;</span>,</span>
<span id="cb733-3"><a href="deep.html#cb733-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">download =</span> <span class="cn">TRUE</span>,</span>
<span id="cb733-4"><a href="deep.html#cb733-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">train =</span> <span class="cn">FALSE</span>,</span>
<span id="cb733-5"><a href="deep.html#cb733-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">transform =</span> transform_to_tensor</span>
<span id="cb733-6"><a href="deep.html#cb733-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>Build dataloader:</p>
<div class="sourceCode" id="cb734"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb734-1"><a href="deep.html#cb734-1" aria-hidden="true" tabindex="-1"></a>train_dl <span class="ot">=</span> <span class="fu">dataloader</span>(train_ds, <span class="at">batch_size =</span> <span class="dv">32</span>, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb734-2"><a href="deep.html#cb734-2" aria-hidden="true" tabindex="-1"></a>test_dl <span class="ot">=</span> <span class="fu">dataloader</span>(test_ds, <span class="at">batch_size =</span> <span class="dv">32</span>)</span>
<span id="cb734-3"><a href="deep.html#cb734-3" aria-hidden="true" tabindex="-1"></a>first_batch <span class="ot">=</span> train_dl<span class="sc">$</span><span class="fu">.iter</span>()</span>
<span id="cb734-4"><a href="deep.html#cb734-4" aria-hidden="true" tabindex="-1"></a>df <span class="ot">=</span> first_batch<span class="sc">$</span><span class="fu">.next</span>()</span>
<span id="cb734-5"><a href="deep.html#cb734-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb734-6"><a href="deep.html#cb734-6" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>x<span class="sc">$</span><span class="fu">size</span>()</span></code></pre></div>
<pre><code>## [1] 32  1 28 28</code></pre>
<p>Build convolutional neural network:
We have here to calculate the shapes of our layers on our own:</p>
<p><strong>We start with our input of shape (batch_size, 1, 28, 28)</strong></p>
<div class="sourceCode" id="cb736"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb736-1"><a href="deep.html#cb736-1" aria-hidden="true" tabindex="-1"></a>sample <span class="ot">=</span> df<span class="sc">$</span>x</span>
<span id="cb736-2"><a href="deep.html#cb736-2" aria-hidden="true" tabindex="-1"></a>sample<span class="sc">$</span><span class="fu">size</span>()</span></code></pre></div>
<pre><code>## [1] 32  1 28 28</code></pre>
<p><strong>First convolutional layer has shape (input channel = 1, number of feature maps = 16, kernel size = 2)</strong></p>
<div class="sourceCode" id="cb738"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb738-1"><a href="deep.html#cb738-1" aria-hidden="true" tabindex="-1"></a>conv1 <span class="ot">=</span> <span class="fu">nn_conv2d</span>(<span class="dv">1</span>, 16L, 2L, <span class="at">stride =</span> 1L)</span>
<span id="cb738-2"><a href="deep.html#cb738-2" aria-hidden="true" tabindex="-1"></a>(sample <span class="sc">%&gt;%</span> conv1)<span class="sc">$</span><span class="fu">size</span>()</span></code></pre></div>
<pre><code>## [1] 32 16 27 27</code></pre>
<p>Output: batch_size = 32, number of feature maps = 16, dimensions of each feature map = <span class="math inline">\((27 , 27)\)</span>
Wit a kernel size of two and stride = 1 we will lose one pixel in each dimension…
Questions:</p>
<ul>
<li>What happens if we increase the stride?</li>
<li>What happens if we increase the kernel size?</li>
</ul>
<p><strong>Pooling layer summarizes each feature map</strong></p>
<div class="sourceCode" id="cb740"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb740-1"><a href="deep.html#cb740-1" aria-hidden="true" tabindex="-1"></a>(sample <span class="sc">%&gt;%</span> conv1 <span class="sc">%&gt;%</span> <span class="fu">nnf_max_pool2d</span>(<span class="at">kernel_size =</span> 2L, <span class="at">stride =</span> 2L))<span class="sc">$</span><span class="fu">size</span>()</span></code></pre></div>
<pre><code>## [1] 32 16 13 13</code></pre>
<p>kernel_size = 2L and stride = 2L halfs the pixel dimensions of our image.</p>
<p><strong>Fully connected layer</strong></p>
<p>Now we have to flatten our final output of the convolutional neural network model to use a normal fully connected layer, but to do so we have to calculate the number of inputs for the fully connected layer:</p>
<div class="sourceCode" id="cb742"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb742-1"><a href="deep.html#cb742-1" aria-hidden="true" tabindex="-1"></a>dims <span class="ot">=</span> (sample <span class="sc">%&gt;%</span> conv1 <span class="sc">%&gt;%</span></span>
<span id="cb742-2"><a href="deep.html#cb742-2" aria-hidden="true" tabindex="-1"></a>          <span class="fu">nnf_max_pool2d</span>(<span class="at">kernel_size =</span> 2L, <span class="at">stride =</span> 2L))<span class="sc">$</span><span class="fu">size</span>()</span>
<span id="cb742-3"><a href="deep.html#cb742-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Without the batch size of course.</span></span>
<span id="cb742-4"><a href="deep.html#cb742-4" aria-hidden="true" tabindex="-1"></a>final <span class="ot">=</span> <span class="fu">prod</span>(dims[<span class="sc">-</span><span class="dv">1</span>]) </span>
<span id="cb742-5"><a href="deep.html#cb742-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(final)</span></code></pre></div>
<pre><code>## [1] 2704</code></pre>
<div class="sourceCode" id="cb744"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb744-1"><a href="deep.html#cb744-1" aria-hidden="true" tabindex="-1"></a>fc <span class="ot">=</span> <span class="fu">nn_linear</span>(final, 10L)</span>
<span id="cb744-2"><a href="deep.html#cb744-2" aria-hidden="true" tabindex="-1"></a>(sample <span class="sc">%&gt;%</span> conv1 <span class="sc">%&gt;%</span> <span class="fu">nnf_max_pool2d</span>(<span class="at">kernel_size =</span> 2L, <span class="at">stride =</span> 2L)</span>
<span id="cb744-3"><a href="deep.html#cb744-3" aria-hidden="true" tabindex="-1"></a>  <span class="sc">%&gt;%</span> <span class="fu">torch_flatten</span>(<span class="at">start_dim =</span> 2L) <span class="sc">%&gt;%</span> fc)<span class="sc">$</span><span class="fu">size</span>()</span></code></pre></div>
<pre><code>## [1] 32 10</code></pre>
<p>Build the network:</p>
<div class="sourceCode" id="cb746"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb746-1"><a href="deep.html#cb746-1" aria-hidden="true" tabindex="-1"></a>net <span class="ot">=</span> <span class="fu">nn_module</span>(</span>
<span id="cb746-2"><a href="deep.html#cb746-2" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;mnist&quot;</span>,</span>
<span id="cb746-3"><a href="deep.html#cb746-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">initialize =</span> <span class="cf">function</span>(){</span>
<span id="cb746-4"><a href="deep.html#cb746-4" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>conv1 <span class="ot">=</span> <span class="fu">nn_conv2d</span>(<span class="dv">1</span>, 16L, 2L)</span>
<span id="cb746-5"><a href="deep.html#cb746-5" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>conv2 <span class="ot">=</span> <span class="fu">nn_conv2d</span>(16L, 16L, 3L)</span>
<span id="cb746-6"><a href="deep.html#cb746-6" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>fc1 <span class="ot">=</span> <span class="fu">nn_linear</span>(400L, 100L)</span>
<span id="cb746-7"><a href="deep.html#cb746-7" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>fc2 <span class="ot">=</span> <span class="fu">nn_linear</span>(100L, 10L)</span>
<span id="cb746-8"><a href="deep.html#cb746-8" aria-hidden="true" tabindex="-1"></a>  },</span>
<span id="cb746-9"><a href="deep.html#cb746-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">forward =</span> <span class="cf">function</span>(x){</span>
<span id="cb746-10"><a href="deep.html#cb746-10" aria-hidden="true" tabindex="-1"></a>    x <span class="sc">%&gt;%</span></span>
<span id="cb746-11"><a href="deep.html#cb746-11" aria-hidden="true" tabindex="-1"></a>      self<span class="sc">$</span><span class="fu">conv1</span>() <span class="sc">%&gt;%</span></span>
<span id="cb746-12"><a href="deep.html#cb746-12" aria-hidden="true" tabindex="-1"></a>      <span class="fu">nnf_relu</span>() <span class="sc">%&gt;%</span></span>
<span id="cb746-13"><a href="deep.html#cb746-13" aria-hidden="true" tabindex="-1"></a>      <span class="fu">nnf_max_pool2d</span>(<span class="dv">2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb746-14"><a href="deep.html#cb746-14" aria-hidden="true" tabindex="-1"></a>      self<span class="sc">$</span><span class="fu">conv2</span>() <span class="sc">%&gt;%</span></span>
<span id="cb746-15"><a href="deep.html#cb746-15" aria-hidden="true" tabindex="-1"></a>      <span class="fu">nnf_relu</span>() <span class="sc">%&gt;%</span></span>
<span id="cb746-16"><a href="deep.html#cb746-16" aria-hidden="true" tabindex="-1"></a>      <span class="fu">nnf_max_pool2d</span>(<span class="dv">2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb746-17"><a href="deep.html#cb746-17" aria-hidden="true" tabindex="-1"></a>      <span class="fu">torch_flatten</span>(<span class="at">start_dim =</span> <span class="dv">2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb746-18"><a href="deep.html#cb746-18" aria-hidden="true" tabindex="-1"></a>      self<span class="sc">$</span><span class="fu">fc1</span>() <span class="sc">%&gt;%</span></span>
<span id="cb746-19"><a href="deep.html#cb746-19" aria-hidden="true" tabindex="-1"></a>      <span class="fu">nnf_relu</span>() <span class="sc">%&gt;%</span></span>
<span id="cb746-20"><a href="deep.html#cb746-20" aria-hidden="true" tabindex="-1"></a>      self<span class="sc">$</span><span class="fu">fc2</span>()</span>
<span id="cb746-21"><a href="deep.html#cb746-21" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb746-22"><a href="deep.html#cb746-22" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</p>
</details>
<p><br/></p>
<p>The rest is as usual: First we compile the model.</p>
<div class="sourceCode" id="cb747"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb747-1"><a href="deep.html#cb747-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb747-2"><a href="deep.html#cb747-2" aria-hidden="true" tabindex="-1"></a>  keras<span class="sc">::</span><span class="fu">compile</span>(</span>
<span id="cb747-3"><a href="deep.html#cb747-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">optimizer =</span> keras<span class="sc">::</span><span class="fu">optimizer_adamax</span>(<span class="fl">0.01</span>),</span>
<span id="cb747-4"><a href="deep.html#cb747-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">loss =</span> loss_categorical_crossentropy</span>
<span id="cb747-5"><a href="deep.html#cb747-5" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb747-6"><a href="deep.html#cb747-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## Model: &quot;sequential_41&quot;
## ____________________________________________________________________________________________________________________
##  Layer (type)                                       Output Shape                                  Param #           
## ====================================================================================================================
##  conv2d_1 (Conv2D)                                  (None, 27, 27, 16)                            80                
##                                                                                                                     
##  max_pooling2d_1 (MaxPooling2D)                     (None, 13, 13, 16)                            0                 
##                                                                                                                     
##  conv2d (Conv2D)                                    (None, 11, 11, 16)                            2320              
##                                                                                                                     
##  max_pooling2d (MaxPooling2D)                       (None, 5, 5, 16)                              0                 
##                                                                                                                     
##  flatten (Flatten)                                  (None, 400)                                   0                 
##                                                                                                                     
##  dense_152 (Dense)                                  (None, 100)                                   40100             
##                                                                                                                     
##  dense_151 (Dense)                                  (None, 10)                                    1010              
##                                                                                                                     
## ====================================================================================================================
## Total params: 43,510
## Trainable params: 43,510
## Non-trainable params: 0
## ____________________________________________________________________________________________________________________</code></pre>
<p>Then, we train the model:</p>
<div class="sourceCode" id="cb749"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb749-1"><a href="deep.html#cb749-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb749-2"><a href="deep.html#cb749-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb749-3"><a href="deep.html#cb749-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb749-4"><a href="deep.html#cb749-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb749-5"><a href="deep.html#cb749-5" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> 5L</span>
<span id="cb749-6"><a href="deep.html#cb749-6" aria-hidden="true" tabindex="-1"></a>batch_size <span class="ot">=</span> 32L</span>
<span id="cb749-7"><a href="deep.html#cb749-7" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb749-8"><a href="deep.html#cb749-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(</span>
<span id="cb749-9"><a href="deep.html#cb749-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> train_x, </span>
<span id="cb749-10"><a href="deep.html#cb749-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> train_y,</span>
<span id="cb749-11"><a href="deep.html#cb749-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">epochs =</span> epochs,</span>
<span id="cb749-12"><a href="deep.html#cb749-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">batch_size =</span> batch_size,</span>
<span id="cb749-13"><a href="deep.html#cb749-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">shuffle =</span> <span class="cn">TRUE</span>,</span>
<span id="cb749-14"><a href="deep.html#cb749-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">validation_split =</span> <span class="fl">0.2</span></span>
<span id="cb749-15"><a href="deep.html#cb749-15" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<details>
<summary>
<strong><span style="color: #CC2FAA;">Torch</span></strong>
</summary>
<p>
<pre><code>Train model:</code></pre>
<div class="sourceCode" id="cb751"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb751-1"><a href="deep.html#cb751-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb751-2"><a href="deep.html#cb751-2" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_manual_seed</span>(321L)</span>
<span id="cb751-3"><a href="deep.html#cb751-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb751-4"><a href="deep.html#cb751-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb751-5"><a href="deep.html#cb751-5" aria-hidden="true" tabindex="-1"></a>model_torch <span class="ot">=</span> <span class="fu">net</span>()</span>
<span id="cb751-6"><a href="deep.html#cb751-6" aria-hidden="true" tabindex="-1"></a>opt <span class="ot">=</span> <span class="fu">optim_adam</span>(<span class="at">params =</span> model_torch<span class="sc">$</span>parameters, <span class="at">lr =</span> <span class="fl">0.01</span>)</span>
<span id="cb751-7"><a href="deep.html#cb751-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb751-8"><a href="deep.html#cb751-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(e <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>){</span>
<span id="cb751-9"><a href="deep.html#cb751-9" aria-hidden="true" tabindex="-1"></a>  losses <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb751-10"><a href="deep.html#cb751-10" aria-hidden="true" tabindex="-1"></a>  coro<span class="sc">::</span><span class="fu">loop</span>(</span>
<span id="cb751-11"><a href="deep.html#cb751-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(batch <span class="cf">in</span> train_dl){</span>
<span id="cb751-12"><a href="deep.html#cb751-12" aria-hidden="true" tabindex="-1"></a>      opt<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb751-13"><a href="deep.html#cb751-13" aria-hidden="true" tabindex="-1"></a>      pred <span class="ot">=</span> <span class="fu">model_torch</span>(batch[[<span class="dv">1</span>]])</span>
<span id="cb751-14"><a href="deep.html#cb751-14" aria-hidden="true" tabindex="-1"></a>      loss <span class="ot">=</span> <span class="fu">nnf_cross_entropy</span>(pred, batch[[<span class="dv">2</span>]], <span class="at">reduction =</span> <span class="st">&quot;mean&quot;</span>)</span>
<span id="cb751-15"><a href="deep.html#cb751-15" aria-hidden="true" tabindex="-1"></a>      loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb751-16"><a href="deep.html#cb751-16" aria-hidden="true" tabindex="-1"></a>      opt<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb751-17"><a href="deep.html#cb751-17" aria-hidden="true" tabindex="-1"></a>      losses <span class="ot">=</span> <span class="fu">c</span>(losses, loss<span class="sc">$</span><span class="fu">item</span>())</span>
<span id="cb751-18"><a href="deep.html#cb751-18" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb751-19"><a href="deep.html#cb751-19" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb751-20"><a href="deep.html#cb751-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">&quot;Loss at epoch %d: %3f</span><span class="sc">\n</span><span class="st">&quot;</span>, e, <span class="fu">mean</span>(losses)))</span>
<span id="cb751-21"><a href="deep.html#cb751-21" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<pre><code>Evaluation:</code></pre>
<div class="sourceCode" id="cb753"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb753-1"><a href="deep.html#cb753-1" aria-hidden="true" tabindex="-1"></a>model_torch<span class="sc">$</span><span class="fu">eval</span>()</span>
<span id="cb753-2"><a href="deep.html#cb753-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb753-3"><a href="deep.html#cb753-3" aria-hidden="true" tabindex="-1"></a>test_losses <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb753-4"><a href="deep.html#cb753-4" aria-hidden="true" tabindex="-1"></a>total <span class="ot">=</span> <span class="dv">0</span></span>
<span id="cb753-5"><a href="deep.html#cb753-5" aria-hidden="true" tabindex="-1"></a>correct <span class="ot">=</span> <span class="dv">0</span></span>
<span id="cb753-6"><a href="deep.html#cb753-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb753-7"><a href="deep.html#cb753-7" aria-hidden="true" tabindex="-1"></a>coro<span class="sc">::</span><span class="fu">loop</span>(</span>
<span id="cb753-8"><a href="deep.html#cb753-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(batch <span class="cf">in</span> test_dl){</span>
<span id="cb753-9"><a href="deep.html#cb753-9" aria-hidden="true" tabindex="-1"></a>    output <span class="ot">=</span> <span class="fu">model_torch</span>(batch[[<span class="dv">1</span>]])</span>
<span id="cb753-10"><a href="deep.html#cb753-10" aria-hidden="true" tabindex="-1"></a>    labels <span class="ot">=</span> batch[[<span class="dv">2</span>]]</span>
<span id="cb753-11"><a href="deep.html#cb753-11" aria-hidden="true" tabindex="-1"></a>    loss <span class="ot">=</span> <span class="fu">nnf_cross_entropy</span>(output, labels)</span>
<span id="cb753-12"><a href="deep.html#cb753-12" aria-hidden="true" tabindex="-1"></a>    test_losses <span class="ot">=</span> <span class="fu">c</span>(test_losses, loss<span class="sc">$</span><span class="fu">item</span>())</span>
<span id="cb753-13"><a href="deep.html#cb753-13" aria-hidden="true" tabindex="-1"></a>    predicted <span class="ot">=</span> <span class="fu">torch_max</span>(output<span class="sc">$</span><span class="fu">data</span>(), <span class="at">dim =</span> <span class="dv">2</span>)[[<span class="dv">2</span>]]</span>
<span id="cb753-14"><a href="deep.html#cb753-14" aria-hidden="true" tabindex="-1"></a>    total <span class="ot">=</span> total <span class="sc">+</span> labels<span class="sc">$</span><span class="fu">size</span>(<span class="dv">1</span>)</span>
<span id="cb753-15"><a href="deep.html#cb753-15" aria-hidden="true" tabindex="-1"></a>    correct <span class="ot">=</span> correct <span class="sc">+</span> (predicted <span class="sc">==</span> labels)<span class="sc">$</span><span class="fu">sum</span>()<span class="sc">$</span><span class="fu">item</span>()</span>
<span id="cb753-16"><a href="deep.html#cb753-16" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb753-17"><a href="deep.html#cb753-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb753-18"><a href="deep.html#cb753-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb753-19"><a href="deep.html#cb753-19" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(test_losses)</span>
<span id="cb753-20"><a href="deep.html#cb753-20" aria-hidden="true" tabindex="-1"></a>test_accuracy <span class="ot">=</span>  correct<span class="sc">/</span>total</span>
<span id="cb753-21"><a href="deep.html#cb753-21" aria-hidden="true" tabindex="-1"></a>test_accuracy</span></code></pre></div>
</p>
</details>
<p><br/></p>
</div>
<div id="advanced-training-techniques" class="section level2" number="5.4">
<h2><span class="header-section-number">5.4</span> Advanced Training Techniques</h2>
<div id="data-augmentation" class="section level3" number="5.4.1">
<h3><span class="header-section-number">5.4.1</span> Data Augmentation</h3>
<p>Having to train a convolutional neural network using very little data is a common problem. Data augmentation helps to artificially increase the number of images.</p>
<p>The idea is that a convolutional neural network learns specific structures such as edges from images. Rotating, adding noise, and zooming in and out will preserve the overall key structure we are interested in, but the model will see new images and has to search once again for the key structures.</p>
<p>Luckily, it is very easy to use data augmentation in Keras.</p>
<p>To show this, we will use our flower data set. We have to define a generator object (a specific object which infinitely draws samples from our data set). In the generator we can turn on the data augmentation.</p>
<div class="sourceCode" id="cb754"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb754-1"><a href="deep.html#cb754-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb754-2"><a href="deep.html#cb754-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb754-3"><a href="deep.html#cb754-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb754-4"><a href="deep.html#cb754-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb754-5"><a href="deep.html#cb754-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> EcoData<span class="sc">::</span><span class="fu">dataset_flower</span>()</span>
<span id="cb754-6"><a href="deep.html#cb754-6" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> data<span class="sc">$</span>train<span class="sc">/</span><span class="dv">255</span></span>
<span id="cb754-7"><a href="deep.html#cb754-7" aria-hidden="true" tabindex="-1"></a>labels <span class="ot">=</span> data<span class="sc">$</span>labels</span>
<span id="cb754-8"><a href="deep.html#cb754-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb754-9"><a href="deep.html#cb754-9" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb754-10"><a href="deep.html#cb754-10" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb754-11"><a href="deep.html#cb754-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filter =</span> 16L, <span class="at">kernel_size =</span> <span class="fu">c</span>(5L, 5L),</span>
<span id="cb754-12"><a href="deep.html#cb754-12" aria-hidden="true" tabindex="-1"></a>                <span class="at">input_shape =</span> <span class="fu">c</span>(80L, 80L, 3L), <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb754-13"><a href="deep.html#cb754-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span></span>
<span id="cb754-14"><a href="deep.html#cb754-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filter =</span> 32L, <span class="at">kernel_size =</span> <span class="fu">c</span>(3L, 3L),</span>
<span id="cb754-15"><a href="deep.html#cb754-15" aria-hidden="true" tabindex="-1"></a>                <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb754-16"><a href="deep.html#cb754-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span></span>
<span id="cb754-17"><a href="deep.html#cb754-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filter =</span> 64L, <span class="at">kernel_size =</span> <span class="fu">c</span>(3L, 3L),</span>
<span id="cb754-18"><a href="deep.html#cb754-18" aria-hidden="true" tabindex="-1"></a>                <span class="at">strides =</span> <span class="fu">c</span>(2L, 2L), <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb754-19"><a href="deep.html#cb754-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span></span>
<span id="cb754-20"><a href="deep.html#cb754-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_flatten</span>() <span class="sc">%&gt;%</span></span>
<span id="cb754-21"><a href="deep.html#cb754-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="fl">0.5</span>) <span class="sc">%&gt;%</span></span>
<span id="cb754-22"><a href="deep.html#cb754-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 5L, <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>)</span>
<span id="cb754-23"><a href="deep.html#cb754-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb754-24"><a href="deep.html#cb754-24" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb754-25"><a href="deep.html#cb754-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Data augmentation.</span></span>
<span id="cb754-26"><a href="deep.html#cb754-26" aria-hidden="true" tabindex="-1"></a>aug <span class="ot">=</span> <span class="fu">image_data_generator</span>(<span class="at">rotation_range =</span> <span class="dv">90</span>, </span>
<span id="cb754-27"><a href="deep.html#cb754-27" aria-hidden="true" tabindex="-1"></a>                           <span class="at">zoom_range =</span> <span class="fu">c</span>(<span class="fl">0.3</span>), </span>
<span id="cb754-28"><a href="deep.html#cb754-28" aria-hidden="true" tabindex="-1"></a>                           <span class="at">horizontal_flip =</span> <span class="cn">TRUE</span>, </span>
<span id="cb754-29"><a href="deep.html#cb754-29" aria-hidden="true" tabindex="-1"></a>                           <span class="at">vertical_flip =</span> <span class="cn">TRUE</span>)</span>
<span id="cb754-30"><a href="deep.html#cb754-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb754-31"><a href="deep.html#cb754-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Data preparation / splitting.</span></span>
<span id="cb754-32"><a href="deep.html#cb754-32" aria-hidden="true" tabindex="-1"></a>indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(train), <span class="fl">0.1</span> <span class="sc">*</span> <span class="fu">nrow</span>(train))</span>
<span id="cb754-33"><a href="deep.html#cb754-33" aria-hidden="true" tabindex="-1"></a>generator <span class="ot">=</span> <span class="fu">flow_images_from_data</span>(train[<span class="sc">-</span>indices,,,],</span>
<span id="cb754-34"><a href="deep.html#cb754-34" aria-hidden="true" tabindex="-1"></a>                                  <span class="fu">k_one_hot</span>(labels[<span class="sc">-</span>indices], <span class="at">num_classes =</span> 5L),</span>
<span id="cb754-35"><a href="deep.html#cb754-35" aria-hidden="true" tabindex="-1"></a>                                  <span class="at">generator =</span> aug,</span>
<span id="cb754-36"><a href="deep.html#cb754-36" aria-hidden="true" tabindex="-1"></a>                                  <span class="at">batch_size =</span> 25L,</span>
<span id="cb754-37"><a href="deep.html#cb754-37" aria-hidden="true" tabindex="-1"></a>                                  <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb754-38"><a href="deep.html#cb754-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb754-39"><a href="deep.html#cb754-39" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> train[indices,,,]</span>
<span id="cb754-40"><a href="deep.html#cb754-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb754-41"><a href="deep.html#cb754-41" aria-hidden="true" tabindex="-1"></a><span class="do">## Training loop with early stopping:</span></span>
<span id="cb754-42"><a href="deep.html#cb754-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb754-43"><a href="deep.html#cb754-43" aria-hidden="true" tabindex="-1"></a><span class="co"># As we use an iterator (the generator), validation loss is not applicable.</span></span>
<span id="cb754-44"><a href="deep.html#cb754-44" aria-hidden="true" tabindex="-1"></a><span class="co"># An available metric is the normal loss.</span></span>
<span id="cb754-45"><a href="deep.html#cb754-45" aria-hidden="true" tabindex="-1"></a>early <span class="ot">=</span> keras<span class="sc">::</span><span class="fu">callback_early_stopping</span>(<span class="at">patience =</span> 2L, <span class="at">monitor =</span> <span class="st">&quot;loss&quot;</span>)</span>
<span id="cb754-46"><a href="deep.html#cb754-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb754-47"><a href="deep.html#cb754-47" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb754-48"><a href="deep.html#cb754-48" aria-hidden="true" tabindex="-1"></a>    keras<span class="sc">::</span><span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb754-49"><a href="deep.html#cb754-49" aria-hidden="true" tabindex="-1"></a>                   <span class="at">optimizer =</span> keras<span class="sc">::</span><span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.01</span>))</span>
<span id="cb754-50"><a href="deep.html#cb754-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb754-51"><a href="deep.html#cb754-51" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb754-52"><a href="deep.html#cb754-52" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(generator, <span class="at">epochs =</span> 20L, <span class="at">batch_size =</span> 25L,</span>
<span id="cb754-53"><a href="deep.html#cb754-53" aria-hidden="true" tabindex="-1"></a>        <span class="at">shuffle =</span> <span class="cn">TRUE</span>, <span class="at">callbacks =</span> <span class="fu">c</span>(early))</span>
<span id="cb754-54"><a href="deep.html#cb754-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb754-55"><a href="deep.html#cb754-55" aria-hidden="true" tabindex="-1"></a><span class="co"># Predictions on the training set:</span></span>
<span id="cb754-56"><a href="deep.html#cb754-56" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">predict</span>(model, data<span class="sc">$</span>train[<span class="sc">-</span>indices,,,]) <span class="sc">%&gt;%</span> <span class="fu">apply</span>(<span class="dv">1</span>, which.max) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb754-57"><a href="deep.html#cb754-57" aria-hidden="true" tabindex="-1"></a>Metrics<span class="sc">::</span><span class="fu">accuracy</span>(pred, labels[<span class="sc">-</span>indices])</span>
<span id="cb754-58"><a href="deep.html#cb754-58" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(pred)</span>
<span id="cb754-59"><a href="deep.html#cb754-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb754-60"><a href="deep.html#cb754-60" aria-hidden="true" tabindex="-1"></a><span class="co"># Predictions on the holdout / test set:</span></span>
<span id="cb754-61"><a href="deep.html#cb754-61" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">predict</span>(model, test) <span class="sc">%&gt;%</span> <span class="fu">apply</span>(<span class="dv">1</span>, which.max) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb754-62"><a href="deep.html#cb754-62" aria-hidden="true" tabindex="-1"></a>Metrics<span class="sc">::</span><span class="fu">accuracy</span>(pred, labels[indices])</span>
<span id="cb754-63"><a href="deep.html#cb754-63" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(pred)</span>
<span id="cb754-64"><a href="deep.html#cb754-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb754-65"><a href="deep.html#cb754-65" aria-hidden="true" tabindex="-1"></a><span class="co"># If you want to predict on the holdout for submission, use:</span></span>
<span id="cb754-66"><a href="deep.html#cb754-66" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">predict</span>(model, EcoData<span class="sc">::</span><span class="fu">dataset_flower</span>()<span class="sc">$</span>test<span class="sc">/</span><span class="dv">255</span>) <span class="sc">%&gt;%</span></span>
<span id="cb754-67"><a href="deep.html#cb754-67" aria-hidden="true" tabindex="-1"></a>  <span class="fu">apply</span>(<span class="dv">1</span>, which.max) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb754-68"><a href="deep.html#cb754-68" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(pred)</span></code></pre></div>
<p>Using data augmentation we can artificially increase the number of images.</p>
<details>
<summary>
<strong><span style="color: #CC2FAA;">Torch</span></strong>
</summary>
<p>
<pre><code>In Torch, we have to change the transform function (but only for the train dataloader):</code></pre>
<div class="sourceCode" id="cb756"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb756-1"><a href="deep.html#cb756-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb756-2"><a href="deep.html#cb756-2" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_manual_seed</span>(321L)</span>
<span id="cb756-3"><a href="deep.html#cb756-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb756-4"><a href="deep.html#cb756-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb756-5"><a href="deep.html#cb756-5" aria-hidden="true" tabindex="-1"></a>train_transforms <span class="ot">=</span> <span class="cf">function</span>(img){</span>
<span id="cb756-6"><a href="deep.html#cb756-6" aria-hidden="true" tabindex="-1"></a>  img <span class="sc">%&gt;%</span></span>
<span id="cb756-7"><a href="deep.html#cb756-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">transform_to_tensor</span>() <span class="sc">%&gt;%</span></span>
<span id="cb756-8"><a href="deep.html#cb756-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">transform_random_horizontal_flip</span>(<span class="at">p =</span> <span class="fl">0.3</span>) <span class="sc">%&gt;%</span></span>
<span id="cb756-9"><a href="deep.html#cb756-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">transform_random_resized_crop</span>(<span class="at">size =</span> <span class="fu">c</span>(28L, 28L)) <span class="sc">%&gt;%</span></span>
<span id="cb756-10"><a href="deep.html#cb756-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">transform_random_vertical_flip</span>(<span class="fl">0.3</span>)</span>
<span id="cb756-11"><a href="deep.html#cb756-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb756-12"><a href="deep.html#cb756-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb756-13"><a href="deep.html#cb756-13" aria-hidden="true" tabindex="-1"></a>train_ds <span class="ot">=</span> <span class="fu">mnist_dataset</span>(<span class="st">&quot;.&quot;</span>, <span class="at">download =</span> <span class="cn">TRUE</span>, <span class="at">train =</span> <span class="cn">TRUE</span>,</span>
<span id="cb756-14"><a href="deep.html#cb756-14" aria-hidden="true" tabindex="-1"></a>                         <span class="at">transform =</span> train_transforms)</span>
<span id="cb756-15"><a href="deep.html#cb756-15" aria-hidden="true" tabindex="-1"></a>test_ds <span class="ot">=</span> <span class="fu">mnist_dataset</span>(<span class="st">&quot;.&quot;</span>, <span class="at">download =</span> <span class="cn">TRUE</span>, <span class="at">train =</span> <span class="cn">FALSE</span>,</span>
<span id="cb756-16"><a href="deep.html#cb756-16" aria-hidden="true" tabindex="-1"></a>                        <span class="at">transform =</span> transform_to_tensor)</span>
<span id="cb756-17"><a href="deep.html#cb756-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb756-18"><a href="deep.html#cb756-18" aria-hidden="true" tabindex="-1"></a>train_dl <span class="ot">=</span> <span class="fu">dataloader</span>(train_ds, <span class="at">batch_size =</span> 100L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb756-19"><a href="deep.html#cb756-19" aria-hidden="true" tabindex="-1"></a>test_dl <span class="ot">=</span> <span class="fu">dataloader</span>(test_ds, <span class="at">batch_size =</span> 100L)</span>
<span id="cb756-20"><a href="deep.html#cb756-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb756-21"><a href="deep.html#cb756-21" aria-hidden="true" tabindex="-1"></a>model_torch <span class="ot">=</span> <span class="fu">net</span>()</span>
<span id="cb756-22"><a href="deep.html#cb756-22" aria-hidden="true" tabindex="-1"></a>opt <span class="ot">=</span> <span class="fu">optim_adam</span>(<span class="at">params =</span> model_torch<span class="sc">$</span>parameters, <span class="at">lr =</span> <span class="fl">0.01</span>)</span>
<span id="cb756-23"><a href="deep.html#cb756-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb756-24"><a href="deep.html#cb756-24" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(e <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">1</span>){</span>
<span id="cb756-25"><a href="deep.html#cb756-25" aria-hidden="true" tabindex="-1"></a>  losses <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb756-26"><a href="deep.html#cb756-26" aria-hidden="true" tabindex="-1"></a>  coro<span class="sc">::</span><span class="fu">loop</span>(</span>
<span id="cb756-27"><a href="deep.html#cb756-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(batch <span class="cf">in</span> train_dl){</span>
<span id="cb756-28"><a href="deep.html#cb756-28" aria-hidden="true" tabindex="-1"></a>      opt<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb756-29"><a href="deep.html#cb756-29" aria-hidden="true" tabindex="-1"></a>      pred <span class="ot">=</span> <span class="fu">model_torch</span>(batch[[<span class="dv">1</span>]])</span>
<span id="cb756-30"><a href="deep.html#cb756-30" aria-hidden="true" tabindex="-1"></a>      loss <span class="ot">=</span> <span class="fu">nnf_cross_entropy</span>(pred, batch[[<span class="dv">2</span>]], <span class="at">reduction =</span> <span class="st">&quot;mean&quot;</span>)</span>
<span id="cb756-31"><a href="deep.html#cb756-31" aria-hidden="true" tabindex="-1"></a>      loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb756-32"><a href="deep.html#cb756-32" aria-hidden="true" tabindex="-1"></a>      opt<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb756-33"><a href="deep.html#cb756-33" aria-hidden="true" tabindex="-1"></a>      losses <span class="ot">=</span> <span class="fu">c</span>(losses, loss<span class="sc">$</span><span class="fu">item</span>())</span>
<span id="cb756-34"><a href="deep.html#cb756-34" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb756-35"><a href="deep.html#cb756-35" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb756-36"><a href="deep.html#cb756-36" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb756-37"><a href="deep.html#cb756-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">&quot;Loss at epoch %d: %3f</span><span class="sc">\n</span><span class="st">&quot;</span>, e, <span class="fu">mean</span>(losses)))</span>
<span id="cb756-38"><a href="deep.html#cb756-38" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb756-39"><a href="deep.html#cb756-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb756-40"><a href="deep.html#cb756-40" aria-hidden="true" tabindex="-1"></a>model_torch<span class="sc">$</span><span class="fu">eval</span>()</span>
<span id="cb756-41"><a href="deep.html#cb756-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb756-42"><a href="deep.html#cb756-42" aria-hidden="true" tabindex="-1"></a>test_losses <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb756-43"><a href="deep.html#cb756-43" aria-hidden="true" tabindex="-1"></a>total <span class="ot">=</span> <span class="dv">0</span></span>
<span id="cb756-44"><a href="deep.html#cb756-44" aria-hidden="true" tabindex="-1"></a>correct <span class="ot">=</span> <span class="dv">0</span></span>
<span id="cb756-45"><a href="deep.html#cb756-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb756-46"><a href="deep.html#cb756-46" aria-hidden="true" tabindex="-1"></a>coro<span class="sc">::</span><span class="fu">loop</span>(</span>
<span id="cb756-47"><a href="deep.html#cb756-47" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(batch <span class="cf">in</span> test_dl){</span>
<span id="cb756-48"><a href="deep.html#cb756-48" aria-hidden="true" tabindex="-1"></a>    output <span class="ot">=</span> <span class="fu">model_torch</span>(batch[[<span class="dv">1</span>]])</span>
<span id="cb756-49"><a href="deep.html#cb756-49" aria-hidden="true" tabindex="-1"></a>    labels <span class="ot">=</span> batch[[<span class="dv">2</span>]]</span>
<span id="cb756-50"><a href="deep.html#cb756-50" aria-hidden="true" tabindex="-1"></a>    loss <span class="ot">=</span> <span class="fu">nnf_cross_entropy</span>(output, labels)</span>
<span id="cb756-51"><a href="deep.html#cb756-51" aria-hidden="true" tabindex="-1"></a>    test_losses <span class="ot">=</span> <span class="fu">c</span>(test_losses, loss<span class="sc">$</span><span class="fu">item</span>())</span>
<span id="cb756-52"><a href="deep.html#cb756-52" aria-hidden="true" tabindex="-1"></a>    predicted <span class="ot">=</span> <span class="fu">torch_max</span>(output<span class="sc">$</span><span class="fu">data</span>(), <span class="at">dim =</span> <span class="dv">2</span>)[[<span class="dv">2</span>]]</span>
<span id="cb756-53"><a href="deep.html#cb756-53" aria-hidden="true" tabindex="-1"></a>    total <span class="ot">=</span> total <span class="sc">+</span> labels<span class="sc">$</span><span class="fu">size</span>(<span class="dv">1</span>)</span>
<span id="cb756-54"><a href="deep.html#cb756-54" aria-hidden="true" tabindex="-1"></a>    correct <span class="ot">=</span> correct <span class="sc">+</span> (predicted <span class="sc">==</span> labels)<span class="sc">$</span><span class="fu">sum</span>()<span class="sc">$</span><span class="fu">item</span>()</span>
<span id="cb756-55"><a href="deep.html#cb756-55" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb756-56"><a href="deep.html#cb756-56" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb756-57"><a href="deep.html#cb756-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb756-58"><a href="deep.html#cb756-58" aria-hidden="true" tabindex="-1"></a>test_accuracy <span class="ot">=</span>  correct<span class="sc">/</span>total</span>
<span id="cb756-59"><a href="deep.html#cb756-59" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(test_accuracy)</span></code></pre></div>
</p>
</details>
<p><br/></p>
</div>
<div id="transfer" class="section level3" number="5.4.2">
<h3><span class="header-section-number">5.4.2</span> Transfer Learning</h3>
<p>Another approach to reduce the necessary number of images or to speed up convergence of the models is the use of transfer learning.</p>
<p>The main idea of transfer learning is that all the convolutional layers have mainly one task - learning to identify highly correlated neighboring features. This knowledge is then used for new tasks.
The convolutional layers learn structures such as edges in images and only the top layer, the dense layer is the actual classifier of the convolutional neural network for a specific task.
Thus, one could think that we could only train the top layer as classifier. To do so, it will be confronted by sets of different edges/structures and has to decide the label based on these.</p>
<p>Again, this sounds very complicated but it is again quite easy with Keras.</p>
<p>We will do this now with the CIFAR10 data set, so we have to prepare the data:</p>
<div class="sourceCode" id="cb757"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb757-1"><a href="deep.html#cb757-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb757-2"><a href="deep.html#cb757-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb757-3"><a href="deep.html#cb757-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb757-4"><a href="deep.html#cb757-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb757-5"><a href="deep.html#cb757-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> keras<span class="sc">::</span><span class="fu">dataset_cifar10</span>()</span>
<span id="cb757-6"><a href="deep.html#cb757-6" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> data<span class="sc">$</span>train</span>
<span id="cb757-7"><a href="deep.html#cb757-7" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> data<span class="sc">$</span>test</span>
<span id="cb757-8"><a href="deep.html#cb757-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb757-9"><a href="deep.html#cb757-9" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(data)</span>
<span id="cb757-10"><a href="deep.html#cb757-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb757-11"><a href="deep.html#cb757-11" aria-hidden="true" tabindex="-1"></a>image <span class="ot">=</span> train<span class="sc">$</span>x[<span class="dv">5</span>,,,]</span>
<span id="cb757-12"><a href="deep.html#cb757-12" aria-hidden="true" tabindex="-1"></a>image <span class="sc">%&gt;%</span></span>
<span id="cb757-13"><a href="deep.html#cb757-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">image_to_array</span>() <span class="sc">%&gt;%</span></span>
<span id="cb757-14"><a href="deep.html#cb757-14" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">/</span><span class="st">`</span>(., <span class="dv">255</span>) <span class="sc">%&gt;%</span></span>
<span id="cb757-15"><a href="deep.html#cb757-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.raster</span>() <span class="sc">%&gt;%</span></span>
<span id="cb757-16"><a href="deep.html#cb757-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter5_27-1.png" width="672" /></p>
<div class="sourceCode" id="cb758"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb758-1"><a href="deep.html#cb758-1" aria-hidden="true" tabindex="-1"></a>train_x <span class="ot">=</span> <span class="fu">array</span>(train<span class="sc">$</span>x<span class="sc">/</span><span class="dv">255</span>, <span class="fu">c</span>(<span class="fu">dim</span>(train<span class="sc">$</span>x)))</span>
<span id="cb758-2"><a href="deep.html#cb758-2" aria-hidden="true" tabindex="-1"></a>test_x <span class="ot">=</span> <span class="fu">array</span>(test<span class="sc">$</span>x<span class="sc">/</span><span class="dv">255</span>, <span class="fu">c</span>(<span class="fu">dim</span>(test<span class="sc">$</span>x)))</span>
<span id="cb758-3"><a href="deep.html#cb758-3" aria-hidden="true" tabindex="-1"></a>train_y <span class="ot">=</span> <span class="fu">to_categorical</span>(train<span class="sc">$</span>y, <span class="dv">10</span>)</span>
<span id="cb758-4"><a href="deep.html#cb758-4" aria-hidden="true" tabindex="-1"></a>test_y <span class="ot">=</span> <span class="fu">to_categorical</span>(test<span class="sc">$</span>y, <span class="dv">10</span>)</span>
<span id="cb758-5"><a href="deep.html#cb758-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb758-6"><a href="deep.html#cb758-6" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(train, test, data)</span></code></pre></div>
<pre><code>## Warning in rm(train, test, data): object &#39;data&#39; not found</code></pre>
<p>Keras provides download functions for all famous architectures/convolutional neural network models which are already trained on the imagenet data set (another famous data set). These trained networks come already without their top layer, so we have to set include_top to false and change the input shape.</p>
<div class="sourceCode" id="cb760"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb760-1"><a href="deep.html#cb760-1" aria-hidden="true" tabindex="-1"></a>densenet <span class="ot">=</span> <span class="fu">application_densenet201</span>(<span class="at">include_top =</span> <span class="cn">FALSE</span>,</span>
<span id="cb760-2"><a href="deep.html#cb760-2" aria-hidden="true" tabindex="-1"></a>                                   <span class="at">input_shape  =</span> <span class="fu">c</span>(32L, 32L, 3L))</span></code></pre></div>
<p>Now, we will not use a sequential model but just a “keras_model” where we can specify the inputs and outputs. Thereby, the output is our own top layer, but the inputs are the densenet inputs, as these are already pre-trained.</p>
<div class="sourceCode" id="cb761"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb761-1"><a href="deep.html#cb761-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> keras<span class="sc">::</span><span class="fu">keras_model</span>(</span>
<span id="cb761-2"><a href="deep.html#cb761-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">inputs =</span> densenet<span class="sc">$</span>input,</span>
<span id="cb761-3"><a href="deep.html#cb761-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">outputs =</span> <span class="fu">layer_flatten</span>(</span>
<span id="cb761-4"><a href="deep.html#cb761-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(densenet<span class="sc">$</span>output, <span class="at">units =</span> 10L, <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>)</span>
<span id="cb761-5"><a href="deep.html#cb761-5" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb761-6"><a href="deep.html#cb761-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb761-7"><a href="deep.html#cb761-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb761-8"><a href="deep.html#cb761-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Notice that this snippet just creates one (!) new layer.</span></span>
<span id="cb761-9"><a href="deep.html#cb761-9" aria-hidden="true" tabindex="-1"></a><span class="co"># The densenet&#39;s inputs are connected with the model&#39;s inputs.</span></span>
<span id="cb761-10"><a href="deep.html#cb761-10" aria-hidden="true" tabindex="-1"></a><span class="co"># The densenet&#39;s outputs are connected with our own layer (with 10 nodes).</span></span>
<span id="cb761-11"><a href="deep.html#cb761-11" aria-hidden="true" tabindex="-1"></a><span class="co"># This layer is also the output layer of the model.</span></span></code></pre></div>
<p>In the next step we want to freeze all layers except for our own last layer. Freezing means that these are not trained: We do not want to train the complete model, we only want to train the last layer. You can check the number of trainable weights via summary(model).</p>
<div class="sourceCode" id="cb762"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb762-1"><a href="deep.html#cb762-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">freeze_weights</span>(<span class="at">to =</span> <span class="fu">length</span>(model<span class="sc">$</span>layers) <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb762-2"><a href="deep.html#cb762-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## Model: &quot;model_1&quot;
## ____________________________________________________________________________________________________________________
##  Layer (type)                         Output Shape             Param #       Connected to                           
## ====================================================================================================================
##  input_3 (InputLayer)                 [(None, 32, 32, 3)]      0             []                                     
##                                                                                                                     
##  zero_padding2d (ZeroPadding2D)       (None, 38, 38, 3)        0             [&#39;input_3[0][0]&#39;]                      
##                                                                                                                     
##  conv1/conv (Conv2D)                  (None, 16, 16, 64)       9408          [&#39;zero_padding2d[0][0]&#39;]               
##                                                                                                                     
##  conv1/bn (BatchNormalization)        (None, 16, 16, 64)       256           [&#39;conv1/conv[0][0]&#39;]                   
##                                                                                                                     
##  conv1/relu (Activation)              (None, 16, 16, 64)       0             [&#39;conv1/bn[0][0]&#39;]                     
##                                                                                                                     
##  zero_padding2d_1 (ZeroPadding2D)     (None, 18, 18, 64)       0             [&#39;conv1/relu[0][0]&#39;]                   
##                                                                                                                     
##  pool1 (MaxPooling2D)                 (None, 8, 8, 64)         0             [&#39;zero_padding2d_1[0][0]&#39;]             
##                                                                                                                     
##  conv2_block1_0_bn (BatchNormalizatio  (None, 8, 8, 64)        256           [&#39;pool1[0][0]&#39;]                        
##  n)                                                                                                                 
##                                                                                                                     
##  conv2_block1_0_relu (Activation)     (None, 8, 8, 64)         0             [&#39;conv2_block1_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv2_block1_1_conv (Conv2D)         (None, 8, 8, 128)        8192          [&#39;conv2_block1_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv2_block1_1_bn (BatchNormalizatio  (None, 8, 8, 128)       512           [&#39;conv2_block1_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv2_block1_1_relu (Activation)     (None, 8, 8, 128)        0             [&#39;conv2_block1_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv2_block1_2_conv (Conv2D)         (None, 8, 8, 32)         36864         [&#39;conv2_block1_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv2_block1_concat (Concatenate)    (None, 8, 8, 96)         0             [&#39;pool1[0][0]&#39;,                        
##                                                                               &#39;conv2_block1_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv2_block2_0_bn (BatchNormalizatio  (None, 8, 8, 96)        384           [&#39;conv2_block1_concat[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv2_block2_0_relu (Activation)     (None, 8, 8, 96)         0             [&#39;conv2_block2_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv2_block2_1_conv (Conv2D)         (None, 8, 8, 128)        12288         [&#39;conv2_block2_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv2_block2_1_bn (BatchNormalizatio  (None, 8, 8, 128)       512           [&#39;conv2_block2_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv2_block2_1_relu (Activation)     (None, 8, 8, 128)        0             [&#39;conv2_block2_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv2_block2_2_conv (Conv2D)         (None, 8, 8, 32)         36864         [&#39;conv2_block2_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv2_block2_concat (Concatenate)    (None, 8, 8, 128)        0             [&#39;conv2_block1_concat[0][0]&#39;,          
##                                                                               &#39;conv2_block2_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv2_block3_0_bn (BatchNormalizatio  (None, 8, 8, 128)       512           [&#39;conv2_block2_concat[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv2_block3_0_relu (Activation)     (None, 8, 8, 128)        0             [&#39;conv2_block3_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv2_block3_1_conv (Conv2D)         (None, 8, 8, 128)        16384         [&#39;conv2_block3_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv2_block3_1_bn (BatchNormalizatio  (None, 8, 8, 128)       512           [&#39;conv2_block3_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv2_block3_1_relu (Activation)     (None, 8, 8, 128)        0             [&#39;conv2_block3_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv2_block3_2_conv (Conv2D)         (None, 8, 8, 32)         36864         [&#39;conv2_block3_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv2_block3_concat (Concatenate)    (None, 8, 8, 160)        0             [&#39;conv2_block2_concat[0][0]&#39;,          
##                                                                               &#39;conv2_block3_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv2_block4_0_bn (BatchNormalizatio  (None, 8, 8, 160)       640           [&#39;conv2_block3_concat[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv2_block4_0_relu (Activation)     (None, 8, 8, 160)        0             [&#39;conv2_block4_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv2_block4_1_conv (Conv2D)         (None, 8, 8, 128)        20480         [&#39;conv2_block4_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv2_block4_1_bn (BatchNormalizatio  (None, 8, 8, 128)       512           [&#39;conv2_block4_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv2_block4_1_relu (Activation)     (None, 8, 8, 128)        0             [&#39;conv2_block4_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv2_block4_2_conv (Conv2D)         (None, 8, 8, 32)         36864         [&#39;conv2_block4_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv2_block4_concat (Concatenate)    (None, 8, 8, 192)        0             [&#39;conv2_block3_concat[0][0]&#39;,          
##                                                                               &#39;conv2_block4_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv2_block5_0_bn (BatchNormalizatio  (None, 8, 8, 192)       768           [&#39;conv2_block4_concat[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv2_block5_0_relu (Activation)     (None, 8, 8, 192)        0             [&#39;conv2_block5_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv2_block5_1_conv (Conv2D)         (None, 8, 8, 128)        24576         [&#39;conv2_block5_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv2_block5_1_bn (BatchNormalizatio  (None, 8, 8, 128)       512           [&#39;conv2_block5_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv2_block5_1_relu (Activation)     (None, 8, 8, 128)        0             [&#39;conv2_block5_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv2_block5_2_conv (Conv2D)         (None, 8, 8, 32)         36864         [&#39;conv2_block5_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv2_block5_concat (Concatenate)    (None, 8, 8, 224)        0             [&#39;conv2_block4_concat[0][0]&#39;,          
##                                                                               &#39;conv2_block5_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv2_block6_0_bn (BatchNormalizatio  (None, 8, 8, 224)       896           [&#39;conv2_block5_concat[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv2_block6_0_relu (Activation)     (None, 8, 8, 224)        0             [&#39;conv2_block6_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv2_block6_1_conv (Conv2D)         (None, 8, 8, 128)        28672         [&#39;conv2_block6_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv2_block6_1_bn (BatchNormalizatio  (None, 8, 8, 128)       512           [&#39;conv2_block6_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv2_block6_1_relu (Activation)     (None, 8, 8, 128)        0             [&#39;conv2_block6_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv2_block6_2_conv (Conv2D)         (None, 8, 8, 32)         36864         [&#39;conv2_block6_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv2_block6_concat (Concatenate)    (None, 8, 8, 256)        0             [&#39;conv2_block5_concat[0][0]&#39;,          
##                                                                               &#39;conv2_block6_2_conv[0][0]&#39;]          
##                                                                                                                     
##  pool2_bn (BatchNormalization)        (None, 8, 8, 256)        1024          [&#39;conv2_block6_concat[0][0]&#39;]          
##                                                                                                                     
##  pool2_relu (Activation)              (None, 8, 8, 256)        0             [&#39;pool2_bn[0][0]&#39;]                     
##                                                                                                                     
##  pool2_conv (Conv2D)                  (None, 8, 8, 128)        32768         [&#39;pool2_relu[0][0]&#39;]                   
##                                                                                                                     
##  pool2_pool (AveragePooling2D)        (None, 4, 4, 128)        0             [&#39;pool2_conv[0][0]&#39;]                   
##                                                                                                                     
##  conv3_block1_0_bn (BatchNormalizatio  (None, 4, 4, 128)       512           [&#39;pool2_pool[0][0]&#39;]                   
##  n)                                                                                                                 
##                                                                                                                     
##  conv3_block1_0_relu (Activation)     (None, 4, 4, 128)        0             [&#39;conv3_block1_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv3_block1_1_conv (Conv2D)         (None, 4, 4, 128)        16384         [&#39;conv3_block1_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv3_block1_1_bn (BatchNormalizatio  (None, 4, 4, 128)       512           [&#39;conv3_block1_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv3_block1_1_relu (Activation)     (None, 4, 4, 128)        0             [&#39;conv3_block1_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv3_block1_2_conv (Conv2D)         (None, 4, 4, 32)         36864         [&#39;conv3_block1_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv3_block1_concat (Concatenate)    (None, 4, 4, 160)        0             [&#39;pool2_pool[0][0]&#39;,                   
##                                                                               &#39;conv3_block1_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv3_block2_0_bn (BatchNormalizatio  (None, 4, 4, 160)       640           [&#39;conv3_block1_concat[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv3_block2_0_relu (Activation)     (None, 4, 4, 160)        0             [&#39;conv3_block2_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv3_block2_1_conv (Conv2D)         (None, 4, 4, 128)        20480         [&#39;conv3_block2_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv3_block2_1_bn (BatchNormalizatio  (None, 4, 4, 128)       512           [&#39;conv3_block2_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv3_block2_1_relu (Activation)     (None, 4, 4, 128)        0             [&#39;conv3_block2_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv3_block2_2_conv (Conv2D)         (None, 4, 4, 32)         36864         [&#39;conv3_block2_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv3_block2_concat (Concatenate)    (None, 4, 4, 192)        0             [&#39;conv3_block1_concat[0][0]&#39;,          
##                                                                               &#39;conv3_block2_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv3_block3_0_bn (BatchNormalizatio  (None, 4, 4, 192)       768           [&#39;conv3_block2_concat[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv3_block3_0_relu (Activation)     (None, 4, 4, 192)        0             [&#39;conv3_block3_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv3_block3_1_conv (Conv2D)         (None, 4, 4, 128)        24576         [&#39;conv3_block3_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv3_block3_1_bn (BatchNormalizatio  (None, 4, 4, 128)       512           [&#39;conv3_block3_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv3_block3_1_relu (Activation)     (None, 4, 4, 128)        0             [&#39;conv3_block3_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv3_block3_2_conv (Conv2D)         (None, 4, 4, 32)         36864         [&#39;conv3_block3_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv3_block3_concat (Concatenate)    (None, 4, 4, 224)        0             [&#39;conv3_block2_concat[0][0]&#39;,          
##                                                                               &#39;conv3_block3_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv3_block4_0_bn (BatchNormalizatio  (None, 4, 4, 224)       896           [&#39;conv3_block3_concat[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv3_block4_0_relu (Activation)     (None, 4, 4, 224)        0             [&#39;conv3_block4_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv3_block4_1_conv (Conv2D)         (None, 4, 4, 128)        28672         [&#39;conv3_block4_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv3_block4_1_bn (BatchNormalizatio  (None, 4, 4, 128)       512           [&#39;conv3_block4_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv3_block4_1_relu (Activation)     (None, 4, 4, 128)        0             [&#39;conv3_block4_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv3_block4_2_conv (Conv2D)         (None, 4, 4, 32)         36864         [&#39;conv3_block4_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv3_block4_concat (Concatenate)    (None, 4, 4, 256)        0             [&#39;conv3_block3_concat[0][0]&#39;,          
##                                                                               &#39;conv3_block4_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv3_block5_0_bn (BatchNormalizatio  (None, 4, 4, 256)       1024          [&#39;conv3_block4_concat[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv3_block5_0_relu (Activation)     (None, 4, 4, 256)        0             [&#39;conv3_block5_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv3_block5_1_conv (Conv2D)         (None, 4, 4, 128)        32768         [&#39;conv3_block5_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv3_block5_1_bn (BatchNormalizatio  (None, 4, 4, 128)       512           [&#39;conv3_block5_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv3_block5_1_relu (Activation)     (None, 4, 4, 128)        0             [&#39;conv3_block5_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv3_block5_2_conv (Conv2D)         (None, 4, 4, 32)         36864         [&#39;conv3_block5_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv3_block5_concat (Concatenate)    (None, 4, 4, 288)        0             [&#39;conv3_block4_concat[0][0]&#39;,          
##                                                                               &#39;conv3_block5_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv3_block6_0_bn (BatchNormalizatio  (None, 4, 4, 288)       1152          [&#39;conv3_block5_concat[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv3_block6_0_relu (Activation)     (None, 4, 4, 288)        0             [&#39;conv3_block6_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv3_block6_1_conv (Conv2D)         (None, 4, 4, 128)        36864         [&#39;conv3_block6_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv3_block6_1_bn (BatchNormalizatio  (None, 4, 4, 128)       512           [&#39;conv3_block6_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv3_block6_1_relu (Activation)     (None, 4, 4, 128)        0             [&#39;conv3_block6_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv3_block6_2_conv (Conv2D)         (None, 4, 4, 32)         36864         [&#39;conv3_block6_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv3_block6_concat (Concatenate)    (None, 4, 4, 320)        0             [&#39;conv3_block5_concat[0][0]&#39;,          
##                                                                               &#39;conv3_block6_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv3_block7_0_bn (BatchNormalizatio  (None, 4, 4, 320)       1280          [&#39;conv3_block6_concat[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv3_block7_0_relu (Activation)     (None, 4, 4, 320)        0             [&#39;conv3_block7_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv3_block7_1_conv (Conv2D)         (None, 4, 4, 128)        40960         [&#39;conv3_block7_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv3_block7_1_bn (BatchNormalizatio  (None, 4, 4, 128)       512           [&#39;conv3_block7_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv3_block7_1_relu (Activation)     (None, 4, 4, 128)        0             [&#39;conv3_block7_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv3_block7_2_conv (Conv2D)         (None, 4, 4, 32)         36864         [&#39;conv3_block7_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv3_block7_concat (Concatenate)    (None, 4, 4, 352)        0             [&#39;conv3_block6_concat[0][0]&#39;,          
##                                                                               &#39;conv3_block7_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv3_block8_0_bn (BatchNormalizatio  (None, 4, 4, 352)       1408          [&#39;conv3_block7_concat[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv3_block8_0_relu (Activation)     (None, 4, 4, 352)        0             [&#39;conv3_block8_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv3_block8_1_conv (Conv2D)         (None, 4, 4, 128)        45056         [&#39;conv3_block8_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv3_block8_1_bn (BatchNormalizatio  (None, 4, 4, 128)       512           [&#39;conv3_block8_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv3_block8_1_relu (Activation)     (None, 4, 4, 128)        0             [&#39;conv3_block8_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv3_block8_2_conv (Conv2D)         (None, 4, 4, 32)         36864         [&#39;conv3_block8_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv3_block8_concat (Concatenate)    (None, 4, 4, 384)        0             [&#39;conv3_block7_concat[0][0]&#39;,          
##                                                                               &#39;conv3_block8_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv3_block9_0_bn (BatchNormalizatio  (None, 4, 4, 384)       1536          [&#39;conv3_block8_concat[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv3_block9_0_relu (Activation)     (None, 4, 4, 384)        0             [&#39;conv3_block9_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv3_block9_1_conv (Conv2D)         (None, 4, 4, 128)        49152         [&#39;conv3_block9_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv3_block9_1_bn (BatchNormalizatio  (None, 4, 4, 128)       512           [&#39;conv3_block9_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv3_block9_1_relu (Activation)     (None, 4, 4, 128)        0             [&#39;conv3_block9_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv3_block9_2_conv (Conv2D)         (None, 4, 4, 32)         36864         [&#39;conv3_block9_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv3_block9_concat (Concatenate)    (None, 4, 4, 416)        0             [&#39;conv3_block8_concat[0][0]&#39;,          
##                                                                               &#39;conv3_block9_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv3_block10_0_bn (BatchNormalizati  (None, 4, 4, 416)       1664          [&#39;conv3_block9_concat[0][0]&#39;]          
##  on)                                                                                                                
##                                                                                                                     
##  conv3_block10_0_relu (Activation)    (None, 4, 4, 416)        0             [&#39;conv3_block10_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv3_block10_1_conv (Conv2D)        (None, 4, 4, 128)        53248         [&#39;conv3_block10_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv3_block10_1_bn (BatchNormalizati  (None, 4, 4, 128)       512           [&#39;conv3_block10_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv3_block10_1_relu (Activation)    (None, 4, 4, 128)        0             [&#39;conv3_block10_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv3_block10_2_conv (Conv2D)        (None, 4, 4, 32)         36864         [&#39;conv3_block10_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv3_block10_concat (Concatenate)   (None, 4, 4, 448)        0             [&#39;conv3_block9_concat[0][0]&#39;,          
##                                                                               &#39;conv3_block10_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv3_block11_0_bn (BatchNormalizati  (None, 4, 4, 448)       1792          [&#39;conv3_block10_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv3_block11_0_relu (Activation)    (None, 4, 4, 448)        0             [&#39;conv3_block11_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv3_block11_1_conv (Conv2D)        (None, 4, 4, 128)        57344         [&#39;conv3_block11_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv3_block11_1_bn (BatchNormalizati  (None, 4, 4, 128)       512           [&#39;conv3_block11_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv3_block11_1_relu (Activation)    (None, 4, 4, 128)        0             [&#39;conv3_block11_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv3_block11_2_conv (Conv2D)        (None, 4, 4, 32)         36864         [&#39;conv3_block11_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv3_block11_concat (Concatenate)   (None, 4, 4, 480)        0             [&#39;conv3_block10_concat[0][0]&#39;,         
##                                                                               &#39;conv3_block11_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv3_block12_0_bn (BatchNormalizati  (None, 4, 4, 480)       1920          [&#39;conv3_block11_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv3_block12_0_relu (Activation)    (None, 4, 4, 480)        0             [&#39;conv3_block12_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv3_block12_1_conv (Conv2D)        (None, 4, 4, 128)        61440         [&#39;conv3_block12_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv3_block12_1_bn (BatchNormalizati  (None, 4, 4, 128)       512           [&#39;conv3_block12_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv3_block12_1_relu (Activation)    (None, 4, 4, 128)        0             [&#39;conv3_block12_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv3_block12_2_conv (Conv2D)        (None, 4, 4, 32)         36864         [&#39;conv3_block12_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv3_block12_concat (Concatenate)   (None, 4, 4, 512)        0             [&#39;conv3_block11_concat[0][0]&#39;,         
##                                                                               &#39;conv3_block12_2_conv[0][0]&#39;]         
##                                                                                                                     
##  pool3_bn (BatchNormalization)        (None, 4, 4, 512)        2048          [&#39;conv3_block12_concat[0][0]&#39;]         
##                                                                                                                     
##  pool3_relu (Activation)              (None, 4, 4, 512)        0             [&#39;pool3_bn[0][0]&#39;]                     
##                                                                                                                     
##  pool3_conv (Conv2D)                  (None, 4, 4, 256)        131072        [&#39;pool3_relu[0][0]&#39;]                   
##                                                                                                                     
##  pool3_pool (AveragePooling2D)        (None, 2, 2, 256)        0             [&#39;pool3_conv[0][0]&#39;]                   
##                                                                                                                     
##  conv4_block1_0_bn (BatchNormalizatio  (None, 2, 2, 256)       1024          [&#39;pool3_pool[0][0]&#39;]                   
##  n)                                                                                                                 
##                                                                                                                     
##  conv4_block1_0_relu (Activation)     (None, 2, 2, 256)        0             [&#39;conv4_block1_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv4_block1_1_conv (Conv2D)         (None, 2, 2, 128)        32768         [&#39;conv4_block1_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv4_block1_1_bn (BatchNormalizatio  (None, 2, 2, 128)       512           [&#39;conv4_block1_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv4_block1_1_relu (Activation)     (None, 2, 2, 128)        0             [&#39;conv4_block1_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv4_block1_2_conv (Conv2D)         (None, 2, 2, 32)         36864         [&#39;conv4_block1_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv4_block1_concat (Concatenate)    (None, 2, 2, 288)        0             [&#39;pool3_pool[0][0]&#39;,                   
##                                                                               &#39;conv4_block1_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv4_block2_0_bn (BatchNormalizatio  (None, 2, 2, 288)       1152          [&#39;conv4_block1_concat[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv4_block2_0_relu (Activation)     (None, 2, 2, 288)        0             [&#39;conv4_block2_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv4_block2_1_conv (Conv2D)         (None, 2, 2, 128)        36864         [&#39;conv4_block2_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv4_block2_1_bn (BatchNormalizatio  (None, 2, 2, 128)       512           [&#39;conv4_block2_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv4_block2_1_relu (Activation)     (None, 2, 2, 128)        0             [&#39;conv4_block2_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv4_block2_2_conv (Conv2D)         (None, 2, 2, 32)         36864         [&#39;conv4_block2_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv4_block2_concat (Concatenate)    (None, 2, 2, 320)        0             [&#39;conv4_block1_concat[0][0]&#39;,          
##                                                                               &#39;conv4_block2_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv4_block3_0_bn (BatchNormalizatio  (None, 2, 2, 320)       1280          [&#39;conv4_block2_concat[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv4_block3_0_relu (Activation)     (None, 2, 2, 320)        0             [&#39;conv4_block3_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv4_block3_1_conv (Conv2D)         (None, 2, 2, 128)        40960         [&#39;conv4_block3_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv4_block3_1_bn (BatchNormalizatio  (None, 2, 2, 128)       512           [&#39;conv4_block3_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv4_block3_1_relu (Activation)     (None, 2, 2, 128)        0             [&#39;conv4_block3_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv4_block3_2_conv (Conv2D)         (None, 2, 2, 32)         36864         [&#39;conv4_block3_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv4_block3_concat (Concatenate)    (None, 2, 2, 352)        0             [&#39;conv4_block2_concat[0][0]&#39;,          
##                                                                               &#39;conv4_block3_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv4_block4_0_bn (BatchNormalizatio  (None, 2, 2, 352)       1408          [&#39;conv4_block3_concat[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv4_block4_0_relu (Activation)     (None, 2, 2, 352)        0             [&#39;conv4_block4_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv4_block4_1_conv (Conv2D)         (None, 2, 2, 128)        45056         [&#39;conv4_block4_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv4_block4_1_bn (BatchNormalizatio  (None, 2, 2, 128)       512           [&#39;conv4_block4_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv4_block4_1_relu (Activation)     (None, 2, 2, 128)        0             [&#39;conv4_block4_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv4_block4_2_conv (Conv2D)         (None, 2, 2, 32)         36864         [&#39;conv4_block4_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv4_block4_concat (Concatenate)    (None, 2, 2, 384)        0             [&#39;conv4_block3_concat[0][0]&#39;,          
##                                                                               &#39;conv4_block4_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv4_block5_0_bn (BatchNormalizatio  (None, 2, 2, 384)       1536          [&#39;conv4_block4_concat[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv4_block5_0_relu (Activation)     (None, 2, 2, 384)        0             [&#39;conv4_block5_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv4_block5_1_conv (Conv2D)         (None, 2, 2, 128)        49152         [&#39;conv4_block5_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv4_block5_1_bn (BatchNormalizatio  (None, 2, 2, 128)       512           [&#39;conv4_block5_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv4_block5_1_relu (Activation)     (None, 2, 2, 128)        0             [&#39;conv4_block5_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv4_block5_2_conv (Conv2D)         (None, 2, 2, 32)         36864         [&#39;conv4_block5_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv4_block5_concat (Concatenate)    (None, 2, 2, 416)        0             [&#39;conv4_block4_concat[0][0]&#39;,          
##                                                                               &#39;conv4_block5_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv4_block6_0_bn (BatchNormalizatio  (None, 2, 2, 416)       1664          [&#39;conv4_block5_concat[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv4_block6_0_relu (Activation)     (None, 2, 2, 416)        0             [&#39;conv4_block6_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv4_block6_1_conv (Conv2D)         (None, 2, 2, 128)        53248         [&#39;conv4_block6_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv4_block6_1_bn (BatchNormalizatio  (None, 2, 2, 128)       512           [&#39;conv4_block6_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv4_block6_1_relu (Activation)     (None, 2, 2, 128)        0             [&#39;conv4_block6_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv4_block6_2_conv (Conv2D)         (None, 2, 2, 32)         36864         [&#39;conv4_block6_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv4_block6_concat (Concatenate)    (None, 2, 2, 448)        0             [&#39;conv4_block5_concat[0][0]&#39;,          
##                                                                               &#39;conv4_block6_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv4_block7_0_bn (BatchNormalizatio  (None, 2, 2, 448)       1792          [&#39;conv4_block6_concat[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv4_block7_0_relu (Activation)     (None, 2, 2, 448)        0             [&#39;conv4_block7_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv4_block7_1_conv (Conv2D)         (None, 2, 2, 128)        57344         [&#39;conv4_block7_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv4_block7_1_bn (BatchNormalizatio  (None, 2, 2, 128)       512           [&#39;conv4_block7_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv4_block7_1_relu (Activation)     (None, 2, 2, 128)        0             [&#39;conv4_block7_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv4_block7_2_conv (Conv2D)         (None, 2, 2, 32)         36864         [&#39;conv4_block7_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv4_block7_concat (Concatenate)    (None, 2, 2, 480)        0             [&#39;conv4_block6_concat[0][0]&#39;,          
##                                                                               &#39;conv4_block7_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv4_block8_0_bn (BatchNormalizatio  (None, 2, 2, 480)       1920          [&#39;conv4_block7_concat[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv4_block8_0_relu (Activation)     (None, 2, 2, 480)        0             [&#39;conv4_block8_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv4_block8_1_conv (Conv2D)         (None, 2, 2, 128)        61440         [&#39;conv4_block8_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv4_block8_1_bn (BatchNormalizatio  (None, 2, 2, 128)       512           [&#39;conv4_block8_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv4_block8_1_relu (Activation)     (None, 2, 2, 128)        0             [&#39;conv4_block8_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv4_block8_2_conv (Conv2D)         (None, 2, 2, 32)         36864         [&#39;conv4_block8_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv4_block8_concat (Concatenate)    (None, 2, 2, 512)        0             [&#39;conv4_block7_concat[0][0]&#39;,          
##                                                                               &#39;conv4_block8_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv4_block9_0_bn (BatchNormalizatio  (None, 2, 2, 512)       2048          [&#39;conv4_block8_concat[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv4_block9_0_relu (Activation)     (None, 2, 2, 512)        0             [&#39;conv4_block9_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv4_block9_1_conv (Conv2D)         (None, 2, 2, 128)        65536         [&#39;conv4_block9_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv4_block9_1_bn (BatchNormalizatio  (None, 2, 2, 128)       512           [&#39;conv4_block9_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv4_block9_1_relu (Activation)     (None, 2, 2, 128)        0             [&#39;conv4_block9_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv4_block9_2_conv (Conv2D)         (None, 2, 2, 32)         36864         [&#39;conv4_block9_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv4_block9_concat (Concatenate)    (None, 2, 2, 544)        0             [&#39;conv4_block8_concat[0][0]&#39;,          
##                                                                               &#39;conv4_block9_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv4_block10_0_bn (BatchNormalizati  (None, 2, 2, 544)       2176          [&#39;conv4_block9_concat[0][0]&#39;]          
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block10_0_relu (Activation)    (None, 2, 2, 544)        0             [&#39;conv4_block10_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block10_1_conv (Conv2D)        (None, 2, 2, 128)        69632         [&#39;conv4_block10_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block10_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block10_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block10_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block10_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block10_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block10_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block10_concat (Concatenate)   (None, 2, 2, 576)        0             [&#39;conv4_block9_concat[0][0]&#39;,          
##                                                                               &#39;conv4_block10_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block11_0_bn (BatchNormalizati  (None, 2, 2, 576)       2304          [&#39;conv4_block10_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block11_0_relu (Activation)    (None, 2, 2, 576)        0             [&#39;conv4_block11_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block11_1_conv (Conv2D)        (None, 2, 2, 128)        73728         [&#39;conv4_block11_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block11_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block11_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block11_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block11_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block11_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block11_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block11_concat (Concatenate)   (None, 2, 2, 608)        0             [&#39;conv4_block10_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block11_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block12_0_bn (BatchNormalizati  (None, 2, 2, 608)       2432          [&#39;conv4_block11_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block12_0_relu (Activation)    (None, 2, 2, 608)        0             [&#39;conv4_block12_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block12_1_conv (Conv2D)        (None, 2, 2, 128)        77824         [&#39;conv4_block12_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block12_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block12_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block12_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block12_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block12_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block12_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block12_concat (Concatenate)   (None, 2, 2, 640)        0             [&#39;conv4_block11_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block12_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block13_0_bn (BatchNormalizati  (None, 2, 2, 640)       2560          [&#39;conv4_block12_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block13_0_relu (Activation)    (None, 2, 2, 640)        0             [&#39;conv4_block13_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block13_1_conv (Conv2D)        (None, 2, 2, 128)        81920         [&#39;conv4_block13_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block13_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block13_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block13_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block13_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block13_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block13_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block13_concat (Concatenate)   (None, 2, 2, 672)        0             [&#39;conv4_block12_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block13_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block14_0_bn (BatchNormalizati  (None, 2, 2, 672)       2688          [&#39;conv4_block13_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block14_0_relu (Activation)    (None, 2, 2, 672)        0             [&#39;conv4_block14_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block14_1_conv (Conv2D)        (None, 2, 2, 128)        86016         [&#39;conv4_block14_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block14_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block14_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block14_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block14_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block14_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block14_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block14_concat (Concatenate)   (None, 2, 2, 704)        0             [&#39;conv4_block13_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block14_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block15_0_bn (BatchNormalizati  (None, 2, 2, 704)       2816          [&#39;conv4_block14_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block15_0_relu (Activation)    (None, 2, 2, 704)        0             [&#39;conv4_block15_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block15_1_conv (Conv2D)        (None, 2, 2, 128)        90112         [&#39;conv4_block15_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block15_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block15_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block15_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block15_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block15_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block15_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block15_concat (Concatenate)   (None, 2, 2, 736)        0             [&#39;conv4_block14_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block15_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block16_0_bn (BatchNormalizati  (None, 2, 2, 736)       2944          [&#39;conv4_block15_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block16_0_relu (Activation)    (None, 2, 2, 736)        0             [&#39;conv4_block16_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block16_1_conv (Conv2D)        (None, 2, 2, 128)        94208         [&#39;conv4_block16_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block16_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block16_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block16_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block16_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block16_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block16_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block16_concat (Concatenate)   (None, 2, 2, 768)        0             [&#39;conv4_block15_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block16_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block17_0_bn (BatchNormalizati  (None, 2, 2, 768)       3072          [&#39;conv4_block16_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block17_0_relu (Activation)    (None, 2, 2, 768)        0             [&#39;conv4_block17_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block17_1_conv (Conv2D)        (None, 2, 2, 128)        98304         [&#39;conv4_block17_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block17_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block17_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block17_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block17_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block17_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block17_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block17_concat (Concatenate)   (None, 2, 2, 800)        0             [&#39;conv4_block16_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block17_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block18_0_bn (BatchNormalizati  (None, 2, 2, 800)       3200          [&#39;conv4_block17_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block18_0_relu (Activation)    (None, 2, 2, 800)        0             [&#39;conv4_block18_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block18_1_conv (Conv2D)        (None, 2, 2, 128)        102400        [&#39;conv4_block18_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block18_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block18_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block18_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block18_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block18_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block18_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block18_concat (Concatenate)   (None, 2, 2, 832)        0             [&#39;conv4_block17_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block18_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block19_0_bn (BatchNormalizati  (None, 2, 2, 832)       3328          [&#39;conv4_block18_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block19_0_relu (Activation)    (None, 2, 2, 832)        0             [&#39;conv4_block19_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block19_1_conv (Conv2D)        (None, 2, 2, 128)        106496        [&#39;conv4_block19_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block19_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block19_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block19_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block19_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block19_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block19_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block19_concat (Concatenate)   (None, 2, 2, 864)        0             [&#39;conv4_block18_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block19_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block20_0_bn (BatchNormalizati  (None, 2, 2, 864)       3456          [&#39;conv4_block19_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block20_0_relu (Activation)    (None, 2, 2, 864)        0             [&#39;conv4_block20_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block20_1_conv (Conv2D)        (None, 2, 2, 128)        110592        [&#39;conv4_block20_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block20_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block20_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block20_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block20_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block20_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block20_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block20_concat (Concatenate)   (None, 2, 2, 896)        0             [&#39;conv4_block19_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block20_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block21_0_bn (BatchNormalizati  (None, 2, 2, 896)       3584          [&#39;conv4_block20_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block21_0_relu (Activation)    (None, 2, 2, 896)        0             [&#39;conv4_block21_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block21_1_conv (Conv2D)        (None, 2, 2, 128)        114688        [&#39;conv4_block21_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block21_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block21_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block21_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block21_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block21_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block21_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block21_concat (Concatenate)   (None, 2, 2, 928)        0             [&#39;conv4_block20_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block21_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block22_0_bn (BatchNormalizati  (None, 2, 2, 928)       3712          [&#39;conv4_block21_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block22_0_relu (Activation)    (None, 2, 2, 928)        0             [&#39;conv4_block22_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block22_1_conv (Conv2D)        (None, 2, 2, 128)        118784        [&#39;conv4_block22_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block22_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block22_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block22_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block22_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block22_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block22_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block22_concat (Concatenate)   (None, 2, 2, 960)        0             [&#39;conv4_block21_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block22_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block23_0_bn (BatchNormalizati  (None, 2, 2, 960)       3840          [&#39;conv4_block22_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block23_0_relu (Activation)    (None, 2, 2, 960)        0             [&#39;conv4_block23_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block23_1_conv (Conv2D)        (None, 2, 2, 128)        122880        [&#39;conv4_block23_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block23_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block23_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block23_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block23_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block23_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block23_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block23_concat (Concatenate)   (None, 2, 2, 992)        0             [&#39;conv4_block22_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block23_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block24_0_bn (BatchNormalizati  (None, 2, 2, 992)       3968          [&#39;conv4_block23_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block24_0_relu (Activation)    (None, 2, 2, 992)        0             [&#39;conv4_block24_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block24_1_conv (Conv2D)        (None, 2, 2, 128)        126976        [&#39;conv4_block24_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block24_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block24_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block24_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block24_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block24_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block24_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block24_concat (Concatenate)   (None, 2, 2, 1024)       0             [&#39;conv4_block23_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block24_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block25_0_bn (BatchNormalizati  (None, 2, 2, 1024)      4096          [&#39;conv4_block24_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block25_0_relu (Activation)    (None, 2, 2, 1024)       0             [&#39;conv4_block25_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block25_1_conv (Conv2D)        (None, 2, 2, 128)        131072        [&#39;conv4_block25_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block25_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block25_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block25_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block25_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block25_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block25_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block25_concat (Concatenate)   (None, 2, 2, 1056)       0             [&#39;conv4_block24_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block25_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block26_0_bn (BatchNormalizati  (None, 2, 2, 1056)      4224          [&#39;conv4_block25_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block26_0_relu (Activation)    (None, 2, 2, 1056)       0             [&#39;conv4_block26_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block26_1_conv (Conv2D)        (None, 2, 2, 128)        135168        [&#39;conv4_block26_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block26_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block26_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block26_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block26_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block26_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block26_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block26_concat (Concatenate)   (None, 2, 2, 1088)       0             [&#39;conv4_block25_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block26_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block27_0_bn (BatchNormalizati  (None, 2, 2, 1088)      4352          [&#39;conv4_block26_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block27_0_relu (Activation)    (None, 2, 2, 1088)       0             [&#39;conv4_block27_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block27_1_conv (Conv2D)        (None, 2, 2, 128)        139264        [&#39;conv4_block27_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block27_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block27_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block27_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block27_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block27_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block27_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block27_concat (Concatenate)   (None, 2, 2, 1120)       0             [&#39;conv4_block26_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block27_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block28_0_bn (BatchNormalizati  (None, 2, 2, 1120)      4480          [&#39;conv4_block27_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block28_0_relu (Activation)    (None, 2, 2, 1120)       0             [&#39;conv4_block28_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block28_1_conv (Conv2D)        (None, 2, 2, 128)        143360        [&#39;conv4_block28_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block28_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block28_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block28_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block28_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block28_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block28_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block28_concat (Concatenate)   (None, 2, 2, 1152)       0             [&#39;conv4_block27_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block28_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block29_0_bn (BatchNormalizati  (None, 2, 2, 1152)      4608          [&#39;conv4_block28_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block29_0_relu (Activation)    (None, 2, 2, 1152)       0             [&#39;conv4_block29_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block29_1_conv (Conv2D)        (None, 2, 2, 128)        147456        [&#39;conv4_block29_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block29_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block29_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block29_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block29_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block29_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block29_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block29_concat (Concatenate)   (None, 2, 2, 1184)       0             [&#39;conv4_block28_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block29_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block30_0_bn (BatchNormalizati  (None, 2, 2, 1184)      4736          [&#39;conv4_block29_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block30_0_relu (Activation)    (None, 2, 2, 1184)       0             [&#39;conv4_block30_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block30_1_conv (Conv2D)        (None, 2, 2, 128)        151552        [&#39;conv4_block30_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block30_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block30_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block30_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block30_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block30_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block30_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block30_concat (Concatenate)   (None, 2, 2, 1216)       0             [&#39;conv4_block29_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block30_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block31_0_bn (BatchNormalizati  (None, 2, 2, 1216)      4864          [&#39;conv4_block30_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block31_0_relu (Activation)    (None, 2, 2, 1216)       0             [&#39;conv4_block31_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block31_1_conv (Conv2D)        (None, 2, 2, 128)        155648        [&#39;conv4_block31_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block31_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block31_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block31_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block31_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block31_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block31_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block31_concat (Concatenate)   (None, 2, 2, 1248)       0             [&#39;conv4_block30_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block31_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block32_0_bn (BatchNormalizati  (None, 2, 2, 1248)      4992          [&#39;conv4_block31_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block32_0_relu (Activation)    (None, 2, 2, 1248)       0             [&#39;conv4_block32_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block32_1_conv (Conv2D)        (None, 2, 2, 128)        159744        [&#39;conv4_block32_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block32_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block32_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block32_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block32_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block32_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block32_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block32_concat (Concatenate)   (None, 2, 2, 1280)       0             [&#39;conv4_block31_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block32_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block33_0_bn (BatchNormalizati  (None, 2, 2, 1280)      5120          [&#39;conv4_block32_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block33_0_relu (Activation)    (None, 2, 2, 1280)       0             [&#39;conv4_block33_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block33_1_conv (Conv2D)        (None, 2, 2, 128)        163840        [&#39;conv4_block33_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block33_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block33_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block33_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block33_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block33_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block33_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block33_concat (Concatenate)   (None, 2, 2, 1312)       0             [&#39;conv4_block32_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block33_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block34_0_bn (BatchNormalizati  (None, 2, 2, 1312)      5248          [&#39;conv4_block33_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block34_0_relu (Activation)    (None, 2, 2, 1312)       0             [&#39;conv4_block34_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block34_1_conv (Conv2D)        (None, 2, 2, 128)        167936        [&#39;conv4_block34_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block34_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block34_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block34_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block34_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block34_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block34_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block34_concat (Concatenate)   (None, 2, 2, 1344)       0             [&#39;conv4_block33_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block34_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block35_0_bn (BatchNormalizati  (None, 2, 2, 1344)      5376          [&#39;conv4_block34_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block35_0_relu (Activation)    (None, 2, 2, 1344)       0             [&#39;conv4_block35_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block35_1_conv (Conv2D)        (None, 2, 2, 128)        172032        [&#39;conv4_block35_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block35_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block35_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block35_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block35_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block35_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block35_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block35_concat (Concatenate)   (None, 2, 2, 1376)       0             [&#39;conv4_block34_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block35_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block36_0_bn (BatchNormalizati  (None, 2, 2, 1376)      5504          [&#39;conv4_block35_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block36_0_relu (Activation)    (None, 2, 2, 1376)       0             [&#39;conv4_block36_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block36_1_conv (Conv2D)        (None, 2, 2, 128)        176128        [&#39;conv4_block36_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block36_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block36_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block36_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block36_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block36_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block36_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block36_concat (Concatenate)   (None, 2, 2, 1408)       0             [&#39;conv4_block35_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block36_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block37_0_bn (BatchNormalizati  (None, 2, 2, 1408)      5632          [&#39;conv4_block36_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block37_0_relu (Activation)    (None, 2, 2, 1408)       0             [&#39;conv4_block37_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block37_1_conv (Conv2D)        (None, 2, 2, 128)        180224        [&#39;conv4_block37_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block37_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block37_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block37_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block37_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block37_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block37_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block37_concat (Concatenate)   (None, 2, 2, 1440)       0             [&#39;conv4_block36_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block37_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block38_0_bn (BatchNormalizati  (None, 2, 2, 1440)      5760          [&#39;conv4_block37_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block38_0_relu (Activation)    (None, 2, 2, 1440)       0             [&#39;conv4_block38_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block38_1_conv (Conv2D)        (None, 2, 2, 128)        184320        [&#39;conv4_block38_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block38_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block38_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block38_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block38_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block38_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block38_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block38_concat (Concatenate)   (None, 2, 2, 1472)       0             [&#39;conv4_block37_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block38_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block39_0_bn (BatchNormalizati  (None, 2, 2, 1472)      5888          [&#39;conv4_block38_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block39_0_relu (Activation)    (None, 2, 2, 1472)       0             [&#39;conv4_block39_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block39_1_conv (Conv2D)        (None, 2, 2, 128)        188416        [&#39;conv4_block39_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block39_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block39_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block39_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block39_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block39_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block39_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block39_concat (Concatenate)   (None, 2, 2, 1504)       0             [&#39;conv4_block38_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block39_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block40_0_bn (BatchNormalizati  (None, 2, 2, 1504)      6016          [&#39;conv4_block39_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block40_0_relu (Activation)    (None, 2, 2, 1504)       0             [&#39;conv4_block40_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block40_1_conv (Conv2D)        (None, 2, 2, 128)        192512        [&#39;conv4_block40_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block40_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block40_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block40_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block40_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block40_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block40_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block40_concat (Concatenate)   (None, 2, 2, 1536)       0             [&#39;conv4_block39_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block40_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block41_0_bn (BatchNormalizati  (None, 2, 2, 1536)      6144          [&#39;conv4_block40_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block41_0_relu (Activation)    (None, 2, 2, 1536)       0             [&#39;conv4_block41_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block41_1_conv (Conv2D)        (None, 2, 2, 128)        196608        [&#39;conv4_block41_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block41_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block41_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block41_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block41_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block41_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block41_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block41_concat (Concatenate)   (None, 2, 2, 1568)       0             [&#39;conv4_block40_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block41_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block42_0_bn (BatchNormalizati  (None, 2, 2, 1568)      6272          [&#39;conv4_block41_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block42_0_relu (Activation)    (None, 2, 2, 1568)       0             [&#39;conv4_block42_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block42_1_conv (Conv2D)        (None, 2, 2, 128)        200704        [&#39;conv4_block42_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block42_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block42_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block42_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block42_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block42_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block42_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block42_concat (Concatenate)   (None, 2, 2, 1600)       0             [&#39;conv4_block41_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block42_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block43_0_bn (BatchNormalizati  (None, 2, 2, 1600)      6400          [&#39;conv4_block42_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block43_0_relu (Activation)    (None, 2, 2, 1600)       0             [&#39;conv4_block43_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block43_1_conv (Conv2D)        (None, 2, 2, 128)        204800        [&#39;conv4_block43_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block43_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block43_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block43_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block43_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block43_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block43_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block43_concat (Concatenate)   (None, 2, 2, 1632)       0             [&#39;conv4_block42_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block43_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block44_0_bn (BatchNormalizati  (None, 2, 2, 1632)      6528          [&#39;conv4_block43_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block44_0_relu (Activation)    (None, 2, 2, 1632)       0             [&#39;conv4_block44_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block44_1_conv (Conv2D)        (None, 2, 2, 128)        208896        [&#39;conv4_block44_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block44_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block44_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block44_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block44_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block44_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block44_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block44_concat (Concatenate)   (None, 2, 2, 1664)       0             [&#39;conv4_block43_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block44_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block45_0_bn (BatchNormalizati  (None, 2, 2, 1664)      6656          [&#39;conv4_block44_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block45_0_relu (Activation)    (None, 2, 2, 1664)       0             [&#39;conv4_block45_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block45_1_conv (Conv2D)        (None, 2, 2, 128)        212992        [&#39;conv4_block45_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block45_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block45_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block45_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block45_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block45_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block45_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block45_concat (Concatenate)   (None, 2, 2, 1696)       0             [&#39;conv4_block44_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block45_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block46_0_bn (BatchNormalizati  (None, 2, 2, 1696)      6784          [&#39;conv4_block45_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block46_0_relu (Activation)    (None, 2, 2, 1696)       0             [&#39;conv4_block46_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block46_1_conv (Conv2D)        (None, 2, 2, 128)        217088        [&#39;conv4_block46_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block46_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block46_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block46_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block46_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block46_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block46_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block46_concat (Concatenate)   (None, 2, 2, 1728)       0             [&#39;conv4_block45_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block46_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block47_0_bn (BatchNormalizati  (None, 2, 2, 1728)      6912          [&#39;conv4_block46_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block47_0_relu (Activation)    (None, 2, 2, 1728)       0             [&#39;conv4_block47_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block47_1_conv (Conv2D)        (None, 2, 2, 128)        221184        [&#39;conv4_block47_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block47_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block47_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block47_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block47_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block47_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block47_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block47_concat (Concatenate)   (None, 2, 2, 1760)       0             [&#39;conv4_block46_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block47_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv4_block48_0_bn (BatchNormalizati  (None, 2, 2, 1760)      7040          [&#39;conv4_block47_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block48_0_relu (Activation)    (None, 2, 2, 1760)       0             [&#39;conv4_block48_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block48_1_conv (Conv2D)        (None, 2, 2, 128)        225280        [&#39;conv4_block48_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block48_1_bn (BatchNormalizati  (None, 2, 2, 128)       512           [&#39;conv4_block48_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv4_block48_1_relu (Activation)    (None, 2, 2, 128)        0             [&#39;conv4_block48_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv4_block48_2_conv (Conv2D)        (None, 2, 2, 32)         36864         [&#39;conv4_block48_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv4_block48_concat (Concatenate)   (None, 2, 2, 1792)       0             [&#39;conv4_block47_concat[0][0]&#39;,         
##                                                                               &#39;conv4_block48_2_conv[0][0]&#39;]         
##                                                                                                                     
##  pool4_bn (BatchNormalization)        (None, 2, 2, 1792)       7168          [&#39;conv4_block48_concat[0][0]&#39;]         
##                                                                                                                     
##  pool4_relu (Activation)              (None, 2, 2, 1792)       0             [&#39;pool4_bn[0][0]&#39;]                     
##                                                                                                                     
##  pool4_conv (Conv2D)                  (None, 2, 2, 896)        1605632       [&#39;pool4_relu[0][0]&#39;]                   
##                                                                                                                     
##  pool4_pool (AveragePooling2D)        (None, 1, 1, 896)        0             [&#39;pool4_conv[0][0]&#39;]                   
##                                                                                                                     
##  conv5_block1_0_bn (BatchNormalizatio  (None, 1, 1, 896)       3584          [&#39;pool4_pool[0][0]&#39;]                   
##  n)                                                                                                                 
##                                                                                                                     
##  conv5_block1_0_relu (Activation)     (None, 1, 1, 896)        0             [&#39;conv5_block1_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv5_block1_1_conv (Conv2D)         (None, 1, 1, 128)        114688        [&#39;conv5_block1_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv5_block1_1_bn (BatchNormalizatio  (None, 1, 1, 128)       512           [&#39;conv5_block1_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv5_block1_1_relu (Activation)     (None, 1, 1, 128)        0             [&#39;conv5_block1_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv5_block1_2_conv (Conv2D)         (None, 1, 1, 32)         36864         [&#39;conv5_block1_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv5_block1_concat (Concatenate)    (None, 1, 1, 928)        0             [&#39;pool4_pool[0][0]&#39;,                   
##                                                                               &#39;conv5_block1_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv5_block2_0_bn (BatchNormalizatio  (None, 1, 1, 928)       3712          [&#39;conv5_block1_concat[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv5_block2_0_relu (Activation)     (None, 1, 1, 928)        0             [&#39;conv5_block2_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv5_block2_1_conv (Conv2D)         (None, 1, 1, 128)        118784        [&#39;conv5_block2_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv5_block2_1_bn (BatchNormalizatio  (None, 1, 1, 128)       512           [&#39;conv5_block2_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv5_block2_1_relu (Activation)     (None, 1, 1, 128)        0             [&#39;conv5_block2_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv5_block2_2_conv (Conv2D)         (None, 1, 1, 32)         36864         [&#39;conv5_block2_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv5_block2_concat (Concatenate)    (None, 1, 1, 960)        0             [&#39;conv5_block1_concat[0][0]&#39;,          
##                                                                               &#39;conv5_block2_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv5_block3_0_bn (BatchNormalizatio  (None, 1, 1, 960)       3840          [&#39;conv5_block2_concat[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv5_block3_0_relu (Activation)     (None, 1, 1, 960)        0             [&#39;conv5_block3_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv5_block3_1_conv (Conv2D)         (None, 1, 1, 128)        122880        [&#39;conv5_block3_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv5_block3_1_bn (BatchNormalizatio  (None, 1, 1, 128)       512           [&#39;conv5_block3_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv5_block3_1_relu (Activation)     (None, 1, 1, 128)        0             [&#39;conv5_block3_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv5_block3_2_conv (Conv2D)         (None, 1, 1, 32)         36864         [&#39;conv5_block3_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv5_block3_concat (Concatenate)    (None, 1, 1, 992)        0             [&#39;conv5_block2_concat[0][0]&#39;,          
##                                                                               &#39;conv5_block3_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv5_block4_0_bn (BatchNormalizatio  (None, 1, 1, 992)       3968          [&#39;conv5_block3_concat[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv5_block4_0_relu (Activation)     (None, 1, 1, 992)        0             [&#39;conv5_block4_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv5_block4_1_conv (Conv2D)         (None, 1, 1, 128)        126976        [&#39;conv5_block4_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv5_block4_1_bn (BatchNormalizatio  (None, 1, 1, 128)       512           [&#39;conv5_block4_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv5_block4_1_relu (Activation)     (None, 1, 1, 128)        0             [&#39;conv5_block4_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv5_block4_2_conv (Conv2D)         (None, 1, 1, 32)         36864         [&#39;conv5_block4_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv5_block4_concat (Concatenate)    (None, 1, 1, 1024)       0             [&#39;conv5_block3_concat[0][0]&#39;,          
##                                                                               &#39;conv5_block4_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv5_block5_0_bn (BatchNormalizatio  (None, 1, 1, 1024)      4096          [&#39;conv5_block4_concat[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv5_block5_0_relu (Activation)     (None, 1, 1, 1024)       0             [&#39;conv5_block5_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv5_block5_1_conv (Conv2D)         (None, 1, 1, 128)        131072        [&#39;conv5_block5_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv5_block5_1_bn (BatchNormalizatio  (None, 1, 1, 128)       512           [&#39;conv5_block5_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv5_block5_1_relu (Activation)     (None, 1, 1, 128)        0             [&#39;conv5_block5_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv5_block5_2_conv (Conv2D)         (None, 1, 1, 32)         36864         [&#39;conv5_block5_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv5_block5_concat (Concatenate)    (None, 1, 1, 1056)       0             [&#39;conv5_block4_concat[0][0]&#39;,          
##                                                                               &#39;conv5_block5_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv5_block6_0_bn (BatchNormalizatio  (None, 1, 1, 1056)      4224          [&#39;conv5_block5_concat[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv5_block6_0_relu (Activation)     (None, 1, 1, 1056)       0             [&#39;conv5_block6_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv5_block6_1_conv (Conv2D)         (None, 1, 1, 128)        135168        [&#39;conv5_block6_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv5_block6_1_bn (BatchNormalizatio  (None, 1, 1, 128)       512           [&#39;conv5_block6_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv5_block6_1_relu (Activation)     (None, 1, 1, 128)        0             [&#39;conv5_block6_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv5_block6_2_conv (Conv2D)         (None, 1, 1, 32)         36864         [&#39;conv5_block6_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv5_block6_concat (Concatenate)    (None, 1, 1, 1088)       0             [&#39;conv5_block5_concat[0][0]&#39;,          
##                                                                               &#39;conv5_block6_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv5_block7_0_bn (BatchNormalizatio  (None, 1, 1, 1088)      4352          [&#39;conv5_block6_concat[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv5_block7_0_relu (Activation)     (None, 1, 1, 1088)       0             [&#39;conv5_block7_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv5_block7_1_conv (Conv2D)         (None, 1, 1, 128)        139264        [&#39;conv5_block7_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv5_block7_1_bn (BatchNormalizatio  (None, 1, 1, 128)       512           [&#39;conv5_block7_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv5_block7_1_relu (Activation)     (None, 1, 1, 128)        0             [&#39;conv5_block7_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv5_block7_2_conv (Conv2D)         (None, 1, 1, 32)         36864         [&#39;conv5_block7_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv5_block7_concat (Concatenate)    (None, 1, 1, 1120)       0             [&#39;conv5_block6_concat[0][0]&#39;,          
##                                                                               &#39;conv5_block7_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv5_block8_0_bn (BatchNormalizatio  (None, 1, 1, 1120)      4480          [&#39;conv5_block7_concat[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv5_block8_0_relu (Activation)     (None, 1, 1, 1120)       0             [&#39;conv5_block8_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv5_block8_1_conv (Conv2D)         (None, 1, 1, 128)        143360        [&#39;conv5_block8_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv5_block8_1_bn (BatchNormalizatio  (None, 1, 1, 128)       512           [&#39;conv5_block8_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv5_block8_1_relu (Activation)     (None, 1, 1, 128)        0             [&#39;conv5_block8_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv5_block8_2_conv (Conv2D)         (None, 1, 1, 32)         36864         [&#39;conv5_block8_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv5_block8_concat (Concatenate)    (None, 1, 1, 1152)       0             [&#39;conv5_block7_concat[0][0]&#39;,          
##                                                                               &#39;conv5_block8_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv5_block9_0_bn (BatchNormalizatio  (None, 1, 1, 1152)      4608          [&#39;conv5_block8_concat[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv5_block9_0_relu (Activation)     (None, 1, 1, 1152)       0             [&#39;conv5_block9_0_bn[0][0]&#39;]            
##                                                                                                                     
##  conv5_block9_1_conv (Conv2D)         (None, 1, 1, 128)        147456        [&#39;conv5_block9_0_relu[0][0]&#39;]          
##                                                                                                                     
##  conv5_block9_1_bn (BatchNormalizatio  (None, 1, 1, 128)       512           [&#39;conv5_block9_1_conv[0][0]&#39;]          
##  n)                                                                                                                 
##                                                                                                                     
##  conv5_block9_1_relu (Activation)     (None, 1, 1, 128)        0             [&#39;conv5_block9_1_bn[0][0]&#39;]            
##                                                                                                                     
##  conv5_block9_2_conv (Conv2D)         (None, 1, 1, 32)         36864         [&#39;conv5_block9_1_relu[0][0]&#39;]          
##                                                                                                                     
##  conv5_block9_concat (Concatenate)    (None, 1, 1, 1184)       0             [&#39;conv5_block8_concat[0][0]&#39;,          
##                                                                               &#39;conv5_block9_2_conv[0][0]&#39;]          
##                                                                                                                     
##  conv5_block10_0_bn (BatchNormalizati  (None, 1, 1, 1184)      4736          [&#39;conv5_block9_concat[0][0]&#39;]          
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block10_0_relu (Activation)    (None, 1, 1, 1184)       0             [&#39;conv5_block10_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block10_1_conv (Conv2D)        (None, 1, 1, 128)        151552        [&#39;conv5_block10_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block10_1_bn (BatchNormalizati  (None, 1, 1, 128)       512           [&#39;conv5_block10_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block10_1_relu (Activation)    (None, 1, 1, 128)        0             [&#39;conv5_block10_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block10_2_conv (Conv2D)        (None, 1, 1, 32)         36864         [&#39;conv5_block10_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block10_concat (Concatenate)   (None, 1, 1, 1216)       0             [&#39;conv5_block9_concat[0][0]&#39;,          
##                                                                               &#39;conv5_block10_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv5_block11_0_bn (BatchNormalizati  (None, 1, 1, 1216)      4864          [&#39;conv5_block10_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block11_0_relu (Activation)    (None, 1, 1, 1216)       0             [&#39;conv5_block11_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block11_1_conv (Conv2D)        (None, 1, 1, 128)        155648        [&#39;conv5_block11_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block11_1_bn (BatchNormalizati  (None, 1, 1, 128)       512           [&#39;conv5_block11_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block11_1_relu (Activation)    (None, 1, 1, 128)        0             [&#39;conv5_block11_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block11_2_conv (Conv2D)        (None, 1, 1, 32)         36864         [&#39;conv5_block11_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block11_concat (Concatenate)   (None, 1, 1, 1248)       0             [&#39;conv5_block10_concat[0][0]&#39;,         
##                                                                               &#39;conv5_block11_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv5_block12_0_bn (BatchNormalizati  (None, 1, 1, 1248)      4992          [&#39;conv5_block11_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block12_0_relu (Activation)    (None, 1, 1, 1248)       0             [&#39;conv5_block12_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block12_1_conv (Conv2D)        (None, 1, 1, 128)        159744        [&#39;conv5_block12_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block12_1_bn (BatchNormalizati  (None, 1, 1, 128)       512           [&#39;conv5_block12_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block12_1_relu (Activation)    (None, 1, 1, 128)        0             [&#39;conv5_block12_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block12_2_conv (Conv2D)        (None, 1, 1, 32)         36864         [&#39;conv5_block12_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block12_concat (Concatenate)   (None, 1, 1, 1280)       0             [&#39;conv5_block11_concat[0][0]&#39;,         
##                                                                               &#39;conv5_block12_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv5_block13_0_bn (BatchNormalizati  (None, 1, 1, 1280)      5120          [&#39;conv5_block12_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block13_0_relu (Activation)    (None, 1, 1, 1280)       0             [&#39;conv5_block13_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block13_1_conv (Conv2D)        (None, 1, 1, 128)        163840        [&#39;conv5_block13_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block13_1_bn (BatchNormalizati  (None, 1, 1, 128)       512           [&#39;conv5_block13_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block13_1_relu (Activation)    (None, 1, 1, 128)        0             [&#39;conv5_block13_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block13_2_conv (Conv2D)        (None, 1, 1, 32)         36864         [&#39;conv5_block13_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block13_concat (Concatenate)   (None, 1, 1, 1312)       0             [&#39;conv5_block12_concat[0][0]&#39;,         
##                                                                               &#39;conv5_block13_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv5_block14_0_bn (BatchNormalizati  (None, 1, 1, 1312)      5248          [&#39;conv5_block13_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block14_0_relu (Activation)    (None, 1, 1, 1312)       0             [&#39;conv5_block14_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block14_1_conv (Conv2D)        (None, 1, 1, 128)        167936        [&#39;conv5_block14_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block14_1_bn (BatchNormalizati  (None, 1, 1, 128)       512           [&#39;conv5_block14_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block14_1_relu (Activation)    (None, 1, 1, 128)        0             [&#39;conv5_block14_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block14_2_conv (Conv2D)        (None, 1, 1, 32)         36864         [&#39;conv5_block14_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block14_concat (Concatenate)   (None, 1, 1, 1344)       0             [&#39;conv5_block13_concat[0][0]&#39;,         
##                                                                               &#39;conv5_block14_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv5_block15_0_bn (BatchNormalizati  (None, 1, 1, 1344)      5376          [&#39;conv5_block14_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block15_0_relu (Activation)    (None, 1, 1, 1344)       0             [&#39;conv5_block15_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block15_1_conv (Conv2D)        (None, 1, 1, 128)        172032        [&#39;conv5_block15_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block15_1_bn (BatchNormalizati  (None, 1, 1, 128)       512           [&#39;conv5_block15_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block15_1_relu (Activation)    (None, 1, 1, 128)        0             [&#39;conv5_block15_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block15_2_conv (Conv2D)        (None, 1, 1, 32)         36864         [&#39;conv5_block15_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block15_concat (Concatenate)   (None, 1, 1, 1376)       0             [&#39;conv5_block14_concat[0][0]&#39;,         
##                                                                               &#39;conv5_block15_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv5_block16_0_bn (BatchNormalizati  (None, 1, 1, 1376)      5504          [&#39;conv5_block15_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block16_0_relu (Activation)    (None, 1, 1, 1376)       0             [&#39;conv5_block16_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block16_1_conv (Conv2D)        (None, 1, 1, 128)        176128        [&#39;conv5_block16_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block16_1_bn (BatchNormalizati  (None, 1, 1, 128)       512           [&#39;conv5_block16_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block16_1_relu (Activation)    (None, 1, 1, 128)        0             [&#39;conv5_block16_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block16_2_conv (Conv2D)        (None, 1, 1, 32)         36864         [&#39;conv5_block16_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block16_concat (Concatenate)   (None, 1, 1, 1408)       0             [&#39;conv5_block15_concat[0][0]&#39;,         
##                                                                               &#39;conv5_block16_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv5_block17_0_bn (BatchNormalizati  (None, 1, 1, 1408)      5632          [&#39;conv5_block16_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block17_0_relu (Activation)    (None, 1, 1, 1408)       0             [&#39;conv5_block17_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block17_1_conv (Conv2D)        (None, 1, 1, 128)        180224        [&#39;conv5_block17_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block17_1_bn (BatchNormalizati  (None, 1, 1, 128)       512           [&#39;conv5_block17_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block17_1_relu (Activation)    (None, 1, 1, 128)        0             [&#39;conv5_block17_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block17_2_conv (Conv2D)        (None, 1, 1, 32)         36864         [&#39;conv5_block17_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block17_concat (Concatenate)   (None, 1, 1, 1440)       0             [&#39;conv5_block16_concat[0][0]&#39;,         
##                                                                               &#39;conv5_block17_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv5_block18_0_bn (BatchNormalizati  (None, 1, 1, 1440)      5760          [&#39;conv5_block17_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block18_0_relu (Activation)    (None, 1, 1, 1440)       0             [&#39;conv5_block18_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block18_1_conv (Conv2D)        (None, 1, 1, 128)        184320        [&#39;conv5_block18_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block18_1_bn (BatchNormalizati  (None, 1, 1, 128)       512           [&#39;conv5_block18_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block18_1_relu (Activation)    (None, 1, 1, 128)        0             [&#39;conv5_block18_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block18_2_conv (Conv2D)        (None, 1, 1, 32)         36864         [&#39;conv5_block18_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block18_concat (Concatenate)   (None, 1, 1, 1472)       0             [&#39;conv5_block17_concat[0][0]&#39;,         
##                                                                               &#39;conv5_block18_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv5_block19_0_bn (BatchNormalizati  (None, 1, 1, 1472)      5888          [&#39;conv5_block18_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block19_0_relu (Activation)    (None, 1, 1, 1472)       0             [&#39;conv5_block19_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block19_1_conv (Conv2D)        (None, 1, 1, 128)        188416        [&#39;conv5_block19_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block19_1_bn (BatchNormalizati  (None, 1, 1, 128)       512           [&#39;conv5_block19_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block19_1_relu (Activation)    (None, 1, 1, 128)        0             [&#39;conv5_block19_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block19_2_conv (Conv2D)        (None, 1, 1, 32)         36864         [&#39;conv5_block19_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block19_concat (Concatenate)   (None, 1, 1, 1504)       0             [&#39;conv5_block18_concat[0][0]&#39;,         
##                                                                               &#39;conv5_block19_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv5_block20_0_bn (BatchNormalizati  (None, 1, 1, 1504)      6016          [&#39;conv5_block19_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block20_0_relu (Activation)    (None, 1, 1, 1504)       0             [&#39;conv5_block20_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block20_1_conv (Conv2D)        (None, 1, 1, 128)        192512        [&#39;conv5_block20_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block20_1_bn (BatchNormalizati  (None, 1, 1, 128)       512           [&#39;conv5_block20_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block20_1_relu (Activation)    (None, 1, 1, 128)        0             [&#39;conv5_block20_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block20_2_conv (Conv2D)        (None, 1, 1, 32)         36864         [&#39;conv5_block20_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block20_concat (Concatenate)   (None, 1, 1, 1536)       0             [&#39;conv5_block19_concat[0][0]&#39;,         
##                                                                               &#39;conv5_block20_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv5_block21_0_bn (BatchNormalizati  (None, 1, 1, 1536)      6144          [&#39;conv5_block20_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block21_0_relu (Activation)    (None, 1, 1, 1536)       0             [&#39;conv5_block21_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block21_1_conv (Conv2D)        (None, 1, 1, 128)        196608        [&#39;conv5_block21_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block21_1_bn (BatchNormalizati  (None, 1, 1, 128)       512           [&#39;conv5_block21_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block21_1_relu (Activation)    (None, 1, 1, 128)        0             [&#39;conv5_block21_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block21_2_conv (Conv2D)        (None, 1, 1, 32)         36864         [&#39;conv5_block21_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block21_concat (Concatenate)   (None, 1, 1, 1568)       0             [&#39;conv5_block20_concat[0][0]&#39;,         
##                                                                               &#39;conv5_block21_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv5_block22_0_bn (BatchNormalizati  (None, 1, 1, 1568)      6272          [&#39;conv5_block21_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block22_0_relu (Activation)    (None, 1, 1, 1568)       0             [&#39;conv5_block22_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block22_1_conv (Conv2D)        (None, 1, 1, 128)        200704        [&#39;conv5_block22_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block22_1_bn (BatchNormalizati  (None, 1, 1, 128)       512           [&#39;conv5_block22_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block22_1_relu (Activation)    (None, 1, 1, 128)        0             [&#39;conv5_block22_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block22_2_conv (Conv2D)        (None, 1, 1, 32)         36864         [&#39;conv5_block22_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block22_concat (Concatenate)   (None, 1, 1, 1600)       0             [&#39;conv5_block21_concat[0][0]&#39;,         
##                                                                               &#39;conv5_block22_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv5_block23_0_bn (BatchNormalizati  (None, 1, 1, 1600)      6400          [&#39;conv5_block22_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block23_0_relu (Activation)    (None, 1, 1, 1600)       0             [&#39;conv5_block23_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block23_1_conv (Conv2D)        (None, 1, 1, 128)        204800        [&#39;conv5_block23_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block23_1_bn (BatchNormalizati  (None, 1, 1, 128)       512           [&#39;conv5_block23_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block23_1_relu (Activation)    (None, 1, 1, 128)        0             [&#39;conv5_block23_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block23_2_conv (Conv2D)        (None, 1, 1, 32)         36864         [&#39;conv5_block23_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block23_concat (Concatenate)   (None, 1, 1, 1632)       0             [&#39;conv5_block22_concat[0][0]&#39;,         
##                                                                               &#39;conv5_block23_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv5_block24_0_bn (BatchNormalizati  (None, 1, 1, 1632)      6528          [&#39;conv5_block23_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block24_0_relu (Activation)    (None, 1, 1, 1632)       0             [&#39;conv5_block24_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block24_1_conv (Conv2D)        (None, 1, 1, 128)        208896        [&#39;conv5_block24_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block24_1_bn (BatchNormalizati  (None, 1, 1, 128)       512           [&#39;conv5_block24_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block24_1_relu (Activation)    (None, 1, 1, 128)        0             [&#39;conv5_block24_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block24_2_conv (Conv2D)        (None, 1, 1, 32)         36864         [&#39;conv5_block24_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block24_concat (Concatenate)   (None, 1, 1, 1664)       0             [&#39;conv5_block23_concat[0][0]&#39;,         
##                                                                               &#39;conv5_block24_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv5_block25_0_bn (BatchNormalizati  (None, 1, 1, 1664)      6656          [&#39;conv5_block24_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block25_0_relu (Activation)    (None, 1, 1, 1664)       0             [&#39;conv5_block25_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block25_1_conv (Conv2D)        (None, 1, 1, 128)        212992        [&#39;conv5_block25_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block25_1_bn (BatchNormalizati  (None, 1, 1, 128)       512           [&#39;conv5_block25_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block25_1_relu (Activation)    (None, 1, 1, 128)        0             [&#39;conv5_block25_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block25_2_conv (Conv2D)        (None, 1, 1, 32)         36864         [&#39;conv5_block25_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block25_concat (Concatenate)   (None, 1, 1, 1696)       0             [&#39;conv5_block24_concat[0][0]&#39;,         
##                                                                               &#39;conv5_block25_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv5_block26_0_bn (BatchNormalizati  (None, 1, 1, 1696)      6784          [&#39;conv5_block25_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block26_0_relu (Activation)    (None, 1, 1, 1696)       0             [&#39;conv5_block26_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block26_1_conv (Conv2D)        (None, 1, 1, 128)        217088        [&#39;conv5_block26_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block26_1_bn (BatchNormalizati  (None, 1, 1, 128)       512           [&#39;conv5_block26_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block26_1_relu (Activation)    (None, 1, 1, 128)        0             [&#39;conv5_block26_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block26_2_conv (Conv2D)        (None, 1, 1, 32)         36864         [&#39;conv5_block26_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block26_concat (Concatenate)   (None, 1, 1, 1728)       0             [&#39;conv5_block25_concat[0][0]&#39;,         
##                                                                               &#39;conv5_block26_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv5_block27_0_bn (BatchNormalizati  (None, 1, 1, 1728)      6912          [&#39;conv5_block26_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block27_0_relu (Activation)    (None, 1, 1, 1728)       0             [&#39;conv5_block27_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block27_1_conv (Conv2D)        (None, 1, 1, 128)        221184        [&#39;conv5_block27_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block27_1_bn (BatchNormalizati  (None, 1, 1, 128)       512           [&#39;conv5_block27_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block27_1_relu (Activation)    (None, 1, 1, 128)        0             [&#39;conv5_block27_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block27_2_conv (Conv2D)        (None, 1, 1, 32)         36864         [&#39;conv5_block27_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block27_concat (Concatenate)   (None, 1, 1, 1760)       0             [&#39;conv5_block26_concat[0][0]&#39;,         
##                                                                               &#39;conv5_block27_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv5_block28_0_bn (BatchNormalizati  (None, 1, 1, 1760)      7040          [&#39;conv5_block27_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block28_0_relu (Activation)    (None, 1, 1, 1760)       0             [&#39;conv5_block28_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block28_1_conv (Conv2D)        (None, 1, 1, 128)        225280        [&#39;conv5_block28_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block28_1_bn (BatchNormalizati  (None, 1, 1, 128)       512           [&#39;conv5_block28_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block28_1_relu (Activation)    (None, 1, 1, 128)        0             [&#39;conv5_block28_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block28_2_conv (Conv2D)        (None, 1, 1, 32)         36864         [&#39;conv5_block28_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block28_concat (Concatenate)   (None, 1, 1, 1792)       0             [&#39;conv5_block27_concat[0][0]&#39;,         
##                                                                               &#39;conv5_block28_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv5_block29_0_bn (BatchNormalizati  (None, 1, 1, 1792)      7168          [&#39;conv5_block28_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block29_0_relu (Activation)    (None, 1, 1, 1792)       0             [&#39;conv5_block29_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block29_1_conv (Conv2D)        (None, 1, 1, 128)        229376        [&#39;conv5_block29_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block29_1_bn (BatchNormalizati  (None, 1, 1, 128)       512           [&#39;conv5_block29_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block29_1_relu (Activation)    (None, 1, 1, 128)        0             [&#39;conv5_block29_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block29_2_conv (Conv2D)        (None, 1, 1, 32)         36864         [&#39;conv5_block29_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block29_concat (Concatenate)   (None, 1, 1, 1824)       0             [&#39;conv5_block28_concat[0][0]&#39;,         
##                                                                               &#39;conv5_block29_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv5_block30_0_bn (BatchNormalizati  (None, 1, 1, 1824)      7296          [&#39;conv5_block29_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block30_0_relu (Activation)    (None, 1, 1, 1824)       0             [&#39;conv5_block30_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block30_1_conv (Conv2D)        (None, 1, 1, 128)        233472        [&#39;conv5_block30_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block30_1_bn (BatchNormalizati  (None, 1, 1, 128)       512           [&#39;conv5_block30_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block30_1_relu (Activation)    (None, 1, 1, 128)        0             [&#39;conv5_block30_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block30_2_conv (Conv2D)        (None, 1, 1, 32)         36864         [&#39;conv5_block30_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block30_concat (Concatenate)   (None, 1, 1, 1856)       0             [&#39;conv5_block29_concat[0][0]&#39;,         
##                                                                               &#39;conv5_block30_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv5_block31_0_bn (BatchNormalizati  (None, 1, 1, 1856)      7424          [&#39;conv5_block30_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block31_0_relu (Activation)    (None, 1, 1, 1856)       0             [&#39;conv5_block31_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block31_1_conv (Conv2D)        (None, 1, 1, 128)        237568        [&#39;conv5_block31_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block31_1_bn (BatchNormalizati  (None, 1, 1, 128)       512           [&#39;conv5_block31_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block31_1_relu (Activation)    (None, 1, 1, 128)        0             [&#39;conv5_block31_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block31_2_conv (Conv2D)        (None, 1, 1, 32)         36864         [&#39;conv5_block31_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block31_concat (Concatenate)   (None, 1, 1, 1888)       0             [&#39;conv5_block30_concat[0][0]&#39;,         
##                                                                               &#39;conv5_block31_2_conv[0][0]&#39;]         
##                                                                                                                     
##  conv5_block32_0_bn (BatchNormalizati  (None, 1, 1, 1888)      7552          [&#39;conv5_block31_concat[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block32_0_relu (Activation)    (None, 1, 1, 1888)       0             [&#39;conv5_block32_0_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block32_1_conv (Conv2D)        (None, 1, 1, 128)        241664        [&#39;conv5_block32_0_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block32_1_bn (BatchNormalizati  (None, 1, 1, 128)       512           [&#39;conv5_block32_1_conv[0][0]&#39;]         
##  on)                                                                                                                
##                                                                                                                     
##  conv5_block32_1_relu (Activation)    (None, 1, 1, 128)        0             [&#39;conv5_block32_1_bn[0][0]&#39;]           
##                                                                                                                     
##  conv5_block32_2_conv (Conv2D)        (None, 1, 1, 32)         36864         [&#39;conv5_block32_1_relu[0][0]&#39;]         
##                                                                                                                     
##  conv5_block32_concat (Concatenate)   (None, 1, 1, 1920)       0             [&#39;conv5_block31_concat[0][0]&#39;,         
##                                                                               &#39;conv5_block32_2_conv[0][0]&#39;]         
##                                                                                                                     
##  bn (BatchNormalization)              (None, 1, 1, 1920)       7680          [&#39;conv5_block32_concat[0][0]&#39;]         
##                                                                                                                     
##  relu (Activation)                    (None, 1, 1, 1920)       0             [&#39;bn[0][0]&#39;]                           
##                                                                                                                     
##  dense_153 (Dense)                    (None, 1, 1, 10)         19210         [&#39;relu[0][0]&#39;]                         
##                                                                                                                     
##  flatten_1 (Flatten)                  (None, 10)               0             [&#39;dense_153[0][0]&#39;]                    
##                                                                                                                     
## ====================================================================================================================
## Total params: 18,341,194
## Trainable params: 0
## Non-trainable params: 18,341,194
## ____________________________________________________________________________________________________________________</code></pre>
<p>And then the usual training:</p>
<div class="sourceCode" id="cb764"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb764-1"><a href="deep.html#cb764-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb764-2"><a href="deep.html#cb764-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb764-3"><a href="deep.html#cb764-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb764-4"><a href="deep.html#cb764-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb764-5"><a href="deep.html#cb764-5" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb764-6"><a href="deep.html#cb764-6" aria-hidden="true" tabindex="-1"></a>  keras<span class="sc">::</span><span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy, </span>
<span id="cb764-7"><a href="deep.html#cb764-7" aria-hidden="true" tabindex="-1"></a>                 <span class="at">optimizer =</span> <span class="fu">optimizer_adamax</span>())</span>
<span id="cb764-8"><a href="deep.html#cb764-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb764-9"><a href="deep.html#cb764-9" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb764-10"><a href="deep.html#cb764-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(</span>
<span id="cb764-11"><a href="deep.html#cb764-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> train_x, </span>
<span id="cb764-12"><a href="deep.html#cb764-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> train_y,</span>
<span id="cb764-13"><a href="deep.html#cb764-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">epochs =</span> 1L,</span>
<span id="cb764-14"><a href="deep.html#cb764-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">batch_size =</span> 32L,</span>
<span id="cb764-15"><a href="deep.html#cb764-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">shuffle =</span> <span class="cn">TRUE</span>,</span>
<span id="cb764-16"><a href="deep.html#cb764-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">validation_split =</span> <span class="fl">0.2</span></span>
<span id="cb764-17"><a href="deep.html#cb764-17" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<p>We have seen, that transfer learning can easily be done using Keras.</p>
<details>
<summary>
<strong><span style="color: #CC2FAA;">Torch</span></strong>
</summary>
<p>
<pre><code>In Torch, we have to change the transform function (but only for the train dataloader):</code></pre>
<div class="sourceCode" id="cb766"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb766-1"><a href="deep.html#cb766-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torchvision)</span>
<span id="cb766-2"><a href="deep.html#cb766-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb766-3"><a href="deep.html#cb766-3" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_manual_seed</span>(321L)</span>
<span id="cb766-4"><a href="deep.html#cb766-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb766-5"><a href="deep.html#cb766-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb766-6"><a href="deep.html#cb766-6" aria-hidden="true" tabindex="-1"></a>train_ds <span class="ot">=</span> <span class="fu">cifar10_dataset</span>(<span class="st">&quot;.&quot;</span>, <span class="at">download =</span> <span class="cn">TRUE</span>, <span class="at">train =</span> <span class="cn">TRUE</span>,</span>
<span id="cb766-7"><a href="deep.html#cb766-7" aria-hidden="true" tabindex="-1"></a>                           <span class="at">transform =</span> transform_to_tensor)</span>
<span id="cb766-8"><a href="deep.html#cb766-8" aria-hidden="true" tabindex="-1"></a>test_ds <span class="ot">=</span> <span class="fu">cifar10_dataset</span>(<span class="st">&quot;.&quot;</span>, <span class="at">download =</span> <span class="cn">TRUE</span>, <span class="at">train =</span> <span class="cn">FALSE</span>,</span>
<span id="cb766-9"><a href="deep.html#cb766-9" aria-hidden="true" tabindex="-1"></a>                          <span class="at">transform =</span> transform_to_tensor)</span>
<span id="cb766-10"><a href="deep.html#cb766-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb766-11"><a href="deep.html#cb766-11" aria-hidden="true" tabindex="-1"></a>train_dl <span class="ot">=</span> <span class="fu">dataloader</span>(train_ds, <span class="at">batch_size =</span> 100L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb766-12"><a href="deep.html#cb766-12" aria-hidden="true" tabindex="-1"></a>test_dl <span class="ot">=</span> <span class="fu">dataloader</span>(test_ds, <span class="at">batch_size =</span> 100L)</span>
<span id="cb766-13"><a href="deep.html#cb766-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb766-14"><a href="deep.html#cb766-14" aria-hidden="true" tabindex="-1"></a>model_torch <span class="ot">=</span> <span class="fu">model_resnet18</span>(<span class="at">pretrained =</span> <span class="cn">TRUE</span>)</span>
<span id="cb766-15"><a href="deep.html#cb766-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb766-16"><a href="deep.html#cb766-16" aria-hidden="true" tabindex="-1"></a><span class="co"># We will set all model parameters to constant values:</span></span>
<span id="cb766-17"><a href="deep.html#cb766-17" aria-hidden="true" tabindex="-1"></a>model_torch<span class="sc">$</span>parameters <span class="sc">%&gt;%</span></span>
<span id="cb766-18"><a href="deep.html#cb766-18" aria-hidden="true" tabindex="-1"></a>  purrr<span class="sc">::</span><span class="fu">walk</span>(<span class="cf">function</span>(param) param<span class="sc">$</span><span class="fu">requires_grad_</span>(<span class="cn">FALSE</span>))</span>
<span id="cb766-19"><a href="deep.html#cb766-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb766-20"><a href="deep.html#cb766-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Let&#39;s replace the last layer (last layer is named &#39;fc&#39;) with our own layer:</span></span>
<span id="cb766-21"><a href="deep.html#cb766-21" aria-hidden="true" tabindex="-1"></a>inFeat <span class="ot">=</span> model_torch<span class="sc">$</span>fc<span class="sc">$</span>in_features</span>
<span id="cb766-22"><a href="deep.html#cb766-22" aria-hidden="true" tabindex="-1"></a>model_torch<span class="sc">$</span>fc <span class="ot">=</span> <span class="fu">nn_linear</span>(inFeat, <span class="at">out_features =</span> 10L)</span>
<span id="cb766-23"><a href="deep.html#cb766-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb766-24"><a href="deep.html#cb766-24" aria-hidden="true" tabindex="-1"></a>opt <span class="ot">=</span> <span class="fu">optim_adam</span>(<span class="at">params =</span> model_torch<span class="sc">$</span>parameters, <span class="at">lr =</span> <span class="fl">0.01</span>)</span>
<span id="cb766-25"><a href="deep.html#cb766-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb766-26"><a href="deep.html#cb766-26" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(e <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">1</span>){</span>
<span id="cb766-27"><a href="deep.html#cb766-27" aria-hidden="true" tabindex="-1"></a>  losses <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb766-28"><a href="deep.html#cb766-28" aria-hidden="true" tabindex="-1"></a>  coro<span class="sc">::</span><span class="fu">loop</span>(</span>
<span id="cb766-29"><a href="deep.html#cb766-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(batch <span class="cf">in</span> train_dl){</span>
<span id="cb766-30"><a href="deep.html#cb766-30" aria-hidden="true" tabindex="-1"></a>      opt<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb766-31"><a href="deep.html#cb766-31" aria-hidden="true" tabindex="-1"></a>      pred <span class="ot">=</span> <span class="fu">model_torch</span>(batch[[<span class="dv">1</span>]])</span>
<span id="cb766-32"><a href="deep.html#cb766-32" aria-hidden="true" tabindex="-1"></a>      loss <span class="ot">=</span> <span class="fu">nnf_cross_entropy</span>(pred, batch[[<span class="dv">2</span>]], <span class="at">reduction =</span> <span class="st">&quot;mean&quot;</span>)</span>
<span id="cb766-33"><a href="deep.html#cb766-33" aria-hidden="true" tabindex="-1"></a>      loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb766-34"><a href="deep.html#cb766-34" aria-hidden="true" tabindex="-1"></a>      opt<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb766-35"><a href="deep.html#cb766-35" aria-hidden="true" tabindex="-1"></a>      losses <span class="ot">=</span> <span class="fu">c</span>(losses, loss<span class="sc">$</span><span class="fu">item</span>())</span>
<span id="cb766-36"><a href="deep.html#cb766-36" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb766-37"><a href="deep.html#cb766-37" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb766-38"><a href="deep.html#cb766-38" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb766-39"><a href="deep.html#cb766-39" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">&quot;Loss at epoch %d: %3f</span><span class="sc">\n</span><span class="st">&quot;</span>, e, <span class="fu">mean</span>(losses)))</span>
<span id="cb766-40"><a href="deep.html#cb766-40" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb766-41"><a href="deep.html#cb766-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb766-42"><a href="deep.html#cb766-42" aria-hidden="true" tabindex="-1"></a>model_torch<span class="sc">$</span><span class="fu">eval</span>()</span>
<span id="cb766-43"><a href="deep.html#cb766-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb766-44"><a href="deep.html#cb766-44" aria-hidden="true" tabindex="-1"></a>test_losses <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb766-45"><a href="deep.html#cb766-45" aria-hidden="true" tabindex="-1"></a>total <span class="ot">=</span> <span class="dv">0</span></span>
<span id="cb766-46"><a href="deep.html#cb766-46" aria-hidden="true" tabindex="-1"></a>correct <span class="ot">=</span> <span class="dv">0</span></span>
<span id="cb766-47"><a href="deep.html#cb766-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb766-48"><a href="deep.html#cb766-48" aria-hidden="true" tabindex="-1"></a>coro<span class="sc">::</span><span class="fu">loop</span>(</span>
<span id="cb766-49"><a href="deep.html#cb766-49" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(batch <span class="cf">in</span> test_dl){</span>
<span id="cb766-50"><a href="deep.html#cb766-50" aria-hidden="true" tabindex="-1"></a>    output <span class="ot">=</span> <span class="fu">model_torch</span>(batch[[<span class="dv">1</span>]])</span>
<span id="cb766-51"><a href="deep.html#cb766-51" aria-hidden="true" tabindex="-1"></a>    labels <span class="ot">=</span> batch[[<span class="dv">2</span>]]</span>
<span id="cb766-52"><a href="deep.html#cb766-52" aria-hidden="true" tabindex="-1"></a>    loss <span class="ot">=</span> <span class="fu">nnf_cross_entropy</span>(output, labels)</span>
<span id="cb766-53"><a href="deep.html#cb766-53" aria-hidden="true" tabindex="-1"></a>    test_losses <span class="ot">=</span> <span class="fu">c</span>(test_losses, loss<span class="sc">$</span><span class="fu">item</span>())</span>
<span id="cb766-54"><a href="deep.html#cb766-54" aria-hidden="true" tabindex="-1"></a>    predicted <span class="ot">=</span> <span class="fu">torch_max</span>(output<span class="sc">$</span><span class="fu">data</span>(), <span class="at">dim =</span> <span class="dv">2</span>)[[<span class="dv">2</span>]]</span>
<span id="cb766-55"><a href="deep.html#cb766-55" aria-hidden="true" tabindex="-1"></a>    total <span class="ot">=</span> total <span class="sc">+</span> labels<span class="sc">$</span><span class="fu">size</span>(<span class="dv">1</span>)</span>
<span id="cb766-56"><a href="deep.html#cb766-56" aria-hidden="true" tabindex="-1"></a>    correct <span class="ot">=</span> correct <span class="sc">+</span> (predicted <span class="sc">==</span> labels)<span class="sc">$</span><span class="fu">sum</span>()<span class="sc">$</span><span class="fu">item</span>()</span>
<span id="cb766-57"><a href="deep.html#cb766-57" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb766-58"><a href="deep.html#cb766-58" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb766-59"><a href="deep.html#cb766-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb766-60"><a href="deep.html#cb766-60" aria-hidden="true" tabindex="-1"></a>test_accuracy <span class="ot">=</span>  correct<span class="sc">/</span>total</span>
<span id="cb766-61"><a href="deep.html#cb766-61" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(test_accuracy)</span></code></pre></div>
</p>
</details>
<p><br/></p>
<p><strong>Flower data set</strong></p>
<p>Let’s do that with our flower data set:</p>
<div class="sourceCode" id="cb767"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb767-1"><a href="deep.html#cb767-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb767-2"><a href="deep.html#cb767-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb767-3"><a href="deep.html#cb767-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb767-4"><a href="deep.html#cb767-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb767-5"><a href="deep.html#cb767-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> EcoData<span class="sc">::</span><span class="fu">dataset_flower</span>()</span>
<span id="cb767-6"><a href="deep.html#cb767-6" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> data<span class="sc">$</span>train</span>
<span id="cb767-7"><a href="deep.html#cb767-7" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> data<span class="sc">$</span>test</span>
<span id="cb767-8"><a href="deep.html#cb767-8" aria-hidden="true" tabindex="-1"></a>labels <span class="ot">=</span> data<span class="sc">$</span>labels</span>
<span id="cb767-9"><a href="deep.html#cb767-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb767-10"><a href="deep.html#cb767-10" aria-hidden="true" tabindex="-1"></a>densenet <span class="ot">=</span> keras<span class="sc">::</span><span class="fu">application_densenet201</span>(<span class="at">include_top =</span> <span class="cn">FALSE</span>,</span>
<span id="cb767-11"><a href="deep.html#cb767-11" aria-hidden="true" tabindex="-1"></a>                                          <span class="at">input_shape =</span> <span class="fu">list</span>(80L, 80L, 3L))</span>
<span id="cb767-12"><a href="deep.html#cb767-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb767-13"><a href="deep.html#cb767-13" aria-hidden="true" tabindex="-1"></a>keras<span class="sc">::</span><span class="fu">freeze_weights</span>(densenet)</span>
<span id="cb767-14"><a href="deep.html#cb767-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb767-15"><a href="deep.html#cb767-15" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model</span>(<span class="at">inputs =</span> densenet<span class="sc">$</span>input, </span>
<span id="cb767-16"><a href="deep.html#cb767-16" aria-hidden="true" tabindex="-1"></a>                    <span class="at">outputs =</span> densenet<span class="sc">$</span>output <span class="sc">%&gt;%</span></span>
<span id="cb767-17"><a href="deep.html#cb767-17" aria-hidden="true" tabindex="-1"></a>                      <span class="fu">layer_flatten</span>() <span class="sc">%&gt;%</span></span>
<span id="cb767-18"><a href="deep.html#cb767-18" aria-hidden="true" tabindex="-1"></a>                      <span class="fu">layer_dropout</span>(<span class="fl">0.2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb767-19"><a href="deep.html#cb767-19" aria-hidden="true" tabindex="-1"></a>                      <span class="fu">layer_dense</span>(<span class="at">units =</span> 200L) <span class="sc">%&gt;%</span></span>
<span id="cb767-20"><a href="deep.html#cb767-20" aria-hidden="true" tabindex="-1"></a>                      <span class="fu">layer_dropout</span>(<span class="fl">0.2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb767-21"><a href="deep.html#cb767-21" aria-hidden="true" tabindex="-1"></a>                      <span class="fu">layer_dense</span>(<span class="at">units =</span> 5L, <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>))</span>
<span id="cb767-22"><a href="deep.html#cb767-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb767-23"><a href="deep.html#cb767-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Data augmentation.</span></span>
<span id="cb767-24"><a href="deep.html#cb767-24" aria-hidden="true" tabindex="-1"></a>aug <span class="ot">=</span> <span class="fu">image_data_generator</span>(<span class="at">rotation_range =</span> <span class="dv">180</span>, <span class="at">zoom_range =</span> <span class="fl">0.4</span>,</span>
<span id="cb767-25"><a href="deep.html#cb767-25" aria-hidden="true" tabindex="-1"></a>                           <span class="at">width_shift_range =</span> <span class="fl">0.2</span>, <span class="at">height_shift_range =</span> <span class="fl">0.2</span>,</span>
<span id="cb767-26"><a href="deep.html#cb767-26" aria-hidden="true" tabindex="-1"></a>                           <span class="at">vertical_flip =</span> <span class="cn">TRUE</span>, <span class="at">horizontal_flip =</span> <span class="cn">TRUE</span>,</span>
<span id="cb767-27"><a href="deep.html#cb767-27" aria-hidden="true" tabindex="-1"></a>                           <span class="at">preprocessing_function =</span> imagenet_preprocess_input)</span>
<span id="cb767-28"><a href="deep.html#cb767-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb767-29"><a href="deep.html#cb767-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Data preparation / splitting.</span></span>
<span id="cb767-30"><a href="deep.html#cb767-30" aria-hidden="true" tabindex="-1"></a>indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(train), <span class="fl">0.1</span> <span class="sc">*</span> <span class="fu">nrow</span>(train))</span>
<span id="cb767-31"><a href="deep.html#cb767-31" aria-hidden="true" tabindex="-1"></a>generator <span class="ot">=</span> <span class="fu">flow_images_from_data</span>(train[<span class="sc">-</span>indices,,,]<span class="sc">/</span><span class="dv">255</span>,</span>
<span id="cb767-32"><a href="deep.html#cb767-32" aria-hidden="true" tabindex="-1"></a>                                  <span class="fu">k_one_hot</span>(labels[<span class="sc">-</span>indices], <span class="at">num_classes =</span> 5L), </span>
<span id="cb767-33"><a href="deep.html#cb767-33" aria-hidden="true" tabindex="-1"></a>                                  <span class="at">batch_size =</span> 25L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>,</span>
<span id="cb767-34"><a href="deep.html#cb767-34" aria-hidden="true" tabindex="-1"></a>                                  <span class="at">generator =</span> aug)</span>
<span id="cb767-35"><a href="deep.html#cb767-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb767-36"><a href="deep.html#cb767-36" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> <span class="fu">imagenet_preprocess_input</span>(train[indices,,,])</span>
<span id="cb767-37"><a href="deep.html#cb767-37" aria-hidden="true" tabindex="-1"></a>test_labels <span class="ot">=</span> <span class="fu">k_one_hot</span>(labels[indices], <span class="at">num_classes =</span> 5L)</span>
<span id="cb767-38"><a href="deep.html#cb767-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb767-39"><a href="deep.html#cb767-39" aria-hidden="true" tabindex="-1"></a><span class="do">## Training loop with early stopping:</span></span>
<span id="cb767-40"><a href="deep.html#cb767-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb767-41"><a href="deep.html#cb767-41" aria-hidden="true" tabindex="-1"></a><span class="co"># As we use an iterator (the generator), validation loss is not applicable.</span></span>
<span id="cb767-42"><a href="deep.html#cb767-42" aria-hidden="true" tabindex="-1"></a><span class="co"># An available metric is the normal loss.</span></span>
<span id="cb767-43"><a href="deep.html#cb767-43" aria-hidden="true" tabindex="-1"></a>early <span class="ot">=</span> keras<span class="sc">::</span><span class="fu">callback_early_stopping</span>(<span class="at">patience =</span> 2L, <span class="at">monitor =</span> <span class="st">&quot;loss&quot;</span>)</span>
<span id="cb767-44"><a href="deep.html#cb767-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb767-45"><a href="deep.html#cb767-45" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb767-46"><a href="deep.html#cb767-46" aria-hidden="true" tabindex="-1"></a>    keras<span class="sc">::</span><span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb767-47"><a href="deep.html#cb767-47" aria-hidden="true" tabindex="-1"></a>                   <span class="at">optimizer =</span> keras<span class="sc">::</span><span class="fu">optimizer_rmsprop</span>(<span class="at">learning_rate =</span> <span class="fl">0.0005</span>))</span>
<span id="cb767-48"><a href="deep.html#cb767-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb767-49"><a href="deep.html#cb767-49" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb767-50"><a href="deep.html#cb767-50" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(generator, <span class="at">epochs =</span> 8L, <span class="at">batch_size =</span> 45L,</span>
<span id="cb767-51"><a href="deep.html#cb767-51" aria-hidden="true" tabindex="-1"></a>        <span class="at">shuffle =</span> <span class="cn">TRUE</span>, <span class="at">callbacks =</span> <span class="fu">c</span>(early))</span>
<span id="cb767-52"><a href="deep.html#cb767-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb767-53"><a href="deep.html#cb767-53" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">predict</span>(model, <span class="fu">imagenet_preprocess_input</span>(data<span class="sc">$</span>test))</span>
<span id="cb767-54"><a href="deep.html#cb767-54" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> <span class="fu">apply</span>(pred, <span class="dv">1</span>, which.max) <span class="sc">-</span> <span class="dv">1</span></span></code></pre></div>
</div>
<div id="influence-of-batch-size-and-learning-rate" class="section level3" number="5.4.3">
<h3><span class="header-section-number">5.4.3</span> Influence of Batch Size and Learning Rate</h3>
<p>In this chapter, the influence of batch size and learning rate is explored using the MNIST data set.
If you are more interested in this topic (you should be), read this
<a href="https://medium.com/mini-distill/effect-of-batch-size-on-training-dynamics-21c14f7a716e" target="_blank" rel="noopener">article</a>.</p>
<div id="batch-size" class="section level4" number="5.4.3.1">
<h4><span class="header-section-number">5.4.3.1</span> Batch Size</h4>
<p>Different batch sizes may massively influence the outcome of a training step. Finding a suitable batch size is a task itself.</p>
<p>As a general rule of thumb:</p>
<ul>
<li>The lower the batch size, the longer the calculations take, the less (!) memory is needed and the more accurate the training (including less overfitting).</li>
<li>The higher the batch size, the wider the training steps (like with a higher learning rate).</li>
<li>Changing batch sizes and learning rates is always possible and this might “heal” previous mistakes. Maybe you have to “push” the system out of its local neighborhood.</li>
<li>It also depends on the respective problem.</li>
</ul>
<div class="sourceCode" id="cb768"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb768-1"><a href="deep.html#cb768-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb768-2"><a href="deep.html#cb768-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb768-3"><a href="deep.html#cb768-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb768-4"><a href="deep.html#cb768-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb768-5"><a href="deep.html#cb768-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">dataset_mnist</span>()</span>
<span id="cb768-6"><a href="deep.html#cb768-6" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> data<span class="sc">$</span>train</span>
<span id="cb768-7"><a href="deep.html#cb768-7" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> data<span class="sc">$</span>test</span>
<span id="cb768-8"><a href="deep.html#cb768-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb768-9"><a href="deep.html#cb768-9" aria-hidden="true" tabindex="-1"></a>train_x <span class="ot">=</span> <span class="fu">array</span>(train<span class="sc">$</span>x<span class="sc">/</span><span class="dv">255</span>, <span class="fu">c</span>(<span class="fu">dim</span>(train<span class="sc">$</span>x), <span class="dv">1</span>))</span>
<span id="cb768-10"><a href="deep.html#cb768-10" aria-hidden="true" tabindex="-1"></a>test_x <span class="ot">=</span> <span class="fu">array</span>(test<span class="sc">$</span>x<span class="sc">/</span><span class="dv">255</span>, <span class="fu">c</span>(<span class="fu">dim</span>(test<span class="sc">$</span>x), <span class="dv">1</span>))</span>
<span id="cb768-11"><a href="deep.html#cb768-11" aria-hidden="true" tabindex="-1"></a>train_y <span class="ot">=</span> <span class="fu">to_categorical</span>(train<span class="sc">$</span>y, <span class="dv">10</span>)</span>
<span id="cb768-12"><a href="deep.html#cb768-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb768-13"><a href="deep.html#cb768-13" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb768-14"><a href="deep.html#cb768-14" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb768-15"><a href="deep.html#cb768-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">input_shape =</span> <span class="fu">c</span>(28L, 28L, 1L), <span class="at">filters =</span> 16L,</span>
<span id="cb768-16"><a href="deep.html#cb768-16" aria-hidden="true" tabindex="-1"></a>               <span class="at">kernel_size =</span> <span class="fu">c</span>(2L, 2L), <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb768-17"><a href="deep.html#cb768-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span></span>
<span id="cb768-18"><a href="deep.html#cb768-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> 16L, <span class="at">kernel_size =</span> <span class="fu">c</span>(3L, 3L), <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb768-19"><a href="deep.html#cb768-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span></span>
<span id="cb768-20"><a href="deep.html#cb768-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_flatten</span>() <span class="sc">%&gt;%</span></span>
<span id="cb768-21"><a href="deep.html#cb768-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb768-22"><a href="deep.html#cb768-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(10L, <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>)</span>
<span id="cb768-23"><a href="deep.html#cb768-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb768-24"><a href="deep.html#cb768-24" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb768-25"><a href="deep.html#cb768-25" aria-hidden="true" tabindex="-1"></a>  keras<span class="sc">::</span><span class="fu">compile</span>(</span>
<span id="cb768-26"><a href="deep.html#cb768-26" aria-hidden="true" tabindex="-1"></a>      <span class="at">optimizer =</span> keras<span class="sc">::</span><span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.01</span>),</span>
<span id="cb768-27"><a href="deep.html#cb768-27" aria-hidden="true" tabindex="-1"></a>      <span class="at">loss =</span> loss_categorical_crossentropy</span>
<span id="cb768-28"><a href="deep.html#cb768-28" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb768-29"><a href="deep.html#cb768-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb768-30"><a href="deep.html#cb768-30" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> 5L</span>
<span id="cb768-31"><a href="deep.html#cb768-31" aria-hidden="true" tabindex="-1"></a>batch_size <span class="ot">=</span> 32L</span>
<span id="cb768-32"><a href="deep.html#cb768-32" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb768-33"><a href="deep.html#cb768-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(</span>
<span id="cb768-34"><a href="deep.html#cb768-34" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> train_x, </span>
<span id="cb768-35"><a href="deep.html#cb768-35" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> train_y,</span>
<span id="cb768-36"><a href="deep.html#cb768-36" aria-hidden="true" tabindex="-1"></a>    <span class="at">epochs =</span> epochs,</span>
<span id="cb768-37"><a href="deep.html#cb768-37" aria-hidden="true" tabindex="-1"></a>    <span class="at">batch_size =</span> batch_size,</span>
<span id="cb768-38"><a href="deep.html#cb768-38" aria-hidden="true" tabindex="-1"></a>    <span class="at">shuffle =</span> <span class="cn">TRUE</span>,</span>
<span id="cb768-39"><a href="deep.html#cb768-39" aria-hidden="true" tabindex="-1"></a>    <span class="at">validation_split =</span> <span class="fl">0.2</span></span>
<span id="cb768-40"><a href="deep.html#cb768-40" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb768-41"><a href="deep.html#cb768-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb768-42"><a href="deep.html#cb768-42" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> model <span class="sc">%&gt;%</span> <span class="fu">predict</span>(test_x) <span class="sc">%&gt;%</span> <span class="fu">apply</span>(<span class="dv">1</span>, which.max) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb768-43"><a href="deep.html#cb768-43" aria-hidden="true" tabindex="-1"></a>Metrics<span class="sc">::</span><span class="fu">accuracy</span>(pred, test<span class="sc">$</span>y) <span class="co"># 0.9884</span></span></code></pre></div>
<pre><code>## [1] 0.9873</code></pre>
<p><strong>Higher batch size:</strong></p>
<div class="sourceCode" id="cb770"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb770-1"><a href="deep.html#cb770-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb770-2"><a href="deep.html#cb770-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb770-3"><a href="deep.html#cb770-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb770-4"><a href="deep.html#cb770-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb770-5"><a href="deep.html#cb770-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">dataset_mnist</span>()</span>
<span id="cb770-6"><a href="deep.html#cb770-6" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> data<span class="sc">$</span>train</span>
<span id="cb770-7"><a href="deep.html#cb770-7" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> data<span class="sc">$</span>test</span>
<span id="cb770-8"><a href="deep.html#cb770-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb770-9"><a href="deep.html#cb770-9" aria-hidden="true" tabindex="-1"></a>train_x <span class="ot">=</span> <span class="fu">array</span>(train<span class="sc">$</span>x<span class="sc">/</span><span class="dv">255</span>, <span class="fu">c</span>(<span class="fu">dim</span>(train<span class="sc">$</span>x), <span class="dv">1</span>))</span>
<span id="cb770-10"><a href="deep.html#cb770-10" aria-hidden="true" tabindex="-1"></a>test_x <span class="ot">=</span> <span class="fu">array</span>(test<span class="sc">$</span>x<span class="sc">/</span><span class="dv">255</span>, <span class="fu">c</span>(<span class="fu">dim</span>(test<span class="sc">$</span>x), <span class="dv">1</span>))</span>
<span id="cb770-11"><a href="deep.html#cb770-11" aria-hidden="true" tabindex="-1"></a>train_y <span class="ot">=</span> <span class="fu">to_categorical</span>(train<span class="sc">$</span>y, <span class="dv">10</span>)</span>
<span id="cb770-12"><a href="deep.html#cb770-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb770-13"><a href="deep.html#cb770-13" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb770-14"><a href="deep.html#cb770-14" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb770-15"><a href="deep.html#cb770-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">input_shape =</span> <span class="fu">c</span>(28L, 28L, 1L), <span class="at">filters =</span> 16L,</span>
<span id="cb770-16"><a href="deep.html#cb770-16" aria-hidden="true" tabindex="-1"></a>               <span class="at">kernel_size =</span> <span class="fu">c</span>(2L, 2L), <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb770-17"><a href="deep.html#cb770-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span></span>
<span id="cb770-18"><a href="deep.html#cb770-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> 16L, <span class="at">kernel_size =</span> <span class="fu">c</span>(3L, 3L), <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb770-19"><a href="deep.html#cb770-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span></span>
<span id="cb770-20"><a href="deep.html#cb770-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_flatten</span>() <span class="sc">%&gt;%</span></span>
<span id="cb770-21"><a href="deep.html#cb770-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb770-22"><a href="deep.html#cb770-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(10L, <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>)</span>
<span id="cb770-23"><a href="deep.html#cb770-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb770-24"><a href="deep.html#cb770-24" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb770-25"><a href="deep.html#cb770-25" aria-hidden="true" tabindex="-1"></a>  keras<span class="sc">::</span><span class="fu">compile</span>(</span>
<span id="cb770-26"><a href="deep.html#cb770-26" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> keras<span class="sc">::</span><span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.01</span>),</span>
<span id="cb770-27"><a href="deep.html#cb770-27" aria-hidden="true" tabindex="-1"></a>    <span class="at">loss =</span> loss_categorical_crossentropy</span>
<span id="cb770-28"><a href="deep.html#cb770-28" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb770-29"><a href="deep.html#cb770-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb770-30"><a href="deep.html#cb770-30" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> 5L</span>
<span id="cb770-31"><a href="deep.html#cb770-31" aria-hidden="true" tabindex="-1"></a>batch_size <span class="ot">=</span> 100L</span>
<span id="cb770-32"><a href="deep.html#cb770-32" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb770-33"><a href="deep.html#cb770-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(</span>
<span id="cb770-34"><a href="deep.html#cb770-34" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> train_x, </span>
<span id="cb770-35"><a href="deep.html#cb770-35" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> train_y,</span>
<span id="cb770-36"><a href="deep.html#cb770-36" aria-hidden="true" tabindex="-1"></a>    <span class="at">epochs =</span> epochs,</span>
<span id="cb770-37"><a href="deep.html#cb770-37" aria-hidden="true" tabindex="-1"></a>    <span class="at">batch_size =</span> batch_size,</span>
<span id="cb770-38"><a href="deep.html#cb770-38" aria-hidden="true" tabindex="-1"></a>    <span class="at">shuffle =</span> <span class="cn">TRUE</span>,</span>
<span id="cb770-39"><a href="deep.html#cb770-39" aria-hidden="true" tabindex="-1"></a>    <span class="at">validation_split =</span> <span class="fl">0.2</span></span>
<span id="cb770-40"><a href="deep.html#cb770-40" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb770-41"><a href="deep.html#cb770-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb770-42"><a href="deep.html#cb770-42" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> model <span class="sc">%&gt;%</span> <span class="fu">predict</span>(test_x) <span class="sc">%&gt;%</span> <span class="fu">apply</span>(<span class="dv">1</span>, which.max) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb770-43"><a href="deep.html#cb770-43" aria-hidden="true" tabindex="-1"></a>Metrics<span class="sc">::</span><span class="fu">accuracy</span>(pred, test<span class="sc">$</span>y) <span class="co"># 0.9864</span></span></code></pre></div>
<pre><code>## [1] 0.9866</code></pre>
<p><strong>Lower batch size:</strong></p>
<div class="sourceCode" id="cb772"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb772-1"><a href="deep.html#cb772-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb772-2"><a href="deep.html#cb772-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb772-3"><a href="deep.html#cb772-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb772-4"><a href="deep.html#cb772-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb772-5"><a href="deep.html#cb772-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">dataset_mnist</span>()</span>
<span id="cb772-6"><a href="deep.html#cb772-6" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> data<span class="sc">$</span>train</span>
<span id="cb772-7"><a href="deep.html#cb772-7" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> data<span class="sc">$</span>test</span>
<span id="cb772-8"><a href="deep.html#cb772-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb772-9"><a href="deep.html#cb772-9" aria-hidden="true" tabindex="-1"></a>train_x <span class="ot">=</span> <span class="fu">array</span>(train<span class="sc">$</span>x<span class="sc">/</span><span class="dv">255</span>, <span class="fu">c</span>(<span class="fu">dim</span>(train<span class="sc">$</span>x), <span class="dv">1</span>))</span>
<span id="cb772-10"><a href="deep.html#cb772-10" aria-hidden="true" tabindex="-1"></a>test_x <span class="ot">=</span> <span class="fu">array</span>(test<span class="sc">$</span>x<span class="sc">/</span><span class="dv">255</span>, <span class="fu">c</span>(<span class="fu">dim</span>(test<span class="sc">$</span>x), <span class="dv">1</span>))</span>
<span id="cb772-11"><a href="deep.html#cb772-11" aria-hidden="true" tabindex="-1"></a>train_y <span class="ot">=</span> <span class="fu">to_categorical</span>(train<span class="sc">$</span>y, <span class="dv">10</span>)</span>
<span id="cb772-12"><a href="deep.html#cb772-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb772-13"><a href="deep.html#cb772-13" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb772-14"><a href="deep.html#cb772-14" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb772-15"><a href="deep.html#cb772-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">input_shape =</span> <span class="fu">c</span>(28L, 28L, 1L), <span class="at">filters =</span> 16L,</span>
<span id="cb772-16"><a href="deep.html#cb772-16" aria-hidden="true" tabindex="-1"></a>               <span class="at">kernel_size =</span> <span class="fu">c</span>(2L, 2L), <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb772-17"><a href="deep.html#cb772-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span></span>
<span id="cb772-18"><a href="deep.html#cb772-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> 16L, <span class="at">kernel_size =</span> <span class="fu">c</span>(3L, 3L), <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb772-19"><a href="deep.html#cb772-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span></span>
<span id="cb772-20"><a href="deep.html#cb772-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_flatten</span>() <span class="sc">%&gt;%</span></span>
<span id="cb772-21"><a href="deep.html#cb772-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb772-22"><a href="deep.html#cb772-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(10L, <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>)</span>
<span id="cb772-23"><a href="deep.html#cb772-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb772-24"><a href="deep.html#cb772-24" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb772-25"><a href="deep.html#cb772-25" aria-hidden="true" tabindex="-1"></a>  keras<span class="sc">::</span><span class="fu">compile</span>(</span>
<span id="cb772-26"><a href="deep.html#cb772-26" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> keras<span class="sc">::</span><span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.01</span>),</span>
<span id="cb772-27"><a href="deep.html#cb772-27" aria-hidden="true" tabindex="-1"></a>    <span class="at">loss =</span> loss_categorical_crossentropy</span>
<span id="cb772-28"><a href="deep.html#cb772-28" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb772-29"><a href="deep.html#cb772-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb772-30"><a href="deep.html#cb772-30" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> 5L</span>
<span id="cb772-31"><a href="deep.html#cb772-31" aria-hidden="true" tabindex="-1"></a>batch_size <span class="ot">=</span> 10L</span>
<span id="cb772-32"><a href="deep.html#cb772-32" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb772-33"><a href="deep.html#cb772-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(</span>
<span id="cb772-34"><a href="deep.html#cb772-34" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> train_x, </span>
<span id="cb772-35"><a href="deep.html#cb772-35" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> train_y,</span>
<span id="cb772-36"><a href="deep.html#cb772-36" aria-hidden="true" tabindex="-1"></a>    <span class="at">epochs =</span> epochs,</span>
<span id="cb772-37"><a href="deep.html#cb772-37" aria-hidden="true" tabindex="-1"></a>    <span class="at">batch_size =</span> batch_size,</span>
<span id="cb772-38"><a href="deep.html#cb772-38" aria-hidden="true" tabindex="-1"></a>    <span class="at">shuffle =</span> <span class="cn">TRUE</span>,</span>
<span id="cb772-39"><a href="deep.html#cb772-39" aria-hidden="true" tabindex="-1"></a>    <span class="at">validation_split =</span> <span class="fl">0.2</span></span>
<span id="cb772-40"><a href="deep.html#cb772-40" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb772-41"><a href="deep.html#cb772-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb772-42"><a href="deep.html#cb772-42" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> model <span class="sc">%&gt;%</span> <span class="fu">predict</span>(test_x) <span class="sc">%&gt;%</span> <span class="fu">apply</span>(<span class="dv">1</span>, which.max) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb772-43"><a href="deep.html#cb772-43" aria-hidden="true" tabindex="-1"></a>Metrics<span class="sc">::</span><span class="fu">accuracy</span>(pred, test<span class="sc">$</span>y) <span class="co"># 0.9869</span></span></code></pre></div>
<pre><code>## [1] 0.9875</code></pre>
<p><strong>Lowest (1) batch size:</strong></p>
<div class="sourceCode" id="cb774"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb774-1"><a href="deep.html#cb774-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb774-2"><a href="deep.html#cb774-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb774-3"><a href="deep.html#cb774-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb774-4"><a href="deep.html#cb774-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb774-5"><a href="deep.html#cb774-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">dataset_mnist</span>()</span>
<span id="cb774-6"><a href="deep.html#cb774-6" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> data<span class="sc">$</span>train</span>
<span id="cb774-7"><a href="deep.html#cb774-7" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> data<span class="sc">$</span>test</span>
<span id="cb774-8"><a href="deep.html#cb774-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb774-9"><a href="deep.html#cb774-9" aria-hidden="true" tabindex="-1"></a>train_x <span class="ot">=</span> <span class="fu">array</span>(train<span class="sc">$</span>x<span class="sc">/</span><span class="dv">255</span>, <span class="fu">c</span>(<span class="fu">dim</span>(train<span class="sc">$</span>x), <span class="dv">1</span>))</span>
<span id="cb774-10"><a href="deep.html#cb774-10" aria-hidden="true" tabindex="-1"></a>test_x <span class="ot">=</span> <span class="fu">array</span>(test<span class="sc">$</span>x<span class="sc">/</span><span class="dv">255</span>, <span class="fu">c</span>(<span class="fu">dim</span>(test<span class="sc">$</span>x), <span class="dv">1</span>))</span>
<span id="cb774-11"><a href="deep.html#cb774-11" aria-hidden="true" tabindex="-1"></a>train_y <span class="ot">=</span> <span class="fu">to_categorical</span>(train<span class="sc">$</span>y, <span class="dv">10</span>)</span>
<span id="cb774-12"><a href="deep.html#cb774-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb774-13"><a href="deep.html#cb774-13" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb774-14"><a href="deep.html#cb774-14" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb774-15"><a href="deep.html#cb774-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">input_shape =</span> <span class="fu">c</span>(28L, 28L, 1L), <span class="at">filters =</span> 16L,</span>
<span id="cb774-16"><a href="deep.html#cb774-16" aria-hidden="true" tabindex="-1"></a>               <span class="at">kernel_size =</span> <span class="fu">c</span>(2L, 2L), <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb774-17"><a href="deep.html#cb774-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span></span>
<span id="cb774-18"><a href="deep.html#cb774-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> 16L, <span class="at">kernel_size =</span> <span class="fu">c</span>(3L, 3L), <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb774-19"><a href="deep.html#cb774-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span></span>
<span id="cb774-20"><a href="deep.html#cb774-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_flatten</span>() <span class="sc">%&gt;%</span></span>
<span id="cb774-21"><a href="deep.html#cb774-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb774-22"><a href="deep.html#cb774-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(10L, <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>)</span>
<span id="cb774-23"><a href="deep.html#cb774-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb774-24"><a href="deep.html#cb774-24" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb774-25"><a href="deep.html#cb774-25" aria-hidden="true" tabindex="-1"></a>  keras<span class="sc">::</span><span class="fu">compile</span>(</span>
<span id="cb774-26"><a href="deep.html#cb774-26" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> keras<span class="sc">::</span><span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.01</span>),</span>
<span id="cb774-27"><a href="deep.html#cb774-27" aria-hidden="true" tabindex="-1"></a>    <span class="at">loss =</span> loss_categorical_crossentropy</span>
<span id="cb774-28"><a href="deep.html#cb774-28" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb774-29"><a href="deep.html#cb774-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb774-30"><a href="deep.html#cb774-30" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> 5L</span>
<span id="cb774-31"><a href="deep.html#cb774-31" aria-hidden="true" tabindex="-1"></a>batch_size <span class="ot">=</span> 1L</span>
<span id="cb774-32"><a href="deep.html#cb774-32" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb774-33"><a href="deep.html#cb774-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(</span>
<span id="cb774-34"><a href="deep.html#cb774-34" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> train_x, </span>
<span id="cb774-35"><a href="deep.html#cb774-35" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> train_y,</span>
<span id="cb774-36"><a href="deep.html#cb774-36" aria-hidden="true" tabindex="-1"></a>    <span class="at">epochs =</span> epochs,</span>
<span id="cb774-37"><a href="deep.html#cb774-37" aria-hidden="true" tabindex="-1"></a>    <span class="at">batch_size =</span> batch_size,</span>
<span id="cb774-38"><a href="deep.html#cb774-38" aria-hidden="true" tabindex="-1"></a>    <span class="at">shuffle =</span> <span class="cn">TRUE</span>,</span>
<span id="cb774-39"><a href="deep.html#cb774-39" aria-hidden="true" tabindex="-1"></a>    <span class="at">validation_split =</span> <span class="fl">0.2</span></span>
<span id="cb774-40"><a href="deep.html#cb774-40" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb774-41"><a href="deep.html#cb774-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb774-42"><a href="deep.html#cb774-42" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> model <span class="sc">%&gt;%</span> <span class="fu">predict</span>(test_x) <span class="sc">%&gt;%</span> <span class="fu">apply</span>(<span class="dv">1</span>, which.max) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb774-43"><a href="deep.html#cb774-43" aria-hidden="true" tabindex="-1"></a>Metrics<span class="sc">::</span><span class="fu">accuracy</span>(pred, test<span class="sc">$</span>y) <span class="co"># 0.982</span></span></code></pre></div>
<pre><code>## [1] 0.9834</code></pre>
<p><strong>Highest (complete) batch size:</strong></p>
<p>This might not run, because too much memory is needed.</p>
<div class="sourceCode" id="cb776"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb776-1"><a href="deep.html#cb776-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb776-2"><a href="deep.html#cb776-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb776-3"><a href="deep.html#cb776-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb776-4"><a href="deep.html#cb776-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb776-5"><a href="deep.html#cb776-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">dataset_mnist</span>()</span>
<span id="cb776-6"><a href="deep.html#cb776-6" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> data<span class="sc">$</span>train</span>
<span id="cb776-7"><a href="deep.html#cb776-7" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> data<span class="sc">$</span>test</span>
<span id="cb776-8"><a href="deep.html#cb776-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb776-9"><a href="deep.html#cb776-9" aria-hidden="true" tabindex="-1"></a>train_x <span class="ot">=</span> <span class="fu">array</span>(train<span class="sc">$</span>x<span class="sc">/</span><span class="dv">255</span>, <span class="fu">c</span>(<span class="fu">dim</span>(train<span class="sc">$</span>x), <span class="dv">1</span>))</span>
<span id="cb776-10"><a href="deep.html#cb776-10" aria-hidden="true" tabindex="-1"></a>test_x <span class="ot">=</span> <span class="fu">array</span>(test<span class="sc">$</span>x<span class="sc">/</span><span class="dv">255</span>, <span class="fu">c</span>(<span class="fu">dim</span>(test<span class="sc">$</span>x), <span class="dv">1</span>))</span>
<span id="cb776-11"><a href="deep.html#cb776-11" aria-hidden="true" tabindex="-1"></a>train_y <span class="ot">=</span> <span class="fu">to_categorical</span>(train<span class="sc">$</span>y, <span class="dv">10</span>)</span>
<span id="cb776-12"><a href="deep.html#cb776-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb776-13"><a href="deep.html#cb776-13" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb776-14"><a href="deep.html#cb776-14" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb776-15"><a href="deep.html#cb776-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">input_shape =</span> <span class="fu">c</span>(28L, 28L, 1L), <span class="at">filters =</span> 16L,</span>
<span id="cb776-16"><a href="deep.html#cb776-16" aria-hidden="true" tabindex="-1"></a>               <span class="at">kernel_size =</span> <span class="fu">c</span>(2L, 2L), <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb776-17"><a href="deep.html#cb776-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span></span>
<span id="cb776-18"><a href="deep.html#cb776-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> 16L, <span class="at">kernel_size =</span> <span class="fu">c</span>(3L, 3L), <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb776-19"><a href="deep.html#cb776-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span></span>
<span id="cb776-20"><a href="deep.html#cb776-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_flatten</span>() <span class="sc">%&gt;%</span></span>
<span id="cb776-21"><a href="deep.html#cb776-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb776-22"><a href="deep.html#cb776-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(10L, <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>)</span>
<span id="cb776-23"><a href="deep.html#cb776-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb776-24"><a href="deep.html#cb776-24" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb776-25"><a href="deep.html#cb776-25" aria-hidden="true" tabindex="-1"></a>  keras<span class="sc">::</span><span class="fu">compile</span>(</span>
<span id="cb776-26"><a href="deep.html#cb776-26" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> keras<span class="sc">::</span><span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.01</span>),</span>
<span id="cb776-27"><a href="deep.html#cb776-27" aria-hidden="true" tabindex="-1"></a>    <span class="at">loss =</span> loss_categorical_crossentropy</span>
<span id="cb776-28"><a href="deep.html#cb776-28" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb776-29"><a href="deep.html#cb776-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb776-30"><a href="deep.html#cb776-30" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> 5L</span>
<span id="cb776-31"><a href="deep.html#cb776-31" aria-hidden="true" tabindex="-1"></a>batch_size <span class="ot">=</span> <span class="fu">nrow</span>(test_x)</span>
<span id="cb776-32"><a href="deep.html#cb776-32" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb776-33"><a href="deep.html#cb776-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(</span>
<span id="cb776-34"><a href="deep.html#cb776-34" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> train_x, </span>
<span id="cb776-35"><a href="deep.html#cb776-35" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> train_y,</span>
<span id="cb776-36"><a href="deep.html#cb776-36" aria-hidden="true" tabindex="-1"></a>    <span class="at">epochs =</span> epochs,</span>
<span id="cb776-37"><a href="deep.html#cb776-37" aria-hidden="true" tabindex="-1"></a>    <span class="at">batch_size =</span> batch_size,</span>
<span id="cb776-38"><a href="deep.html#cb776-38" aria-hidden="true" tabindex="-1"></a>    <span class="at">shuffle =</span> <span class="cn">TRUE</span>,</span>
<span id="cb776-39"><a href="deep.html#cb776-39" aria-hidden="true" tabindex="-1"></a>    <span class="at">validation_split =</span> <span class="fl">0.2</span></span>
<span id="cb776-40"><a href="deep.html#cb776-40" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb776-41"><a href="deep.html#cb776-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb776-42"><a href="deep.html#cb776-42" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> model <span class="sc">%&gt;%</span> <span class="fu">predict</span>(test_x) <span class="sc">%&gt;%</span> <span class="fu">apply</span>(<span class="dv">1</span>, which.max) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb776-43"><a href="deep.html#cb776-43" aria-hidden="true" tabindex="-1"></a>Metrics<span class="sc">::</span><span class="fu">accuracy</span>(pred, test<span class="sc">$</span>y) <span class="co"># ???</span></span></code></pre></div>
</div>
<div id="learning-rate" class="section level4" number="5.4.3.2">
<h4><span class="header-section-number">5.4.3.2</span> Learning Rate</h4>
<p>Choosing a high learning rate at the beginning may yield acceptable results relatively fast. It would take much more time to get there with a small learning rate. But keeping the learning rate this high may result in jumping over the desired optimal values. So decreasing the learning rate with time might help.</p>
<p>TensorFlow / Keras can manage a changing learning rate. This may also be a periodic function or an increase one. You are not limited to a decreasing learning rate. Defining own learning rates is a bit more complicated than just using the inbuilt Keras functions. If you need a self-made learning rate, you can find some recipe <a href="http://thecooldata.com/2018/12/changing-learning-rate-during-training-on-each-batch-iteration-using-callbacks-in-r-keras/" target="_blank" rel="noopener">here</a>.</p>
<p><strong>An example of the inbuilt functions for managing learning rates in Keras:</strong></p>
<p>The function declaration of the adamax optimizer is as follows:</p>
<div class="sourceCode" id="cb777"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb777-1"><a href="deep.html#cb777-1" aria-hidden="true" tabindex="-1"></a><span class="fu">optimizer_adamax</span>(</span>
<span id="cb777-2"><a href="deep.html#cb777-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">learning_rate =</span> <span class="fl">0.002</span>,</span>
<span id="cb777-3"><a href="deep.html#cb777-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">beta_1 =</span> <span class="fl">0.9</span>,</span>
<span id="cb777-4"><a href="deep.html#cb777-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">beta_2 =</span> <span class="fl">0.999</span>,</span>
<span id="cb777-5"><a href="deep.html#cb777-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">epsilon =</span> <span class="cn">NULL</span>,</span>
<span id="cb777-6"><a href="deep.html#cb777-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">decay =</span> <span class="dv">0</span>,</span>
<span id="cb777-7"><a href="deep.html#cb777-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">clipnorm =</span> <span class="cn">NULL</span>,</span>
<span id="cb777-8"><a href="deep.html#cb777-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">clipvalue =</span> <span class="cn">NULL</span>,</span>
<span id="cb777-9"><a href="deep.html#cb777-9" aria-hidden="true" tabindex="-1"></a>  ...</span>
<span id="cb777-10"><a href="deep.html#cb777-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb777-11"><a href="deep.html#cb777-11" aria-hidden="true" tabindex="-1"></a><span class="co"># learning_rate:  float &gt;= 0. Learning rate.</span></span>
<span id="cb777-12"><a href="deep.html#cb777-12" aria-hidden="true" tabindex="-1"></a><span class="co"># beta_1:         The exponential decay rate for the 1st moment estimates.</span></span>
<span id="cb777-13"><a href="deep.html#cb777-13" aria-hidden="true" tabindex="-1"></a>                  <span class="co"># float, 0 &lt; beta &lt; 1. Generally close to 1.</span></span>
<span id="cb777-14"><a href="deep.html#cb777-14" aria-hidden="true" tabindex="-1"></a><span class="co"># beta_2:         The exponential decay rate for the 2nd moment estimates.</span></span>
<span id="cb777-15"><a href="deep.html#cb777-15" aria-hidden="true" tabindex="-1"></a>                  <span class="co"># float, 0 &lt; beta &lt; 1. Generally close to 1.</span></span>
<span id="cb777-16"><a href="deep.html#cb777-16" aria-hidden="true" tabindex="-1"></a><span class="co"># epsilon:        float &gt;= 0. Fuzz factor. If NULL, defaults to k_epsilon().</span></span>
<span id="cb777-17"><a href="deep.html#cb777-17" aria-hidden="true" tabindex="-1"></a><span class="co"># decay:            float &gt;= 0. Learning rate decay over each update.</span></span>
<span id="cb777-18"><a href="deep.html#cb777-18" aria-hidden="true" tabindex="-1"></a><span class="co"># clipnorm:       Gradients will be clipped when their L2 norm exceeds this value.</span></span>
<span id="cb777-19"><a href="deep.html#cb777-19" aria-hidden="true" tabindex="-1"></a><span class="co"># clipvalue:      Gradients will be clipped when their absolute value exceeds this value.</span></span></code></pre></div>
<p>You can easily specify a decay this way. Mind interval boundaries and suitable parameter values!</p>
<div class="sourceCode" id="cb778"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb778-1"><a href="deep.html#cb778-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb778-2"><a href="deep.html#cb778-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb778-3"><a href="deep.html#cb778-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb778-4"><a href="deep.html#cb778-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb778-5"><a href="deep.html#cb778-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">dataset_mnist</span>()</span>
<span id="cb778-6"><a href="deep.html#cb778-6" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> data<span class="sc">$</span>train</span>
<span id="cb778-7"><a href="deep.html#cb778-7" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> data<span class="sc">$</span>test</span>
<span id="cb778-8"><a href="deep.html#cb778-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb778-9"><a href="deep.html#cb778-9" aria-hidden="true" tabindex="-1"></a>train_x <span class="ot">=</span> <span class="fu">array</span>(train<span class="sc">$</span>x<span class="sc">/</span><span class="dv">255</span>, <span class="fu">c</span>(<span class="fu">dim</span>(train<span class="sc">$</span>x), <span class="dv">1</span>))</span>
<span id="cb778-10"><a href="deep.html#cb778-10" aria-hidden="true" tabindex="-1"></a>test_x <span class="ot">=</span> <span class="fu">array</span>(test<span class="sc">$</span>x<span class="sc">/</span><span class="dv">255</span>, <span class="fu">c</span>(<span class="fu">dim</span>(test<span class="sc">$</span>x), <span class="dv">1</span>))</span>
<span id="cb778-11"><a href="deep.html#cb778-11" aria-hidden="true" tabindex="-1"></a>train_y <span class="ot">=</span> <span class="fu">to_categorical</span>(train<span class="sc">$</span>y, <span class="dv">10</span>)</span>
<span id="cb778-12"><a href="deep.html#cb778-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb778-13"><a href="deep.html#cb778-13" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb778-14"><a href="deep.html#cb778-14" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb778-15"><a href="deep.html#cb778-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">input_shape =</span> <span class="fu">c</span>(28L, 28L, 1L), <span class="at">filters =</span> 16L,</span>
<span id="cb778-16"><a href="deep.html#cb778-16" aria-hidden="true" tabindex="-1"></a>               <span class="at">kernel_size =</span> <span class="fu">c</span>(2L, 2L), <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb778-17"><a href="deep.html#cb778-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span></span>
<span id="cb778-18"><a href="deep.html#cb778-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> 16L, <span class="at">kernel_size =</span> <span class="fu">c</span>(3L, 3L), <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb778-19"><a href="deep.html#cb778-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span></span>
<span id="cb778-20"><a href="deep.html#cb778-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_flatten</span>() <span class="sc">%&gt;%</span></span>
<span id="cb778-21"><a href="deep.html#cb778-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(100L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb778-22"><a href="deep.html#cb778-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(10L, <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>)</span>
<span id="cb778-23"><a href="deep.html#cb778-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb778-24"><a href="deep.html#cb778-24" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb778-25"><a href="deep.html#cb778-25" aria-hidden="true" tabindex="-1"></a>  keras<span class="sc">::</span><span class="fu">compile</span>(</span>
<span id="cb778-26"><a href="deep.html#cb778-26" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> keras<span class="sc">::</span><span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.02</span>, <span class="at">decay =</span> <span class="fl">0.002</span>),</span>
<span id="cb778-27"><a href="deep.html#cb778-27" aria-hidden="true" tabindex="-1"></a>    <span class="at">loss =</span> loss_categorical_crossentropy</span>
<span id="cb778-28"><a href="deep.html#cb778-28" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb778-29"><a href="deep.html#cb778-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb778-30"><a href="deep.html#cb778-30" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> 5L</span>
<span id="cb778-31"><a href="deep.html#cb778-31" aria-hidden="true" tabindex="-1"></a>batch_size <span class="ot">=</span> 32L</span>
<span id="cb778-32"><a href="deep.html#cb778-32" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb778-33"><a href="deep.html#cb778-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(</span>
<span id="cb778-34"><a href="deep.html#cb778-34" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> train_x, </span>
<span id="cb778-35"><a href="deep.html#cb778-35" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> train_y,</span>
<span id="cb778-36"><a href="deep.html#cb778-36" aria-hidden="true" tabindex="-1"></a>    <span class="at">epochs =</span> epochs,</span>
<span id="cb778-37"><a href="deep.html#cb778-37" aria-hidden="true" tabindex="-1"></a>    <span class="at">batch_size =</span> batch_size,</span>
<span id="cb778-38"><a href="deep.html#cb778-38" aria-hidden="true" tabindex="-1"></a>    <span class="at">shuffle =</span> <span class="cn">TRUE</span>,</span>
<span id="cb778-39"><a href="deep.html#cb778-39" aria-hidden="true" tabindex="-1"></a>    <span class="at">validation_split =</span> <span class="fl">0.2</span></span>
<span id="cb778-40"><a href="deep.html#cb778-40" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb778-41"><a href="deep.html#cb778-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb778-42"><a href="deep.html#cb778-42" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> model <span class="sc">%&gt;%</span> <span class="fu">predict</span>(test_x) <span class="sc">%&gt;%</span> <span class="fu">apply</span>(<span class="dv">1</span>, which.max) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb778-43"><a href="deep.html#cb778-43" aria-hidden="true" tabindex="-1"></a>Metrics<span class="sc">::</span><span class="fu">accuracy</span>(pred, test<span class="sc">$</span>y) <span class="co"># 0.9882</span></span></code></pre></div>
<pre><code>## [1] 0.9883</code></pre>
<p>Except for the decay in learning rate, this example is identical to the first one concerning the batch size (0.9884).</p>
</div>
<div id="conclusion" class="section level4" number="5.4.3.3">
<h4><span class="header-section-number">5.4.3.3</span> Conclusion</h4>
<p>There is a (very) complex interplay of batch size, learning rate and optimization algorithm. This topic is to deep for this course.</p>
<p>Most times, doing a longer training or increasing the batch size rather than decreasing the learning rate is recommended.
But this is a matter of further research and also personal attitude. Of course, it also depends on the respective problem.</p>
</div>
<div id="caveat-about-learning-rates-and-activation-functions-already-mentioned-in-the-intro" class="section level4" number="5.4.3.4">
<h4><span class="header-section-number">5.4.3.4</span> Caveat About Learning Rates and Activation Functions (already mentioned in the intro)</h4>
<p>Depending on activation functions, it might occur that the network won’t get updated, even with high learning rates (called <em>vanishing gradient</em>, especially for “sigmoid” functions).
Furthermore, updates might overshoot (called <em>exploding gradients</em>) or activation functions will result in many zeros (especially for “relu,” <em>dying relu</em>).</p>
<p>In general, the first layers of a network tend to learn (much) more slowly than subsequent ones.</p>
  <hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<p>The next exercise is on the flower data set in the Ecodata package.</p>
<p>Follow the steps, we did above and build your own convolutional neural network.</p>
<p>In the end, submit your predictions to the submission server. If you have extra time, have a look at kaggle and find the flower data set challenge for specific architectures tailored for this data set.</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<p>The following code shows different behavior in the context of data augmentation and model complexity.</p>
<p>The topic of overfitting can be seen cleary: Compare the simple model and its performance on the training and the test data. Then compare the more complex or even the regularized models and their performance on training and test data.</p>
<p>You see that the very simple models tend to overfit.</p>
<div class="sourceCode" id="cb780"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb780-1"><a href="deep.html#cb780-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb780-2"><a href="deep.html#cb780-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb780-3"><a href="deep.html#cb780-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb780-4"><a href="deep.html#cb780-4" aria-hidden="true" tabindex="-1"></a>flowerCNN <span class="ot">=</span> <span class="cf">function</span>(</span>
<span id="cb780-5"><a href="deep.html#cb780-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">networkSize =</span> <span class="fu">c</span>(<span class="st">&quot;small&quot;</span>, <span class="st">&quot;medium&quot;</span>, <span class="st">&quot;big&quot;</span>)[<span class="dv">3</span>],</span>
<span id="cb780-6"><a href="deep.html#cb780-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">useGenerator =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="cn">NA</span>)[<span class="dv">3</span>],</span>
<span id="cb780-7"><a href="deep.html#cb780-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">batch_size =</span> 25L,</span>
<span id="cb780-8"><a href="deep.html#cb780-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">epochs =</span> 10L,</span>
<span id="cb780-9"><a href="deep.html#cb780-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">learning_rate =</span> <span class="fl">0.01</span>,</span>
<span id="cb780-10"><a href="deep.html#cb780-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">percentageTrain =</span> <span class="fl">0.9</span></span>
<span id="cb780-11"><a href="deep.html#cb780-11" aria-hidden="true" tabindex="-1"></a>){</span>
<span id="cb780-12"><a href="deep.html#cb780-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gc</span>(<span class="cn">FALSE</span>) <span class="co"># Clean up system (use garbage collection).</span></span>
<span id="cb780-13"><a href="deep.html#cb780-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)    <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb780-14"><a href="deep.html#cb780-14" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb780-15"><a href="deep.html#cb780-15" aria-hidden="true" tabindex="-1"></a>  <span class="do">###############</span></span>
<span id="cb780-16"><a href="deep.html#cb780-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Prepare training and test sets:</span></span>
<span id="cb780-17"><a href="deep.html#cb780-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb780-18"><a href="deep.html#cb780-18" aria-hidden="true" tabindex="-1"></a>  train <span class="ot">=</span> EcoData<span class="sc">::</span><span class="fu">dataset_flower</span>()<span class="sc">$</span>train<span class="sc">/</span><span class="dv">255</span></span>
<span id="cb780-19"><a href="deep.html#cb780-19" aria-hidden="true" tabindex="-1"></a>  indicesTrain <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(train), percentageTrain <span class="sc">*</span> <span class="fu">nrow</span>(train))</span>
<span id="cb780-20"><a href="deep.html#cb780-20" aria-hidden="true" tabindex="-1"></a>  test <span class="ot">=</span> train[<span class="sc">-</span>indicesTrain,,,]</span>
<span id="cb780-21"><a href="deep.html#cb780-21" aria-hidden="true" tabindex="-1"></a>  train <span class="ot">=</span> train[indicesTrain,,,]</span>
<span id="cb780-22"><a href="deep.html#cb780-22" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb780-23"><a href="deep.html#cb780-23" aria-hidden="true" tabindex="-1"></a>  labelsTrain <span class="ot">=</span> EcoData<span class="sc">::</span><span class="fu">dataset_flower</span>()<span class="sc">$</span>labels</span>
<span id="cb780-24"><a href="deep.html#cb780-24" aria-hidden="true" tabindex="-1"></a>  labelsTest <span class="ot">=</span> labelsTrain[<span class="sc">-</span>indicesTrain]</span>
<span id="cb780-25"><a href="deep.html#cb780-25" aria-hidden="true" tabindex="-1"></a>  labelsTrain <span class="ot">=</span> labelsTrain[indicesTrain]</span>
<span id="cb780-26"><a href="deep.html#cb780-26" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb780-27"><a href="deep.html#cb780-27" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb780-28"><a href="deep.html#cb780-28" aria-hidden="true" tabindex="-1"></a>  <span class="do">###############</span></span>
<span id="cb780-29"><a href="deep.html#cb780-29" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Models:</span></span>
<span id="cb780-30"><a href="deep.html#cb780-30" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb780-31"><a href="deep.html#cb780-31" aria-hidden="true" tabindex="-1"></a>  model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb780-32"><a href="deep.html#cb780-32" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb780-33"><a href="deep.html#cb780-33" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(networkSize <span class="sc">==</span> <span class="st">&quot;small&quot;</span>){</span>
<span id="cb780-34"><a href="deep.html#cb780-34" aria-hidden="true" tabindex="-1"></a>    modelString <span class="ot">=</span> <span class="st">&quot;small model&quot;</span></span>
<span id="cb780-35"><a href="deep.html#cb780-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb780-36"><a href="deep.html#cb780-36" aria-hidden="true" tabindex="-1"></a>    model <span class="sc">%&gt;%</span> </span>
<span id="cb780-37"><a href="deep.html#cb780-37" aria-hidden="true" tabindex="-1"></a>      <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> 4L, <span class="at">kernel_size =</span> 2L,</span>
<span id="cb780-38"><a href="deep.html#cb780-38" aria-hidden="true" tabindex="-1"></a>                    <span class="at">input_shape =</span> <span class="fu">list</span>(80L, 80L, 3L)) <span class="sc">%&gt;%</span> </span>
<span id="cb780-39"><a href="deep.html#cb780-39" aria-hidden="true" tabindex="-1"></a>      <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb780-40"><a href="deep.html#cb780-40" aria-hidden="true" tabindex="-1"></a>      <span class="fu">layer_flatten</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb780-41"><a href="deep.html#cb780-41" aria-hidden="true" tabindex="-1"></a>      <span class="fu">layer_dense</span>(<span class="at">units =</span> 5L, <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>)</span>
<span id="cb780-42"><a href="deep.html#cb780-42" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb780-43"><a href="deep.html#cb780-43" aria-hidden="true" tabindex="-1"></a>  }<span class="cf">else</span> <span class="cf">if</span>(networkSize <span class="sc">==</span> <span class="st">&quot;medium&quot;</span>){</span>
<span id="cb780-44"><a href="deep.html#cb780-44" aria-hidden="true" tabindex="-1"></a>    modelString <span class="ot">=</span> <span class="st">&quot;medium model&quot;</span></span>
<span id="cb780-45"><a href="deep.html#cb780-45" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb780-46"><a href="deep.html#cb780-46" aria-hidden="true" tabindex="-1"></a>    model <span class="sc">%&gt;%</span></span>
<span id="cb780-47"><a href="deep.html#cb780-47" aria-hidden="true" tabindex="-1"></a>      <span class="fu">layer_conv_2d</span>(<span class="at">filter =</span> 16L, <span class="at">kernel_size =</span> <span class="fu">c</span>(5L, 5L),</span>
<span id="cb780-48"><a href="deep.html#cb780-48" aria-hidden="true" tabindex="-1"></a>                    <span class="at">input_shape =</span> <span class="fu">c</span>(80L, 80L, 3L), <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb780-49"><a href="deep.html#cb780-49" aria-hidden="true" tabindex="-1"></a>      <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span></span>
<span id="cb780-50"><a href="deep.html#cb780-50" aria-hidden="true" tabindex="-1"></a>      <span class="fu">layer_conv_2d</span>(<span class="at">filter =</span> 32L, <span class="at">kernel_size =</span> <span class="fu">c</span>(3L, 3L),</span>
<span id="cb780-51"><a href="deep.html#cb780-51" aria-hidden="true" tabindex="-1"></a>                    <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb780-52"><a href="deep.html#cb780-52" aria-hidden="true" tabindex="-1"></a>      <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span></span>
<span id="cb780-53"><a href="deep.html#cb780-53" aria-hidden="true" tabindex="-1"></a>      <span class="fu">layer_conv_2d</span>(<span class="at">filter =</span> 64L, <span class="at">kernel_size =</span> <span class="fu">c</span>(3L, 3L),</span>
<span id="cb780-54"><a href="deep.html#cb780-54" aria-hidden="true" tabindex="-1"></a>                    <span class="at">strides =</span> <span class="fu">c</span>(2L, 2L), <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb780-55"><a href="deep.html#cb780-55" aria-hidden="true" tabindex="-1"></a>      <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span></span>
<span id="cb780-56"><a href="deep.html#cb780-56" aria-hidden="true" tabindex="-1"></a>      <span class="fu">layer_flatten</span>() <span class="sc">%&gt;%</span></span>
<span id="cb780-57"><a href="deep.html#cb780-57" aria-hidden="true" tabindex="-1"></a>      <span class="fu">layer_dropout</span>(<span class="fl">0.5</span>) <span class="sc">%&gt;%</span></span>
<span id="cb780-58"><a href="deep.html#cb780-58" aria-hidden="true" tabindex="-1"></a>      <span class="fu">layer_dense</span>(<span class="at">units =</span> 5L, <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>)</span>
<span id="cb780-59"><a href="deep.html#cb780-59" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb780-60"><a href="deep.html#cb780-60" aria-hidden="true" tabindex="-1"></a>  } <span class="cf">else</span> <span class="cf">if</span>(networkSize <span class="sc">==</span> <span class="st">&quot;big&quot;</span>){</span>
<span id="cb780-61"><a href="deep.html#cb780-61" aria-hidden="true" tabindex="-1"></a>    modelString <span class="ot">=</span> <span class="st">&quot;big model&quot;</span></span>
<span id="cb780-62"><a href="deep.html#cb780-62" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb780-63"><a href="deep.html#cb780-63" aria-hidden="true" tabindex="-1"></a>    model <span class="sc">%&gt;%</span></span>
<span id="cb780-64"><a href="deep.html#cb780-64" aria-hidden="true" tabindex="-1"></a>      <span class="fu">layer_conv_2d</span>(<span class="at">filter =</span> 48L, <span class="at">kernel_size =</span> <span class="fu">c</span>(5L, 5L),</span>
<span id="cb780-65"><a href="deep.html#cb780-65" aria-hidden="true" tabindex="-1"></a>                    <span class="at">input_shape =</span> <span class="fu">c</span>(80L, 80L, 3L), <span class="at">activation =</span> <span class="st">&quot;leaky_relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb780-66"><a href="deep.html#cb780-66" aria-hidden="true" tabindex="-1"></a>      <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span></span>
<span id="cb780-67"><a href="deep.html#cb780-67" aria-hidden="true" tabindex="-1"></a>      <span class="fu">layer_conv_2d</span>(<span class="at">filter =</span> 48L, <span class="at">kernel_size =</span> <span class="fu">c</span>(3L, 3L),</span>
<span id="cb780-68"><a href="deep.html#cb780-68" aria-hidden="true" tabindex="-1"></a>                    <span class="at">activation =</span> <span class="st">&quot;leaky_relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb780-69"><a href="deep.html#cb780-69" aria-hidden="true" tabindex="-1"></a>      <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span></span>
<span id="cb780-70"><a href="deep.html#cb780-70" aria-hidden="true" tabindex="-1"></a>      <span class="fu">layer_conv_2d</span>(<span class="at">filter =</span> 64L, <span class="at">kernel_size =</span> <span class="fu">c</span>(3L, 3L),</span>
<span id="cb780-71"><a href="deep.html#cb780-71" aria-hidden="true" tabindex="-1"></a>                    <span class="at">strides =</span> <span class="fu">c</span>(2L, 2L), <span class="at">activation =</span> <span class="st">&quot;leaky_relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb780-72"><a href="deep.html#cb780-72" aria-hidden="true" tabindex="-1"></a>      <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span></span>
<span id="cb780-73"><a href="deep.html#cb780-73" aria-hidden="true" tabindex="-1"></a>      <span class="fu">layer_flatten</span>() <span class="sc">%&gt;%</span></span>
<span id="cb780-74"><a href="deep.html#cb780-74" aria-hidden="true" tabindex="-1"></a>      <span class="fu">layer_dropout</span>(<span class="fl">0.35</span>) <span class="sc">%&gt;%</span></span>
<span id="cb780-75"><a href="deep.html#cb780-75" aria-hidden="true" tabindex="-1"></a>      <span class="fu">layer_dense</span>(<span class="at">units =</span> 256L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>,</span>
<span id="cb780-76"><a href="deep.html#cb780-76" aria-hidden="true" tabindex="-1"></a>                  <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l2</span>(.<span class="dv">25</span>)</span>
<span id="cb780-77"><a href="deep.html#cb780-77" aria-hidden="true" tabindex="-1"></a>      ) <span class="sc">%&gt;%</span></span>
<span id="cb780-78"><a href="deep.html#cb780-78" aria-hidden="true" tabindex="-1"></a>      <span class="fu">layer_dropout</span>(<span class="fl">0.4</span>) <span class="sc">%&gt;%</span></span>
<span id="cb780-79"><a href="deep.html#cb780-79" aria-hidden="true" tabindex="-1"></a>      <span class="fu">layer_dense</span>(<span class="at">units =</span> 128L, <span class="at">activation =</span> <span class="st">&quot;leaky_relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb780-80"><a href="deep.html#cb780-80" aria-hidden="true" tabindex="-1"></a>      <span class="fu">layer_dropout</span>(<span class="fl">0.4</span>) <span class="sc">%&gt;%</span></span>
<span id="cb780-81"><a href="deep.html#cb780-81" aria-hidden="true" tabindex="-1"></a>      <span class="fu">layer_dense</span>(<span class="at">units =</span> 64L, <span class="at">activation =</span> <span class="st">&quot;leaky_relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb780-82"><a href="deep.html#cb780-82" aria-hidden="true" tabindex="-1"></a>      <span class="fu">layer_dropout</span>(<span class="fl">0.4</span>) <span class="sc">%&gt;%</span></span>
<span id="cb780-83"><a href="deep.html#cb780-83" aria-hidden="true" tabindex="-1"></a>      <span class="fu">layer_dense</span>(<span class="at">units =</span> 5L, <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>)</span>
<span id="cb780-84"><a href="deep.html#cb780-84" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb780-85"><a href="deep.html#cb780-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb780-86"><a href="deep.html#cb780-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb780-87"><a href="deep.html#cb780-87" aria-hidden="true" tabindex="-1"></a>  <span class="do">###############</span></span>
<span id="cb780-88"><a href="deep.html#cb780-88" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Generators for augmentation:</span></span>
<span id="cb780-89"><a href="deep.html#cb780-89" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb780-90"><a href="deep.html#cb780-90" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="sc">!</span><span class="fu">is.na</span>(useGenerator)){</span>
<span id="cb780-91"><a href="deep.html#cb780-91" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(useGenerator <span class="sc">==</span> <span class="dv">1</span>){</span>
<span id="cb780-92"><a href="deep.html#cb780-92" aria-hidden="true" tabindex="-1"></a>      generatorString <span class="ot">=</span> <span class="st">&quot;generator 1&quot;</span></span>
<span id="cb780-93"><a href="deep.html#cb780-93" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb780-94"><a href="deep.html#cb780-94" aria-hidden="true" tabindex="-1"></a>      generator <span class="ot">=</span> keras<span class="sc">::</span><span class="fu">flow_images_from_data</span>(</span>
<span id="cb780-95"><a href="deep.html#cb780-95" aria-hidden="true" tabindex="-1"></a>        <span class="at">x =</span> train,</span>
<span id="cb780-96"><a href="deep.html#cb780-96" aria-hidden="true" tabindex="-1"></a>        <span class="at">y =</span> <span class="fu">k_one_hot</span>(labelsTrain, <span class="at">num_classes =</span> 5L),</span>
<span id="cb780-97"><a href="deep.html#cb780-97" aria-hidden="true" tabindex="-1"></a>        <span class="at">generator =</span> keras<span class="sc">::</span><span class="fu">image_data_generator</span>(</span>
<span id="cb780-98"><a href="deep.html#cb780-98" aria-hidden="true" tabindex="-1"></a>          <span class="at">rotation_range =</span> <span class="dv">180</span>,</span>
<span id="cb780-99"><a href="deep.html#cb780-99" aria-hidden="true" tabindex="-1"></a>          <span class="at">zoom_range =</span> <span class="fu">c</span>(<span class="fl">0.3</span>),</span>
<span id="cb780-100"><a href="deep.html#cb780-100" aria-hidden="true" tabindex="-1"></a>          <span class="at">horizontal_flip =</span> <span class="cn">TRUE</span>,</span>
<span id="cb780-101"><a href="deep.html#cb780-101" aria-hidden="true" tabindex="-1"></a>          <span class="at">vertical_flip =</span> <span class="cn">TRUE</span>,</span>
<span id="cb780-102"><a href="deep.html#cb780-102" aria-hidden="true" tabindex="-1"></a>          <span class="at">samplewise_center =</span> <span class="cn">TRUE</span>,</span>
<span id="cb780-103"><a href="deep.html#cb780-103" aria-hidden="true" tabindex="-1"></a>          <span class="at">samplewise_std_normalization =</span> <span class="cn">TRUE</span>),</span>
<span id="cb780-104"><a href="deep.html#cb780-104" aria-hidden="true" tabindex="-1"></a>        <span class="at">batch_size =</span> batch_size,</span>
<span id="cb780-105"><a href="deep.html#cb780-105" aria-hidden="true" tabindex="-1"></a>        <span class="at">shuffle =</span> <span class="cn">TRUE</span></span>
<span id="cb780-106"><a href="deep.html#cb780-106" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb780-107"><a href="deep.html#cb780-107" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb780-108"><a href="deep.html#cb780-108" aria-hidden="true" tabindex="-1"></a>    }<span class="cf">else</span> <span class="cf">if</span>(useGenerator <span class="sc">==</span> <span class="dv">2</span>){</span>
<span id="cb780-109"><a href="deep.html#cb780-109" aria-hidden="true" tabindex="-1"></a>      generatorString <span class="ot">=</span> <span class="st">&quot;generator 2&quot;</span></span>
<span id="cb780-110"><a href="deep.html#cb780-110" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb780-111"><a href="deep.html#cb780-111" aria-hidden="true" tabindex="-1"></a>      generator <span class="ot">=</span> keras<span class="sc">::</span><span class="fu">flow_images_from_data</span>(</span>
<span id="cb780-112"><a href="deep.html#cb780-112" aria-hidden="true" tabindex="-1"></a>        <span class="at">x =</span> train,</span>
<span id="cb780-113"><a href="deep.html#cb780-113" aria-hidden="true" tabindex="-1"></a>        <span class="at">y =</span> keras<span class="sc">::</span><span class="fu">k_one_hot</span>(labelsTrain, 5L),</span>
<span id="cb780-114"><a href="deep.html#cb780-114" aria-hidden="true" tabindex="-1"></a>        <span class="at">batch_size =</span> batch_size</span>
<span id="cb780-115"><a href="deep.html#cb780-115" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb780-116"><a href="deep.html#cb780-116" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb780-117"><a href="deep.html#cb780-117" aria-hidden="true" tabindex="-1"></a>  }<span class="cf">else</span>{ generatorString <span class="ot">=</span> <span class="st">&quot;no generator&quot;</span> }</span>
<span id="cb780-118"><a href="deep.html#cb780-118" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb780-119"><a href="deep.html#cb780-119" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb780-120"><a href="deep.html#cb780-120" aria-hidden="true" tabindex="-1"></a>  <span class="do">###############</span></span>
<span id="cb780-121"><a href="deep.html#cb780-121" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Model selection and compilation:</span></span>
<span id="cb780-122"><a href="deep.html#cb780-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb780-123"><a href="deep.html#cb780-123" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb780-124"><a href="deep.html#cb780-124" aria-hidden="true" tabindex="-1"></a>    keras<span class="sc">::</span><span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb780-125"><a href="deep.html#cb780-125" aria-hidden="true" tabindex="-1"></a>                   <span class="at">optimizer =</span> keras<span class="sc">::</span><span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> learning_rate))</span>
<span id="cb780-126"><a href="deep.html#cb780-126" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb780-127"><a href="deep.html#cb780-127" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="fu">is.na</span>(useGenerator)){ <span class="co"># Use no generator.</span></span>
<span id="cb780-128"><a href="deep.html#cb780-128" aria-hidden="true" tabindex="-1"></a>    model <span class="sc">%&gt;%</span></span>
<span id="cb780-129"><a href="deep.html#cb780-129" aria-hidden="true" tabindex="-1"></a>      <span class="fu">fit</span>(<span class="at">x =</span> train, <span class="at">y =</span> <span class="fu">to_categorical</span>(<span class="fu">matrix</span>(labelsTrain, <span class="at">ncol =</span> 1L), 5L),</span>
<span id="cb780-130"><a href="deep.html#cb780-130" aria-hidden="true" tabindex="-1"></a>          <span class="at">epochs =</span> epochs, <span class="at">batch_size =</span> batch_size, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb780-131"><a href="deep.html#cb780-131" aria-hidden="true" tabindex="-1"></a>  }<span class="cf">else</span>{</span>
<span id="cb780-132"><a href="deep.html#cb780-132" aria-hidden="true" tabindex="-1"></a>    model <span class="sc">%&gt;%</span></span>
<span id="cb780-133"><a href="deep.html#cb780-133" aria-hidden="true" tabindex="-1"></a>      <span class="fu">fit</span>(generator, <span class="at">epochs =</span> epochs, <span class="at">batch_size =</span> batch_size, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb780-134"><a href="deep.html#cb780-134" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb780-135"><a href="deep.html#cb780-135" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb780-136"><a href="deep.html#cb780-136" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb780-137"><a href="deep.html#cb780-137" aria-hidden="true" tabindex="-1"></a>  <span class="do">###############</span></span>
<span id="cb780-138"><a href="deep.html#cb780-138" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Predictions:</span></span>
<span id="cb780-139"><a href="deep.html#cb780-139" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb780-140"><a href="deep.html#cb780-140" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="fu">paste0</span>(<span class="st">&quot;</span><span class="sc">\n</span><span class="st">Modalities: &quot;</span>, modelString, <span class="st">&quot;, &quot;</span>, generatorString, <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>))</span>
<span id="cb780-141"><a href="deep.html#cb780-141" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb780-142"><a href="deep.html#cb780-142" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Predictions on the training set:</span></span>
<span id="cb780-143"><a href="deep.html#cb780-143" aria-hidden="true" tabindex="-1"></a>  predTrain <span class="ot">=</span> <span class="fu">predict</span>(model, train) <span class="sc">%&gt;%</span> <span class="fu">apply</span>(<span class="dv">1</span>, which.max) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb780-144"><a href="deep.html#cb780-144" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="fu">paste0</span>(<span class="st">&quot;</span><span class="sc">\n</span><span class="st">Accuracy on training set: &quot;</span>,</span>
<span id="cb780-145"><a href="deep.html#cb780-145" aria-hidden="true" tabindex="-1"></a>               <span class="fu">round</span>(Metrics<span class="sc">::</span><span class="fu">accuracy</span>(predTrain, labelsTrain), <span class="dv">2</span>), <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>))</span>
<span id="cb780-146"><a href="deep.html#cb780-146" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(<span class="fu">round</span>(<span class="fu">table</span>(predTrain) <span class="sc">/</span> <span class="fu">nrow</span>(train), <span class="dv">2</span>))</span>
<span id="cb780-147"><a href="deep.html#cb780-147" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb780-148"><a href="deep.html#cb780-148" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Predictions on the test set:</span></span>
<span id="cb780-149"><a href="deep.html#cb780-149" aria-hidden="true" tabindex="-1"></a>  predTest <span class="ot">=</span> <span class="fu">predict</span>(model, test) <span class="sc">%&gt;%</span> <span class="fu">apply</span>(<span class="dv">1</span>, which.max) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb780-150"><a href="deep.html#cb780-150" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="fu">paste0</span>(<span class="st">&quot;</span><span class="sc">\n</span><span class="st">Accuracy on test set: &quot;</span>,</span>
<span id="cb780-151"><a href="deep.html#cb780-151" aria-hidden="true" tabindex="-1"></a>               <span class="fu">round</span>(Metrics<span class="sc">::</span><span class="fu">accuracy</span>(predTest, labelsTest), <span class="dv">2</span>), <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>))</span>
<span id="cb780-152"><a href="deep.html#cb780-152" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(<span class="fu">round</span>(<span class="fu">table</span>(predTest) <span class="sc">/</span> <span class="fu">nrow</span>(test), <span class="dv">2</span>))</span>
<span id="cb780-153"><a href="deep.html#cb780-153" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb780-154"><a href="deep.html#cb780-154" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Predictions on the holdout for submission:</span></span>
<span id="cb780-155"><a href="deep.html#cb780-155" aria-hidden="true" tabindex="-1"></a>  predHoldout <span class="ot">=</span> <span class="fu">predict</span>(model, EcoData<span class="sc">::</span><span class="fu">dataset_flower</span>()<span class="sc">$</span>test<span class="sc">/</span><span class="dv">255</span>) <span class="sc">%&gt;%</span></span>
<span id="cb780-156"><a href="deep.html#cb780-156" aria-hidden="true" tabindex="-1"></a>    <span class="fu">apply</span>(<span class="dv">1</span>, which.max) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb780-157"><a href="deep.html#cb780-157" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb780-158"><a href="deep.html#cb780-158" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(predHoldout)</span>
<span id="cb780-159"><a href="deep.html#cb780-159" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb780-160"><a href="deep.html#cb780-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb780-161"><a href="deep.html#cb780-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb780-162"><a href="deep.html#cb780-162" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(networkSize <span class="cf">in</span> <span class="fu">c</span>(<span class="st">&quot;small&quot;</span>, <span class="st">&quot;medium&quot;</span>, <span class="st">&quot;big&quot;</span>)){</span>
<span id="cb780-163"><a href="deep.html#cb780-163" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(useGenerator <span class="cf">in</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="cn">NA</span>)){</span>
<span id="cb780-164"><a href="deep.html#cb780-164" aria-hidden="true" tabindex="-1"></a>    pred <span class="ot">=</span> <span class="fu">flowerCNN</span>(<span class="at">networkSize =</span> networkSize, <span class="at">useGenerator =</span> useGenerator)</span>
<span id="cb780-165"><a href="deep.html#cb780-165" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb780-166"><a href="deep.html#cb780-166" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<pre><code>## 
## Modalities: small model, generator 1
## 
## Accuracy on training set: 0.31
## predTrain
##    0    1    2    3    4 
## 0.65 0.11 0.19 0.00 0.05 
## 
## Accuracy on test set: 0.32
## predTest
##    0    1    2    3    4 
## 0.64 0.11 0.19 0.00 0.06 
## 
## Modalities: small model, generator 2
## 
## Accuracy on training set: 0.89
## predTrain
##    0    1    2    3    4 
## 0.16 0.26 0.16 0.18 0.24 
## 
## Accuracy on test set: 0.45
## predTest
##    0    1    2    3    4 
## 0.11 0.31 0.13 0.24 0.22 
## 
## Modalities: small model, no generator
## 
## Accuracy on training set: 0.91
## predTrain
##    0    1    2    3    4 
## 0.16 0.27 0.17 0.17 0.23 
## 
## Accuracy on test set: 0.46
## predTest
##    0    1    2    3    4 
## 0.13 0.31 0.17 0.22 0.17 
## 
## Modalities: medium model, generator 1
## 
## Accuracy on training set: 0.25
## predTrain
##    1    2 
## 0.99 0.01 
## 
## Accuracy on test set: 0.25
## predTest
##    1    2 
## 0.99 0.01 
## 
## Modalities: medium model, generator 2
## 
## Accuracy on training set: 0.7
## predTrain
##    0    1    2    3    4 
## 0.16 0.34 0.09 0.20 0.20 
## 
## Accuracy on test set: 0.67
## predTest
##    0    1    2    3    4 
## 0.17 0.33 0.10 0.20 0.19 
## 
## Modalities: medium model, no generator
## 
## Accuracy on training set: 0.68
## predTrain
##    0    1    2    3    4 
## 0.21 0.24 0.28 0.17 0.10 
## 
## Accuracy on test set: 0.66
## predTest
##    0    1    2    3    4 
## 0.20 0.23 0.30 0.17 0.10 
## 
## Modalities: big model, generator 1
## 
## Accuracy on training set: 0.3
## predTrain
##    1    2    4 
## 0.91 0.00 0.09 
## 
## Accuracy on test set: 0.3
## predTest
##    1    4 
## 0.89 0.11 
## 
## Modalities: big model, generator 2
## 
## Accuracy on training set: 0.71
## predTrain
##    0    1    2    3    4 
## 0.13 0.33 0.09 0.20 0.25 
## 
## Accuracy on test set: 0.65
## predTest
##    0    1    2    3    4 
## 0.12 0.35 0.08 0.20 0.25 
## 
## Modalities: big model, no generator
## 
## Accuracy on training set: 0.69
## predTrain
##    0    1    2    3    4 
## 0.16 0.21 0.25 0.17 0.20 
## 
## Accuracy on test set: 0.63
## predTest
##    0    1    2    3    4 
## 0.15 0.23 0.24 0.15 0.23</code></pre>
<p><strong>Even more complex model:</strong></p>
<p>The following snippet offers a solution for data generation with oversampling and undersampling, because the distribution of classes is not equal in the flower data set.</p>
<div class="sourceCode" id="cb782"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb782-1"><a href="deep.html#cb782-1" aria-hidden="true" tabindex="-1"></a>getData <span class="ot">=</span> <span class="cf">function</span>(<span class="at">oversample =</span> <span class="cn">TRUE</span>, <span class="at">undersample =</span> <span class="cn">FALSE</span>){</span>
<span id="cb782-2"><a href="deep.html#cb782-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># &quot;undersample&quot; has priority over &quot;oversample&quot;.</span></span>
<span id="cb782-3"><a href="deep.html#cb782-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb782-4"><a href="deep.html#cb782-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># As the whole task is very compute-intensive and needs much memory,</span></span>
<span id="cb782-5"><a href="deep.html#cb782-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># pack data acquisition in a function.</span></span>
<span id="cb782-6"><a href="deep.html#cb782-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># The used local memory is cleaned automatically at the end of the scope.</span></span>
<span id="cb782-7"><a href="deep.html#cb782-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb782-8"><a href="deep.html#cb782-8" aria-hidden="true" tabindex="-1"></a>  data <span class="ot">=</span> EcoData<span class="sc">::</span><span class="fu">dataset_flower</span>()</span>
<span id="cb782-9"><a href="deep.html#cb782-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># &lt;&lt;-: Global scope.</span></span>
<span id="cb782-10"><a href="deep.html#cb782-10" aria-hidden="true" tabindex="-1"></a>  trainLocal <span class="ot">=</span> data<span class="sc">$</span>train<span class="sc">/</span><span class="dv">255</span></span>
<span id="cb782-11"><a href="deep.html#cb782-11" aria-hidden="true" tabindex="-1"></a>  labelsLocal <span class="ot">=</span> data<span class="sc">$</span>labels</span>
<span id="cb782-12"><a href="deep.html#cb782-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb782-13"><a href="deep.html#cb782-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb782-14"><a href="deep.html#cb782-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(<span class="fu">table</span>(labelsLocal)) <span class="co"># The classes are not equally distributed.</span></span>
<span id="cb782-15"><a href="deep.html#cb782-15" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Many models tend to predict class 1 overproportionally often.</span></span>
<span id="cb782-16"><a href="deep.html#cb782-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb782-17"><a href="deep.html#cb782-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(undersample){</span>
<span id="cb782-18"><a href="deep.html#cb782-18" aria-hidden="true" tabindex="-1"></a>    n <span class="ot">=</span> <span class="fu">min</span>(<span class="fu">table</span>(labelsLocal))</span>
<span id="cb782-19"><a href="deep.html#cb782-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb782-20"><a href="deep.html#cb782-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Minimal size of classes times number of classes.</span></span>
<span id="cb782-21"><a href="deep.html#cb782-21" aria-hidden="true" tabindex="-1"></a>    total <span class="ot">=</span> n <span class="sc">*</span> <span class="fu">length</span>(<span class="fu">levels</span>(<span class="fu">as.factor</span>(labelsLocal)))</span>
<span id="cb782-22"><a href="deep.html#cb782-22" aria-hidden="true" tabindex="-1"></a>    newIndices <span class="ot">=</span> <span class="fu">rep</span>(<span class="cn">FALSE</span>, total)</span>
<span id="cb782-23"><a href="deep.html#cb782-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb782-24"><a href="deep.html#cb782-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(<span class="fu">levels</span>(<span class="fu">as.factor</span>(labelsLocal)))){</span>
<span id="cb782-25"><a href="deep.html#cb782-25" aria-hidden="true" tabindex="-1"></a>      newIndices[<span class="fu">sample</span>(<span class="fu">which</span>(labelsLocal <span class="sc">==</span> i <span class="sc">-</span> <span class="dv">1</span>), n, <span class="at">replace =</span> <span class="cn">FALSE</span>)] <span class="ot">=</span> <span class="cn">TRUE</span></span>
<span id="cb782-26"><a href="deep.html#cb782-26" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb782-27"><a href="deep.html#cb782-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb782-28"><a href="deep.html#cb782-28" aria-hidden="true" tabindex="-1"></a>    newIndices <span class="ot">=</span> <span class="fu">which</span>(newIndices)</span>
<span id="cb782-29"><a href="deep.html#cb782-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb782-30"><a href="deep.html#cb782-30" aria-hidden="true" tabindex="-1"></a>    trainingSet <span class="ot">&lt;&lt;-</span> trainLocal[newIndices,,,]</span>
<span id="cb782-31"><a href="deep.html#cb782-31" aria-hidden="true" tabindex="-1"></a>    flowerLabels <span class="ot">&lt;&lt;-</span> labelsLocal[newIndices]</span>
<span id="cb782-32"><a href="deep.html#cb782-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb782-33"><a href="deep.html#cb782-33" aria-hidden="true" tabindex="-1"></a>    <span class="fu">print</span>(<span class="fu">table</span>(flowerLabels))</span>
<span id="cb782-34"><a href="deep.html#cb782-34" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>()</span>
<span id="cb782-35"><a href="deep.html#cb782-35" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb782-36"><a href="deep.html#cb782-36" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb782-37"><a href="deep.html#cb782-37" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="sc">!</span>oversample){</span>
<span id="cb782-38"><a href="deep.html#cb782-38" aria-hidden="true" tabindex="-1"></a>    trainingSet <span class="ot">&lt;&lt;-</span> trainLocal</span>
<span id="cb782-39"><a href="deep.html#cb782-39" aria-hidden="true" tabindex="-1"></a>    flowerLabels <span class="ot">&lt;&lt;-</span> labelsLocal</span>
<span id="cb782-40"><a href="deep.html#cb782-40" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>()</span>
<span id="cb782-41"><a href="deep.html#cb782-41" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb782-42"><a href="deep.html#cb782-42" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb782-43"><a href="deep.html#cb782-43" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">max</span>(<span class="fu">table</span>(labelsLocal)) <span class="sc">+</span> <span class="dv">14</span>) <span class="co"># Number of samples to extend each class to.</span></span>
<span id="cb782-44"><a href="deep.html#cb782-44" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb782-45"><a href="deep.html#cb782-45" aria-hidden="true" tabindex="-1"></a>  <span class="do">## Sample new data (with replacement):</span></span>
<span id="cb782-46"><a href="deep.html#cb782-46" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(<span class="fu">levels</span>(<span class="fu">as.factor</span>(labelsLocal)))){</span>
<span id="cb782-47"><a href="deep.html#cb782-47" aria-hidden="true" tabindex="-1"></a>    missing <span class="ot">=</span> n <span class="sc">-</span> <span class="fu">table</span>(labelsLocal)[i]  <span class="co"># Number of elements missing compared to n.</span></span>
<span id="cb782-48"><a href="deep.html#cb782-48" aria-hidden="true" tabindex="-1"></a>    indices <span class="ot">=</span> <span class="fu">which</span>(labelsLocal <span class="sc">==</span> i <span class="sc">-</span> <span class="dv">1</span>)  <span class="co"># Indices of all elements of class i.</span></span>
<span id="cb782-49"><a href="deep.html#cb782-49" aria-hidden="true" tabindex="-1"></a>    newIndices <span class="ot">=</span> <span class="fu">sample</span>(indices, missing, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb782-50"><a href="deep.html#cb782-50" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb782-51"><a href="deep.html#cb782-51" aria-hidden="true" tabindex="-1"></a>    trainLocal <span class="ot">&lt;&lt;-</span> abind<span class="sc">::</span><span class="fu">abind</span>(trainLocal, trainLocal[newIndices,,,], <span class="at">along =</span> <span class="dv">1</span>)</span>
<span id="cb782-52"><a href="deep.html#cb782-52" aria-hidden="true" tabindex="-1"></a>    <span class="co"># As only new indices are added, there is no confusion with using the old ones.</span></span>
<span id="cb782-53"><a href="deep.html#cb782-53" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb782-54"><a href="deep.html#cb782-54" aria-hidden="true" tabindex="-1"></a>    labelsLocal <span class="ot">=</span> <span class="fu">c</span>(labelsLocal, <span class="fu">rep</span>(<span class="fu">as.integer</span>(i <span class="sc">-</span> <span class="dv">1</span>), missing))</span>
<span id="cb782-55"><a href="deep.html#cb782-55" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb782-56"><a href="deep.html#cb782-56" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb782-57"><a href="deep.html#cb782-57" aria-hidden="true" tabindex="-1"></a>  trainingSet <span class="ot">&lt;&lt;-</span> trainLocal</span>
<span id="cb782-58"><a href="deep.html#cb782-58" aria-hidden="true" tabindex="-1"></a>  flowerLabels <span class="ot">&lt;&lt;-</span> labelsLocal</span>
<span id="cb782-59"><a href="deep.html#cb782-59" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb782-60"><a href="deep.html#cb782-60" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(<span class="fu">table</span>(flowerLabels))</span>
<span id="cb782-61"><a href="deep.html#cb782-61" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Read in for example the following way:</p>
<div class="sourceCode" id="cb783"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb783-1"><a href="deep.html#cb783-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">exists</span>(<span class="st">&quot;done&quot;</span>)){  <span class="co"># Do not calculate this more often than 1 time.</span></span>
<span id="cb783-2"><a href="deep.html#cb783-2" aria-hidden="true" tabindex="-1"></a>  trainingSet <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb783-3"><a href="deep.html#cb783-3" aria-hidden="true" tabindex="-1"></a>  flowerLabels <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb783-4"><a href="deep.html#cb783-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">getData</span>(<span class="at">oversample =</span> <span class="cn">FALSE</span>, <span class="at">undersample =</span> <span class="cn">FALSE</span>)</span>
<span id="cb783-5"><a href="deep.html#cb783-5" aria-hidden="true" tabindex="-1"></a>  done <span class="ot">=</span> <span class="dv">1</span></span>
<span id="cb783-6"><a href="deep.html#cb783-6" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<h2>
Be careful, this exercise uses A LOT OF MEMORY!! If you have a SSD, you might want to turn pagefile / swap off. If you don’t have at least 8 GB RAM, don’t try to run this exercise, it won’t work.
</h2>
<p>To avoid crashes of your system, you might want to do some memory management, like:</p>
<ul>
<li>After model training, unload the training set and load the test set.</li>
<li>Generally remove data that is used no longer.</li>
<li>Lazy load new images (not shown here) out of a generator (later shown in section <a href="gan.html#gan">7</a>, but with manually written training loop).</li>
</ul>
<div class="sourceCode" id="cb784"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb784-1"><a href="deep.html#cb784-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb784-2"><a href="deep.html#cb784-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb784-3"><a href="deep.html#cb784-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb784-4"><a href="deep.html#cb784-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb784-5"><a href="deep.html#cb784-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">exists</span>(<span class="st">&quot;doneWithTest&quot;</span>)){  <span class="co"># Do not calculate this more often than 1 time.</span></span>
<span id="cb784-6"><a href="deep.html#cb784-6" aria-hidden="true" tabindex="-1"></a>  trainingSet <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb784-7"><a href="deep.html#cb784-7" aria-hidden="true" tabindex="-1"></a>  flowerLabels <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb784-8"><a href="deep.html#cb784-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">getData</span>(<span class="at">oversample =</span> <span class="cn">FALSE</span>, <span class="at">undersample =</span> <span class="cn">FALSE</span>)</span>
<span id="cb784-9"><a href="deep.html#cb784-9" aria-hidden="true" tabindex="-1"></a>  doneWithTest <span class="ot">=</span> <span class="dv">1</span></span>
<span id="cb784-10"><a href="deep.html#cb784-10" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<pre><code>## labelsLocal
##   0   1   2   3   4 
## 538 736 548 513 688</code></pre>
<div class="sourceCode" id="cb786"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb786-1"><a href="deep.html#cb786-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb786-2"><a href="deep.html#cb786-2" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb786-3"><a href="deep.html#cb786-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filter =</span> 48L, <span class="at">kernel_size =</span> <span class="fu">c</span>(4L, 4L),</span>
<span id="cb786-4"><a href="deep.html#cb786-4" aria-hidden="true" tabindex="-1"></a>                <span class="at">input_shape =</span> <span class="fu">c</span>(80L, 80L, 3L), <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb786-5"><a href="deep.html#cb786-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span></span>
<span id="cb786-6"><a href="deep.html#cb786-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filter =</span> 48L, <span class="at">kernel_size =</span> <span class="fu">c</span>(3L, 3L), <span class="at">activation =</span> <span class="st">&quot;elu&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb786-7"><a href="deep.html#cb786-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span></span>
<span id="cb786-8"><a href="deep.html#cb786-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filter =</span> 64L, <span class="at">kernel_size =</span> <span class="fu">c</span>(2L, 2L), <span class="at">activation =</span> <span class="st">&quot;gelu&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb786-9"><a href="deep.html#cb786-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span></span>
<span id="cb786-10"><a href="deep.html#cb786-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_flatten</span>() <span class="sc">%&gt;%</span></span>
<span id="cb786-11"><a href="deep.html#cb786-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="fl">0.33</span>) <span class="sc">%&gt;%</span></span>
<span id="cb786-12"><a href="deep.html#cb786-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 750L, <span class="at">activation =</span> <span class="st">&quot;gelu&quot;</span>,</span>
<span id="cb786-13"><a href="deep.html#cb786-13" aria-hidden="true" tabindex="-1"></a>              <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l1</span>(.<span class="dv">75</span>),</span>
<span id="cb786-14"><a href="deep.html#cb786-14" aria-hidden="true" tabindex="-1"></a>              <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l2</span>(.<span class="dv">0055</span>)</span>
<span id="cb786-15"><a href="deep.html#cb786-15" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb786-16"><a href="deep.html#cb786-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="fl">0.4</span>) <span class="sc">%&gt;%</span></span>
<span id="cb786-17"><a href="deep.html#cb786-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 175L, <span class="at">activation =</span> <span class="st">&quot;gelu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb786-18"><a href="deep.html#cb786-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="fl">0.35</span>) <span class="sc">%&gt;%</span></span>
<span id="cb786-19"><a href="deep.html#cb786-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 75L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb786-20"><a href="deep.html#cb786-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 50L, <span class="at">activation =</span> <span class="st">&quot;gelu&quot;</span>,</span>
<span id="cb786-21"><a href="deep.html#cb786-21" aria-hidden="true" tabindex="-1"></a>              <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l2</span>(.<span class="dv">75</span>),</span>
<span id="cb786-22"><a href="deep.html#cb786-22" aria-hidden="true" tabindex="-1"></a>              <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1</span>(.<span class="dv">0055</span>)</span>
<span id="cb786-23"><a href="deep.html#cb786-23" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb786-24"><a href="deep.html#cb786-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="fl">0.3</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb786-25"><a href="deep.html#cb786-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 5L, <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>)</span>
<span id="cb786-26"><a href="deep.html#cb786-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb786-27"><a href="deep.html#cb786-27" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb786-28"><a href="deep.html#cb786-28" aria-hidden="true" tabindex="-1"></a>  keras<span class="sc">::</span><span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb786-29"><a href="deep.html#cb786-29" aria-hidden="true" tabindex="-1"></a>                 <span class="at">optimizer =</span> <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.011</span>))</span>
<span id="cb786-30"><a href="deep.html#cb786-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb786-31"><a href="deep.html#cb786-31" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb786-32"><a href="deep.html#cb786-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> trainingSet, <span class="at">y =</span> <span class="fu">to_categorical</span>(<span class="fu">matrix</span>(flowerLabels, <span class="at">ncol =</span> 1L), 5L),</span>
<span id="cb786-33"><a href="deep.html#cb786-33" aria-hidden="true" tabindex="-1"></a>      <span class="at">epochs =</span> 50L, <span class="at">batch_size =</span> 100L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>, <span class="at">validation_split =</span> <span class="fl">0.2</span>)</span>
<span id="cb786-34"><a href="deep.html#cb786-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb786-35"><a href="deep.html#cb786-35" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">=</span> model <span class="sc">%&gt;%</span> <span class="fu">predict</span>(trainingSet)</span>
<span id="cb786-36"><a href="deep.html#cb786-36" aria-hidden="true" tabindex="-1"></a>pred_classes <span class="ot">=</span> <span class="fu">apply</span>(pred, <span class="dv">1</span>, which.max)</span>
<span id="cb786-37"><a href="deep.html#cb786-37" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">table</span>(pred_classes))</span></code></pre></div>
<pre><code>## pred_classes
##   1   2   3   4 
## 531 854 955 683</code></pre>
<div class="sourceCode" id="cb788"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb788-1"><a href="deep.html#cb788-1" aria-hidden="true" tabindex="-1"></a>Metrics<span class="sc">::</span><span class="fu">accuracy</span>(pred_classes <span class="sc">-</span> 1L, flowerLabels)</span></code></pre></div>
<pre><code>## [1] 0.6218988</code></pre>
<div class="sourceCode" id="cb790"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb790-1"><a href="deep.html#cb790-1" aria-hidden="true" tabindex="-1"></a><span class="co">#pred_classes = model %&gt;% predict(EcoData::dataset_flower()$test/255) %&gt;%</span></span>
<span id="cb790-2"><a href="deep.html#cb790-2" aria-hidden="true" tabindex="-1"></a><span class="co">#  apply(1, which.max) - 1L  # Do not forget &quot;/255&quot; and  &quot;- 1L&quot;!!</span></span>
<span id="cb790-3"><a href="deep.html#cb790-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb790-4"><a href="deep.html#cb790-4" aria-hidden="true" tabindex="-1"></a><span class="co">#write.csv(pred_classes, file = &quot;flower_CNN.csv&quot;)</span></span></code></pre></div>
<p>As you can see, the network works in principle (76% accuracy for training data). Mind, that this is not a binary classification problem and we are expecting roughly 20% accuracy by chance.</p>
<p>Just a little hint: More complex networks are not always better. This won’t be shown explicitly (as it is very computing-intensive). You can try for example 64 filter kernels per layer or copy one of the convolutional layers (including pooling layer) to see what happens.</p>
<p>Now, we are training without holdouts to get the most power.</p>
<div class="sourceCode" id="cb791"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb791-1"><a href="deep.html#cb791-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb791-2"><a href="deep.html#cb791-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb791-3"><a href="deep.html#cb791-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb791-4"><a href="deep.html#cb791-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb791-5"><a href="deep.html#cb791-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">exists</span>(<span class="st">&quot;doneWithoutTest&quot;</span>)){  <span class="co"># Do not calculate this more often than 1 time.</span></span>
<span id="cb791-6"><a href="deep.html#cb791-6" aria-hidden="true" tabindex="-1"></a>  trainingSet <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb791-7"><a href="deep.html#cb791-7" aria-hidden="true" tabindex="-1"></a>  flowerLabels <span class="ot">=</span> <span class="fu">c</span>()</span>
<span id="cb791-8"><a href="deep.html#cb791-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">getData</span>(<span class="at">oversample =</span> <span class="cn">FALSE</span>, <span class="at">undersample =</span> <span class="cn">FALSE</span>)</span>
<span id="cb791-9"><a href="deep.html#cb791-9" aria-hidden="true" tabindex="-1"></a>  doneWithoutTest <span class="ot">=</span> <span class="dv">1</span></span>
<span id="cb791-10"><a href="deep.html#cb791-10" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<pre><code>## labelsLocal
##   0   1   2   3   4 
## 538 736 548 513 688</code></pre>
<div class="sourceCode" id="cb793"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb793-1"><a href="deep.html#cb793-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb793-2"><a href="deep.html#cb793-2" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> </span>
<span id="cb793-3"><a href="deep.html#cb793-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filter =</span> 48L, <span class="at">kernel_size =</span> <span class="fu">c</span>(4L, 4L),</span>
<span id="cb793-4"><a href="deep.html#cb793-4" aria-hidden="true" tabindex="-1"></a>                <span class="at">input_shape =</span> <span class="fu">c</span>(80L, 80L, 3L), <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb793-5"><a href="deep.html#cb793-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span></span>
<span id="cb793-6"><a href="deep.html#cb793-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filter =</span> 48L, <span class="at">kernel_size =</span> <span class="fu">c</span>(3L, 3L), <span class="at">activation =</span> <span class="st">&quot;elu&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb793-7"><a href="deep.html#cb793-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span></span>
<span id="cb793-8"><a href="deep.html#cb793-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filter =</span> 64L, <span class="at">kernel_size =</span> <span class="fu">c</span>(2L, 2L), <span class="at">activation =</span> <span class="st">&quot;gelu&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb793-9"><a href="deep.html#cb793-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_max_pooling_2d</span>() <span class="sc">%&gt;%</span></span>
<span id="cb793-10"><a href="deep.html#cb793-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_flatten</span>() <span class="sc">%&gt;%</span></span>
<span id="cb793-11"><a href="deep.html#cb793-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="fl">0.33</span>) <span class="sc">%&gt;%</span></span>
<span id="cb793-12"><a href="deep.html#cb793-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 750L, <span class="at">activation =</span> <span class="st">&quot;gelu&quot;</span>,</span>
<span id="cb793-13"><a href="deep.html#cb793-13" aria-hidden="true" tabindex="-1"></a>              <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l1</span>(.<span class="dv">75</span>),</span>
<span id="cb793-14"><a href="deep.html#cb793-14" aria-hidden="true" tabindex="-1"></a>              <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l2</span>(.<span class="dv">0055</span>)</span>
<span id="cb793-15"><a href="deep.html#cb793-15" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb793-16"><a href="deep.html#cb793-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="fl">0.4</span>) <span class="sc">%&gt;%</span></span>
<span id="cb793-17"><a href="deep.html#cb793-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 175L, <span class="at">activation =</span> <span class="st">&quot;gelu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb793-18"><a href="deep.html#cb793-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="fl">0.35</span>) <span class="sc">%&gt;%</span></span>
<span id="cb793-19"><a href="deep.html#cb793-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 75L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb793-20"><a href="deep.html#cb793-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 50L, <span class="at">activation =</span> <span class="st">&quot;gelu&quot;</span>,</span>
<span id="cb793-21"><a href="deep.html#cb793-21" aria-hidden="true" tabindex="-1"></a>              <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l2</span>(.<span class="dv">75</span>),</span>
<span id="cb793-22"><a href="deep.html#cb793-22" aria-hidden="true" tabindex="-1"></a>              <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1</span>(.<span class="dv">0055</span>)</span>
<span id="cb793-23"><a href="deep.html#cb793-23" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb793-24"><a href="deep.html#cb793-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="fl">0.3</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb793-25"><a href="deep.html#cb793-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 5L, <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>)</span>
<span id="cb793-26"><a href="deep.html#cb793-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb793-27"><a href="deep.html#cb793-27" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb793-28"><a href="deep.html#cb793-28" aria-hidden="true" tabindex="-1"></a>  keras<span class="sc">::</span><span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb793-29"><a href="deep.html#cb793-29" aria-hidden="true" tabindex="-1"></a>                 <span class="at">optimizer =</span> <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.011</span>))</span>
<span id="cb793-30"><a href="deep.html#cb793-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb793-31"><a href="deep.html#cb793-31" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb793-32"><a href="deep.html#cb793-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> trainingSet, <span class="at">y =</span> <span class="fu">to_categorical</span>(<span class="fu">matrix</span>(flowerLabels, <span class="at">ncol =</span> 1L), 5L),</span>
<span id="cb793-33"><a href="deep.html#cb793-33" aria-hidden="true" tabindex="-1"></a>      <span class="at">epochs =</span> 50L, <span class="at">batch_size =</span> 100L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb793-34"><a href="deep.html#cb793-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb793-35"><a href="deep.html#cb793-35" aria-hidden="true" tabindex="-1"></a>pred_classes <span class="ot">=</span> <span class="fu">apply</span>(model <span class="sc">%&gt;%</span> <span class="fu">predict</span>(trainingSet), <span class="dv">1</span>, which.max)</span>
<span id="cb793-36"><a href="deep.html#cb793-36" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">table</span>(pred_classes))</span></code></pre></div>
<pre><code>## pred_classes
##   1   2   3   4   5 
## 491 618 156 964 794</code></pre>
<div class="sourceCode" id="cb795"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb795-1"><a href="deep.html#cb795-1" aria-hidden="true" tabindex="-1"></a>Metrics<span class="sc">::</span><span class="fu">accuracy</span>(pred_classes <span class="sc">-</span> 1L, flowerLabels)</span></code></pre></div>
<pre><code>## [1] 0.621568</code></pre>
<div class="sourceCode" id="cb797"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb797-1"><a href="deep.html#cb797-1" aria-hidden="true" tabindex="-1"></a>pred_classes <span class="ot">=</span> model <span class="sc">%&gt;%</span> <span class="fu">predict</span>(EcoData<span class="sc">::</span><span class="fu">dataset_flower</span>()<span class="sc">$</span>test<span class="sc">/</span><span class="dv">255</span>) <span class="sc">%&gt;%</span></span>
<span id="cb797-2"><a href="deep.html#cb797-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">apply</span>(<span class="dv">1</span>, which.max) <span class="sc">-</span> 1L  <span class="co"># Do not forget &quot;/255&quot; and  &quot;- 1L&quot;!!</span></span>
<span id="cb797-3"><a href="deep.html#cb797-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb797-4"><a href="deep.html#cb797-4" aria-hidden="true" tabindex="-1"></a><span class="fu">write.csv</span>(pred_classes, <span class="at">file =</span> <span class="st">&quot;flower_CNN.csv&quot;</span>)</span></code></pre></div>
<p>Maybe you can find (much?) better networks, that fit already better than 84% on the training data.
Mind, that there are 5 classes. If your model predicts only 3 or 4 of them, is is not surprising, that the accuracy is low.</p>
    </p>
  </details>
  <br/><hr/>

</div>
</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-dropout" class="csl-entry">
Srivastava, Nitish, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. <span>“Dropout: A Simple Way to Prevent Neural Networks from Overfitting.”</span> <em>The Journal of Machine Learning Research</em> 15 (1): 1929–58.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="fundamental.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="interpretation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

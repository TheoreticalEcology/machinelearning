<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Introduction to Machine Learning | Machine Learning and AI in TensorFlow and R</title>
  <meta name="description" content="3 Introduction to Machine Learning | Machine Learning and AI in TensorFlow and R" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Introduction to Machine Learning | Machine Learning and AI in TensorFlow and R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="3 Introduction to Machine Learning | Machine Learning and AI in TensorFlow and R" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Introduction to Machine Learning | Machine Learning and AI in TensorFlow and R" />
  
  <meta name="twitter:description" content="3 Introduction to Machine Learning | Machine Learning and AI in TensorFlow and R" />
  

<meta name="author" content="Maximilian Pichler and Florian Hartig" />


<meta name="date" content="2021-11-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="reminder.html"/>
<link rel="next" href="fundamental.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/viz-1.8.2/viz.js"></script>
<link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="libs/grViz-binding-1.0.6.1/grViz.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #ffffff;
    color: #a0a0a0;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
div.sourceCode
  { color: #1f1c1b; background-color: #ffffff; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span { color: #1f1c1b; } /* Normal */
code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
code span.an { color: #ca60ca; } /* Annotation */
code span.at { color: #0057ae; } /* Attribute */
code span.bn { color: #b08000; } /* BaseN */
code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #924c9d; } /* Char */
code span.cn { color: #aa5500; } /* Constant */
code span.co { color: #898887; } /* Comment */
code span.cv { color: #0095ff; } /* CommentVar */
code span.do { color: #607880; } /* Documentation */
code span.dt { color: #0057ae; } /* DataType */
code span.dv { color: #b08000; } /* DecVal */
code span.er { color: #bf0303; text-decoration: underline; } /* Error */
code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
code span.fl { color: #b08000; } /* Float */
code span.fu { color: #644a9b; } /* Function */
code span.im { color: #ff5500; } /* Import */
code span.in { color: #b08000; } /* Information */
code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
code span.op { color: #1f1c1b; } /* Operator */
code span.ot { color: #006e28; } /* Other */
code span.pp { color: #006e28; } /* Preprocessor */
code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #ff5500; } /* SpecialString */
code span.st { color: #bf0303; } /* String */
code span.va { color: #0057ae; } /* Variable */
code span.vs { color: #bf0303; } /* VerbatimString */
code span.wa { color: #bf0303; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#r-system"><i class="fa fa-check"></i><b>1.1</b> R System</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#tensorflow-and-keras"><i class="fa fa-check"></i><b>1.2</b> TensorFlow and Keras</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#torch-for-r"><i class="fa fa-check"></i><b>1.3</b> Torch for R</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#ecodata"><i class="fa fa-check"></i><b>1.4</b> EcoData</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#further-used-libraries"><i class="fa fa-check"></i><b>1.5</b> Further Used Libraries</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#linuxunix-systems-have-to-fulfill-some-durther-dependencies"><i class="fa fa-check"></i><b>1.6</b> Linux/UNIX systems have to fulfill some durther dependencies</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="reminder.html"><a href="reminder.html"><i class="fa fa-check"></i><b>2</b> Reminders About Basic Operations in R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="reminder.html"><a href="reminder.html#your-r-system"><i class="fa fa-check"></i><b>2.1</b> Your R System</a></li>
<li class="chapter" data-level="2.2" data-path="reminder.html"><a href="reminder.html#data-types-in-r"><i class="fa fa-check"></i><b>2.2</b> Data types in R</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="reminder.html"><a href="reminder.html#test-your-knowledge"><i class="fa fa-check"></i><b>2.2.1</b> Test Your Knowledge</a></li>
<li class="chapter" data-level="2.2.2" data-path="reminder.html"><a href="reminder.html#iris-data"><i class="fa fa-check"></i><b>2.2.2</b> Iris Data</a></li>
<li class="chapter" data-level="2.2.3" data-path="reminder.html"><a href="reminder.html#dynamic-typing"><i class="fa fa-check"></i><b>2.2.3</b> Dynamic typing</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="reminder.html"><a href="reminder.html#data-selection-slicing-and-subsetting"><i class="fa fa-check"></i><b>2.3</b> Data selection, Slicing and Subsetting</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="reminder.html"><a href="reminder.html#subsetting-and-slicing-for-single-data-types"><i class="fa fa-check"></i><b>2.3.1</b> Subsetting and Slicing for Single Data Types</a></li>
<li class="chapter" data-level="2.3.2" data-path="reminder.html"><a href="reminder.html#logic-and-slicing"><i class="fa fa-check"></i><b>2.3.2</b> Logic and Slicing</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="reminder.html"><a href="reminder.html#applying-functions-and-aggregates-across-a-data-set"><i class="fa fa-check"></i><b>2.4</b> Applying Functions and Aggregates Across a Data set</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="reminder.html"><a href="reminder.html#functions"><i class="fa fa-check"></i><b>2.4.1</b> Functions</a></li>
<li class="chapter" data-level="2.4.2" data-path="reminder.html"><a href="reminder.html#the-apply-function"><i class="fa fa-check"></i><b>2.4.2</b> The apply() Function</a></li>
<li class="chapter" data-level="2.4.3" data-path="reminder.html"><a href="reminder.html#the-aggregate-function"><i class="fa fa-check"></i><b>2.4.3</b> The aggregate() Function</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="reminder.html"><a href="reminder.html#plotting"><i class="fa fa-check"></i><b>2.5</b> Plotting</a></li>
<li class="chapter" data-level="2.6" data-path="reminder.html"><a href="reminder.html#additional-resources"><i class="fa fa-check"></i><b>2.6</b> Additional Resources</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="reminder.html"><a href="reminder.html#books"><i class="fa fa-check"></i><b>2.6.1</b> Books</a></li>
<li class="chapter" data-level="2.6.2" data-path="reminder.html"><a href="reminder.html#instructional-videos"><i class="fa fa-check"></i><b>2.6.2</b> Instructional videos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>3</b> Introduction to Machine Learning</a>
<ul>
<li class="chapter" data-level="3.1" data-path="introduction.html"><a href="introduction.html#unsupervised-learning"><i class="fa fa-check"></i><b>3.1</b> Unsupervised Learning</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="introduction.html"><a href="introduction.html#hierarchical-clustering"><i class="fa fa-check"></i><b>3.1.1</b> Hierarchical Clustering</a></li>
<li class="chapter" data-level="3.1.2" data-path="introduction.html"><a href="introduction.html#k-means-clustering"><i class="fa fa-check"></i><b>3.1.2</b> K-means Clustering</a></li>
<li class="chapter" data-level="3.1.3" data-path="introduction.html"><a href="introduction.html#density-based-clustering"><i class="fa fa-check"></i><b>3.1.3</b> Density-based Clustering</a></li>
<li class="chapter" data-level="3.1.4" data-path="introduction.html"><a href="introduction.html#model-based-clustering"><i class="fa fa-check"></i><b>3.1.4</b> Model-based Clustering</a></li>
<li class="chapter" data-level="3.1.5" data-path="introduction.html"><a href="introduction.html#ordination"><i class="fa fa-check"></i><b>3.1.5</b> Ordination</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="introduction.html"><a href="introduction.html#supervised-learning-regression-and-classification"><i class="fa fa-check"></i><b>3.2</b> Supervised Learning: Regression and Classification</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="introduction.html"><a href="introduction.html#supervised-regression-using-random-forest"><i class="fa fa-check"></i><b>3.2.1</b> Supervised Regression Using Random Forest</a></li>
<li class="chapter" data-level="3.2.2" data-path="introduction.html"><a href="introduction.html#supervised-classification-using-random-forest"><i class="fa fa-check"></i><b>3.2.2</b> Supervised Classification Using Random Forest</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="introduction.html"><a href="introduction.html#basicMath"><i class="fa fa-check"></i><b>3.3</b> Small Introduction Into the Underlying Mathematical Concepts of all Following Lessons - Optional</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="introduction.html"><a href="introduction.html#caveat-about-learning-rates-and-activation-functions"><i class="fa fa-check"></i><b>3.3.1</b> Caveat About Learning Rates and Activation Functions</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="introduction.html"><a href="introduction.html#introduction-to-tensorflow"><i class="fa fa-check"></i><b>3.4</b> Introduction to TensorFlow</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="introduction.html"><a href="introduction.html#tensorflow-data-containers"><i class="fa fa-check"></i><b>3.4.1</b> TensorFlow Data Containers</a></li>
<li class="chapter" data-level="3.4.2" data-path="introduction.html"><a href="introduction.html#basic-operations"><i class="fa fa-check"></i><b>3.4.2</b> Basic Operations</a></li>
<li class="chapter" data-level="3.4.3" data-path="introduction.html"><a href="introduction.html#tensorflow-data-types---good-practice-with-r-tensorflow"><i class="fa fa-check"></i><b>3.4.3</b> TensorFlow Data Types - Good Practice With R-TensorFlow</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="introduction.html"><a href="introduction.html#introduction-to-pytorch"><i class="fa fa-check"></i><b>3.5</b> Introduction to PyTorch</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="introduction.html"><a href="introduction.html#pytorch-data-containers"><i class="fa fa-check"></i><b>3.5.1</b> PyTorch Data Containers</a></li>
<li class="chapter" data-level="3.5.2" data-path="introduction.html"><a href="introduction.html#basic-operations-1"><i class="fa fa-check"></i><b>3.5.2</b> Basic Operations</a></li>
<li class="chapter" data-level="3.5.3" data-path="introduction.html"><a href="introduction.html#torch-data-types---good-practice-with-r-torch"><i class="fa fa-check"></i><b>3.5.3</b> Torch Data Types - Good Practice With R-Torch</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="introduction.html"><a href="introduction.html#first-steps-with-the-keras-framework"><i class="fa fa-check"></i><b>3.6</b> First Steps With the Keras Framework</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="introduction.html"><a href="introduction.html#example-workflow-in-keras"><i class="fa fa-check"></i><b>3.6.1</b> Example Workflow in Keras</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="fundamental.html"><a href="fundamental.html"><i class="fa fa-check"></i><b>4</b> Fundamental Principles and Techniques</a>
<ul>
<li class="chapter" data-level="4.1" data-path="fundamental.html"><a href="fundamental.html#machine-learning-principles"><i class="fa fa-check"></i><b>4.1</b> Machine Learning Principles</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="fundamental.html"><a href="fundamental.html#optimization"><i class="fa fa-check"></i><b>4.1.1</b> Optimization</a></li>
<li class="chapter" data-level="4.1.2" data-path="fundamental.html"><a href="fundamental.html#advanced-optimization-example"><i class="fa fa-check"></i><b>4.1.2</b> Advanced Optimization Example</a></li>
<li class="chapter" data-level="4.1.3" data-path="fundamental.html"><a href="fundamental.html#regularization"><i class="fa fa-check"></i><b>4.1.3</b> Regularization</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="fundamental.html"><a href="fundamental.html#artificial-neural-networks"><i class="fa fa-check"></i><b>4.2</b> Artificial Neural Networks</a></li>
<li class="chapter" data-level="4.3" data-path="fundamental.html"><a href="fundamental.html#tree-based-machine-learning-algorithms"><i class="fa fa-check"></i><b>4.3</b> Tree-based Machine Learning Algorithms</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="fundamental.html"><a href="fundamental.html#classification-and-regression-trees"><i class="fa fa-check"></i><b>4.3.1</b> Classification and Regression Trees</a></li>
<li class="chapter" data-level="4.3.2" data-path="fundamental.html"><a href="fundamental.html#random-forest"><i class="fa fa-check"></i><b>4.3.2</b> Random Forest</a></li>
<li class="chapter" data-level="4.3.3" data-path="fundamental.html"><a href="fundamental.html#boosted-regression-trees"><i class="fa fa-check"></i><b>4.3.3</b> Boosted Regression Trees</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="fundamental.html"><a href="fundamental.html#distance-based-algorithms"><i class="fa fa-check"></i><b>4.4</b> Distance-based Algorithms</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="fundamental.html"><a href="fundamental.html#k-nearest-neighbor"><i class="fa fa-check"></i><b>4.4.1</b> K-Nearest-Neighbor</a></li>
<li class="chapter" data-level="4.4.2" data-path="fundamental.html"><a href="fundamental.html#support-vector-machines-svms"><i class="fa fa-check"></i><b>4.4.2</b> Support Vector Machines (SVMs)</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="fundamental.html"><a href="fundamental.html#the-standard-machine-learning-pipeline-at-the-eexample-of-the-titanic-data-set"><i class="fa fa-check"></i><b>4.5</b> The Standard Machine Learning Pipeline at the Eexample of the Titanic Data set</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="fundamental.html"><a href="fundamental.html#data-cleaning"><i class="fa fa-check"></i><b>4.5.1</b> Data Cleaning</a></li>
<li class="chapter" data-level="4.5.2" data-path="fundamental.html"><a href="fundamental.html#preprocessing-and-feature-selection"><i class="fa fa-check"></i><b>4.5.2</b> Preprocessing and Feature Selection</a></li>
<li class="chapter" data-level="4.5.3" data-path="fundamental.html"><a href="fundamental.html#split-data-for-training-and-testing"><i class="fa fa-check"></i><b>4.5.3</b> Split Data for Training and Testing</a></li>
<li class="chapter" data-level="4.5.4" data-path="fundamental.html"><a href="fundamental.html#model-fitting"><i class="fa fa-check"></i><b>4.5.4</b> Model Fitting</a></li>
<li class="chapter" data-level="4.5.5" data-path="fundamental.html"><a href="fundamental.html#model-evaluation"><i class="fa fa-check"></i><b>4.5.5</b> Model Evaluation</a></li>
<li class="chapter" data-level="4.5.6" data-path="fundamental.html"><a href="fundamental.html#predictions-and-submission"><i class="fa fa-check"></i><b>4.5.6</b> Predictions and Submission</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="fundamental.html"><a href="fundamental.html#mlr"><i class="fa fa-check"></i><b>4.6</b> Bonus - Machine Learning Pipelines with mlr3</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="fundamental.html"><a href="fundamental.html#mlr3---the-basic-workflow"><i class="fa fa-check"></i><b>4.6.1</b> mlr3 - The Basic Workflow</a></li>
<li class="chapter" data-level="4.6.2" data-path="fundamental.html"><a href="fundamental.html#mlr3---hyperparameter-tuning"><i class="fa fa-check"></i><b>4.6.2</b> mlr3 - Hyperparameter Tuning</a></li>
<li class="chapter" data-level="4.6.3" data-path="fundamental.html"><a href="fundamental.html#mlr3---hyperparameter-tuning-with-oversampling"><i class="fa fa-check"></i><b>4.6.3</b> mlr3 - Hyperparameter Tuning with Oversampling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="deep.html"><a href="deep.html"><i class="fa fa-check"></i><b>5</b> Deep Learning</a>
<ul>
<li class="chapter" data-level="5.1" data-path="deep.html"><a href="deep.html#network-architectures"><i class="fa fa-check"></i><b>5.1</b> Network Architectures</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="deep.html"><a href="deep.html#deep-neural-networks-dnns"><i class="fa fa-check"></i><b>5.1.1</b> Deep Neural Networks (DNNs)</a></li>
<li class="chapter" data-level="5.1.2" data-path="deep.html"><a href="deep.html#convolutional-neural-networks-cnns"><i class="fa fa-check"></i><b>5.1.2</b> Convolutional Neural Networks (CNNs)</a></li>
<li class="chapter" data-level="5.1.3" data-path="deep.html"><a href="deep.html#recurrent-neural-networks-rnns"><i class="fa fa-check"></i><b>5.1.3</b> Recurrent Neural Networks (RNNs)</a></li>
<li class="chapter" data-level="5.1.4" data-path="deep.html"><a href="deep.html#natural-language-processing-nlp"><i class="fa fa-check"></i><b>5.1.4</b> Natural Language Processing (NLP)</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="deep.html"><a href="deep.html#case-study-dropout-and-early-stopping-in-a-deep-neural-network"><i class="fa fa-check"></i><b>5.2</b> Case Study: Dropout and Early Stopping in a Deep Neural Network</a></li>
<li class="chapter" data-level="5.3" data-path="deep.html"><a href="deep.html#case-study-fitting-a-convolutional-neural-network-on-mnist"><i class="fa fa-check"></i><b>5.3</b> Case Study: Fitting a Convolutional Neural Network on MNIST</a></li>
<li class="chapter" data-level="5.4" data-path="deep.html"><a href="deep.html#advanced-training-techniques"><i class="fa fa-check"></i><b>5.4</b> Advanced Training Techniques</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="deep.html"><a href="deep.html#data-augmentation"><i class="fa fa-check"></i><b>5.4.1</b> Data Augmentation</a></li>
<li class="chapter" data-level="5.4.2" data-path="deep.html"><a href="deep.html#transfer"><i class="fa fa-check"></i><b>5.4.2</b> Transfer Learning</a></li>
<li class="chapter" data-level="5.4.3" data-path="deep.html"><a href="deep.html#influence-of-batch-size-and-learning-rate"><i class="fa fa-check"></i><b>5.4.3</b> Influence of Batch Size and Learning Rate</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="interpretation.html"><a href="interpretation.html"><i class="fa fa-check"></i><b>6</b> Interpretation and Causality With Machine Learning</a>
<ul>
<li class="chapter" data-level="6.1" data-path="interpretation.html"><a href="interpretation.html#explainable-ai"><i class="fa fa-check"></i><b>6.1</b> Explainable AI</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="interpretation.html"><a href="interpretation.html#a-practical-example"><i class="fa fa-check"></i><b>6.1.1</b> A Practical Example</a></li>
<li class="chapter" data-level="6.1.2" data-path="interpretation.html"><a href="interpretation.html#feature-importance"><i class="fa fa-check"></i><b>6.1.2</b> Feature Importance</a></li>
<li class="chapter" data-level="6.1.3" data-path="interpretation.html"><a href="interpretation.html#partial-dependencies"><i class="fa fa-check"></i><b>6.1.3</b> Partial Dependencies</a></li>
<li class="chapter" data-level="6.1.4" data-path="interpretation.html"><a href="interpretation.html#accumulated-local-effects"><i class="fa fa-check"></i><b>6.1.4</b> Accumulated Local Effects</a></li>
<li class="chapter" data-level="6.1.5" data-path="interpretation.html"><a href="interpretation.html#friedmans-h-statistic"><i class="fa fa-check"></i><b>6.1.5</b> Friedman’s H-statistic</a></li>
<li class="chapter" data-level="6.1.6" data-path="interpretation.html"><a href="interpretation.html#global-explainer---simplifying-the-machine-learning-model"><i class="fa fa-check"></i><b>6.1.6</b> Global Explainer - Simplifying the Machine Learning Model</a></li>
<li class="chapter" data-level="6.1.7" data-path="interpretation.html"><a href="interpretation.html#local-explainer---lime-explaining-single-instances-observations"><i class="fa fa-check"></i><b>6.1.7</b> Local Explainer - LIME Explaining Single Instances (observations)</a></li>
<li class="chapter" data-level="6.1.8" data-path="interpretation.html"><a href="interpretation.html#local-explainer---shapley"><i class="fa fa-check"></i><b>6.1.8</b> Local Explainer - Shapley</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="interpretation.html"><a href="interpretation.html#causal-inference-and-machine-learning"><i class="fa fa-check"></i><b>6.2</b> Causal Inference and Machine Learning</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="interpretation.html"><a href="interpretation.html#causalInference"><i class="fa fa-check"></i><b>6.2.1</b> Causal Inference on Static Data</a></li>
<li class="chapter" data-level="6.2.2" data-path="interpretation.html"><a href="interpretation.html#structural-equation-models"><i class="fa fa-check"></i><b>6.2.2</b> Structural Equation Models</a></li>
<li class="chapter" data-level="6.2.3" data-path="interpretation.html"><a href="interpretation.html#automatic-causal-discovery"><i class="fa fa-check"></i><b>6.2.3</b> Automatic Causal Discovery</a></li>
<li class="chapter" data-level="6.2.4" data-path="interpretation.html"><a href="interpretation.html#causal-inference-on-dynamic-data"><i class="fa fa-check"></i><b>6.2.4</b> Causal Inference on Dynamic Data</a></li>
<li class="chapter" data-level="6.2.5" data-path="interpretation.html"><a href="interpretation.html#outlook-for-machine-learning"><i class="fa fa-check"></i><b>6.2.5</b> Outlook for Machine Learning</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="gan.html"><a href="gan.html"><i class="fa fa-check"></i><b>7</b> Generative Modeling and Reinforcement Learning</a>
<ul>
<li class="chapter" data-level="7.1" data-path="gan.html"><a href="gan.html#autoencoder"><i class="fa fa-check"></i><b>7.1</b> Autoencoder</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="gan.html"><a href="gan.html#autoencoder---deep-neural-network-mnist"><i class="fa fa-check"></i><b>7.1.1</b> Autoencoder - Deep Neural Network MNIST</a></li>
<li class="chapter" data-level="7.1.2" data-path="gan.html"><a href="gan.html#autoencoder---mnist-convolutional-neural-networks"><i class="fa fa-check"></i><b>7.1.2</b> Autoencoder - MNIST Convolutional Neural Networks</a></li>
<li class="chapter" data-level="7.1.3" data-path="gan.html"><a href="gan.html#VAE"><i class="fa fa-check"></i><b>7.1.3</b> Variational Autoencoder (VAE)</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="gan.html"><a href="gan.html#GANS"><i class="fa fa-check"></i><b>7.2</b> Generative Adversarial Networks (GANs)</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="gan.html"><a href="gan.html#mnist---generative-adversarial-networks-based-on-deep-neural-networks"><i class="fa fa-check"></i><b>7.2.1</b> MNIST - Generative Adversarial Networks Based on Deep Neural Networks</a></li>
<li class="chapter" data-level="7.2.2" data-path="gan.html"><a href="gan.html#flower---gan"><i class="fa fa-check"></i><b>7.2.2</b> Flower - GAN</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="gan.html"><a href="gan.html#reinforcement-learning"><i class="fa fa-check"></i><b>7.3</b> Reinforcement learning</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="datasets.html"><a href="datasets.html"><i class="fa fa-check"></i><b>8</b> Data sets</a>
<ul>
<li class="chapter" data-level="8.1" data-path="datasets.html"><a href="datasets.html#titanic"><i class="fa fa-check"></i><b>8.1</b> Titanic</a></li>
<li class="chapter" data-level="8.2" data-path="datasets.html"><a href="datasets.html#plant-pollinator-database"><i class="fa fa-check"></i><b>8.2</b> Plant-pollinator Database</a></li>
<li class="chapter" data-level="8.3" data-path="datasets.html"><a href="datasets.html#wine"><i class="fa fa-check"></i><b>8.3</b> Wine</a></li>
<li class="chapter" data-level="8.4" data-path="datasets.html"><a href="datasets.html#nasa"><i class="fa fa-check"></i><b>8.4</b> Nasa</a></li>
<li class="chapter" data-level="8.5" data-path="datasets.html"><a href="datasets.html#flower"><i class="fa fa-check"></i><b>8.5</b> Flower</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning and AI in TensorFlow and R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introduction" class="section level1" number="3">
<h1><span class="header-section-number">3</span> Introduction to Machine Learning</h1>
<!-- Put this here (right after the first markdown headline) and only here for each document! -->
<script src="./scripts/multipleChoice.js"></script>
<p>There are three basic machine learning tasks:</p>
<ul>
<li>Supervised learning</li>
<li>Unsupervised learning</li>
<li>Reinforcement learning</li>
</ul>
<p>In <strong>supervised learning</strong>, you train algorithms using labeled data, what means that you already know the correct answer for a part of the data (the so called <em>training data</em>).</p>
<p><strong>Unsupervised learning</strong> in contrast is a technique, where one does not need to monitor the model or apply labels. Instead, you allow the model to work on its own to discover information.</p>
<p><strong>Reinforcement learning</strong> is a technique that emulates a game-like situation. The algorithm finds a solution by trial and error and gets either <em>rewards</em> or <em>penalties</em> for every action. As in games, the goal is to maximize the rewards. We will talk more about this technique on the last day of the course.</p>
<p>For the moment, we will focus on the first two tasks, supervised and unsupervised learning. To do so, we will begin with a small example. But before you start with the code, here is a video to prepare you for what we will do in the class:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/1AVrWvRvfxs" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<div id="unsupervised-learning" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Unsupervised Learning</h2>
<p>In unsupervised learning, we want to identify patterns in data without having any examples (supervision) about what the correct patterns / classes are. As an example, consider the iris data set. Here, we have 150 observations of 4 floral traits:</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="introduction.html#cb65-1" aria-hidden="true" tabindex="-1"></a>iris <span class="ot">=</span> datasets<span class="sc">::</span>iris</span>
<span id="cb65-2"><a href="introduction.html#cb65-2" aria-hidden="true" tabindex="-1"></a>colors <span class="ot">=</span> <span class="fu">hcl.colors</span>(<span class="dv">3</span>)</span>
<span id="cb65-3"><a href="introduction.html#cb65-3" aria-hidden="true" tabindex="-1"></a>traits <span class="ot">=</span> <span class="fu">as.matrix</span>(iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>]) </span>
<span id="cb65-4"><a href="introduction.html#cb65-4" aria-hidden="true" tabindex="-1"></a>species <span class="ot">=</span> iris<span class="sc">$</span>Species</span>
<span id="cb65-5"><a href="introduction.html#cb65-5" aria-hidden="true" tabindex="-1"></a><span class="fu">image</span>(<span class="at">y =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, <span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(species) , <span class="at">z =</span> traits, </span>
<span id="cb65-6"><a href="introduction.html#cb65-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">ylab =</span> <span class="st">&quot;Floral trait&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;Individual&quot;</span>)</span>
<span id="cb65-7"><a href="introduction.html#cb65-7" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(<span class="fl">50.5</span>, <span class="dv">0</span>, <span class="fl">50.5</span>, <span class="dv">5</span>, <span class="at">col =</span> <span class="st">&quot;black&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb65-8"><a href="introduction.html#cb65-8" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(<span class="fl">100.5</span>, <span class="dv">0</span>, <span class="fl">100.5</span>, <span class="dv">5</span>, <span class="at">col =</span> <span class="st">&quot;black&quot;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_1__iris_plot-1.png" width="960" /></p>
<p>The observations are from 3 species and indeed those species tend to have different traits, meaning that the observations form 3 clusters.</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="introduction.html#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(traits, <span class="at">pch =</span> <span class="fu">as.integer</span>(species), <span class="at">col =</span> colors[<span class="fu">as.integer</span>(species)])</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_2-1.png" width="672" /></p>
<p>However, imagine we don’t know what species are, what is basically the situation in which people in the antique have been. The people just noted that some plants have different flowers than others, and decided to give them different names. This kind of process is what unsupervised learning does.</p>
<div id="hierarchical-clustering" class="section level3" number="3.1.1">
<h3><span class="header-section-number">3.1.1</span> Hierarchical Clustering</h3>
<p>A cluster refers to a collection of data points aggregated together because of certain similarities.</p>
<p>In hierarchical clustering, a hierarchy (tree) between data points is built.</p>
<ul>
<li>Agglomerative: Start with each data point in their own cluster, merge them up hierarchically.</li>
<li>Divisive: Start with all data points in one cluster, and split hierarchically.</li>
</ul>
<p>Merges / splits are done according to linkage criterion, which measures distance between (potential) clusters. Cut the tree at a certain height to get clusters.</p>
<p>Here an example</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="introduction.html#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb67-2"><a href="introduction.html#cb67-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-3"><a href="introduction.html#cb67-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Reminder: traits = as.matrix(iris[,1:4]).</span></span>
<span id="cb67-4"><a href="introduction.html#cb67-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-5"><a href="introduction.html#cb67-5" aria-hidden="true" tabindex="-1"></a>d <span class="ot">=</span> <span class="fu">dist</span>(traits)</span>
<span id="cb67-6"><a href="introduction.html#cb67-6" aria-hidden="true" tabindex="-1"></a>hc <span class="ot">=</span> <span class="fu">hclust</span>(d, <span class="at">method =</span> <span class="st">&quot;complete&quot;</span>)</span>
<span id="cb67-7"><a href="introduction.html#cb67-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-8"><a href="introduction.html#cb67-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(hc)</span>
<span id="cb67-9"><a href="introduction.html#cb67-9" aria-hidden="true" tabindex="-1"></a><span class="fu">rect.hclust</span>(hc, <span class="at">k =</span> <span class="dv">3</span>)  <span class="co"># Draw rectangles around the branches.</span></span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_3-1.png" width="672" /></p>
<p>Same plot, but with colors for true species identity</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="introduction.html#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ape)</span>
<span id="cb68-2"><a href="introduction.html#cb68-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-3"><a href="introduction.html#cb68-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">as.phylo</span>(hc), </span>
<span id="cb68-4"><a href="introduction.html#cb68-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">tip.color =</span> colors[<span class="fu">as.integer</span>(species)], </span>
<span id="cb68-5"><a href="introduction.html#cb68-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">direction =</span> <span class="st">&quot;downwards&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_4-1.png" width="672" /></p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="introduction.html#cb69-1" aria-hidden="true" tabindex="-1"></a>hcRes3 <span class="ot">=</span> <span class="fu">cutree</span>(hc, <span class="at">k =</span> <span class="dv">3</span>)   <span class="co">#Cut a dendrogram tree into groups.</span></span></code></pre></div>
<p>Calculate confusion matrix. Note we are switching labels here so that it fits to the species.</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="introduction.html#cb70-1" aria-hidden="true" tabindex="-1"></a>tmp <span class="ot">=</span> hcRes3</span>
<span id="cb70-2"><a href="introduction.html#cb70-2" aria-hidden="true" tabindex="-1"></a>tmp[hcRes3 <span class="sc">==</span> <span class="dv">2</span>] <span class="ot">=</span> <span class="dv">3</span></span>
<span id="cb70-3"><a href="introduction.html#cb70-3" aria-hidden="true" tabindex="-1"></a>tmp[hcRes3 <span class="sc">==</span> <span class="dv">3</span>] <span class="ot">=</span> <span class="dv">2</span></span>
<span id="cb70-4"><a href="introduction.html#cb70-4" aria-hidden="true" tabindex="-1"></a>hcRes3 <span class="ot">=</span> tmp</span>
<span id="cb70-5"><a href="introduction.html#cb70-5" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(hcRes3, species)</span></code></pre></div>
<pre><code>##       species
## hcRes3 setosa versicolor virginica
##      1     50          0         0
##      2      0         27         1
##      3      0         23        49</code></pre>
<p>Note that results might change if you choose a different agglomeration method, distance metric or scale of your variables. Compare, e.g. to this example:</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="introduction.html#cb72-1" aria-hidden="true" tabindex="-1"></a>hc <span class="ot">=</span> <span class="fu">hclust</span>(d, <span class="at">method =</span> <span class="st">&quot;ward.D2&quot;</span>)</span>
<span id="cb72-2"><a href="introduction.html#cb72-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-3"><a href="introduction.html#cb72-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">as.phylo</span>(hc), </span>
<span id="cb72-4"><a href="introduction.html#cb72-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">tip.color =</span> colors[<span class="fu">as.integer</span>(species)], </span>
<span id="cb72-5"><a href="introduction.html#cb72-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">direction =</span> <span class="st">&quot;downwards&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_6-1.png" width="672" /></p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="introduction.html#cb73-1" aria-hidden="true" tabindex="-1"></a>hcRes3 <span class="ot">=</span> <span class="fu">cutree</span>(hc, <span class="at">k =</span> <span class="dv">3</span>)   <span class="co">#Cut a dendrogram tree into groups.</span></span>
<span id="cb73-2"><a href="introduction.html#cb73-2" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(hcRes3, species)</span></code></pre></div>
<pre><code>##       species
## hcRes3 setosa versicolor virginica
##      1     50          0         0
##      2      0         49        15
##      3      0          1        35</code></pre>
<p>Which method is best?</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="introduction.html#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dendextend)</span></code></pre></div>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="introduction.html#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb76-2"><a href="introduction.html#cb76-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-3"><a href="introduction.html#cb76-3" aria-hidden="true" tabindex="-1"></a>methods <span class="ot">=</span> <span class="fu">c</span>(<span class="st">&quot;ward.D&quot;</span>, <span class="st">&quot;single&quot;</span>, <span class="st">&quot;complete&quot;</span>, <span class="st">&quot;average&quot;</span>,</span>
<span id="cb76-4"><a href="introduction.html#cb76-4" aria-hidden="true" tabindex="-1"></a>             <span class="st">&quot;mcquitty&quot;</span>, <span class="st">&quot;median&quot;</span>, <span class="st">&quot;centroid&quot;</span>, <span class="st">&quot;ward.D2&quot;</span>)</span>
<span id="cb76-5"><a href="introduction.html#cb76-5" aria-hidden="true" tabindex="-1"></a>out <span class="ot">=</span> <span class="fu">dendlist</span>()   <span class="co"># Create a dendlist object from several dendrograms.</span></span>
<span id="cb76-6"><a href="introduction.html#cb76-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(method <span class="cf">in</span> methods){</span>
<span id="cb76-7"><a href="introduction.html#cb76-7" aria-hidden="true" tabindex="-1"></a>  res <span class="ot">=</span> <span class="fu">hclust</span>(d, <span class="at">method =</span> method)   </span>
<span id="cb76-8"><a href="introduction.html#cb76-8" aria-hidden="true" tabindex="-1"></a>  out <span class="ot">=</span> <span class="fu">dendlist</span>(out, <span class="fu">as.dendrogram</span>(res))</span>
<span id="cb76-9"><a href="introduction.html#cb76-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb76-10"><a href="introduction.html#cb76-10" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(out) <span class="ot">=</span> methods</span>
<span id="cb76-11"><a href="introduction.html#cb76-11" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(out)</span></code></pre></div>
<pre><code>## $ward.D
## &#39;dendrogram&#39; with 2 branches and 150 members total, at height 200.0981 
## 
## $single
## &#39;dendrogram&#39; with 2 branches and 150 members total, at height 1.640122 
## 
## $complete
## &#39;dendrogram&#39; with 2 branches and 150 members total, at height 7.085196 
## 
## $average
## &#39;dendrogram&#39; with 2 branches and 150 members total, at height 4.069377 
## 
## $mcquitty
## &#39;dendrogram&#39; with 2 branches and 150 members total, at height 4.520039 
## 
## $median
## &#39;dendrogram&#39; with 2 branches and 150 members total, at height 2.883062 
## 
## $centroid
## &#39;dendrogram&#39; with 2 branches and 150 members total, at height 3.001472 
## 
## $ward.D2
## &#39;dendrogram&#39; with 2 branches and 150 members total, at height 32.50651 
## 
## attr(,&quot;class&quot;)
## [1] &quot;dendlist&quot;</code></pre>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="introduction.html#cb78-1" aria-hidden="true" tabindex="-1"></a>get_ordered_3_clusters <span class="ot">=</span> <span class="cf">function</span>(dend){</span>
<span id="cb78-2"><a href="introduction.html#cb78-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># order.dendrogram function returns the order (index)</span></span>
<span id="cb78-3"><a href="introduction.html#cb78-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># or the &quot;label&quot; attribute for the leaves.</span></span>
<span id="cb78-4"><a href="introduction.html#cb78-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># cutree: Cut the tree (dendrogram) into groups of data.</span></span>
<span id="cb78-5"><a href="introduction.html#cb78-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cutree</span>(dend, <span class="at">k =</span> <span class="dv">3</span>)[<span class="fu">order.dendrogram</span>(dend)]</span>
<span id="cb78-6"><a href="introduction.html#cb78-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb78-7"><a href="introduction.html#cb78-7" aria-hidden="true" tabindex="-1"></a>dend_3_clusters <span class="ot">=</span> <span class="fu">lapply</span>(out, get_ordered_3_clusters)</span>
<span id="cb78-8"><a href="introduction.html#cb78-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-9"><a href="introduction.html#cb78-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate Fowlkes-Mallows Index (determine the similarity between clusterings)</span></span>
<span id="cb78-10"><a href="introduction.html#cb78-10" aria-hidden="true" tabindex="-1"></a>compare_clusters_to_iris <span class="ot">=</span> <span class="cf">function</span>(clus){</span>
<span id="cb78-11"><a href="introduction.html#cb78-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">FM_index</span>(clus, <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="at">each =</span> <span class="dv">50</span>), <span class="at">assume_sorted_vectors =</span> <span class="cn">TRUE</span>)</span>
<span id="cb78-12"><a href="introduction.html#cb78-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb78-13"><a href="introduction.html#cb78-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-14"><a href="introduction.html#cb78-14" aria-hidden="true" tabindex="-1"></a>clusters_performance <span class="ot">=</span> <span class="fu">sapply</span>(dend_3_clusters, compare_clusters_to_iris)</span>
<span id="cb78-15"><a href="introduction.html#cb78-15" aria-hidden="true" tabindex="-1"></a><span class="fu">dotchart</span>(<span class="fu">sort</span>(clusters_performance), <span class="at">xlim =</span> <span class="fu">c</span>(<span class="fl">0.3</span>, <span class="dv">1</span>),</span>
<span id="cb78-16"><a href="introduction.html#cb78-16" aria-hidden="true" tabindex="-1"></a>         <span class="at">xlab =</span> <span class="st">&quot;Fowlkes-Mallows index&quot;</span>,</span>
<span id="cb78-17"><a href="introduction.html#cb78-17" aria-hidden="true" tabindex="-1"></a>         <span class="at">main =</span> <span class="st">&quot;Performance of linkage methods</span></span>
<span id="cb78-18"><a href="introduction.html#cb78-18" aria-hidden="true" tabindex="-1"></a><span class="st">         in detecting the 3 species </span><span class="sc">\n</span><span class="st"> in our example&quot;</span>,</span>
<span id="cb78-19"><a href="introduction.html#cb78-19" aria-hidden="true" tabindex="-1"></a>         <span class="at">pch =</span> <span class="dv">19</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_8-1.png" width="672" /></p>
<p>We might conclude that ward.D2 works best here. However, as we will learn later, optimizing the method without a hold-out for testing implies that our model may be overfitting. We should check this using cross-validation.</p>
</div>
<div id="k-means-clustering" class="section level3" number="3.1.2">
<h3><span class="header-section-number">3.1.2</span> K-means Clustering</h3>
<p>Another example for an unsupervised learning algorithm is k-means clustering, one of the simplest and most popular unsupervised machine learning algorithms.</p>
<p>To start with the algorithm, you first have to specify the number of clusters (for our example the number of species). Each cluster has a centroid, which is the assumed or real location representing the center of the cluster (for our example this would be how an average plant of a specific species would look like). The algorithm starts by randomly putting centroids somewhere. Afterwards each data point is assigned to the respective cluster that raises the overall in-cluster sum of squares (variance) related to the distance to the centroid least of all. After the algorithm has placed all data points into a cluster the centroids get updated. By iterating this procedure until the assignment doesn’t change any longer, the algorithm can find the (locally) optimal centroids and the data points belonging to this cluster.
Note that results might differ according to the initial positions of the centroids. Thus several (locally) optimal solutions might be found.</p>
<p>The “k” in K-means refers to the number of clusters and the ‘means’ refers to averaging the data-points to find the centroids.</p>
<p>A typical pipeline for using k-means clustering looks the same as for other algorithms. After having visualized the data, we fit a model, visualize the results and have a look at the performance by use of the confusion matrix. By setting a fixed seed, we can ensure that results are reproducible.</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="introduction.html#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb79-2"><a href="introduction.html#cb79-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-3"><a href="introduction.html#cb79-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Reminder: traits = as.matrix(iris[,1:4]).</span></span>
<span id="cb79-4"><a href="introduction.html#cb79-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-5"><a href="introduction.html#cb79-5" aria-hidden="true" tabindex="-1"></a>kc <span class="ot">=</span> <span class="fu">kmeans</span>(traits, <span class="dv">3</span>)</span>
<span id="cb79-6"><a href="introduction.html#cb79-6" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(kc)</span></code></pre></div>
<pre><code>## K-means clustering with 3 clusters of sizes 50, 62, 38
## 
## Cluster means:
##   Sepal.Length Sepal.Width Petal.Length Petal.Width
## 1     5.006000    3.428000     1.462000    0.246000
## 2     5.901613    2.748387     4.393548    1.433871
## 3     6.850000    3.073684     5.742105    2.071053
## 
## Clustering vector:
##   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 3 2 2 2 2 2 2 2
##  [61] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 3 3 3 3 2 3 3 3 3 3 3 2 2 3 3 3 3 2
## [121] 3 2 3 2 3 3 2 2 3 3 3 3 3 2 3 3 3 3 2 3 3 3 2 3 3 3 2 3 3 2
## 
## Within cluster sum of squares by cluster:
## [1] 15.15100 39.82097 23.87947
##  (between_SS / total_SS =  88.4 %)
## 
## Available components:
## 
## [1] &quot;cluster&quot;      &quot;centers&quot;      &quot;totss&quot;        &quot;withinss&quot;     &quot;tot.withinss&quot; &quot;betweenss&quot;    &quot;size&quot;         &quot;iter&quot;        
## [9] &quot;ifault&quot;</code></pre>
<p><em>Visualizing the results.</em>
Color codes true species identity, symbol shows cluster result.</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="introduction.html#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(iris[<span class="fu">c</span>(<span class="st">&quot;Sepal.Length&quot;</span>, <span class="st">&quot;Sepal.Width&quot;</span>)],</span>
<span id="cb81-2"><a href="introduction.html#cb81-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span>  colors[<span class="fu">as.integer</span>(species)], <span class="at">pch =</span> kc<span class="sc">$</span>cluster)</span>
<span id="cb81-3"><a href="introduction.html#cb81-3" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(kc<span class="sc">$</span>centers[, <span class="fu">c</span>(<span class="st">&quot;Sepal.Length&quot;</span>, <span class="st">&quot;Sepal.Width&quot;</span>)],</span>
<span id="cb81-4"><a href="introduction.html#cb81-4" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> colors, <span class="at">pch =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="at">cex =</span> <span class="dv">3</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_10-1.png" width="672" /></p>
<p>We see that there are are some discrepancies. Confusion matrix:</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="introduction.html#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(iris<span class="sc">$</span>Species, kc<span class="sc">$</span>cluster)</span></code></pre></div>
<pre><code>##             
##               1  2  3
##   setosa     50  0  0
##   versicolor  0 48  2
##   virginica   0 14 36</code></pre>
<p>If you want to animate the clustering process, you could run</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="introduction.html#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(animation)</span>
<span id="cb84-2"><a href="introduction.html#cb84-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-3"><a href="introduction.html#cb84-3" aria-hidden="true" tabindex="-1"></a><span class="fu">saveGIF</span>(<span class="fu">kmeans.ani</span>(<span class="at">x =</span> traits[,<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>], <span class="at">col =</span> colors),</span>
<span id="cb84-4"><a href="introduction.html#cb84-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">interval =</span> <span class="dv">1</span>, <span class="at">ani.width =</span> <span class="dv">800</span>, <span class="at">ani.height =</span> <span class="dv">800</span>)</span></code></pre></div>
<p><strong>Elbow technique</strong> to determine the probably best suited number of clusters:</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="introduction.html#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb85-2"><a href="introduction.html#cb85-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-3"><a href="introduction.html#cb85-3" aria-hidden="true" tabindex="-1"></a>getSumSq <span class="ot">=</span> <span class="cf">function</span>(k){ <span class="fu">kmeans</span>(traits, k, <span class="at">nstart =</span> <span class="dv">25</span>)<span class="sc">$</span>tot.withinss }</span>
<span id="cb85-4"><a href="introduction.html#cb85-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-5"><a href="introduction.html#cb85-5" aria-hidden="true" tabindex="-1"></a><span class="co">#Perform algorithm for different cluster sizes and retrieve variance.</span></span>
<span id="cb85-6"><a href="introduction.html#cb85-6" aria-hidden="true" tabindex="-1"></a>iris.kmeans1to10 <span class="ot">=</span> <span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>, getSumSq)</span>
<span id="cb85-7"><a href="introduction.html#cb85-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>, iris.kmeans1to10, <span class="at">type =</span> <span class="st">&quot;b&quot;</span>, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">frame =</span> <span class="cn">FALSE</span>, </span>
<span id="cb85-8"><a href="introduction.html#cb85-8" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Number of clusters K&quot;</span>,</span>
<span id="cb85-9"><a href="introduction.html#cb85-9" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;Total within-clusters sum of squares&quot;</span>,</span>
<span id="cb85-10"><a href="introduction.html#cb85-10" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;black&quot;</span>, <span class="st">&quot;red&quot;</span>, <span class="fu">rep</span>(<span class="st">&quot;black&quot;</span>, <span class="dv">8</span>)))</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_13-1.png" width="672" /></p>
<p>Often, one is interested in sparse models. Furthermore, higher k than necessary tends to overfitting. At the kink in the picture, the sum of squares dropped enough and k is still low enough.
But keep in mind, this is only a rule of thumb and might be wrong in some special cases.</p>
</div>
<div id="density-based-clustering" class="section level3" number="3.1.3">
<h3><span class="header-section-number">3.1.3</span> Density-based Clustering</h3>
<p>Determine the affinity of a data point according to the affinity of its k nearest neighbors.
This is a very general description as there are many ways to do so.</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="introduction.html#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Reminder: traits = as.matrix(iris[,1:4]).</span></span>
<span id="cb86-2"><a href="introduction.html#cb86-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-3"><a href="introduction.html#cb86-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dbscan)</span>
<span id="cb86-4"><a href="introduction.html#cb86-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb86-5"><a href="introduction.html#cb86-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-6"><a href="introduction.html#cb86-6" aria-hidden="true" tabindex="-1"></a><span class="fu">kNNdistplot</span>(traits, <span class="at">k =</span> <span class="dv">4</span>)   <span class="co"># Calculate and plot k-nearest-neighbor distances.</span></span>
<span id="cb86-7"><a href="introduction.html#cb86-7" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="fl">0.4</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_14-1.png" width="672" /></p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="introduction.html#cb87-1" aria-hidden="true" tabindex="-1"></a>dc <span class="ot">=</span> <span class="fu">dbscan</span>(traits, <span class="at">eps =</span> <span class="fl">0.4</span>, <span class="at">minPts =</span> <span class="dv">6</span>)</span>
<span id="cb87-2"><a href="introduction.html#cb87-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(dc)</span></code></pre></div>
<pre><code>## DBSCAN clustering for 150 objects.
## Parameters: eps = 0.4, minPts = 6
## The clustering contains 4 cluster(s) and 32 noise points.
## 
##  0  1  2  3  4 
## 32 46 36 14 22 
## 
## Available fields: cluster, eps, minPts</code></pre>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="introduction.html#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(factoextra)</span></code></pre></div>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="introduction.html#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_cluster</span>(dc, traits, <span class="at">geom =</span> <span class="st">&quot;point&quot;</span>, <span class="at">ggtheme =</span> <span class="fu">theme_light</span>())</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_16-1.png" width="672" /></p>
</div>
<div id="model-based-clustering" class="section level3" number="3.1.4">
<h3><span class="header-section-number">3.1.4</span> Model-based Clustering</h3>
<p>The last class of methods for unsupervised clustering are so-called <em>model-based clustering methods</em>.</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="introduction.html#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mclust)</span></code></pre></div>
<pre><code>##     __  ___________    __  _____________
##    /  |/  / ____/ /   / / / / ___/_  __/
##   / /|_/ / /   / /   / / / /\__ \ / /   
##  / /  / / /___/ /___/ /_/ /___/ // /    
## /_/  /_/\____/_____/\____//____//_/    version 5.4.8
## Type &#39;citation(&quot;mclust&quot;)&#39; for citing this R package in publications.</code></pre>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="introduction.html#cb93-1" aria-hidden="true" tabindex="-1"></a>mb <span class="ot">=</span> <span class="fu">Mclust</span>(traits)</span></code></pre></div>
<p>Mclust automatically compares a number of candidate models (clusters, shape) according to BIC (The BIC is a criterion for classifying algorithms depending their prediction quality and their usage of parameters). We can look at the selected model via:</p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="introduction.html#cb94-1" aria-hidden="true" tabindex="-1"></a>mb<span class="sc">$</span>G <span class="co"># Two clusters.</span></span></code></pre></div>
<pre><code>## [1] 2</code></pre>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="introduction.html#cb96-1" aria-hidden="true" tabindex="-1"></a>mb<span class="sc">$</span>modelName <span class="co"># &gt; Ellipsoidal, equal shape.</span></span></code></pre></div>
<pre><code>## [1] &quot;VEV&quot;</code></pre>
<p>We see that the algorithm prefers having 2 clusters. For better comparability to the other 2 methods, we will override this by setting:</p>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="introduction.html#cb98-1" aria-hidden="true" tabindex="-1"></a>mb3 <span class="ot">=</span> <span class="fu">Mclust</span>(traits, <span class="dv">3</span>)</span></code></pre></div>
<pre><code>## fitting ...
## 
  |                                                                                                                          
  |                                                                                                                    |   0%
  |                                                                                                                          
  |========                                                                                                            |   7%
  |                                                                                                                          
  |===============                                                                                                     |  13%
  |                                                                                                                          
  |=======================                                                                                             |  20%
  |                                                                                                                          
  |===============================                                                                                     |  27%
  |                                                                                                                          
  |=======================================                                                                             |  33%
  |                                                                                                                          
  |==============================================                                                                      |  40%
  |                                                                                                                          
  |======================================================                                                              |  47%
  |                                                                                                                          
  |==============================================================                                                      |  53%
  |                                                                                                                          
  |======================================================================                                              |  60%
  |                                                                                                                          
  |=============================================================================                                       |  67%
  |                                                                                                                          
  |=====================================================================================                               |  73%
  |                                                                                                                          
  |=============================================================================================                       |  80%
  |                                                                                                                          
  |=====================================================================================================               |  87%
  |                                                                                                                          
  |============================================================================================================        |  93%
  |                                                                                                                          
  |====================================================================================================================| 100%</code></pre>
<p>Result in terms of the predicted densities for 3 clusters</p>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="introduction.html#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mb3, <span class="st">&quot;density&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_21-1.png" width="672" /></p>
<p>Predicted clusters:</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="introduction.html#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mb3, <span class="at">what=</span><span class="fu">c</span>(<span class="st">&quot;classification&quot;</span>), <span class="at">add =</span> T)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_22-1.png" width="672" /></p>
<p>Confusion matrix:</p>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="introduction.html#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(iris<span class="sc">$</span>Species, mb3<span class="sc">$</span>classification)</span></code></pre></div>
<pre><code>##             
##               1  2  3
##   setosa     50  0  0
##   versicolor  0 45  5
##   virginica   0  0 50</code></pre>
</div>
<div id="ordination" class="section level3" number="3.1.5">
<h3><span class="header-section-number">3.1.5</span> Ordination</h3>
<p>Ordination is used in explorative analysis and compared to clustering, similar objects are ordered together.
So there is a relationship between clustering and ordination. Here a PCA ordination on on the iris data set.</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="introduction.html#cb104-1" aria-hidden="true" tabindex="-1"></a>pcTraits <span class="ot">=</span> <span class="fu">prcomp</span>(traits, <span class="at">center =</span> <span class="cn">TRUE</span>, <span class="at">scale. =</span> <span class="cn">TRUE</span>)</span>
<span id="cb104-2"><a href="introduction.html#cb104-2" aria-hidden="true" tabindex="-1"></a><span class="fu">biplot</span>(pcTraits, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.25</span>, <span class="fl">0.25</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.25</span>, <span class="fl">0.25</span>))</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_24-1.png" width="672" /></p>
<p>You can cluster the results of this ordination, ordinate before clustering, or superimpose one on the other.</p>
  <hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Tasks</span></strong><br/>
<p>Go through the 4(5) algorithms above, and check if they are sensitive (i.e. if results change) if you scale the input features (= predictors), instead of using the raw data. Discuss in your group: Which is more appropriate for this analysis and/or in general: Scaling or not scaling?</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
  <strong><span style="font-size:20px;">Hierarchical Clustering</span></strong>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb105-1"><a href="introduction.html#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dendextend)</span>
<span id="cb105-2"><a href="introduction.html#cb105-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-3"><a href="introduction.html#cb105-3" aria-hidden="true" tabindex="-1"></a>methods <span class="ot">=</span> <span class="fu">c</span>(<span class="st">&quot;ward.D&quot;</span>, <span class="st">&quot;single&quot;</span>, <span class="st">&quot;complete&quot;</span>, <span class="st">&quot;average&quot;</span>,</span>
<span id="cb105-4"><a href="introduction.html#cb105-4" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;mcquitty&quot;</span>, <span class="st">&quot;median&quot;</span>, <span class="st">&quot;centroid&quot;</span>, <span class="st">&quot;ward.D2&quot;</span>)</span>
<span id="cb105-5"><a href="introduction.html#cb105-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-6"><a href="introduction.html#cb105-6" aria-hidden="true" tabindex="-1"></a>cluster_all_methods <span class="ot">=</span> <span class="cf">function</span>(distances){</span>
<span id="cb105-7"><a href="introduction.html#cb105-7" aria-hidden="true" tabindex="-1"></a>  out <span class="ot">=</span> <span class="fu">dendlist</span>()</span>
<span id="cb105-8"><a href="introduction.html#cb105-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(method <span class="cf">in</span> methods){</span>
<span id="cb105-9"><a href="introduction.html#cb105-9" aria-hidden="true" tabindex="-1"></a>    res <span class="ot">=</span> <span class="fu">hclust</span>(distances, <span class="at">method =</span> method)   </span>
<span id="cb105-10"><a href="introduction.html#cb105-10" aria-hidden="true" tabindex="-1"></a>    out <span class="ot">=</span> <span class="fu">dendlist</span>(out, <span class="fu">as.dendrogram</span>(res))</span>
<span id="cb105-11"><a href="introduction.html#cb105-11" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb105-12"><a href="introduction.html#cb105-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">names</span>(out) <span class="ot">=</span> methods</span>
<span id="cb105-13"><a href="introduction.html#cb105-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb105-14"><a href="introduction.html#cb105-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(out)</span>
<span id="cb105-15"><a href="introduction.html#cb105-15" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb105-16"><a href="introduction.html#cb105-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-17"><a href="introduction.html#cb105-17" aria-hidden="true" tabindex="-1"></a>get_ordered_3_clusters <span class="ot">=</span> <span class="cf">function</span>(dend){</span>
<span id="cb105-18"><a href="introduction.html#cb105-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">cutree</span>(dend, <span class="at">k =</span> <span class="dv">3</span>)[<span class="fu">order.dendrogram</span>(dend)])</span>
<span id="cb105-19"><a href="introduction.html#cb105-19" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb105-20"><a href="introduction.html#cb105-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-21"><a href="introduction.html#cb105-21" aria-hidden="true" tabindex="-1"></a>compare_clusters_to_iris <span class="ot">=</span> <span class="cf">function</span>(clus){</span>
<span id="cb105-22"><a href="introduction.html#cb105-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">FM_index</span>(clus, <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="at">each =</span> <span class="dv">50</span>), <span class="at">assume_sorted_vectors =</span> <span class="cn">TRUE</span>))</span>
<span id="cb105-23"><a href="introduction.html#cb105-23" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb105-24"><a href="introduction.html#cb105-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-25"><a href="introduction.html#cb105-25" aria-hidden="true" tabindex="-1"></a>do_clustering <span class="ot">=</span> <span class="cf">function</span>(traits, <span class="at">scale =</span> <span class="cn">FALSE</span>){</span>
<span id="cb105-26"><a href="introduction.html#cb105-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb105-27"><a href="introduction.html#cb105-27" aria-hidden="true" tabindex="-1"></a>  headline <span class="ot">=</span> <span class="st">&quot;Performance of linkage methods</span><span class="sc">\n</span><span class="st">in detecting the 3 species</span><span class="sc">\n</span><span class="st">&quot;</span></span>
<span id="cb105-28"><a href="introduction.html#cb105-28" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb105-29"><a href="introduction.html#cb105-29" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(scale){</span>
<span id="cb105-30"><a href="introduction.html#cb105-30" aria-hidden="true" tabindex="-1"></a>    traits <span class="ot">=</span> <span class="fu">scale</span>(traits)  <span class="co"># Do scaling on copy of traits.</span></span>
<span id="cb105-31"><a href="introduction.html#cb105-31" aria-hidden="true" tabindex="-1"></a>    headline <span class="ot">=</span> <span class="fu">paste0</span>(headline, <span class="st">&quot;Scaled&quot;</span>)</span>
<span id="cb105-32"><a href="introduction.html#cb105-32" aria-hidden="true" tabindex="-1"></a>  }<span class="cf">else</span>{ headline <span class="ot">=</span> <span class="fu">paste0</span>(headline, <span class="st">&quot;Not scaled&quot;</span>) }</span>
<span id="cb105-33"><a href="introduction.html#cb105-33" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb105-34"><a href="introduction.html#cb105-34" aria-hidden="true" tabindex="-1"></a>  distances <span class="ot">=</span> <span class="fu">dist</span>(traits)</span>
<span id="cb105-35"><a href="introduction.html#cb105-35" aria-hidden="true" tabindex="-1"></a>  out <span class="ot">=</span> <span class="fu">cluster_all_methods</span>(distances)</span>
<span id="cb105-36"><a href="introduction.html#cb105-36" aria-hidden="true" tabindex="-1"></a>  dend_3_clusters <span class="ot">=</span> <span class="fu">lapply</span>(out, get_ordered_3_clusters)</span>
<span id="cb105-37"><a href="introduction.html#cb105-37" aria-hidden="true" tabindex="-1"></a>  clusters_performance <span class="ot">=</span> <span class="fu">sapply</span>(dend_3_clusters, compare_clusters_to_iris)</span>
<span id="cb105-38"><a href="introduction.html#cb105-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dotchart</span>(<span class="fu">sort</span>(clusters_performance), <span class="at">xlim =</span> <span class="fu">c</span>(<span class="fl">0.3</span>,<span class="dv">1</span>),</span>
<span id="cb105-39"><a href="introduction.html#cb105-39" aria-hidden="true" tabindex="-1"></a>           <span class="at">xlab =</span> <span class="st">&quot;Fowlkes-Mallows index&quot;</span>,</span>
<span id="cb105-40"><a href="introduction.html#cb105-40" aria-hidden="true" tabindex="-1"></a>           <span class="at">main =</span> headline,</span>
<span id="cb105-41"><a href="introduction.html#cb105-41" aria-hidden="true" tabindex="-1"></a>           <span class="at">pch =</span> <span class="dv">19</span>)</span>
<span id="cb105-42"><a href="introduction.html#cb105-42" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb105-43"><a href="introduction.html#cb105-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-44"><a href="introduction.html#cb105-44" aria-hidden="true" tabindex="-1"></a>traits <span class="ot">=</span> <span class="fu">as.matrix</span>(iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span>
<span id="cb105-45"><a href="introduction.html#cb105-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-46"><a href="introduction.html#cb105-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Do clustering on unscaled data.</span></span>
<span id="cb105-47"><a href="introduction.html#cb105-47" aria-hidden="true" tabindex="-1"></a><span class="fu">do_clustering</span>(traits, <span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_task_0-1.png" width="672" /></p>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="introduction.html#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Do clustering on scaled data.</span></span>
<span id="cb106-2"><a href="introduction.html#cb106-2" aria-hidden="true" tabindex="-1"></a><span class="fu">do_clustering</span>(traits, <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_task_0-2.png" width="672" /></p>
<p>It seems that scaling is harmful for hierarchical clustering. But this might be a deception.
<strong>Be careful:</strong> If you have data on different units or magnitudes, scaling is definitely useful! Otherwise variables with higher values get higher influence.</p>
  <strong><span style="font-size:20px;">K-means Clustering</span></strong>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="introduction.html#cb107-1" aria-hidden="true" tabindex="-1"></a>do_clustering <span class="ot">=</span> <span class="cf">function</span>(traits, <span class="at">scale =</span> <span class="cn">FALSE</span>){</span>
<span id="cb107-2"><a href="introduction.html#cb107-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb107-3"><a href="introduction.html#cb107-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb107-4"><a href="introduction.html#cb107-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(scale){</span>
<span id="cb107-5"><a href="introduction.html#cb107-5" aria-hidden="true" tabindex="-1"></a>    traits <span class="ot">=</span> <span class="fu">scale</span>(traits)  <span class="co"># Do scaling on copy of traits.</span></span>
<span id="cb107-6"><a href="introduction.html#cb107-6" aria-hidden="true" tabindex="-1"></a>    headline <span class="ot">=</span> <span class="st">&quot;K-means Clustering</span><span class="sc">\n</span><span class="st">Scaled</span><span class="sc">\n</span><span class="st">Sum of all tries: &quot;</span></span>
<span id="cb107-7"><a href="introduction.html#cb107-7" aria-hidden="true" tabindex="-1"></a>  }<span class="cf">else</span>{ headline <span class="ot">=</span> <span class="st">&quot;K-means Clustering</span><span class="sc">\n</span><span class="st">Not scaled</span><span class="sc">\n</span><span class="st">Sum of all tries: &quot;</span> }</span>
<span id="cb107-8"><a href="introduction.html#cb107-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb107-9"><a href="introduction.html#cb107-9" aria-hidden="true" tabindex="-1"></a>  getSumSq <span class="ot">=</span> <span class="cf">function</span>(k){ <span class="fu">kmeans</span>(traits, k, <span class="at">nstart =</span> <span class="dv">25</span>)<span class="sc">$</span>tot.withinss }</span>
<span id="cb107-10"><a href="introduction.html#cb107-10" aria-hidden="true" tabindex="-1"></a>  iris.kmeans1to10 <span class="ot">=</span> <span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>, getSumSq)</span>
<span id="cb107-11"><a href="introduction.html#cb107-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb107-12"><a href="introduction.html#cb107-12" aria-hidden="true" tabindex="-1"></a>  headline <span class="ot">=</span> <span class="fu">paste0</span>(headline, <span class="fu">round</span>(<span class="fu">sum</span>(iris.kmeans1to10), <span class="dv">2</span>))</span>
<span id="cb107-13"><a href="introduction.html#cb107-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb107-14"><a href="introduction.html#cb107-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>, iris.kmeans1to10, <span class="at">type =</span> <span class="st">&quot;b&quot;</span>, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">frame =</span> <span class="cn">FALSE</span>,</span>
<span id="cb107-15"><a href="introduction.html#cb107-15" aria-hidden="true" tabindex="-1"></a>       <span class="at">main =</span> headline,</span>
<span id="cb107-16"><a href="introduction.html#cb107-16" aria-hidden="true" tabindex="-1"></a>       <span class="at">xlab =</span> <span class="st">&quot;Number of clusters K&quot;</span>,</span>
<span id="cb107-17"><a href="introduction.html#cb107-17" aria-hidden="true" tabindex="-1"></a>       <span class="at">ylab =</span> <span class="st">&quot;Total within-clusters sum of squares&quot;</span>,</span>
<span id="cb107-18"><a href="introduction.html#cb107-18" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;black&quot;</span>, <span class="st">&quot;red&quot;</span>, <span class="fu">rep</span>(<span class="st">&quot;black&quot;</span>, <span class="dv">8</span>)) )</span>
<span id="cb107-19"><a href="introduction.html#cb107-19" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb107-20"><a href="introduction.html#cb107-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-21"><a href="introduction.html#cb107-21" aria-hidden="true" tabindex="-1"></a>traits <span class="ot">=</span> <span class="fu">as.matrix</span>(iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span>
<span id="cb107-22"><a href="introduction.html#cb107-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-23"><a href="introduction.html#cb107-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Do clustering on unscaled data.</span></span>
<span id="cb107-24"><a href="introduction.html#cb107-24" aria-hidden="true" tabindex="-1"></a><span class="fu">do_clustering</span>(traits, <span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_task_1-1.png" width="672" /></p>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="introduction.html#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Do clustering on scaled data.</span></span>
<span id="cb108-2"><a href="introduction.html#cb108-2" aria-hidden="true" tabindex="-1"></a><span class="fu">do_clustering</span>(traits, <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_task_1-2.png" width="672" /></p>
<p>It seems that scaling is harmful for K-means clustering. But this might be a deception.
<strong><em>Be careful:</em></strong> If you have data on different units or magnitudes, scaling is definitely useful! Otherwise variables with higher values get higher influence.</p>
  <strong><span style="font-size:20px;">Density-based Clustering</span></strong>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb109-1"><a href="introduction.html#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dbscan)</span>
<span id="cb109-2"><a href="introduction.html#cb109-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-3"><a href="introduction.html#cb109-3" aria-hidden="true" tabindex="-1"></a>correct <span class="ot">=</span> <span class="fu">as.factor</span>(iris[,<span class="dv">5</span>])</span>
<span id="cb109-4"><a href="introduction.html#cb109-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Start at 1. Noise points will get 0 later.</span></span>
<span id="cb109-5"><a href="introduction.html#cb109-5" aria-hidden="true" tabindex="-1"></a><span class="fu">levels</span>(correct) <span class="ot">=</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(<span class="fu">levels</span>(correct))</span>
<span id="cb109-6"><a href="introduction.html#cb109-6" aria-hidden="true" tabindex="-1"></a>correct</span></code></pre></div>
<pre><code>##   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2
##  [61] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
## [121] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
## Levels: 1 2 3</code></pre>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="introduction.html#cb111-1" aria-hidden="true" tabindex="-1"></a>do_clustering <span class="ot">=</span> <span class="cf">function</span>(traits, <span class="at">scale =</span> <span class="cn">FALSE</span>){</span>
<span id="cb111-2"><a href="introduction.html#cb111-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb111-3"><a href="introduction.html#cb111-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb111-4"><a href="introduction.html#cb111-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(scale){ traits <span class="ot">=</span> <span class="fu">scale</span>(traits) } <span class="co"># Do scaling on copy of traits.</span></span>
<span id="cb111-5"><a href="introduction.html#cb111-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb111-6"><a href="introduction.html#cb111-6" aria-hidden="true" tabindex="-1"></a>  <span class="do">#####</span></span>
<span id="cb111-7"><a href="introduction.html#cb111-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Play around with the parameters &quot;eps&quot; and &quot;minPts&quot; on your own!</span></span>
<span id="cb111-8"><a href="introduction.html#cb111-8" aria-hidden="true" tabindex="-1"></a>  <span class="do">#####</span></span>
<span id="cb111-9"><a href="introduction.html#cb111-9" aria-hidden="true" tabindex="-1"></a>  dc <span class="ot">=</span> <span class="fu">dbscan</span>(traits, <span class="at">eps =</span> <span class="fl">0.41</span>, <span class="at">minPts =</span> <span class="dv">4</span>)</span>
<span id="cb111-10"><a href="introduction.html#cb111-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb111-11"><a href="introduction.html#cb111-11" aria-hidden="true" tabindex="-1"></a>  labels <span class="ot">=</span> <span class="fu">as.factor</span>(dc<span class="sc">$</span>cluster)</span>
<span id="cb111-12"><a href="introduction.html#cb111-12" aria-hidden="true" tabindex="-1"></a>  noise <span class="ot">=</span> <span class="fu">sum</span>(dc<span class="sc">$</span>cluster <span class="sc">==</span> <span class="dv">0</span>)</span>
<span id="cb111-13"><a href="introduction.html#cb111-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">levels</span>(labels) <span class="ot">=</span> <span class="fu">c</span>(<span class="st">&quot;noise&quot;</span>, <span class="dv">1</span><span class="sc">:</span>( <span class="fu">length</span>(<span class="fu">levels</span>(labels)) <span class="sc">-</span> <span class="dv">1</span>))</span>
<span id="cb111-14"><a href="introduction.html#cb111-14" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb111-15"><a href="introduction.html#cb111-15" aria-hidden="true" tabindex="-1"></a>  tbl <span class="ot">=</span> <span class="fu">table</span>(correct, labels)</span>
<span id="cb111-16"><a href="introduction.html#cb111-16" aria-hidden="true" tabindex="-1"></a>  correct_classified <span class="ot">=</span> <span class="dv">0</span></span>
<span id="cb111-17"><a href="introduction.html#cb111-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(<span class="fu">levels</span>(correct))){</span>
<span id="cb111-18"><a href="introduction.html#cb111-18" aria-hidden="true" tabindex="-1"></a>    correct_classified <span class="ot">=</span> correct_classified <span class="sc">+</span> tbl[i, i <span class="sc">+</span> <span class="dv">1</span>]</span>
<span id="cb111-19"><a href="introduction.html#cb111-19" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb111-20"><a href="introduction.html#cb111-20" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb111-21"><a href="introduction.html#cb111-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>( <span class="cf">if</span>(scale){ <span class="st">&quot;Scaled&quot;</span> }<span class="cf">else</span>{ <span class="st">&quot;Not scaled&quot;</span> }, <span class="st">&quot;</span><span class="sc">\n\n</span><span class="st">&quot;</span> )</span>
<span id="cb111-22"><a href="introduction.html#cb111-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">&quot;Confusion matrix:</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb111-23"><a href="introduction.html#cb111-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(tbl)</span>
<span id="cb111-24"><a href="introduction.html#cb111-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">&quot;</span><span class="sc">\n</span><span class="st">Correct classified points: &quot;</span>, correct_classified, <span class="st">&quot; / &quot;</span>, <span class="fu">length</span>(iris[,<span class="dv">5</span>]))</span>
<span id="cb111-25"><a href="introduction.html#cb111-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">&quot;</span><span class="sc">\n</span><span class="st">Sum of noise points: &quot;</span>, noise, <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb111-26"><a href="introduction.html#cb111-26" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb111-27"><a href="introduction.html#cb111-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-28"><a href="introduction.html#cb111-28" aria-hidden="true" tabindex="-1"></a>traits <span class="ot">=</span> <span class="fu">as.matrix</span>(iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span>
<span id="cb111-29"><a href="introduction.html#cb111-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-30"><a href="introduction.html#cb111-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Do clustering on unscaled data.</span></span>
<span id="cb111-31"><a href="introduction.html#cb111-31" aria-hidden="true" tabindex="-1"></a><span class="fu">do_clustering</span>(traits, <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## Not scaled 
## 
## Confusion matrix:
##        labels
## correct noise  1  2  3  4
##       1     3 47  0  0  0
##       2     5  0 38  3  4
##       3    17  0  0 33  0
## 
## Correct classified points:  118  /  150
## Sum of noise points:  25</code></pre>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="introduction.html#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Do clustering on scaled data.</span></span>
<span id="cb113-2"><a href="introduction.html#cb113-2" aria-hidden="true" tabindex="-1"></a><span class="fu">do_clustering</span>(traits, <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## Scaled 
## 
## Confusion matrix:
##        labels
## correct noise  1  2  3  4
##       1     9 41  0  0  0
##       2    14  0 36  0  0
##       3    36  0  1  4  9
## 
## Correct classified points:  81  /  150
## Sum of noise points:  59</code></pre>
<p>It seems that scaling is harmful for density based clustering. But this might be a deception.
<strong><em>Be careful:</em></strong> If you have data on different units or magnitudes, scaling is definitely useful! Otherwise variables with higher values get higher influence.</p>
  <strong><span style="font-size:20px;">Model-based Clustering</span></strong>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="introduction.html#cb115-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mclust)</span>
<span id="cb115-2"><a href="introduction.html#cb115-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-3"><a href="introduction.html#cb115-3" aria-hidden="true" tabindex="-1"></a>do_clustering <span class="ot">=</span> <span class="cf">function</span>(traits, <span class="at">scale =</span> <span class="cn">FALSE</span>){</span>
<span id="cb115-4"><a href="introduction.html#cb115-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb115-5"><a href="introduction.html#cb115-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb115-6"><a href="introduction.html#cb115-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(scale){ traits <span class="ot">=</span> <span class="fu">scale</span>(traits) } <span class="co"># Do scaling on copy of traits.</span></span>
<span id="cb115-7"><a href="introduction.html#cb115-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb115-8"><a href="introduction.html#cb115-8" aria-hidden="true" tabindex="-1"></a>  mb3 <span class="ot">=</span> <span class="fu">Mclust</span>(traits, <span class="dv">3</span>)</span>
<span id="cb115-9"><a href="introduction.html#cb115-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb115-10"><a href="introduction.html#cb115-10" aria-hidden="true" tabindex="-1"></a>  tbl <span class="ot">=</span> <span class="fu">table</span>(iris<span class="sc">$</span>Species, mb3<span class="sc">$</span>classification)</span>
<span id="cb115-11"><a href="introduction.html#cb115-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb115-12"><a href="introduction.html#cb115-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>( <span class="cf">if</span>(scale){ <span class="st">&quot;Scaled&quot;</span> }<span class="cf">else</span>{ <span class="st">&quot;Not scaled&quot;</span> }, <span class="st">&quot;</span><span class="sc">\n\n</span><span class="st">&quot;</span> )</span>
<span id="cb115-13"><a href="introduction.html#cb115-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">&quot;Confusion matrix:</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb115-14"><a href="introduction.html#cb115-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(tbl)</span>
<span id="cb115-15"><a href="introduction.html#cb115-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">&quot;</span><span class="sc">\n</span><span class="st">Correct classified points: &quot;</span>, <span class="fu">sum</span>(<span class="fu">diag</span>(tbl)), <span class="st">&quot; / &quot;</span>, <span class="fu">length</span>(iris[,<span class="dv">5</span>]))</span>
<span id="cb115-16"><a href="introduction.html#cb115-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb115-17"><a href="introduction.html#cb115-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-18"><a href="introduction.html#cb115-18" aria-hidden="true" tabindex="-1"></a>traits <span class="ot">=</span> <span class="fu">as.matrix</span>(iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span>
<span id="cb115-19"><a href="introduction.html#cb115-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-20"><a href="introduction.html#cb115-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Do clustering on unscaled data.</span></span>
<span id="cb115-21"><a href="introduction.html#cb115-21" aria-hidden="true" tabindex="-1"></a><span class="fu">do_clustering</span>(traits, <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## fitting ...
## 
  |                                                                                                                          
  |                                                                                                                    |   0%
  |                                                                                                                          
  |========                                                                                                            |   7%
  |                                                                                                                          
  |===============                                                                                                     |  13%
  |                                                                                                                          
  |=======================                                                                                             |  20%
  |                                                                                                                          
  |===============================                                                                                     |  27%
  |                                                                                                                          
  |=======================================                                                                             |  33%
  |                                                                                                                          
  |==============================================                                                                      |  40%
  |                                                                                                                          
  |======================================================                                                              |  47%
  |                                                                                                                          
  |==============================================================                                                      |  53%
  |                                                                                                                          
  |======================================================================                                              |  60%
  |                                                                                                                          
  |=============================================================================                                       |  67%
  |                                                                                                                          
  |=====================================================================================                               |  73%
  |                                                                                                                          
  |=============================================================================================                       |  80%
  |                                                                                                                          
  |=====================================================================================================               |  87%
  |                                                                                                                          
  |============================================================================================================        |  93%
  |                                                                                                                          
  |====================================================================================================================| 100%
## Not scaled 
## 
## Confusion matrix:
##             
##               1  2  3
##   setosa     50  0  0
##   versicolor  0 45  5
##   virginica   0  0 50
## 
## Correct classified points:  145  /  150</code></pre>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="introduction.html#cb117-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Do clustering on scaled data.</span></span>
<span id="cb117-2"><a href="introduction.html#cb117-2" aria-hidden="true" tabindex="-1"></a><span class="fu">do_clustering</span>(traits, <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## fitting ...
## 
  |                                                                                                                          
  |                                                                                                                    |   0%
  |                                                                                                                          
  |========                                                                                                            |   7%
  |                                                                                                                          
  |===============                                                                                                     |  13%
  |                                                                                                                          
  |=======================                                                                                             |  20%
  |                                                                                                                          
  |===============================                                                                                     |  27%
  |                                                                                                                          
  |=======================================                                                                             |  33%
  |                                                                                                                          
  |==============================================                                                                      |  40%
  |                                                                                                                          
  |======================================================                                                              |  47%
  |                                                                                                                          
  |==============================================================                                                      |  53%
  |                                                                                                                          
  |======================================================================                                              |  60%
  |                                                                                                                          
  |=============================================================================                                       |  67%
  |                                                                                                                          
  |=====================================================================================                               |  73%
  |                                                                                                                          
  |=============================================================================================                       |  80%
  |                                                                                                                          
  |=====================================================================================================               |  87%
  |                                                                                                                          
  |============================================================================================================        |  93%
  |                                                                                                                          
  |====================================================================================================================| 100%
## Scaled 
## 
## Confusion matrix:
##             
##               1  2  3
##   setosa     50  0  0
##   versicolor  0 45  5
##   virginica   0  0 50
## 
## Correct classified points:  145  /  150</code></pre>
<p>For model based clustering, scaling does not matter.</p>
  <strong><span style="font-size:20px;">Ordination</span></strong>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="introduction.html#cb119-1" aria-hidden="true" tabindex="-1"></a>traits <span class="ot">=</span> <span class="fu">as.matrix</span>(iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span>
<span id="cb119-2"><a href="introduction.html#cb119-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-3"><a href="introduction.html#cb119-3" aria-hidden="true" tabindex="-1"></a><span class="fu">biplot</span>(<span class="fu">prcomp</span>(traits, <span class="at">center =</span> <span class="cn">TRUE</span>, <span class="at">scale. =</span> <span class="cn">TRUE</span>),</span>
<span id="cb119-4"><a href="introduction.html#cb119-4" aria-hidden="true" tabindex="-1"></a>       <span class="at">main =</span> <span class="st">&quot;Use integrated scaling&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_task_4-1.png" width="672" /></p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="introduction.html#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="fu">biplot</span>(<span class="fu">prcomp</span>(<span class="fu">scale</span>(traits), <span class="at">center =</span> <span class="cn">FALSE</span>, <span class="at">scale. =</span> <span class="cn">FALSE</span>),</span>
<span id="cb120-2"><a href="introduction.html#cb120-2" aria-hidden="true" tabindex="-1"></a>       <span class="at">main =</span> <span class="st">&quot;Scale explicitly&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_task_4-2.png" width="672" /></p>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="introduction.html#cb121-1" aria-hidden="true" tabindex="-1"></a><span class="fu">biplot</span>(<span class="fu">prcomp</span>(traits, <span class="at">center =</span> <span class="cn">FALSE</span>, <span class="at">scale. =</span> <span class="cn">FALSE</span>),</span>
<span id="cb121-2"><a href="introduction.html#cb121-2" aria-hidden="true" tabindex="-1"></a>       <span class="at">main =</span> <span class="st">&quot;No scaling at all&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_task_4-3.png" width="672" /></p>
<p>For PCA ordination, scaling matters.
Because we are interested in directions of maximal variance, all parameters should be scaled, or the one with the highest values might dominate all others.</p>
    </p>
  </details>
  <br/><hr/>
</div>
</div>
<div id="supervised-learning-regression-and-classification" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Supervised Learning: Regression and Classification</h2>
<p>The two most prominent branches of supervised learning are regression and classification. Fundamentally, classification is about predicting a label and regression is about predicting a quantity. The following video explains that in more depth:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/i04Pfrb71vk" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<div id="supervised-regression-using-random-forest" class="section level3" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> Supervised Regression Using Random Forest</h3>
<p>The random forest (RF) algorithm is possibly the most widely used machine learning algorithm and can be used for regression and classification. We will talk more about the algorithm tomorrow.</p>
<p>For the moment, we want to go through a typical workflow for a supervised regression: First, we visualize the data. Next, we fit the model and lastly we visualize the results. We will again use the iris data set that we used before. The goal is now to predict Sepal.Length based on the information about the other variables (including species).</p>
<p>Fitting the model:</p>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="introduction.html#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span>
<span id="cb122-2"><a href="introduction.html#cb122-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span></code></pre></div>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="introduction.html#cb123-1" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">=</span> <span class="fu">randomForest</span>(Sepal.Length <span class="sc">~</span> ., <span class="at">data =</span> iris)   <span class="co"># ~.: Against all others.</span></span>
<span id="cb123-2"><a href="introduction.html#cb123-2" aria-hidden="true" tabindex="-1"></a><span class="co"># str(m1)</span></span>
<span id="cb123-3"><a href="introduction.html#cb123-3" aria-hidden="true" tabindex="-1"></a><span class="co"># m1$type</span></span>
<span id="cb123-4"><a href="introduction.html#cb123-4" aria-hidden="true" tabindex="-1"></a><span class="co"># predict(m1)</span></span>
<span id="cb123-5"><a href="introduction.html#cb123-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(m1)</span></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = Sepal.Length ~ ., data = iris) 
##                Type of random forest: regression
##                      Number of trees: 500
## No. of variables tried at each split: 1
## 
##           Mean of squared residuals: 0.1364625
##                     % Var explained: 79.97</code></pre>
<p>Visualization of the results:</p>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="introduction.html#cb125-1" aria-hidden="true" tabindex="-1"></a>oldpar <span class="ot">=</span> <span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb125-2"><a href="introduction.html#cb125-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">predict</span>(m1), iris<span class="sc">$</span>Sepal.Length, <span class="at">xlab =</span> <span class="st">&quot;Predicted&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Observed&quot;</span>)</span>
<span id="cb125-3"><a href="introduction.html#cb125-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb125-4"><a href="introduction.html#cb125-4" aria-hidden="true" tabindex="-1"></a><span class="fu">varImpPlot</span>(m1)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_28-1.png" width="672" /></p>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="introduction.html#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(oldpar)</span></code></pre></div>
<p>To understand the structure of a random forest in more detail, we can use a package from GitHub.</p>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="introduction.html#cb127-1" aria-hidden="true" tabindex="-1"></a>reprtree<span class="sc">:::</span><span class="fu">plot.getTree</span>(m1, iris)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_29-1.png" width="672" /></p>
<p>Here, one of the regression trees is shown.</p>
</div>
<div id="supervised-classification-using-random-forest" class="section level3" number="3.2.2">
<h3><span class="header-section-number">3.2.2</span> Supervised Classification Using Random Forest</h3>
<p>With the random forest, we can also do classification. The steps are the same as for regression tasks, but we can additionally see how well it performed by looking at the confusion matrix. Each row of this matrix contains the instances in a predicted class and each column represents the instances in the actual class. Thus the diagonals are the correctly predicted classes and the off-diagonal elements are the falsely classified elements.</p>
<p>Fitting the model:</p>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="introduction.html#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb128-2"><a href="introduction.html#cb128-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-3"><a href="introduction.html#cb128-3" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">=</span> <span class="fu">randomForest</span>(Species <span class="sc">~</span> ., <span class="at">data =</span> iris)</span></code></pre></div>
<p>Visualizing one of the fitted models:</p>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="introduction.html#cb129-1" aria-hidden="true" tabindex="-1"></a>oldpar <span class="ot">=</span> <span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb129-2"><a href="introduction.html#cb129-2" aria-hidden="true" tabindex="-1"></a>reprtree<span class="sc">:::</span><span class="fu">plot.getTree</span>(m1, iris)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_31-1.png" width="672" /></p>
<p>Visualizing results ecologically:</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="introduction.html#cb130-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb130-2"><a href="introduction.html#cb130-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(iris<span class="sc">$</span>Petal.Width, iris<span class="sc">$</span>Petal.Length, <span class="at">col =</span> iris<span class="sc">$</span>Species, <span class="at">main =</span> <span class="st">&quot;Observed&quot;</span>)</span>
<span id="cb130-3"><a href="introduction.html#cb130-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(iris<span class="sc">$</span>Petal.Width, iris<span class="sc">$</span>Petal.Length, <span class="at">col =</span> <span class="fu">predict</span>(m1), <span class="at">main =</span> <span class="st">&quot;Predicted&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_32-1.png" width="672" /></p>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="introduction.html#cb131-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(oldpar)   <span class="co">#Reset par.</span></span></code></pre></div>
<p>Confusion matrix:</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="introduction.html#cb132-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(<span class="fu">predict</span>(m1), iris<span class="sc">$</span>Species)</span></code></pre></div>
<pre><code>##             
##              setosa versicolor virginica
##   setosa         50          0         0
##   versicolor      0         47         4
##   virginica       0          3        46</code></pre>
  <hr/>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Questions</span></strong>
    </summary>
    <p>
      <script>
        makeMultipleChoiceForm(
         'Using a random forest on the iris dataset, which parameter would be more important (remember there is a function to check this) to predict Petal.Width?',
          'radio',
          [
            {
              'answer':'Species.',
              'correct':true,
              'explanationIfSelected':'',
              'explanationIfNotSelected':'',
              'explanationGeneral':''
            },
            {
              'answer':'Sepal.Width.',
              'correct':false,
              'explanationIfSelected':'',
              'explanationIfNotSelected':'',
              'explanationGeneral':''
            },
          ],
          ''
        );
      </script>
    </p>
  </details>
  <hr/>
</div>
</div>
<div id="basicMath" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Small Introduction Into the Underlying Mathematical Concepts of all Following Lessons - Optional</h2>
<p>If are not yet familiar with the underlying concepts of neural networks and want to know more about that, it is suggested to read / view the following videos / sites. Consider the Links and videos with descriptions in parentheses as optional bonus.</p>
<p><em><strong>This might be useful to understand the further concepts in more depth.</strong></em></p>
<ul>
<li><p>(<a href="https://en.wikipedia.org/wiki/Newton%27s_method#Description" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Newton%27s_method#Description</a> (Especially the animated graphic is interesting).)</p></li>
<li><p><a href="https://en.wikipedia.org/wiki/Gradient_descent#Description" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Gradient_descent#Description</a></p></li>
<li><p><a href="https://mlfromscratch.com/neural-networks-explained/#/" target="_blank" rel="noopener">Neural networks (Backpropagation, etc.)</a>.</p></li>
<li><p><a href="https://mlfromscratch.com/activation-functions-explained/#/" target="_blank" rel="noopener">Activation functions in detail</a> (requires the above as prerequisite).</p></li>
</ul>
<p><em><strong>Videos about the topic</strong></em>:</p>
<ul>
<li><strong>Gradient descent explained</strong></li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/sDv4f4s2SB8" frameborder="0" allow="accelerometer; autoplay; clipboard-write;
  encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<ul>
<li>(Stochastic gradient descent explained)</li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/vMh0zPT0tLI" frameborder="0" allow="accelerometer; autoplay; clipboard-write;
  encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<ul>
<li>(Entropy explained)</li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/YtebGVx-Fxw" frameborder="0" allow="accelerometer; autoplay; clipboard-write;
  encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<ul>
<li><strong>Short explanation of entropy, cross entropy and Kullback–Leibler divergence</strong></li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/ErfnhcEV1O8" frameborder="0" allow="accelerometer; autoplay; clipboard-write;
  encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<ul>
<li><strong>Deep Learning (chapter 1)</strong></li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/aircAruvnKk" frameborder="0" allow="accelerometer; autoplay; clipboard-write;
  encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<ul>
<li><strong>How neural networks learn - Deep Learning (chapter 2)</strong></li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/IHZwWFHWa-w" frameborder="0" allow="accelerometer; autoplay; clipboard-write;
  encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<ul>
<li><strong>Backpropagation - Deep Learning (chapter 3)</strong></li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Ilg3gGewQ5U" frameborder="0" allow="accelerometer; autoplay; clipboard-write;
  encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<ul>
<li><strong>Another video about backpropagation (extends the previous one) - Deep Learning (chapter 4)</strong></li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/tIeHLnjs5U8" frameborder="0" allow="accelerometer; autoplay; clipboard-write;
  encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<div id="caveat-about-learning-rates-and-activation-functions" class="section level3" number="3.3.1">
<h3><span class="header-section-number">3.3.1</span> Caveat About Learning Rates and Activation Functions</h3>
<p>Depending on activation functions, it might occur that the network won’t get updated, even with high learning rates (called <em>vanishing gradient</em>, especially for “sigmoid” functions).
Furthermore, updates might overshoot (called <em>exploding gradients</em>) or activation functions will result in many zeros (especially for “relu,” <em>dying relu</em>).</p>
<p>In general, the first layers of a network tend to learn (much) more slowly than subsequent ones.</p>
</div>
</div>
<div id="introduction-to-tensorflow" class="section level2" number="3.4">
<h2><span class="header-section-number">3.4</span> Introduction to TensorFlow</h2>
<p>One of the most commonly used frameworks for machine learning is <strong>TensorFlow</strong>. TensorFlow is an open source <a href="https://en.wikipedia.org/wiki/Linear_algebra" target="_blank" rel="noopener">linear algebra</a> library with focus on neural networks, published by Google in 2015. TensorFlow supports several interesting features, in particular automatic differentiation, several gradient optimizers and CPU and GPU parallelization.</p>
<p>These advantages are nicely explained in the following video:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/MotG3XI2qSs" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<p>To sum up the most important points of the video:</p>
<ul>
<li>TensorFlow is a math library which is highly optimized for neural networks.</li>
<li>If a GPU is available, computations can be easily run on the GPU but even on a CPU TensorFlow is still very fast.</li>
<li>The “backend” (i.e. all the functions and all computations) are written in C++ and CUDA (CUDA is a programming language for NVIDIA GPUs).</li>
<li>The interface (the part of TensorFlow we use) is written in Python and is also available in R, which means, we can write the code in R/Python but it will be executed by the (compiled) C++ backend.</li>
</ul>
<p>All operations in TensorFlow are written in C++ and are highly optimized. But don’t worry, we don’t have to use C++ to use TensorFlow because there are several bindings for other languages. TensorFlow officially supports a Python API, but meanwhile there are several community carried APIs for other languages:</p>
<ul>
<li>R</li>
<li>Go</li>
<li>Rust</li>
<li>Swift</li>
<li>JavaScript</li>
</ul>
<p>In this course we will use TensorFlow with the <a href="https://tensorflow.rstudio.com/" target="_blank" rel="noopener">https://tensorflow.rstudio.com/</a> binding, that was developed and published 2017 by the RStudio team. First, they developed an R package (reticulate) for calling Python in R. Actually, we are using the Python TensorFlow module in R (more about this later).</p>
<p>TensorFlow offers different levels of API. We could implement a neural network completely by ourselves or we could use Keras which is provided as a submodule by TensorFlow. Keras is a powerful module for building and training neural networks. It allows us building and training neural networks in a few lines of codes. Since the end of 2018, Keras and TensorFlow are completly interoperable, allowing us to utilize the best of both. In this course, we will show how we can use Keras for neural networks but also how we can use the TensorFlow’s automatic differenation for using complex objective functions.</p>
<p>Useful links:</p>
<ul>
<li><a href="https://www.tensorflow.org/api_docs/python/tf" target="_blank" rel="noopener">TensorFlow documentation</a> (This is for the Python API, but just replace the “.” with “$.”)</li>
<li><a href="https://tensorflow.rstudio.com/" target="_blank" rel="noopener">Rstudio TensorFlow website</a></li>
</ul>
<div id="tensorflow-data-containers" class="section level3" number="3.4.1">
<h3><span class="header-section-number">3.4.1</span> TensorFlow Data Containers</h3>
<p>TensorFlow has two data containers (structures):</p>
<ul>
<li>constant (tf$constant): Creates a constant (immutable) value in the computation graph.</li>
<li>variable (tf$Variable): Creates a mutable value in the computation graph (used as parameter/weight in models).</li>
</ul>
<p>To get started with TensorFlow, we have to load the library and check if the installation worked.</p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="introduction.html#cb134-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb134-2"><a href="introduction.html#cb134-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb134-3"><a href="introduction.html#cb134-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-4"><a href="introduction.html#cb134-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Don&#39;t worry about weird messages. TensorFlow supports additional optimizations.</span></span>
<span id="cb134-5"><a href="introduction.html#cb134-5" aria-hidden="true" tabindex="-1"></a><span class="fu">exists</span>(<span class="st">&quot;tf&quot;</span>)</span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="introduction.html#cb136-1" aria-hidden="true" tabindex="-1"></a>immutable <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(<span class="fl">5.0</span>)</span></code></pre></div>
<pre><code>## Loaded Tensorflow version 2.7.0</code></pre>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="introduction.html#cb138-1" aria-hidden="true" tabindex="-1"></a>mutable <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(<span class="fl">5.0</span>)</span></code></pre></div>
<p>Don’t worry about weird messages (they will only appear once at the start of the session).</p>
</div>
<div id="basic-operations" class="section level3" number="3.4.2">
<h3><span class="header-section-number">3.4.2</span> Basic Operations</h3>
<p>We now can define the variables and do some math with them:</p>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="introduction.html#cb139-1" aria-hidden="true" tabindex="-1"></a>a <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(<span class="dv">5</span>)</span>
<span id="cb139-2"><a href="introduction.html#cb139-2" aria-hidden="true" tabindex="-1"></a>b <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(<span class="dv">10</span>)</span>
<span id="cb139-3"><a href="introduction.html#cb139-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(a)</span></code></pre></div>
<pre><code>## tf.Tensor(5.0, shape=(), dtype=float32)</code></pre>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="introduction.html#cb141-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(b)</span></code></pre></div>
<pre><code>## tf.Tensor(10.0, shape=(), dtype=float32)</code></pre>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="introduction.html#cb143-1" aria-hidden="true" tabindex="-1"></a>c <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">add</span>(a, b)</span>
<span id="cb143-2"><a href="introduction.html#cb143-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(c)</span></code></pre></div>
<pre><code>## tf.Tensor(15.0, shape=(), dtype=float32)</code></pre>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb145-1"><a href="introduction.html#cb145-1" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span><span class="fu">print</span>(c) <span class="co"># Prints to stderr. For stdout, use k_print_tensor(..., message).</span></span>
<span id="cb145-2"><a href="introduction.html#cb145-2" aria-hidden="true" tabindex="-1"></a><span class="fu">k_print_tensor</span>(c) <span class="co"># Comes out of Keras!</span></span></code></pre></div>
<pre><code>## tf.Tensor(15.0, shape=(), dtype=float32)</code></pre>
<p>Normal R methods such as print() are provided by the R package “tensorflow.”</p>
<p>The TensorFlow library (created by the RStudio team) built R methods for all common operations:</p>
<div class="sourceCode" id="cb147"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb147-1"><a href="introduction.html#cb147-1" aria-hidden="true" tabindex="-1"></a><span class="st">`</span><span class="at">+.tensorflow.tensor</span><span class="st">`</span> <span class="ot">=</span> <span class="cf">function</span>(a, b){ <span class="fu">return</span>(tf<span class="sc">$</span><span class="fu">add</span>(a,b)) }</span>
<span id="cb147-2"><a href="introduction.html#cb147-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Mind the backticks.</span></span>
<span id="cb147-3"><a href="introduction.html#cb147-3" aria-hidden="true" tabindex="-1"></a><span class="fu">k_print_tensor</span>(a<span class="sc">+</span>b)</span></code></pre></div>
<pre><code>## tf.Tensor(15.0, shape=(), dtype=float32)</code></pre>
<p>Their operators also automatically transform R numbers into constant tensors when attempting to add a tensor to an R number:</p>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb149-1"><a href="introduction.html#cb149-1" aria-hidden="true" tabindex="-1"></a>d <span class="ot">=</span> c <span class="sc">+</span> <span class="dv">5</span>  <span class="co"># 5 is automatically converted to a tensor.</span></span>
<span id="cb149-2"><a href="introduction.html#cb149-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(d)</span></code></pre></div>
<pre><code>## tf.Tensor(20.0, shape=(), dtype=float32)</code></pre>
<p>TensorFlow containers are objects, what means that they are not just simple variables of type numeric (class(5)), but they instead have so called methods. Methods are changing the state of a class (which for most of our purposes here is the values of the object).
For instance, there is a method to transform the tensor object back to an R object:</p>
<div class="sourceCode" id="cb151"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb151-1"><a href="introduction.html#cb151-1" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(d)</span></code></pre></div>
<pre><code>## [1] &quot;tensorflow.tensor&quot;                                &quot;tensorflow.python.framework.ops.EagerTensor&quot;     
## [3] &quot;tensorflow.python.framework.ops._EagerTensorBase&quot; &quot;tensorflow.python.framework.ops.Tensor&quot;          
## [5] &quot;tensorflow.python.types.internal.NativeObject&quot;    &quot;tensorflow.python.types.core.Tensor&quot;             
## [7] &quot;python.builtin.object&quot;</code></pre>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb153-1"><a href="introduction.html#cb153-1" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(d<span class="sc">$</span><span class="fu">numpy</span>())</span></code></pre></div>
<pre><code>## [1] &quot;numeric&quot;</code></pre>
</div>
<div id="tensorflow-data-types---good-practice-with-r-tensorflow" class="section level3" number="3.4.3">
<h3><span class="header-section-number">3.4.3</span> TensorFlow Data Types - Good Practice With R-TensorFlow</h3>
<p>R uses dynamic typing, what means you can assign a number, character, function or whatever to a variable and the the type is automatically inferred.
In other languages you have to state the type explicitly, e.g. in C:</p>
<div class="sourceCode" id="cb155"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb155-1"><a href="introduction.html#cb155-1" aria-hidden="true" tabindex="-1"></a><span class="dt">int</span> a = <span class="dv">5</span>;</span>
<span id="cb155-2"><a href="introduction.html#cb155-2" aria-hidden="true" tabindex="-1"></a><span class="dt">float</span> a = <span class="fl">5.0</span>;</span>
<span id="cb155-3"><a href="introduction.html#cb155-3" aria-hidden="true" tabindex="-1"></a><span class="dt">char</span> a = <span class="st">&quot;a&quot;</span>;</span></code></pre></div>
<p>While TensorFlow tries to infer the type dynamically, you must often state it explicitly.
Common important types:</p>
<ul>
<li>float32 (floating point number with 32 bits, “single precision”)</li>
<li>float64 (floating point number with 64 bits, “double precision”)</li>
<li>int8 (integer with 8 bits)</li>
</ul>
<p>The reason why TensorFlow is so explicit about types is that many GPUs (e.g. the NVIDIA GeForces) can handle only up to 32 bit numbers! (you do not need high precision in graphical modeling)</p>
<p>But let us see in practice what we have to do with these types and how to specifcy them:</p>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb156-1"><a href="introduction.html#cb156-1" aria-hidden="true" tabindex="-1"></a>r_matrix <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(<span class="dv">10</span><span class="sc">*</span><span class="dv">10</span>), <span class="dv">10</span>, <span class="dv">10</span>)</span>
<span id="cb156-2"><a href="introduction.html#cb156-2" aria-hidden="true" tabindex="-1"></a>m <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(r_matrix, <span class="at">dtype =</span> <span class="st">&quot;float32&quot;</span>) </span>
<span id="cb156-3"><a href="introduction.html#cb156-3" aria-hidden="true" tabindex="-1"></a>b <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(<span class="fl">2.0</span>, <span class="at">dtype =</span> <span class="st">&quot;float64&quot;</span>)</span>
<span id="cb156-4"><a href="introduction.html#cb156-4" aria-hidden="true" tabindex="-1"></a>c <span class="ot">=</span> m <span class="sc">/</span> b <span class="co"># Doesn&#39;t work! We try to divide float32/float64.</span></span></code></pre></div>
<p>So what went wrong here? We tried to divide a float32 by a float64 number, but we can only divide numbers of the same type!</p>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb157-1"><a href="introduction.html#cb157-1" aria-hidden="true" tabindex="-1"></a>r_matrix <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(<span class="dv">10</span><span class="sc">*</span><span class="dv">10</span>), <span class="dv">10</span>, <span class="dv">10</span>)</span>
<span id="cb157-2"><a href="introduction.html#cb157-2" aria-hidden="true" tabindex="-1"></a>m <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(r_matrix, <span class="at">dtype =</span> <span class="st">&quot;float64&quot;</span>)</span>
<span id="cb157-3"><a href="introduction.html#cb157-3" aria-hidden="true" tabindex="-1"></a>b <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(<span class="fl">2.0</span>, <span class="at">dtype =</span> <span class="st">&quot;float64&quot;</span>)</span>
<span id="cb157-4"><a href="introduction.html#cb157-4" aria-hidden="true" tabindex="-1"></a>c <span class="ot">=</span> m <span class="sc">/</span> b <span class="co"># Now it works.</span></span></code></pre></div>
<p>We can also specify the type of the object by providing an object e.g. tf$float64.</p>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb158-1"><a href="introduction.html#cb158-1" aria-hidden="true" tabindex="-1"></a>r_matrix <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(<span class="dv">10</span><span class="sc">*</span><span class="dv">10</span>), <span class="dv">10</span>, <span class="dv">10</span>)</span>
<span id="cb158-2"><a href="introduction.html#cb158-2" aria-hidden="true" tabindex="-1"></a>m <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(r_matrix, <span class="at">dtype =</span> tf<span class="sc">$</span>float64)</span></code></pre></div>
<p>In TensorFlow, arguments often require exact/explicit data types:
TensorFlow often expects integers as arguments. In R however an integer is normally saved as float.
Thus, we have to use an “L” after an integer to tell the R interpreter that it should be treated as an integer:</p>
<div class="sourceCode" id="cb159"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb159-1"><a href="introduction.html#cb159-1" aria-hidden="true" tabindex="-1"></a><span class="fu">is.integer</span>(<span class="dv">5</span>)</span>
<span id="cb159-2"><a href="introduction.html#cb159-2" aria-hidden="true" tabindex="-1"></a><span class="fu">is.integer</span>(5L)</span>
<span id="cb159-3"><a href="introduction.html#cb159-3" aria-hidden="true" tabindex="-1"></a><span class="fu">matrix</span>(<span class="fu">t</span>(r_matrix), <span class="dv">5</span>, <span class="dv">20</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb159-4"><a href="introduction.html#cb159-4" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span><span class="fu">reshape</span>(r_matrix, <span class="at">shape =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">20</span>))<span class="sc">$</span><span class="fu">numpy</span>()</span>
<span id="cb159-5"><a href="introduction.html#cb159-5" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span><span class="fu">reshape</span>(r_matrix, <span class="at">shape =</span> <span class="fu">c</span>(5L, 20L))<span class="sc">$</span><span class="fu">numpy</span>()</span></code></pre></div>
<p>Skipping the “L” is one of the most common errors when using R-TensorFlow!</p>
  <hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Tasks</span></strong><br/>
<p>To run TensorFlow from R, note that you can access the different mathematical operations in TensorFlow via tf$…, e.g. there is a tf$math$… for all common math operations or the tf$linalg$… for different linear algebra operations.
Tip: type tf$ and then hit the tab key to list all available options (sometimes you have to do this directly in the console).</p>
<p>An example: How to get the maximum value of a vector?</p>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb160-1"><a href="introduction.html#cb160-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb160-2"><a href="introduction.html#cb160-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb160-3"><a href="introduction.html#cb160-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb160-4"><a href="introduction.html#cb160-4" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="dv">100</span><span class="sc">:</span><span class="dv">1</span></span>
<span id="cb160-5"><a href="introduction.html#cb160-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">as.double</span>(<span class="dv">100</span><span class="sc">:</span><span class="dv">1</span>)</span>
<span id="cb160-6"><a href="introduction.html#cb160-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb160-7"><a href="introduction.html#cb160-7" aria-hidden="true" tabindex="-1"></a><span class="fu">max</span>(x)  <span class="co"># R solution. Integer!</span></span>
<span id="cb160-8"><a href="introduction.html#cb160-8" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span>math<span class="sc">$</span><span class="fu">reduce_max</span>(x) <span class="co"># TensorFlow solution. Integer!</span></span>
<span id="cb160-9"><a href="introduction.html#cb160-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb160-10"><a href="introduction.html#cb160-10" aria-hidden="true" tabindex="-1"></a><span class="fu">max</span>(y)  <span class="co"># Float!</span></span>
<span id="cb160-11"><a href="introduction.html#cb160-11" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span>math<span class="sc">$</span><span class="fu">reduce_max</span>(y) <span class="co"># Float!</span></span></code></pre></div>
<p>Rewrite the following expressions (a to g) in TensorFlow:</p>
<div class="sourceCode" id="cb161"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb161-1"><a href="introduction.html#cb161-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="dv">100</span><span class="sc">:</span><span class="dv">1</span></span>
<span id="cb161-2"><a href="introduction.html#cb161-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">as.double</span>(<span class="dv">100</span><span class="sc">:</span><span class="dv">1</span>)</span>
<span id="cb161-3"><a href="introduction.html#cb161-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb161-4"><a href="introduction.html#cb161-4" aria-hidden="true" tabindex="-1"></a><span class="co"># a)</span></span>
<span id="cb161-5"><a href="introduction.html#cb161-5" aria-hidden="true" tabindex="-1"></a><span class="fu">min</span>(x)</span></code></pre></div>
<pre><code>## [1] 1</code></pre>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb163-1"><a href="introduction.html#cb163-1" aria-hidden="true" tabindex="-1"></a><span class="co"># b)</span></span>
<span id="cb163-2"><a href="introduction.html#cb163-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(x)</span></code></pre></div>
<pre><code>## [1] 50.5</code></pre>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb165-1"><a href="introduction.html#cb165-1" aria-hidden="true" tabindex="-1"></a><span class="co"># c) Tip: Use Google!</span></span>
<span id="cb165-2"><a href="introduction.html#cb165-2" aria-hidden="true" tabindex="-1"></a><span class="fu">which.max</span>(x)</span></code></pre></div>
<pre><code>## [1] 1</code></pre>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb167-1"><a href="introduction.html#cb167-1" aria-hidden="true" tabindex="-1"></a><span class="co"># d) </span></span>
<span id="cb167-2"><a href="introduction.html#cb167-2" aria-hidden="true" tabindex="-1"></a><span class="fu">which.min</span>(x)</span></code></pre></div>
<pre><code>## [1] 100</code></pre>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb169-1"><a href="introduction.html#cb169-1" aria-hidden="true" tabindex="-1"></a><span class="co"># e) Tip: Use Google! </span></span>
<span id="cb169-2"><a href="introduction.html#cb169-2" aria-hidden="true" tabindex="-1"></a><span class="fu">order</span>(x)</span></code></pre></div>
<pre><code>##   [1] 100  99  98  97  96  95  94  93  92  91  90  89  88  87  86  85  84  83  82  81  80  79  78  77  76  75  74  73  72  71
##  [31]  70  69  68  67  66  65  64  63  62  61  60  59  58  57  56  55  54  53  52  51  50  49  48  47  46  45  44  43  42  41
##  [61]  40  39  38  37  36  35  34  33  32  31  30  29  28  27  26  25  24  23  22  21  20  19  18  17  16  15  14  13  12  11
##  [91]  10   9   8   7   6   5   4   3   2   1</code></pre>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb171-1"><a href="introduction.html#cb171-1" aria-hidden="true" tabindex="-1"></a><span class="co"># f) Tip: See tf$reshape.</span></span>
<span id="cb171-2"><a href="introduction.html#cb171-2" aria-hidden="true" tabindex="-1"></a>m <span class="ot">=</span> <span class="fu">matrix</span>(y, <span class="dv">10</span>, <span class="dv">10</span>) <span class="co"># Mind: We use y here! (Float)</span></span>
<span id="cb171-3"><a href="introduction.html#cb171-3" aria-hidden="true" tabindex="-1"></a>m_2 <span class="ot">=</span> <span class="fu">abs</span>(m <span class="sc">%*%</span> <span class="fu">t</span>(m))  <span class="co"># m %*% m is the normal matrix multiplication.</span></span>
<span id="cb171-4"><a href="introduction.html#cb171-4" aria-hidden="true" tabindex="-1"></a>m_2_log <span class="ot">=</span> <span class="fu">log</span>(m_2)</span>
<span id="cb171-5"><a href="introduction.html#cb171-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(m_2_log)</span></code></pre></div>
<pre><code>##           [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8]     [,9]    [,10]
##  [1,] 10.55841 10.54402 10.52943 10.51461 10.49957 10.48431 10.46880 10.45305 10.43705 10.42079
##  [2,] 10.54402 10.52969 10.51515 10.50040 10.48542 10.47022 10.45478 10.43910 10.42317 10.40699
##  [3,] 10.52943 10.51515 10.50067 10.48598 10.47107 10.45593 10.44057 10.42496 10.40910 10.39299
##  [4,] 10.51461 10.50040 10.48598 10.47135 10.45651 10.44144 10.42614 10.41061 10.39482 10.37879
##  [5,] 10.49957 10.48542 10.47107 10.45651 10.44173 10.42674 10.41151 10.39605 10.38034 10.36439
##  [6,] 10.48431 10.47022 10.45593 10.44144 10.42674 10.41181 10.39666 10.38127 10.36565 10.34977
##  [7,] 10.46880 10.45478 10.44057 10.42614 10.41151 10.39666 10.38158 10.36628 10.35073 10.33495
##  [8,] 10.45305 10.43910 10.42496 10.41061 10.39605 10.38127 10.36628 10.35105 10.33559 10.31989
##  [9,] 10.43705 10.42317 10.40910 10.39482 10.38034 10.36565 10.35073 10.33559 10.32022 10.30461
## [10,] 10.42079 10.40699 10.39299 10.37879 10.36439 10.34977 10.33495 10.31989 10.30461 10.28909</code></pre>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb173-1"><a href="introduction.html#cb173-1" aria-hidden="true" tabindex="-1"></a><span class="co"># g) Custom mean function i.e. rewrite the function using TensorFlow. </span></span>
<span id="cb173-2"><a href="introduction.html#cb173-2" aria-hidden="true" tabindex="-1"></a>mean_R <span class="ot">=</span> <span class="cf">function</span>(y){</span>
<span id="cb173-3"><a href="introduction.html#cb173-3" aria-hidden="true" tabindex="-1"></a>  result <span class="ot">=</span> <span class="fu">sum</span>(y) <span class="sc">/</span> <span class="fu">length</span>(y)</span>
<span id="cb173-4"><a href="introduction.html#cb173-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(result)</span>
<span id="cb173-5"><a href="introduction.html#cb173-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb173-6"><a href="introduction.html#cb173-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb173-7"><a href="introduction.html#cb173-7" aria-hidden="true" tabindex="-1"></a><span class="fu">mean_R</span>(y) <span class="sc">==</span> <span class="fu">mean</span>(y)    <span class="co"># Test for equality.</span></span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb175-1"><a href="introduction.html#cb175-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb175-2"><a href="introduction.html#cb175-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb175-3"><a href="introduction.html#cb175-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb175-4"><a href="introduction.html#cb175-4" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="dv">100</span><span class="sc">:</span><span class="dv">1</span></span>
<span id="cb175-5"><a href="introduction.html#cb175-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">as.double</span>(<span class="dv">100</span><span class="sc">:</span><span class="dv">1</span>)</span>
<span id="cb175-6"><a href="introduction.html#cb175-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb175-7"><a href="introduction.html#cb175-7" aria-hidden="true" tabindex="-1"></a><span class="co"># a)    min(x)</span></span>
<span id="cb175-8"><a href="introduction.html#cb175-8" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span>math<span class="sc">$</span><span class="fu">reduce_min</span>(x) <span class="co"># Integer!</span></span></code></pre></div>
<pre><code>## tf.Tensor(1, shape=(), dtype=int32)</code></pre>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb177-1"><a href="introduction.html#cb177-1" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span>math<span class="sc">$</span><span class="fu">reduce_min</span>(y) <span class="co"># Float!</span></span></code></pre></div>
<pre><code>## tf.Tensor(1.0, shape=(), dtype=float32)</code></pre>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb179-1"><a href="introduction.html#cb179-1" aria-hidden="true" tabindex="-1"></a><span class="co"># b)    mean(x)</span></span>
<span id="cb179-2"><a href="introduction.html#cb179-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Check out the difference here:</span></span>
<span id="cb179-3"><a href="introduction.html#cb179-3" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(x)</span></code></pre></div>
<pre><code>## [1] 50.5</code></pre>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb181-1"><a href="introduction.html#cb181-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(y)</span></code></pre></div>
<pre><code>## [1] 50.5</code></pre>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb183-1"><a href="introduction.html#cb183-1" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span>math<span class="sc">$</span><span class="fu">reduce_mean</span>(x)  <span class="co"># Integer!</span></span></code></pre></div>
<pre><code>## tf.Tensor(50, shape=(), dtype=int32)</code></pre>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb185-1"><a href="introduction.html#cb185-1" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span>math<span class="sc">$</span><span class="fu">reduce_mean</span>(y)  <span class="co"># Float!</span></span></code></pre></div>
<pre><code>## tf.Tensor(50.5, shape=(), dtype=float32)</code></pre>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb187-1"><a href="introduction.html#cb187-1" aria-hidden="true" tabindex="-1"></a><span class="co"># c)    which.max(x)</span></span>
<span id="cb187-2"><a href="introduction.html#cb187-2" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span><span class="fu">argmax</span>(x)</span></code></pre></div>
<pre><code>## tf.Tensor(0, shape=(), dtype=int64)</code></pre>
<div class="sourceCode" id="cb189"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb189-1"><a href="introduction.html#cb189-1" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span><span class="fu">argmax</span>(y)</span></code></pre></div>
<pre><code>## tf.Tensor(0, shape=(), dtype=int64)</code></pre>
<div class="sourceCode" id="cb191"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb191-1"><a href="introduction.html#cb191-1" aria-hidden="true" tabindex="-1"></a><span class="co"># d)    which.min(x)</span></span>
<span id="cb191-2"><a href="introduction.html#cb191-2" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span><span class="fu">argmin</span>(x)</span></code></pre></div>
<pre><code>## tf.Tensor(99, shape=(), dtype=int64)</code></pre>
<div class="sourceCode" id="cb193"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb193-1"><a href="introduction.html#cb193-1" aria-hidden="true" tabindex="-1"></a><span class="co"># e)    order(x)</span></span>
<span id="cb193-2"><a href="introduction.html#cb193-2" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span><span class="fu">argsort</span>(x)</span></code></pre></div>
<pre><code>## tf.Tensor(
## [99 98 97 96 95 94 93 92 91 90 89 88 87 86 85 84 83 82 81 80 79 78 77 76
##  75 74 73 72 71 70 69 68 67 66 65 64 63 62 61 60 59 58 57 56 55 54 53 52
##  51 50 49 48 47 46 45 44 43 42 41 40 39 38 37 36 35 34 33 32 31 30 29 28
##  27 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10  9  8  7  6  5  4
##   3  2  1  0], shape=(100,), dtype=int32)</code></pre>
<div class="sourceCode" id="cb195"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb195-1"><a href="introduction.html#cb195-1" aria-hidden="true" tabindex="-1"></a><span class="co"># f)</span></span>
<span id="cb195-2"><a href="introduction.html#cb195-2" aria-hidden="true" tabindex="-1"></a><span class="co"># m = matrix(y, 10, 10)</span></span>
<span id="cb195-3"><a href="introduction.html#cb195-3" aria-hidden="true" tabindex="-1"></a><span class="co"># m_2 = abs(m %*% m)</span></span>
<span id="cb195-4"><a href="introduction.html#cb195-4" aria-hidden="true" tabindex="-1"></a><span class="co"># m_2_log = log(m_2)</span></span>
<span id="cb195-5"><a href="introduction.html#cb195-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb195-6"><a href="introduction.html#cb195-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Mind: We use y here! TensorFlow just accepts floats in the following lines!</span></span>
<span id="cb195-7"><a href="introduction.html#cb195-7" aria-hidden="true" tabindex="-1"></a>mTF <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">reshape</span>(y, <span class="fu">list</span>(10L, 10L))</span>
<span id="cb195-8"><a href="introduction.html#cb195-8" aria-hidden="true" tabindex="-1"></a>m_2TF <span class="ot">=</span> tf<span class="sc">$</span>math<span class="sc">$</span><span class="fu">abs</span>( tf<span class="sc">$</span><span class="fu">matmul</span>(mTF, tf<span class="sc">$</span><span class="fu">transpose</span>(mTF)) )</span>
<span id="cb195-9"><a href="introduction.html#cb195-9" aria-hidden="true" tabindex="-1"></a>m_2_logTF <span class="ot">=</span> tf<span class="sc">$</span>math<span class="sc">$</span><span class="fu">log</span>(m_2TF)</span>
<span id="cb195-10"><a href="introduction.html#cb195-10" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(m_2_logTF)</span></code></pre></div>
<pre><code>## tf.Tensor(
## [[11.4217415 11.311237  11.186988  11.045079  10.87965   10.68132
##   10.433674  10.103771   9.608109   8.582045 ]
##  [11.311237  11.200746  11.076511  10.934624  10.769221  10.570931
##   10.323348   9.993557   9.498147   8.473242 ]
##  [11.186988  11.076511  10.952296  10.810434  10.645067  10.446828
##   10.199324   9.869672   9.374583   8.351139 ]
##  [11.045079  10.934624  10.810434  10.668606  10.503284  10.305112
##   10.057709   9.728241   9.233569   8.212026 ]
##  [10.87965   10.769221  10.645067  10.503284  10.338025  10.139941
##    9.892679   9.563459   9.069353   8.0503845]
##  [10.68132   10.570931  10.446828  10.305112  10.139941   9.941987
##    9.694924   9.366061   8.872768   7.857481 ]
##  [10.433674  10.323348  10.199324  10.057709   9.892679   9.694924
##    9.448175   9.119869   8.62784    7.6182513]
##  [10.103771   9.993557   9.869672   9.728241   9.563459   9.366061
##    9.119869   8.79255    8.302762   7.30317  ]
##  [ 9.608109   9.498147   9.374583   9.233569   9.069353   8.872768
##    8.62784    8.302762   7.818028   6.8405466]
##  [ 8.582045   8.473242   8.351139   8.212026   8.0503845  7.857481
##    7.6182513  7.30317    6.8405466  5.9532433]], shape=(10, 10), dtype=float32)</code></pre>
<div class="sourceCode" id="cb197"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb197-1"><a href="introduction.html#cb197-1" aria-hidden="true" tabindex="-1"></a><span class="co"># g)    # Custom mean function</span></span>
<span id="cb197-2"><a href="introduction.html#cb197-2" aria-hidden="true" tabindex="-1"></a>mean_TF <span class="ot">=</span> <span class="cf">function</span>(y){</span>
<span id="cb197-3"><a href="introduction.html#cb197-3" aria-hidden="true" tabindex="-1"></a>  result <span class="ot">=</span> tf<span class="sc">$</span>math<span class="sc">$</span><span class="fu">reduce_sum</span>(y)</span>
<span id="cb197-4"><a href="introduction.html#cb197-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>( result <span class="sc">/</span> <span class="fu">length</span>(y) )  <span class="co"># If y is an R object.</span></span>
<span id="cb197-5"><a href="introduction.html#cb197-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb197-6"><a href="introduction.html#cb197-6" aria-hidden="true" tabindex="-1"></a><span class="fu">mean_TF</span>(y) <span class="sc">==</span> <span class="fu">mean</span>(y)</span></code></pre></div>
<pre><code>## tf.Tensor(True, shape=(), dtype=bool)</code></pre>
    </p>
  </details>
  <br/>
  <hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<p>This exercise compares the speed of R to TensorFlow.
The first exercise is to rewrite the following function in TensorFlow:</p>
<div class="sourceCode" id="cb199"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb199-1"><a href="introduction.html#cb199-1" aria-hidden="true" tabindex="-1"></a>do_something_R <span class="ot">=</span> <span class="cf">function</span>(<span class="at">x =</span> <span class="fu">matrix</span>(<span class="fl">0.0</span>, 10L, 10L)){</span>
<span id="cb199-2"><a href="introduction.html#cb199-2" aria-hidden="true" tabindex="-1"></a>  mean_per_row <span class="ot">=</span> <span class="fu">apply</span>(x, <span class="dv">1</span>, mean)</span>
<span id="cb199-3"><a href="introduction.html#cb199-3" aria-hidden="true" tabindex="-1"></a>  result <span class="ot">=</span> x <span class="sc">-</span> mean_per_row</span>
<span id="cb199-4"><a href="introduction.html#cb199-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(result)</span>
<span id="cb199-5"><a href="introduction.html#cb199-5" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Here, we provide a skeleton for a TensorFlow function:</p>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb200-1"><a href="introduction.html#cb200-1" aria-hidden="true" tabindex="-1"></a>do_something_TF <span class="ot">=</span> <span class="cf">function</span>(<span class="at">x =</span> <span class="fu">matrix</span>(<span class="fl">0.0</span>, 10L, 10L)){</span>
<span id="cb200-2"><a href="introduction.html#cb200-2" aria-hidden="true" tabindex="-1"></a>   ...</span>
<span id="cb200-3"><a href="introduction.html#cb200-3" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>We can compare the speed using the Microbenchmark package:</p>
<div class="sourceCode" id="cb201"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb201-1"><a href="introduction.html#cb201-1" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fl">0.0</span>, 100L, 100L)</span>
<span id="cb201-2"><a href="introduction.html#cb201-2" aria-hidden="true" tabindex="-1"></a>microbenchmark<span class="sc">::</span><span class="fu">microbenchmark</span>(<span class="fu">do_something_R</span>(test), <span class="fu">do_something_TF</span>(test))</span></code></pre></div>
<p>Try different matrix sizes for the test matrix and compare the speed.</p>
<p>Tip: Have a look at the the tf.reduce_mean documentation and the “axis” argument.</p>
<p><br/></p>
<p>Compare the following with different matrix sizes:</p>
<ul>
<li>test = matrix(0.0, 1000L, 500L)</li>
<li>testTF = tf$constant(test)</li>
</ul>
<p>Also try the following:</p>
<div class="sourceCode" id="cb202"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb202-1"><a href="introduction.html#cb202-1" aria-hidden="true" tabindex="-1"></a>microbenchmark<span class="sc">::</span><span class="fu">microbenchmark</span>(</span>
<span id="cb202-2"><a href="introduction.html#cb202-2" aria-hidden="true" tabindex="-1"></a>   tf<span class="sc">$</span><span class="fu">matmul</span>(testTF, tf<span class="sc">$</span><span class="fu">transpose</span>(testTF)), <span class="co"># TensorFlow style.</span></span>
<span id="cb202-3"><a href="introduction.html#cb202-3" aria-hidden="true" tabindex="-1"></a>   test <span class="sc">%*%</span> <span class="fu">t</span>(test)  <span class="co"># R style.</span></span>
<span id="cb202-4"><a href="introduction.html#cb202-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<div class="sourceCode" id="cb203"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb203-1"><a href="introduction.html#cb203-1" aria-hidden="true" tabindex="-1"></a>do_something_TF <span class="ot">=</span> <span class="cf">function</span>(<span class="at">x =</span> <span class="fu">matrix</span>(<span class="fl">0.0</span>, 10L, 10L)){</span>
<span id="cb203-2"><a href="introduction.html#cb203-2" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(x)  <span class="co"># Remember, this is a local copy!</span></span>
<span id="cb203-3"><a href="introduction.html#cb203-3" aria-hidden="true" tabindex="-1"></a>  mean_per_row <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">reduce_mean</span>(x, <span class="at">axis =</span> 0L)</span>
<span id="cb203-4"><a href="introduction.html#cb203-4" aria-hidden="true" tabindex="-1"></a>  result <span class="ot">=</span> x <span class="sc">-</span> mean_per_row</span>
<span id="cb203-5"><a href="introduction.html#cb203-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(result)</span>
<span id="cb203-6"><a href="introduction.html#cb203-6" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb204"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb204-1"><a href="introduction.html#cb204-1" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fl">0.0</span>, 100L, 100L)</span>
<span id="cb204-2"><a href="introduction.html#cb204-2" aria-hidden="true" tabindex="-1"></a>microbenchmark<span class="sc">::</span><span class="fu">microbenchmark</span>(<span class="fu">do_something_R</span>(test), <span class="fu">do_something_TF</span>(test))</span></code></pre></div>
<pre><code>## Unit: microseconds
##                   expr      min       lq     mean    median       uq       max neval cld
##   do_something_R(test)  457.297  493.101 1003.893  509.8455  528.595 47142.537   100  a 
##  do_something_TF(test) 2384.436 2448.121 2563.876 2510.2245 2551.953  6028.575   100   b</code></pre>
<div class="sourceCode" id="cb206"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb206-1"><a href="introduction.html#cb206-1" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fl">0.0</span>, 1000L, 500L)</span>
<span id="cb206-2"><a href="introduction.html#cb206-2" aria-hidden="true" tabindex="-1"></a>microbenchmark<span class="sc">::</span><span class="fu">microbenchmark</span>(<span class="fu">do_something_R</span>(test), <span class="fu">do_something_TF</span>(test))</span></code></pre></div>
<pre><code>## Unit: milliseconds
##                   expr      min       lq      mean   median        uq       max neval cld
##   do_something_R(test) 7.048826 7.350961 10.291932 7.530190 15.173997 21.306708   100   b
##  do_something_TF(test) 3.471403 3.593884  4.028746 3.689198  4.108474  9.197866   100  a</code></pre>
<p>Why is R faster (the first time)?</p>
<ul>
<li><ol style="list-style-type: lower-alpha">
<li>The R functions we used (apply, mean, “-”) are also implemented in C.</li>
</ol></li>
<li><ol start="2" style="list-style-type: lower-alpha">
<li>The problem is not large enough and TensorFlow has an overhead.</li>
</ol></li>
</ul>
<p><br/></p>
<div class="sourceCode" id="cb208"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb208-1"><a href="introduction.html#cb208-1" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fl">0.0</span>, 1000L, 500L)</span>
<span id="cb208-2"><a href="introduction.html#cb208-2" aria-hidden="true" tabindex="-1"></a>testTF <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(test)</span>
<span id="cb208-3"><a href="introduction.html#cb208-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb208-4"><a href="introduction.html#cb208-4" aria-hidden="true" tabindex="-1"></a>microbenchmark<span class="sc">::</span><span class="fu">microbenchmark</span>(</span>
<span id="cb208-5"><a href="introduction.html#cb208-5" aria-hidden="true" tabindex="-1"></a>  tf<span class="sc">$</span><span class="fu">matmul</span>(testTF, tf<span class="sc">$</span><span class="fu">transpose</span>(testTF)),  <span class="co"># TensorFlow style.</span></span>
<span id="cb208-6"><a href="introduction.html#cb208-6" aria-hidden="true" tabindex="-1"></a>  test <span class="sc">%*%</span> <span class="fu">t</span>(test) <span class="co"># R style.</span></span>
<span id="cb208-7"><a href="introduction.html#cb208-7" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## Unit: milliseconds
##                                     expr       min        lq      mean    median        uq       max neval cld
##  tf$matmul(testTF, tf$transpose(testTF))  5.279501  6.674446  8.450876  7.431472  8.791987  20.62599   100  a 
##                         test %*% t(test) 65.143662 69.645367 76.857925 71.003062 77.398229 415.56301   100   b</code></pre>
    </p>
  </details>
  <br/>
  <hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<p>Google to find out how to write the following tasks in TensorFlow:</p>
<div class="sourceCode" id="cb210"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb210-1"><a href="introduction.html#cb210-1" aria-hidden="true" tabindex="-1"></a>A <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">3</span>), <span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb210-2"><a href="introduction.html#cb210-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb210-3"><a href="introduction.html#cb210-3" aria-hidden="true" tabindex="-1"></a><span class="co"># i)</span></span>
<span id="cb210-4"><a href="introduction.html#cb210-4" aria-hidden="true" tabindex="-1"></a><span class="fu">solve</span>(A)  <span class="co"># Solve equation AX = B. If just A  is given, invert it.</span></span></code></pre></div>
<pre><code>##      [,1] [,2]       [,3]
## [1,]    1  0.0 -0.6666667
## [2,]   -1  0.5 -0.1666667
## [3,]    0  0.0  0.3333333</code></pre>
<div class="sourceCode" id="cb212"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb212-1"><a href="introduction.html#cb212-1" aria-hidden="true" tabindex="-1"></a><span class="co"># j)</span></span>
<span id="cb212-2"><a href="introduction.html#cb212-2" aria-hidden="true" tabindex="-1"></a><span class="fu">diag</span>(A) <span class="co"># Diagonal of A, if no matrix is given, construct diagonal matrix.</span></span></code></pre></div>
<pre><code>## [1] 1 2 3</code></pre>
<div class="sourceCode" id="cb214"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb214-1"><a href="introduction.html#cb214-1" aria-hidden="true" tabindex="-1"></a><span class="co"># k)</span></span>
<span id="cb214-2"><a href="introduction.html#cb214-2" aria-hidden="true" tabindex="-1"></a><span class="fu">diag</span>(<span class="fu">diag</span>(A)) <span class="co"># Diagonal matrix with entries diag(A).</span></span></code></pre></div>
<pre><code>##      [,1] [,2] [,3]
## [1,]    1    0    0
## [2,]    0    2    0
## [3,]    0    0    3</code></pre>
<div class="sourceCode" id="cb216"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb216-1"><a href="introduction.html#cb216-1" aria-hidden="true" tabindex="-1"></a><span class="co"># l)</span></span>
<span id="cb216-2"><a href="introduction.html#cb216-2" aria-hidden="true" tabindex="-1"></a><span class="fu">eigen</span>(A)</span></code></pre></div>
<pre><code>## eigen() decomposition
## $values
## [1] 3 2 1
## 
## $vectors
##           [,1] [,2]       [,3]
## [1,] 0.1400280    0  0.4472136
## [2,] 0.9801961    1 -0.8944272
## [3,] 0.1400280    0  0.0000000</code></pre>
<div class="sourceCode" id="cb218"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb218-1"><a href="introduction.html#cb218-1" aria-hidden="true" tabindex="-1"></a><span class="co"># m)</span></span>
<span id="cb218-2"><a href="introduction.html#cb218-2" aria-hidden="true" tabindex="-1"></a><span class="fu">det</span>(A)</span></code></pre></div>
<pre><code>## [1] 6</code></pre>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb220-1"><a href="introduction.html#cb220-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb220-2"><a href="introduction.html#cb220-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb220-3"><a href="introduction.html#cb220-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb220-4"><a href="introduction.html#cb220-4" aria-hidden="true" tabindex="-1"></a>A <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="fl">1.</span>, <span class="fl">2.</span>, <span class="fl">0.</span>, <span class="fl">0.</span>, <span class="fl">2.</span>, <span class="fl">0.</span>, <span class="fl">2.</span>, <span class="fl">5.</span>, <span class="fl">3.</span>), <span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb220-5"><a href="introduction.html#cb220-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Do not use the &quot;L&quot; form here!</span></span>
<span id="cb220-6"><a href="introduction.html#cb220-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb220-7"><a href="introduction.html#cb220-7" aria-hidden="true" tabindex="-1"></a><span class="co"># i)    solve(A)</span></span>
<span id="cb220-8"><a href="introduction.html#cb220-8" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span>linalg<span class="sc">$</span><span class="fu">inv</span>(A)</span></code></pre></div>
<pre><code>## tf.Tensor(
## [[ 1.          0.         -0.66666667]
##  [-1.          0.5        -0.16666667]
##  [ 0.          0.          0.33333333]], shape=(3, 3), dtype=float64)</code></pre>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb222-1"><a href="introduction.html#cb222-1" aria-hidden="true" tabindex="-1"></a><span class="co"># j)    diag(A)</span></span>
<span id="cb222-2"><a href="introduction.html#cb222-2" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span>linalg<span class="sc">$</span><span class="fu">diag_part</span>(A)</span></code></pre></div>
<pre><code>## tf.Tensor([1. 2. 3.], shape=(3,), dtype=float64)</code></pre>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb224-1"><a href="introduction.html#cb224-1" aria-hidden="true" tabindex="-1"></a><span class="co"># k)    diag(diag(A))</span></span>
<span id="cb224-2"><a href="introduction.html#cb224-2" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span>linalg<span class="sc">$</span><span class="fu">diag</span>(tf<span class="sc">$</span>linalg<span class="sc">$</span><span class="fu">diag_part</span>(A))</span></code></pre></div>
<pre><code>## tf.Tensor(
## [[1. 0. 0.]
##  [0. 2. 0.]
##  [0. 0. 3.]], shape=(3, 3), dtype=float64)</code></pre>
<div class="sourceCode" id="cb226"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb226-1"><a href="introduction.html#cb226-1" aria-hidden="true" tabindex="-1"></a><span class="co"># l)    eigen(A)</span></span>
<span id="cb226-2"><a href="introduction.html#cb226-2" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span>linalg<span class="sc">$</span><span class="fu">eigh</span>(A)</span></code></pre></div>
<pre><code>## [[1]]
## tf.Tensor([-0.56155281  3.          3.56155281], shape=(3,), dtype=float64)
## 
## [[2]]
## tf.Tensor(
## [[-0.78820544  0.         -0.61541221]
##  [ 0.61541221  0.         -0.78820544]
##  [ 0.          1.         -0.        ]], shape=(3, 3), dtype=float64)</code></pre>
<div class="sourceCode" id="cb228"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb228-1"><a href="introduction.html#cb228-1" aria-hidden="true" tabindex="-1"></a><span class="co"># m)    det(A)</span></span>
<span id="cb228-2"><a href="introduction.html#cb228-2" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span>linalg<span class="sc">$</span><span class="fu">det</span>(A)</span></code></pre></div>
<pre><code>## tf.Tensor(6.0, shape=(), dtype=float64)</code></pre>
    </p>
  </details>
  <br/>
  <hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<p>TensorFlow supports automatic differentiation (analytical and not numerical!).
Let’s have a look at the function <span class="math inline">\(f(x) = 5 x^2 + 3\)</span> with derivative <span class="math inline">\(f&#39;(x) = 10x\)</span>.
So for <span class="math inline">\(f&#39;(5)\)</span> we will get <span class="math inline">\(10\)</span>.</p>
<p>Let’s do this in TensorFlow. Define the function:</p>
<div class="sourceCode" id="cb230"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb230-1"><a href="introduction.html#cb230-1" aria-hidden="true" tabindex="-1"></a>f <span class="ot">=</span> <span class="cf">function</span>(x){ <span class="fu">return</span>(<span class="fl">5.0</span> <span class="sc">*</span> tf<span class="sc">$</span><span class="fu">square</span>(x) <span class="sc">+</span> <span class="fl">3.0</span>) }</span></code></pre></div>
<p>We want to calculate the derivative for <span class="math inline">\(x = 2.0\)</span>:</p>
<div class="sourceCode" id="cb231"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb231-1"><a href="introduction.html#cb231-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(<span class="fl">2.0</span>)</span></code></pre></div>
<p>To do automatic differentiation, we have to forward <span class="math inline">\(x\)</span> through the function within the tf$GradientTape() environment. We have also have to tell TensorFlow which value to “watch”:</p>
<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb232-1"><a href="introduction.html#cb232-1" aria-hidden="true" tabindex="-1"></a><span class="fu">with</span>(tf<span class="sc">$</span><span class="fu">GradientTape</span>() <span class="sc">%as%</span> tape,</span>
<span id="cb232-2"><a href="introduction.html#cb232-2" aria-hidden="true" tabindex="-1"></a>  {</span>
<span id="cb232-3"><a href="introduction.html#cb232-3" aria-hidden="true" tabindex="-1"></a>    tape<span class="sc">$</span><span class="fu">watch</span>(x)</span>
<span id="cb232-4"><a href="introduction.html#cb232-4" aria-hidden="true" tabindex="-1"></a>    y <span class="ot">=</span> <span class="fu">f</span>(x)</span>
<span id="cb232-5"><a href="introduction.html#cb232-5" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb232-6"><a href="introduction.html#cb232-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>To print the gradient:</p>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb233-1"><a href="introduction.html#cb233-1" aria-hidden="true" tabindex="-1"></a>(tape<span class="sc">$</span><span class="fu">gradient</span>(y, x))</span></code></pre></div>
<pre><code>## tf.Tensor(20.0, shape=(), dtype=float32)</code></pre>
<p>We can also calculate the second order derivative <span class="math inline">\(f&#39;&#39;(x) = 10\)</span>:</p>
<div class="sourceCode" id="cb235"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb235-1"><a href="introduction.html#cb235-1" aria-hidden="true" tabindex="-1"></a><span class="fu">with</span>(tf<span class="sc">$</span><span class="fu">GradientTape</span>() <span class="sc">%as%</span> first,</span>
<span id="cb235-2"><a href="introduction.html#cb235-2" aria-hidden="true" tabindex="-1"></a>  {</span>
<span id="cb235-3"><a href="introduction.html#cb235-3" aria-hidden="true" tabindex="-1"></a>    first<span class="sc">$</span><span class="fu">watch</span>(x)</span>
<span id="cb235-4"><a href="introduction.html#cb235-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">with</span>(tf<span class="sc">$</span><span class="fu">GradientTape</span>() <span class="sc">%as%</span> second,</span>
<span id="cb235-5"><a href="introduction.html#cb235-5" aria-hidden="true" tabindex="-1"></a>      {</span>
<span id="cb235-6"><a href="introduction.html#cb235-6" aria-hidden="true" tabindex="-1"></a>        second<span class="sc">$</span><span class="fu">watch</span>(x)</span>
<span id="cb235-7"><a href="introduction.html#cb235-7" aria-hidden="true" tabindex="-1"></a>        y <span class="ot">=</span> <span class="fu">f</span>(x)</span>
<span id="cb235-8"><a href="introduction.html#cb235-8" aria-hidden="true" tabindex="-1"></a>        g <span class="ot">=</span> first<span class="sc">$</span><span class="fu">gradient</span>(y, x)</span>
<span id="cb235-9"><a href="introduction.html#cb235-9" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb235-10"><a href="introduction.html#cb235-10" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb235-11"><a href="introduction.html#cb235-11" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb235-12"><a href="introduction.html#cb235-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb235-13"><a href="introduction.html#cb235-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-14"><a href="introduction.html#cb235-14" aria-hidden="true" tabindex="-1"></a>(second<span class="sc">$</span><span class="fu">gradient</span>(g, x))</span></code></pre></div>
<pre><code>## tf.Tensor(10.0, shape=(), dtype=float32)</code></pre>
<p>What is happening here? Think about and discuss it.</p>
<p>A more advanced example: <em>Linear regression</em></p>
<p>In this case we first simulate data following <span class="math inline">\(\boldsymbol{y} = \boldsymbol{X} \boldsymbol{w} + \boldsymbol{\epsilon}\)</span> (<span class="math inline">\(\boldsymbol{\epsilon}\)</span> follows a normal distribution == error).</p>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb237-1"><a href="introduction.html#cb237-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb237-2"><a href="introduction.html#cb237-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb237-3"><a href="introduction.html#cb237-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">round</span>(<span class="fu">runif</span>(<span class="dv">500</span>, <span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>), <span class="dv">3</span>), <span class="dv">100</span>, <span class="dv">5</span>)</span>
<span id="cb237-4"><a href="introduction.html#cb237-4" aria-hidden="true" tabindex="-1"></a>w <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="dv">5</span>, <span class="dv">2</span>, <span class="dv">1</span>), <span class="dv">3</span>)</span>
<span id="cb237-5"><a href="introduction.html#cb237-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> x <span class="sc">%*%</span> w <span class="sc">+</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="dv">0</span>, <span class="fl">0.25</span>), <span class="dv">4</span>)</span></code></pre></div>
<p>In R we would do the following to fit a linear regression model:</p>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb238-1"><a href="introduction.html#cb238-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.67893 -0.16399  0.00968  0.15058  0.51099 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 0.004865   0.027447   0.177     0.86    
## x1          2.191511   0.023243  94.287   &lt;2e-16 ***
## x2          2.741690   0.025328 108.249   &lt;2e-16 ***
## x3          1.179181   0.023644  49.872   &lt;2e-16 ***
## x4          0.591873   0.025154  23.530   &lt;2e-16 ***
## x5          2.302417   0.022575 101.991   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.2645 on 94 degrees of freedom
## Multiple R-squared:  0.9974, Adjusted R-squared:  0.9972 
## F-statistic:  7171 on 5 and 94 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Let’s build our own model in TensorFlow.
Here, we use now the variable data container type (remember they are mutable and we need this type for the weights (<span class="math inline">\(\boldsymbol{w}\)</span>) of the regression model). We want our model to learn these weights.</p>
<p>The input (predictors, independent variables or features, <span class="math inline">\(\boldsymbol{X}\)</span>) and the observed (response, <span class="math inline">\(\boldsymbol{y}\)</span>) are constant and will not be learned/optimized.</p>
<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb240-1"><a href="introduction.html#cb240-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb240-2"><a href="introduction.html#cb240-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb240-3"><a href="introduction.html#cb240-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb240-4"><a href="introduction.html#cb240-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb240-5"><a href="introduction.html#cb240-5" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">round</span>(<span class="fu">runif</span>(<span class="dv">500</span>, <span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>), <span class="dv">3</span>), <span class="dv">100</span>, <span class="dv">5</span>)</span>
<span id="cb240-6"><a href="introduction.html#cb240-6" aria-hidden="true" tabindex="-1"></a>w <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="dv">5</span>, <span class="dv">2</span>, <span class="dv">1</span>), <span class="dv">3</span>)</span>
<span id="cb240-7"><a href="introduction.html#cb240-7" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> x <span class="sc">%*%</span> w <span class="sc">+</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="dv">0</span>, <span class="fl">0.25</span>), <span class="dv">4</span>)</span>
<span id="cb240-8"><a href="introduction.html#cb240-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb240-9"><a href="introduction.html#cb240-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Weights we want to learn.</span></span>
<span id="cb240-10"><a href="introduction.html#cb240-10" aria-hidden="true" tabindex="-1"></a><span class="co"># We know the real weights but in reality we wouldn&#39;t know them.</span></span>
<span id="cb240-11"><a href="introduction.html#cb240-11" aria-hidden="true" tabindex="-1"></a><span class="co"># So use guessed ones.</span></span>
<span id="cb240-12"><a href="introduction.html#cb240-12" aria-hidden="true" tabindex="-1"></a>wTF <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">Variable</span>(<span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="dv">5</span>, <span class="dv">0</span>, <span class="fl">0.01</span>), <span class="dv">5</span>, <span class="dv">1</span>))</span>
<span id="cb240-13"><a href="introduction.html#cb240-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb240-14"><a href="introduction.html#cb240-14" aria-hidden="true" tabindex="-1"></a>xTF <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(x)</span>
<span id="cb240-15"><a href="introduction.html#cb240-15" aria-hidden="true" tabindex="-1"></a>yTF <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(y)</span>
<span id="cb240-16"><a href="introduction.html#cb240-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb240-17"><a href="introduction.html#cb240-17" aria-hidden="true" tabindex="-1"></a><span class="co"># We need an optimizer which updates the weights (wTF).</span></span>
<span id="cb240-18"><a href="introduction.html#cb240-18" aria-hidden="true" tabindex="-1"></a>optimizer <span class="ot">=</span> tf<span class="sc">$</span>keras<span class="sc">$</span>optimizers<span class="sc">$</span><span class="fu">Adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.1</span>)</span>
<span id="cb240-19"><a href="introduction.html#cb240-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb240-20"><a href="introduction.html#cb240-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>){</span>
<span id="cb240-21"><a href="introduction.html#cb240-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">with</span>(tf<span class="sc">$</span><span class="fu">GradientTape</span>() <span class="sc">%as%</span> tape,</span>
<span id="cb240-22"><a href="introduction.html#cb240-22" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb240-23"><a href="introduction.html#cb240-23" aria-hidden="true" tabindex="-1"></a>      pred <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">matmul</span>(xTF, wTF)</span>
<span id="cb240-24"><a href="introduction.html#cb240-24" aria-hidden="true" tabindex="-1"></a>      loss <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">sqrt</span>(tf<span class="sc">$</span><span class="fu">reduce_mean</span>(tf<span class="sc">$</span><span class="fu">square</span>(yTF <span class="sc">-</span> pred)))</span>
<span id="cb240-25"><a href="introduction.html#cb240-25" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb240-26"><a href="introduction.html#cb240-26" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb240-27"><a href="introduction.html#cb240-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb240-28"><a href="introduction.html#cb240-28" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="sc">!</span>i<span class="sc">%%</span><span class="dv">10</span>){ <span class="fu">k_print_tensor</span>(loss, <span class="at">message =</span> <span class="st">&quot;Loss: &quot;</span>) }  <span class="co"># Every 10 times.</span></span>
<span id="cb240-29"><a href="introduction.html#cb240-29" aria-hidden="true" tabindex="-1"></a>  grads <span class="ot">=</span> tape<span class="sc">$</span><span class="fu">gradient</span>(loss, wTF)</span>
<span id="cb240-30"><a href="introduction.html#cb240-30" aria-hidden="true" tabindex="-1"></a>  optimizer<span class="sc">$</span><span class="fu">apply_gradients</span>(purrr<span class="sc">::</span><span class="fu">transpose</span>(<span class="fu">list</span>(<span class="fu">list</span>(grads), <span class="fu">list</span>(wTF))))</span>
<span id="cb240-31"><a href="introduction.html#cb240-31" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb240-32"><a href="introduction.html#cb240-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb240-33"><a href="introduction.html#cb240-33" aria-hidden="true" tabindex="-1"></a><span class="fu">k_print_tensor</span>(wTF, <span class="at">message =</span> <span class="st">&quot;Resulting weights:</span><span class="sc">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<pre><code>## &lt;tf.Variable &#39;Variable:0&#39; shape=(5, 1) dtype=float64, numpy=
## array([[2.19290567],
##        [2.74534135],
##        [1.1714656 ],
##        [0.58811305],
##        [2.30174942]])&gt;</code></pre>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb242-1"><a href="introduction.html#cb242-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;Original weights: &quot;</span>, w, <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<pre><code>## Original weights:  2.217 2.719 1.165 0.593 2.303</code></pre>
<p>Discuss the code, go through the code line by line and try to understand it.</p>
<p>Additional exercise:</p>
<p>Play around with the simulation, increase/decrease the number of weights, add an intercept (you also need an additional variable in model).</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<div class="sourceCode" id="cb244"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb244-1"><a href="introduction.html#cb244-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb244-2"><a href="introduction.html#cb244-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb244-3"><a href="introduction.html#cb244-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb244-4"><a href="introduction.html#cb244-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb244-5"><a href="introduction.html#cb244-5" aria-hidden="true" tabindex="-1"></a>numberOfWeights <span class="ot">=</span> <span class="dv">3</span></span>
<span id="cb244-6"><a href="introduction.html#cb244-6" aria-hidden="true" tabindex="-1"></a>numberOfFeatures <span class="ot">=</span> <span class="dv">10000</span></span>
<span id="cb244-7"><a href="introduction.html#cb244-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb244-8"><a href="introduction.html#cb244-8" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">round</span>(<span class="fu">runif</span>(numberOfFeatures <span class="sc">*</span> numberOfWeights, <span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>), <span class="dv">3</span>),</span>
<span id="cb244-9"><a href="introduction.html#cb244-9" aria-hidden="true" tabindex="-1"></a>           numberOfFeatures, numberOfWeights)</span>
<span id="cb244-10"><a href="introduction.html#cb244-10" aria-hidden="true" tabindex="-1"></a>w <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(numberOfWeights, <span class="dv">2</span>, <span class="dv">1</span>), <span class="dv">3</span>)</span>
<span id="cb244-11"><a href="introduction.html#cb244-11" aria-hidden="true" tabindex="-1"></a>intercept <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="dv">1</span>, <span class="dv">3</span>, .<span class="dv">5</span>), <span class="dv">3</span>)</span>
<span id="cb244-12"><a href="introduction.html#cb244-12" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> intercept <span class="sc">+</span> x <span class="sc">%*%</span> w <span class="sc">+</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(numberOfFeatures, <span class="dv">0</span>, <span class="fl">0.25</span>), <span class="dv">4</span>)</span>
<span id="cb244-13"><a href="introduction.html#cb244-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb244-14"><a href="introduction.html#cb244-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Guessed weights and intercept.</span></span>
<span id="cb244-15"><a href="introduction.html#cb244-15" aria-hidden="true" tabindex="-1"></a>wTF <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">Variable</span>(<span class="fu">matrix</span>(<span class="fu">rnorm</span>(numberOfWeights, <span class="dv">0</span>, <span class="fl">0.01</span>), numberOfWeights, <span class="dv">1</span>))</span>
<span id="cb244-16"><a href="introduction.html#cb244-16" aria-hidden="true" tabindex="-1"></a>interceptTF <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">Variable</span>(<span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="dv">1</span>, <span class="dv">0</span>, .<span class="dv">5</span>)), <span class="dv">1</span>, <span class="dv">1</span>) <span class="co"># Double, not float32.</span></span>
<span id="cb244-17"><a href="introduction.html#cb244-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb244-18"><a href="introduction.html#cb244-18" aria-hidden="true" tabindex="-1"></a>xTF <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(x)</span>
<span id="cb244-19"><a href="introduction.html#cb244-19" aria-hidden="true" tabindex="-1"></a>yTF <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(y)</span>
<span id="cb244-20"><a href="introduction.html#cb244-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb244-21"><a href="introduction.html#cb244-21" aria-hidden="true" tabindex="-1"></a>optimizer <span class="ot">=</span> tf<span class="sc">$</span>keras<span class="sc">$</span>optimizers<span class="sc">$</span><span class="fu">Adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.05</span>)</span>
<span id="cb244-22"><a href="introduction.html#cb244-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb244-23"><a href="introduction.html#cb244-23" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>){</span>
<span id="cb244-24"><a href="introduction.html#cb244-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">with</span>(tf<span class="sc">$</span><span class="fu">GradientTape</span>(<span class="at">persistent =</span> <span class="cn">TRUE</span>) <span class="sc">%as%</span> tape,</span>
<span id="cb244-25"><a href="introduction.html#cb244-25" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb244-26"><a href="introduction.html#cb244-26" aria-hidden="true" tabindex="-1"></a>      pred <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">add</span>(interceptTF, tf<span class="sc">$</span><span class="fu">matmul</span>(xTF, wTF))</span>
<span id="cb244-27"><a href="introduction.html#cb244-27" aria-hidden="true" tabindex="-1"></a>      loss <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">sqrt</span>(tf<span class="sc">$</span><span class="fu">reduce_mean</span>(tf<span class="sc">$</span><span class="fu">square</span>(yTF <span class="sc">-</span> pred)))</span>
<span id="cb244-28"><a href="introduction.html#cb244-28" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb244-29"><a href="introduction.html#cb244-29" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb244-30"><a href="introduction.html#cb244-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb244-31"><a href="introduction.html#cb244-31" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="sc">!</span>i<span class="sc">%%</span><span class="dv">10</span>){ <span class="fu">k_print_tensor</span>(loss, <span class="at">message =</span> <span class="st">&quot;Loss: &quot;</span>) }  <span class="co"># Every 10 times.</span></span>
<span id="cb244-32"><a href="introduction.html#cb244-32" aria-hidden="true" tabindex="-1"></a>  grads <span class="ot">=</span> tape<span class="sc">$</span><span class="fu">gradient</span>(loss, wTF)</span>
<span id="cb244-33"><a href="introduction.html#cb244-33" aria-hidden="true" tabindex="-1"></a>  optimizer<span class="sc">$</span><span class="fu">apply_gradients</span>(purrr<span class="sc">::</span><span class="fu">transpose</span>(<span class="fu">list</span>(<span class="fu">list</span>(grads), <span class="fu">list</span>(wTF))))</span>
<span id="cb244-34"><a href="introduction.html#cb244-34" aria-hidden="true" tabindex="-1"></a>  grads <span class="ot">=</span> tape<span class="sc">$</span><span class="fu">gradient</span>(loss, interceptTF)</span>
<span id="cb244-35"><a href="introduction.html#cb244-35" aria-hidden="true" tabindex="-1"></a>  optimizer<span class="sc">$</span><span class="fu">apply_gradients</span>(purrr<span class="sc">::</span><span class="fu">transpose</span>(<span class="fu">list</span>(<span class="fu">list</span>(grads), <span class="fu">list</span>(interceptTF))))</span>
<span id="cb244-36"><a href="introduction.html#cb244-36" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb244-37"><a href="introduction.html#cb244-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb244-38"><a href="introduction.html#cb244-38" aria-hidden="true" tabindex="-1"></a><span class="fu">k_print_tensor</span>(wTF, <span class="at">message =</span> <span class="st">&quot;Resulting weights:</span><span class="sc">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<pre><code>## &lt;tf.Variable &#39;Variable:0&#39; shape=(3, 1) dtype=float64, numpy=
## array([[2.46391571],
##        [2.45852885],
##        [1.00566707]])&gt;</code></pre>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb246-1"><a href="introduction.html#cb246-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;Original weights: &quot;</span>, w, <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<pre><code>## Original weights:  2.47 2.465 1.003</code></pre>
<div class="sourceCode" id="cb248"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb248-1"><a href="introduction.html#cb248-1" aria-hidden="true" tabindex="-1"></a><span class="fu">k_print_tensor</span>(interceptTF, <span class="at">message =</span> <span class="st">&quot;Resulting intercept:</span><span class="sc">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<pre><code>## &lt;tf.Variable &#39;Variable:0&#39; shape=(1, 1) dtype=float64, numpy=array([[4.22135068]])&gt;</code></pre>
<div class="sourceCode" id="cb250"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb250-1"><a href="introduction.html#cb250-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;Original intercept: &quot;</span>, intercept, <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<pre><code>## Original intercept:  4.09</code></pre>
    </p>
  </details>
  <br/><hr/>
</div>
</div>
<div id="introduction-to-pytorch" class="section level2" number="3.5">
<h2><span class="header-section-number">3.5</span> Introduction to PyTorch</h2>
<p>PyTorch is another famous library for deep learning. Like TensorFlow, Torch itself is written in C++ with an API for Python. In 2020, the RStudio team released R-Torch, and while R-TensorFlow calls the Python API in the background, the R-Torch API is built directly on the C++ Torch library!</p>
<p>Useful links:</p>
<ul>
<li><a href="https://pytorch.org/docs/stable/index.html" target="_blank" rel="noopener">PyTorch documentation</a> (This is for the Python API, bust just replace the “.” with “$.”)</li>
<li><a href="https://torch.mlverse.org/" target="_blank" rel="noopener">R-Torch website</a></li>
</ul>
<p>To get started with Torch, we have to load the library and check if the installation worked.</p>
<div class="sourceCode" id="cb252"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb252-1"><a href="introduction.html#cb252-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span></code></pre></div>
<div id="pytorch-data-containers" class="section level3" number="3.5.1">
<h3><span class="header-section-number">3.5.1</span> PyTorch Data Containers</h3>
<p>Unlike TensorFlow, Torch doesn’t have two data containers for mutable and immutable variables. All variables are initialized via the torch_tensor function:</p>
<div class="sourceCode" id="cb253"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb253-1"><a href="introduction.html#cb253-1" aria-hidden="true" tabindex="-1"></a>a <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fl">1.</span>)</span></code></pre></div>
<p>To mark variables as mutable (and to track their operations for automatic differentiation) we have to set the argument ‘requires_grad’ to true in the torch_tensor function:</p>
<div class="sourceCode" id="cb254"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb254-1"><a href="introduction.html#cb254-1" aria-hidden="true" tabindex="-1"></a>mutable <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="dv">5</span>, <span class="at">requires_grad =</span> <span class="cn">TRUE</span>) <span class="co"># tf$Variable(...)</span></span>
<span id="cb254-2"><a href="introduction.html#cb254-2" aria-hidden="true" tabindex="-1"></a>immutable <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="dv">5</span>, <span class="at">requires_grad =</span> <span class="cn">FALSE</span>) <span class="co"># tf$constant(...)</span></span></code></pre></div>
</div>
<div id="basic-operations-1" class="section level3" number="3.5.2">
<h3><span class="header-section-number">3.5.2</span> Basic Operations</h3>
<p>We now can define the variables and do some math with them:</p>
<div class="sourceCode" id="cb255"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb255-1"><a href="introduction.html#cb255-1" aria-hidden="true" tabindex="-1"></a>a <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fl">5.</span>)</span>
<span id="cb255-2"><a href="introduction.html#cb255-2" aria-hidden="true" tabindex="-1"></a>b <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fl">10.</span>)</span>
<span id="cb255-3"><a href="introduction.html#cb255-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(a)</span></code></pre></div>
<pre><code>## torch_tensor
##  5
## [ CPUFloatType{1} ]</code></pre>
<div class="sourceCode" id="cb257"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb257-1"><a href="introduction.html#cb257-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(b)</span></code></pre></div>
<pre><code>## torch_tensor
##  10
## [ CPUFloatType{1} ]</code></pre>
<div class="sourceCode" id="cb259"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb259-1"><a href="introduction.html#cb259-1" aria-hidden="true" tabindex="-1"></a>c <span class="ot">=</span> a<span class="sc">$</span><span class="fu">add</span>(b)</span>
<span id="cb259-2"><a href="introduction.html#cb259-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(c)</span></code></pre></div>
<pre><code>## torch_tensor
##  15
## [ CPUFloatType{1} ]</code></pre>
<p>The R-Torch package provides all common methods (an advantage over TensorFlow).</p>
<div class="sourceCode" id="cb261"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb261-1"><a href="introduction.html#cb261-1" aria-hidden="true" tabindex="-1"></a>a <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fl">5.</span>)</span>
<span id="cb261-2"><a href="introduction.html#cb261-2" aria-hidden="true" tabindex="-1"></a>b <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fl">10.</span>)</span>
<span id="cb261-3"><a href="introduction.html#cb261-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(a<span class="sc">+</span>b)</span></code></pre></div>
<pre><code>## torch_tensor
##  15
## [ CPUFloatType{1} ]</code></pre>
<div class="sourceCode" id="cb263"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb263-1"><a href="introduction.html#cb263-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(a<span class="sc">/</span>b)</span></code></pre></div>
<pre><code>## torch_tensor
##  0.5000
## [ CPUFloatType{1} ]</code></pre>
<div class="sourceCode" id="cb265"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb265-1"><a href="introduction.html#cb265-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(a<span class="sc">*</span>b)</span></code></pre></div>
<pre><code>## torch_tensor
##  50
## [ CPUFloatType{1} ]</code></pre>
<p>Their operators also automatically transform R numbers into tensors when attempting to add a tensor to a R number:</p>
<div class="sourceCode" id="cb267"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb267-1"><a href="introduction.html#cb267-1" aria-hidden="true" tabindex="-1"></a>d <span class="ot">=</span> a <span class="sc">+</span> <span class="dv">5</span>  <span class="co"># 5 is automatically converted to a tensor.</span></span>
<span id="cb267-2"><a href="introduction.html#cb267-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(d)</span></code></pre></div>
<pre><code>## torch_tensor
##  10
## [ CPUFloatType{1} ]</code></pre>
<p>As for TensorFlow, we have to explicitly transform the tensors back to R:</p>
<div class="sourceCode" id="cb269"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb269-1"><a href="introduction.html#cb269-1" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(d)</span></code></pre></div>
<pre><code>## [1] &quot;torch_tensor&quot; &quot;R7&quot;</code></pre>
<div class="sourceCode" id="cb271"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb271-1"><a href="introduction.html#cb271-1" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(<span class="fu">as.numeric</span>(d))</span></code></pre></div>
<pre><code>## [1] &quot;numeric&quot;</code></pre>
</div>
<div id="torch-data-types---good-practice-with-r-torch" class="section level3" number="3.5.3">
<h3><span class="header-section-number">3.5.3</span> Torch Data Types - Good Practice With R-Torch</h3>
<p>Similar to TensorFlow:</p>
<div class="sourceCode" id="cb273"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb273-1"><a href="introduction.html#cb273-1" aria-hidden="true" tabindex="-1"></a>r_matrix <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(<span class="dv">10</span><span class="sc">*</span><span class="dv">10</span>), <span class="dv">10</span>, <span class="dv">10</span>)</span>
<span id="cb273-2"><a href="introduction.html#cb273-2" aria-hidden="true" tabindex="-1"></a>m <span class="ot">=</span> <span class="fu">torch_tensor</span>(r_matrix, <span class="at">dtype =</span> <span class="fu">torch_float32</span>()) </span>
<span id="cb273-3"><a href="introduction.html#cb273-3" aria-hidden="true" tabindex="-1"></a>b <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fl">2.0</span>, <span class="at">dtype =</span> <span class="fu">torch_float64</span>())</span>
<span id="cb273-4"><a href="introduction.html#cb273-4" aria-hidden="true" tabindex="-1"></a>c <span class="ot">=</span> m <span class="sc">/</span> b </span></code></pre></div>
<p>But here’s a difference! With TensorFlow we would get an error, but with R-Torch, m is automatically casted to a double (float64). However, this is still bad practice!</p>
<p>During the course we will try to provide the corresponding PyTorch code snippets for all Keras/TensorFlow examples.</p>
</div>
</div>
<div id="first-steps-with-the-keras-framework" class="section level2" number="3.6">
<h2><span class="header-section-number">3.6</span> First Steps With the Keras Framework</h2>
<p>We have seen that we can use TensorFlow directly out of R, and we could use this knowledge to implement a neural network in TensorFlow directly in R. However, this can be quite cumbersome. For simple problems, it is usually faster to use a higher-level API that helps us with implementing the machine learning models in TensorFlow. The most common of those is Keras.</p>
<p>Keras is a powerful framework for building and training neural networks with a few lines of codes. Since the end of 2018, Keras and TensorFlow are completely interoperable, allowing us to utilize the best of both.</p>
<p>The objective of this lesson is to familiarize yourself with Keras. If you have installed TensorFlow, Keras can be found within TensorFlow: tf.keras. However, the RStudio team has built an R package on top of tf.keras, and it is more convenient to use this. To load the Keras package, type</p>
<div class="sourceCode" id="cb274"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb274-1"><a href="introduction.html#cb274-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span></code></pre></div>
<div id="example-workflow-in-keras" class="section level3" number="3.6.1">
<h3><span class="header-section-number">3.6.1</span> Example Workflow in Keras</h3>
<p>To show how Keras works, we will now build a small classifier to predict the three species of the iris data set. Load the necessary packages and data sets:</p>
<div class="sourceCode" id="cb275"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb275-1"><a href="introduction.html#cb275-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb275-2"><a href="introduction.html#cb275-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb275-3"><a href="introduction.html#cb275-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb275-4"><a href="introduction.html#cb275-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb275-5"><a href="introduction.html#cb275-5" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(iris)</span>
<span id="cb275-6"><a href="introduction.html#cb275-6" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(iris)</span></code></pre></div>
<pre><code>##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species
## 1          5.1         3.5          1.4         0.2  setosa
## 2          4.9         3.0          1.4         0.2  setosa
## 3          4.7         3.2          1.3         0.2  setosa
## 4          4.6         3.1          1.5         0.2  setosa
## 5          5.0         3.6          1.4         0.2  setosa
## 6          5.4         3.9          1.7         0.4  setosa</code></pre>
<p>For neural networks, it is beneficial to scale the predictors (scaling = centering and standardization, see ?scale).
We also split our data into predictors (X) and response (Y = the three species).</p>
<div class="sourceCode" id="cb277"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb277-1"><a href="introduction.html#cb277-1" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">scale</span>(iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span>
<span id="cb277-2"><a href="introduction.html#cb277-2" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span> iris[,<span class="dv">5</span>]</span></code></pre></div>
<p>Additionally, Keras/TensorFlow cannot handle factors and we have to create contrasts (one-hot encoding).
To do so, we have to specify the number of categories. This can be tricky for a beginner, because in other programming languages like Python and C++, arrays start at zero. Thus, when we would specify 3 as number of classes for our three species, we would have the classes 0,1,2,3. Keep this in mind.</p>
<div class="sourceCode" id="cb278"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb278-1"><a href="introduction.html#cb278-1" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span> <span class="fu">to_categorical</span>(<span class="fu">as.integer</span>(Y) <span class="sc">-</span> 1L, <span class="dv">3</span>)</span>
<span id="cb278-2"><a href="introduction.html#cb278-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(Y) <span class="co"># 3 columns, one for each level of the response.</span></span></code></pre></div>
<pre><code>##      [,1] [,2] [,3]
## [1,]    1    0    0
## [2,]    1    0    0
## [3,]    1    0    0
## [4,]    1    0    0
## [5,]    1    0    0
## [6,]    1    0    0</code></pre>
<p>After having prepared the data, we will now see a typical workflow to specify a model in Keras.</p>
<p><strong>1. Initialize a sequential model in Keras:</strong></p>
<div class="sourceCode" id="cb280"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb280-1"><a href="introduction.html#cb280-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span></code></pre></div>
<p>A sequential Keras model is a higher order type of model within Keras and consists of one input and one output model.</p>
<p><strong>2. Add hidden layers to the model (we will learn more about hidden layers during the next days).</strong></p>
<p>When specifying the hidden layers, we also have to specify the shape and a so called <em>activation function</em>.
You can think of the activation function as decision for what is forwarded to the next neuron (but we will learn more about it later).
If you want to know this topic in even more depth, consider watching the videos presented in section <a href="introduction.html#basicMath">3.3</a>.</p>
<p>The shape of the input is the number of predictors (here 4) and the shape of the output is the number of classes (here 3).</p>
<div class="sourceCode" id="cb281"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb281-1"><a href="introduction.html#cb281-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb281-2"><a href="introduction.html#cb281-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(4L)) <span class="sc">%&gt;%</span></span>
<span id="cb281-3"><a href="introduction.html#cb281-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L) <span class="sc">%&gt;%</span></span>
<span id="cb281-4"><a href="introduction.html#cb281-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L) <span class="sc">%&gt;%</span></span>
<span id="cb281-5"><a href="introduction.html#cb281-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 3L, <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>) </span></code></pre></div>
<ul>
<li>softmax scales a potential multidimensional vector to the interval <span class="math inline">\((0, 1]\)</span> for each component. The sum of all components equals 1. This might be very useful for example for handling probabilities. <strong>Ensure ther the labels start at 0! Otherwise the softmax function does not work well!</strong></li>
</ul>
<details>
<summary>
<strong><span style="color: #CC2FAA;">Torch</span></strong>
</summary>
<p>
<p>The Torch syntax is very similar, we will give a list of layers to the “nn_sequential” function. Here, we have to specify the softmax activation function as an extra layer:</p>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb282-1"><a href="introduction.html#cb282-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb282-2"><a href="introduction.html#cb282-2" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_manual_seed</span>(321L)</span>
<span id="cb282-3"><a href="introduction.html#cb282-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb282-4"><a href="introduction.html#cb282-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb282-5"><a href="introduction.html#cb282-5" aria-hidden="true" tabindex="-1"></a>model_torch <span class="ot">=</span> </span>
<span id="cb282-6"><a href="introduction.html#cb282-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_sequential</span>(</span>
<span id="cb282-7"><a href="introduction.html#cb282-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(4L, 20L),</span>
<span id="cb282-8"><a href="introduction.html#cb282-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 20L),</span>
<span id="cb282-9"><a href="introduction.html#cb282-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 20L),</span>
<span id="cb282-10"><a href="introduction.html#cb282-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 3L),</span>
<span id="cb282-11"><a href="introduction.html#cb282-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_softmax</span>(<span class="dv">2</span>)</span>
<span id="cb282-12"><a href="introduction.html#cb282-12" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
</p>
</details>
<p><br/></p>
<p><strong>3. Compile the model with a loss function (here: cross entropy) and an optimizer (here: Adamax).</strong></p>
<p>We will learn about other options later, so for now, do not worry about the “<strong>learning_rate</strong>” (“<strong>lr</strong>” in Torch or earlier in TensorFlow) argument, cross entropy or the optimizer.</p>
<div class="sourceCode" id="cb283"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb283-1"><a href="introduction.html#cb283-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb283-2"><a href="introduction.html#cb283-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy,</span>
<span id="cb283-3"><a href="introduction.html#cb283-3" aria-hidden="true" tabindex="-1"></a>          keras<span class="sc">::</span><span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.001</span>))</span>
<span id="cb283-4"><a href="introduction.html#cb283-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## Model: &quot;sequential&quot;
## ______________________________________________________________________________________________________________________________
##  Layer (type)                                           Output Shape                                       Param #            
## ==============================================================================================================================
##  dense_3 (Dense)                                        (None, 20)                                         100                
##                                                                                                                               
##  dense_2 (Dense)                                        (None, 20)                                         420                
##                                                                                                                               
##  dense_1 (Dense)                                        (None, 20)                                         420                
##                                                                                                                               
##  dense (Dense)                                          (None, 3)                                          63                 
##                                                                                                                               
## ==============================================================================================================================
## Total params: 1,003
## Trainable params: 1,003
## Non-trainable params: 0
## ______________________________________________________________________________________________________________________________</code></pre>
<details>
<summary>
<strong><span style="color: #CC2FAA;">Torch</span></strong>
</summary>
<p>
<p>Specify optimizer and the parameters which will be trained (in our case the parameters of the network):</p>
<div class="sourceCode" id="cb285"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb285-1"><a href="introduction.html#cb285-1" aria-hidden="true" tabindex="-1"></a>optimizer_torch <span class="ot">=</span> <span class="fu">optim_adam</span>(<span class="at">params =</span> model_torch<span class="sc">$</span>parameters, <span class="at">lr =</span> <span class="fl">0.001</span>)</span></code></pre></div>
</p>
</details>
<p><br/></p>
<p><strong>4. Fit model in 30 iterations (epochs)</strong></p>
<div class="sourceCode" id="cb286"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb286-1"><a href="introduction.html#cb286-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb286-2"><a href="introduction.html#cb286-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb286-3"><a href="introduction.html#cb286-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb286-4"><a href="introduction.html#cb286-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb286-5"><a href="introduction.html#cb286-5" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb286-6"><a href="introduction.html#cb286-6" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb286-7"><a href="introduction.html#cb286-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> <span class="fu">apply</span>(Y, <span class="dv">2</span>, as.integer), <span class="at">epochs =</span> 30L,</span>
<span id="cb286-8"><a href="introduction.html#cb286-8" aria-hidden="true" tabindex="-1"></a>        <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<details>
<summary>
<strong><span style="color: #CC2FAA;">Torch</span></strong>
</summary>
<p>
<p>In Torch, we jump directly to the training loop, however, here we have to write our own training loop:</p>
<ol style="list-style-type: decimal">
<li>Get a batch of data.
<ol start="2" style="list-style-type: decimal">
<li>Predict on batch.</li>
<li>Ccalculate loss between predictions and true labels.</li>
<li>Backpropagate error.</li>
<li>Update weights.</li>
<li>Go to step 1 and repeat.</li>
</ol></li>
</ol>
<div class="sourceCode" id="cb287"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb287-1"><a href="introduction.html#cb287-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb287-2"><a href="introduction.html#cb287-2" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_manual_seed</span>(321L)</span>
<span id="cb287-3"><a href="introduction.html#cb287-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb287-4"><a href="introduction.html#cb287-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb287-5"><a href="introduction.html#cb287-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate number of training steps.</span></span>
<span id="cb287-6"><a href="introduction.html#cb287-6" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> <span class="dv">30</span></span>
<span id="cb287-7"><a href="introduction.html#cb287-7" aria-hidden="true" tabindex="-1"></a>batch_size <span class="ot">=</span> <span class="dv">20</span></span>
<span id="cb287-8"><a href="introduction.html#cb287-8" aria-hidden="true" tabindex="-1"></a>steps <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">nrow</span>(X)<span class="sc">/</span>batch_size <span class="sc">*</span> epochs)</span>
<span id="cb287-9"><a href="introduction.html#cb287-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb287-10"><a href="introduction.html#cb287-10" aria-hidden="true" tabindex="-1"></a>X_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(X)</span>
<span id="cb287-11"><a href="introduction.html#cb287-11" aria-hidden="true" tabindex="-1"></a>Y_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fu">apply</span>(Y, <span class="dv">1</span>, which.max)) </span>
<span id="cb287-12"><a href="introduction.html#cb287-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb287-13"><a href="introduction.html#cb287-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Set model into training status.</span></span>
<span id="cb287-14"><a href="introduction.html#cb287-14" aria-hidden="true" tabindex="-1"></a>model_torch<span class="sc">$</span><span class="fu">train</span>()</span>
<span id="cb287-15"><a href="introduction.html#cb287-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb287-16"><a href="introduction.html#cb287-16" aria-hidden="true" tabindex="-1"></a>log_losses <span class="ot">=</span> <span class="cn">NULL</span></span>
<span id="cb287-17"><a href="introduction.html#cb287-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb287-18"><a href="introduction.html#cb287-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Training loop.</span></span>
<span id="cb287-19"><a href="introduction.html#cb287-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>steps){</span>
<span id="cb287-20"><a href="introduction.html#cb287-20" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Get batch.</span></span>
<span id="cb287-21"><a href="introduction.html#cb287-21" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(X), batch_size)</span>
<span id="cb287-22"><a href="introduction.html#cb287-22" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb287-23"><a href="introduction.html#cb287-23" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Reset backpropagation.</span></span>
<span id="cb287-24"><a href="introduction.html#cb287-24" aria-hidden="true" tabindex="-1"></a>  optimizer_torch<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb287-25"><a href="introduction.html#cb287-25" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb287-26"><a href="introduction.html#cb287-26" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Predict and calculate loss.</span></span>
<span id="cb287-27"><a href="introduction.html#cb287-27" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">=</span> <span class="fu">model_torch</span>(X_torch[indices, ])</span>
<span id="cb287-28"><a href="introduction.html#cb287-28" aria-hidden="true" tabindex="-1"></a>  loss <span class="ot">=</span> <span class="fu">nnf_cross_entropy</span>(pred, Y_torch[indices])</span>
<span id="cb287-29"><a href="introduction.html#cb287-29" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb287-30"><a href="introduction.html#cb287-30" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Backpropagation and weight update.</span></span>
<span id="cb287-31"><a href="introduction.html#cb287-31" aria-hidden="true" tabindex="-1"></a>  loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb287-32"><a href="introduction.html#cb287-32" aria-hidden="true" tabindex="-1"></a>  optimizer_torch<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb287-33"><a href="introduction.html#cb287-33" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb287-34"><a href="introduction.html#cb287-34" aria-hidden="true" tabindex="-1"></a>  log_losses[i] <span class="ot">=</span> <span class="fu">as.numeric</span>(loss)</span>
<span id="cb287-35"><a href="introduction.html#cb287-35" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
</p>
</details>
<p><br/></p>
<p><strong>5. Plot training history:</strong></p>
<div class="sourceCode" id="cb288"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb288-1"><a href="introduction.html#cb288-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_72-1.png" width="672" /></p>
<details>
<summary>
<strong><span style="color: #CC2FAA;">Torch</span></strong>
</summary>
<p>
<div class="sourceCode" id="cb289"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb289-1"><a href="introduction.html#cb289-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(log_losses, <span class="at">xlab =</span> <span class="st">&quot;steps&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;loss&quot;</span>, <span class="at">las =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_73-1.png" width="672" /></p>
</p>
</details>
<p><br/></p>
<p><strong>6. Create predictions:</strong></p>
<div class="sourceCode" id="cb290"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb290-1"><a href="introduction.html#cb290-1" aria-hidden="true" tabindex="-1"></a>predictions <span class="ot">=</span> <span class="fu">predict</span>(model, X) <span class="co"># Probabilities for each class.</span></span></code></pre></div>
<p>Get probabilities:</p>
<div class="sourceCode" id="cb291"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb291-1"><a href="introduction.html#cb291-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(predictions) <span class="co"># Quasi-probabilities for each species.</span></span></code></pre></div>
<pre><code>##           [,1]       [,2]        [,3]
## [1,] 0.9819264 0.01476339 0.003310233
## [2,] 0.9563531 0.03986334 0.003783490
## [3,] 0.9830713 0.01501246 0.001916326
## [4,] 0.9789234 0.01915257 0.001923954
## [5,] 0.9871404 0.01057777 0.002281805
## [6,] 0.9808626 0.01525487 0.003882427</code></pre>
<p>For each plant, we want to know for which species we got the highest probability:</p>
<div class="sourceCode" id="cb293"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb293-1"><a href="introduction.html#cb293-1" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">=</span> <span class="fu">apply</span>(predictions, <span class="dv">1</span>, which.max) </span>
<span id="cb293-2"><a href="introduction.html#cb293-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(preds)</span></code></pre></div>
<pre><code>##   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 3 2 3 2 3 2 2 2
##  [61] 2 3 2 3 2 3 3 2 2 2 3 2 2 2 2 3 3 3 3 2 2 2 2 3 2 3 3 2 2 2 2 3 2 2 2 2 2 2 2 2 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 2
## [121] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3</code></pre>
<details>
<summary>
<strong><span style="color: #CC2FAA;">Torch</span></strong>
</summary>
<p>
<div class="sourceCode" id="cb295"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb295-1"><a href="introduction.html#cb295-1" aria-hidden="true" tabindex="-1"></a>model_torch<span class="sc">$</span><span class="fu">eval</span>()</span>
<span id="cb295-2"><a href="introduction.html#cb295-2" aria-hidden="true" tabindex="-1"></a>preds_torch <span class="ot">=</span> <span class="fu">model_torch</span>(<span class="fu">torch_tensor</span>(X))</span>
<span id="cb295-3"><a href="introduction.html#cb295-3" aria-hidden="true" tabindex="-1"></a>preds_torch <span class="ot">=</span> <span class="fu">apply</span>(preds_torch, <span class="dv">1</span>, which.max) </span>
<span id="cb295-4"><a href="introduction.html#cb295-4" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(preds_torch)</span></code></pre></div>
<pre><code>##   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 2 3 2 2 2 3 2 2 2
##  [61] 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 2
## [121] 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3</code></pre>
<div class="sourceCode" id="cb297"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb297-1"><a href="introduction.html#cb297-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(preds_torch <span class="sc">==</span> <span class="fu">as.integer</span>(iris<span class="sc">$</span>Species))</span></code></pre></div>
<pre><code>## [1] 0.9333333</code></pre>
</p>
</details>
<p><br/></p>
<p><strong>7. Calculate Accuracy (how often we have been correct):</strong></p>
<div class="sourceCode" id="cb299"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb299-1"><a href="introduction.html#cb299-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(preds <span class="sc">==</span> <span class="fu">as.integer</span>(iris<span class="sc">$</span>Species))</span></code></pre></div>
<pre><code>## [1] 0.8666667</code></pre>
<p><strong>8. Plot predictions, to see if we have done a good job:</strong></p>
<div class="sourceCode" id="cb301"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb301-1"><a href="introduction.html#cb301-1" aria-hidden="true" tabindex="-1"></a>oldpar <span class="ot">=</span> <span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb301-2"><a href="introduction.html#cb301-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(iris<span class="sc">$</span>Sepal.Length, iris<span class="sc">$</span>Petal.Length, <span class="at">col =</span> iris<span class="sc">$</span>Species,</span>
<span id="cb301-3"><a href="introduction.html#cb301-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;Observed&quot;</span>)</span>
<span id="cb301-4"><a href="introduction.html#cb301-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(iris<span class="sc">$</span>Sepal.Length, iris<span class="sc">$</span>Petal.Length, <span class="at">col =</span> preds,</span>
<span id="cb301-5"><a href="introduction.html#cb301-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;Predicted&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_79-1.png" width="672" /></p>
<div class="sourceCode" id="cb302"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb302-1"><a href="introduction.html#cb302-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(oldpar)   <span class="co"># Reset par.</span></span></code></pre></div>
<p>So you see, building a neural network is very easy with Keras and you can already do it on your own.</p>
  <hr/>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Questions</span></strong>
    </summary>
    <p>
      <script>
        makeMultipleChoiceForm(
         'Have a look at the following two textbooks on machine learning (&apos;<a href="https://www.statlearning.com/" target="_blank" rel="noopener">An Introduction to Statistical Learning</a>&apos; and &apos;<a href="https://web.stanford.edu/~hastie/ElemStatLearn/" target="_blank" rel="noopener">The Elements of Statistical Learning</a>&apos;) - Which of the following statements is true?',
          'checkbox',
          [
            {
              'answer':'Both books can be downloaded for free.',
              'correct':true,
              'explanationIfSelected':'',
              'explanationIfNotSelected':'',
              'explanationGeneral':''
            },
            {
              'answer':'The elements of Statistical Learning was published earlier than the Introduction to Statistical Learning.',
              'correct':true,
              'explanationIfSelected':'',
              'explanationIfNotSelected':'',
              'explanationGeneral':''
            },
            {
              'answer':'The book "an Introduction to Statistical Learning" also includes an online course with videos to the different topics on their website.',
              'correct':true,
              'explanationIfSelected':'',
              'explanationIfNotSelected':'',
              'explanationGeneral':''
            },
            {
              'answer':'Higher model complexity is always better for predicting.',
              'correct':false,
              'explanationIfSelected':'',
              'explanationIfNotSelected':'',
              'explanationGeneral':''
            }
          ],
          ''
        );
      </script>
      
      <img src="images/biasVarianceTradeoff.png" alt="bias variance tradeoff">
      <script>
        makeMultipleChoiceForm(
          'Which of the following statements about the bias-variance trade-off is correct?',
          'checkbox',
          [
            {
              'answer':'The goal of considering the bias-variance trade-off is to get the bias of the model as small as possible.',
              'correct':false,
              'explanationIfSelected':'',
              'explanationIfNotSelected':'',
              'explanationGeneral':''
            },
            {
              'answer':'The goal of considering the bias-variance trade-off is to realize that increasing complexity typically leads to more flexibility (allowing you to reduce bias) but at the cost of uncertainty (variance) in the estimated parameters.',
              'correct':true,
              'explanationIfSelected':'',
              'explanationIfNotSelected':'',
              'explanationGeneral':''
            },
            {
             'answer':'Through the bias-variance trade-off, we see that model complexity also depends on what we want to optimize for: bias, variance (rarely), or total error of the model.',
              'correct':true,
              'explanationIfSelected':'',
              'explanationIfNotSelected':'',
              'explanationGeneral':''
            }
          ],
          ''
        );
      </script>
    </p>
  </details>
  <hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<p>We will now build a regression for the airquality data set with Keras. We want to predict the variable “Ozone.”</p>
<ol start="0" style="list-style-type: decimal">
<li>Load and prepare the data set:</li>
</ol>
<div class="sourceCode" id="cb303"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb303-1"><a href="introduction.html#cb303-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb303-2"><a href="introduction.html#cb303-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb303-3"><a href="introduction.html#cb303-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb303-4"><a href="introduction.html#cb303-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb303-5"><a href="introduction.html#cb303-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality</span></code></pre></div>
<p>Explore the data with summary() and plot():</p>
<div class="sourceCode" id="cb304"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb304-1"><a href="introduction.html#cb304-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(data)</span></code></pre></div>
<pre><code>##      Ozone           Solar.R           Wind             Temp           Month            Day      
##  Min.   :  1.00   Min.   :  7.0   Min.   : 1.700   Min.   :56.00   Min.   :5.000   Min.   : 1.0  
##  1st Qu.: 18.00   1st Qu.:115.8   1st Qu.: 7.400   1st Qu.:72.00   1st Qu.:6.000   1st Qu.: 8.0  
##  Median : 31.50   Median :205.0   Median : 9.700   Median :79.00   Median :7.000   Median :16.0  
##  Mean   : 42.13   Mean   :185.9   Mean   : 9.958   Mean   :77.88   Mean   :6.993   Mean   :15.8  
##  3rd Qu.: 63.25   3rd Qu.:258.8   3rd Qu.:11.500   3rd Qu.:85.00   3rd Qu.:8.000   3rd Qu.:23.0  
##  Max.   :168.00   Max.   :334.0   Max.   :20.700   Max.   :97.00   Max.   :9.000   Max.   :31.0  
##  NA&#39;s   :37       NA&#39;s   :7</code></pre>
<div class="sourceCode" id="cb306"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb306-1"><a href="introduction.html#cb306-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(data)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_task_27-1.png" width="672" /></p>
<ol style="list-style-type: decimal">
<li><p>There are NAs in the data, which we have to remove because Keras cannot handle NAs.
If you don’t know how to remove NAs from a data.frame, use Google (e.g. with the query: “remove-rows-with-all-or-some-nas-missing-values-in-data-frame”).</p></li>
<li><p>Split the data in predictors (<span class="math inline">\(\boldsymbol{X}\)</span>) and response (<span class="math inline">\(\boldsymbol{y}\)</span>, Ozone) and scale the <span class="math inline">\(\boldsymbol{X}\)</span> matrix.</p></li>
<li><p>Build a sequential Keras model.</p></li>
<li><p>Add hidden layers (input and output layer are already specified, you have to add hidden layers between them):</p></li>
</ol>
<div class="sourceCode" id="cb307"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb307-1"><a href="introduction.html#cb307-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb307-2"><a href="introduction.html#cb307-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(5L)) <span class="sc">%&gt;%</span></span>
<span id="cb307-3"><a href="introduction.html#cb307-3" aria-hidden="true" tabindex="-1"></a>   ....</span>
<span id="cb307-4"><a href="introduction.html#cb307-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;linear&quot;</span>)</span></code></pre></div>
<ul>
<li>Why do we use 5L as input shape?</li>
<li>Why only one output node and “linear” activation layer?</li>
</ul>
<ol start="5" style="list-style-type: decimal">
<li>Compile model.</li>
</ol>
<div class="sourceCode" id="cb308"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb308-1"><a href="introduction.html#cb308-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb308-2"><a href="introduction.html#cb308-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.05</span>))</span></code></pre></div>
<p>What is the “mean_squared_error” loss?</p>
<ol start="6" style="list-style-type: decimal">
<li>Fit model:</li>
</ol>
<p>Tip: Only matrices are accepted for <span class="math inline">\(\boldsymbol{X}\)</span> and <span class="math inline">\(\boldsymbol{y}\)</span> by Keras. R often drops a one column matrix into a vector (change it back to a matrix!)</p>
<ol start="7" style="list-style-type: decimal">
<li><p>Plot training history.</p></li>
<li><p>Create predictions.</p></li>
<li><p>Compare your Keras model with a linear model:</p></li>
</ol>
<div class="sourceCode" id="cb309"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb309-1"><a href="introduction.html#cb309-1" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">lm</span>(Ozone <span class="sc">~</span> ., <span class="at">data =</span> data)</span>
<span id="cb309-2"><a href="introduction.html#cb309-2" aria-hidden="true" tabindex="-1"></a>pred_lm <span class="ot">=</span> <span class="fu">predict</span>(fit, data)</span>
<span id="cb309-3"><a href="introduction.html#cb309-3" aria-hidden="true" tabindex="-1"></a>rmse_lm <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_lm)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb309-4"><a href="introduction.html#cb309-4" aria-hidden="true" tabindex="-1"></a>rmse_keras <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_keras)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb309-5"><a href="introduction.html#cb309-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_lm)</span>
<span id="cb309-6"><a href="introduction.html#cb309-6" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_keras)</span></code></pre></div>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<div class="sourceCode" id="cb310"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb310-1"><a href="introduction.html#cb310-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality</span></code></pre></div>
<p><strong>1. There are NAs in the data, which we have to remove because Keras cannot handle NAs.</strong></p>
<div class="sourceCode" id="cb311"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb311-1"><a href="introduction.html#cb311-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> data[<span class="fu">complete.cases</span>(data),]  <span class="co"># Remove NAs.</span></span>
<span id="cb311-2"><a href="introduction.html#cb311-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(data)</span></code></pre></div>
<pre><code>##      Ozone          Solar.R           Wind            Temp           Month            Day       
##  Min.   :  1.0   Min.   :  7.0   Min.   : 2.30   Min.   :57.00   Min.   :5.000   Min.   : 1.00  
##  1st Qu.: 18.0   1st Qu.:113.5   1st Qu.: 7.40   1st Qu.:71.00   1st Qu.:6.000   1st Qu.: 9.00  
##  Median : 31.0   Median :207.0   Median : 9.70   Median :79.00   Median :7.000   Median :16.00  
##  Mean   : 42.1   Mean   :184.8   Mean   : 9.94   Mean   :77.79   Mean   :7.216   Mean   :15.95  
##  3rd Qu.: 62.0   3rd Qu.:255.5   3rd Qu.:11.50   3rd Qu.:84.50   3rd Qu.:9.000   3rd Qu.:22.50  
##  Max.   :168.0   Max.   :334.0   Max.   :20.70   Max.   :97.00   Max.   :9.000   Max.   :31.00</code></pre>
<p><strong>2. Split the data in predictors and response and scale the matrix.</strong></p>
<div class="sourceCode" id="cb313"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb313-1"><a href="introduction.html#cb313-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="dv">2</span><span class="sc">:</span><span class="dv">6</span>])</span>
<span id="cb313-2"><a href="introduction.html#cb313-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> data[,<span class="dv">1</span>]</span></code></pre></div>
<p><strong>3. Build sequential Keras model.</strong></p>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb314-1"><a href="introduction.html#cb314-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb314-2"><a href="introduction.html#cb314-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb314-3"><a href="introduction.html#cb314-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb314-4"><a href="introduction.html#cb314-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb314-5"><a href="introduction.html#cb314-5" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span></code></pre></div>
<p><strong>4. Add hidden layers (input and output layer are already specified, you have to add hidden layers between them).</strong></p>
<div class="sourceCode" id="cb315"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb315-1"><a href="introduction.html#cb315-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb315-2"><a href="introduction.html#cb315-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(5L)) <span class="sc">%&gt;%</span></span>
<span id="cb315-3"><a href="introduction.html#cb315-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L) <span class="sc">%&gt;%</span></span>
<span id="cb315-4"><a href="introduction.html#cb315-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L) <span class="sc">%&gt;%</span></span>
<span id="cb315-5"><a href="introduction.html#cb315-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;linear&quot;</span>)</span></code></pre></div>
<p>We use 5L as input shape, because we have 5 predictors. Analogously, we use 1L for our 1d response.
Because we do not want any compression, dilation or other nonlinear effects, we use the simple linear layer (equal to no activation function at all). For more about activation functions, look for example <a href="https://en.wikipedia.org/wiki/Activation_function" target="_blank" rel="noopener">here</a>. Or wait for the next days.
You may also have seen the previously shown link <a href="https://mlfromscratch.com/activation-functions-explained/#/" target="_blank" rel="noopener">about activation functions in more detail</a>.</p>
<p><strong>5. Compile model.</strong></p>
<div class="sourceCode" id="cb316"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb316-1"><a href="introduction.html#cb316-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb316-2"><a href="introduction.html#cb316-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.05</span>))</span></code></pre></div>
<p>The mean_squared_error is the ordinary least squares approach in regression analysis.</p>
<p><strong>6. Fit model.</strong></p>
<div class="sourceCode" id="cb317"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb317-1"><a href="introduction.html#cb317-1" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb317-2"><a href="introduction.html#cb317-2" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb317-3"><a href="introduction.html#cb317-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> x, <span class="at">y =</span> <span class="fu">matrix</span>(y, <span class="at">ncol =</span> 1L), <span class="at">epochs =</span> 100L,</span>
<span id="cb317-4"><a href="introduction.html#cb317-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><strong>7. Plot training history.</strong></p>
<div class="sourceCode" id="cb318"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb318-1"><a href="introduction.html#cb318-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_task_38-1.png" width="672" /></p>
<div class="sourceCode" id="cb319"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb319-1"><a href="introduction.html#cb319-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb319-2"><a href="introduction.html#cb319-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">evaluate</span>(x, y)</span></code></pre></div>
<pre><code>##     loss 
## 173.4729</code></pre>
<p><strong>8. Create predictions.</strong></p>
<div class="sourceCode" id="cb321"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb321-1"><a href="introduction.html#cb321-1" aria-hidden="true" tabindex="-1"></a>pred_keras <span class="ot">=</span> <span class="fu">predict</span>(model, x)</span></code></pre></div>
<p><strong>9. Compare Keras model with a linear model.</strong></p>
<div class="sourceCode" id="cb322"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb322-1"><a href="introduction.html#cb322-1" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">lm</span>(Ozone <span class="sc">~</span> ., <span class="at">data =</span> data)</span>
<span id="cb322-2"><a href="introduction.html#cb322-2" aria-hidden="true" tabindex="-1"></a>pred_lm <span class="ot">=</span> <span class="fu">predict</span>(fit, data)</span>
<span id="cb322-3"><a href="introduction.html#cb322-3" aria-hidden="true" tabindex="-1"></a>rmse_lm <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_lm)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb322-4"><a href="introduction.html#cb322-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb322-5"><a href="introduction.html#cb322-5" aria-hidden="true" tabindex="-1"></a>rmse_keras <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_keras)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb322-6"><a href="introduction.html#cb322-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb322-7"><a href="introduction.html#cb322-7" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_lm)</span></code></pre></div>
<pre><code>## [1] 14.78897</code></pre>
<div class="sourceCode" id="cb324"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb324-1"><a href="introduction.html#cb324-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_keras)</span></code></pre></div>
<pre><code>## [1] 9.621961</code></pre>
<p><strong>Look at this slightly more complex model and compare the loss plot and the accuracy in contrast to the former.</strong></p>
<div class="sourceCode" id="cb326"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb326-1"><a href="introduction.html#cb326-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb326-2"><a href="introduction.html#cb326-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb326-3"><a href="introduction.html#cb326-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb326-4"><a href="introduction.html#cb326-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb326-5"><a href="introduction.html#cb326-5" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb326-6"><a href="introduction.html#cb326-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb326-7"><a href="introduction.html#cb326-7" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb326-8"><a href="introduction.html#cb326-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(5L)) <span class="sc">%&gt;%</span></span>
<span id="cb326-9"><a href="introduction.html#cb326-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L) <span class="sc">%&gt;%</span></span>
<span id="cb326-10"><a href="introduction.html#cb326-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 30L) <span class="sc">%&gt;%</span></span>
<span id="cb326-11"><a href="introduction.html#cb326-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L) <span class="sc">%&gt;%</span></span>
<span id="cb326-12"><a href="introduction.html#cb326-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;linear&quot;</span>)</span>
<span id="cb326-13"><a href="introduction.html#cb326-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb326-14"><a href="introduction.html#cb326-14" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb326-15"><a href="introduction.html#cb326-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.05</span>))</span>
<span id="cb326-16"><a href="introduction.html#cb326-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb326-17"><a href="introduction.html#cb326-17" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb326-18"><a href="introduction.html#cb326-18" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb326-19"><a href="introduction.html#cb326-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> x, <span class="at">y =</span> <span class="fu">matrix</span>(y, <span class="at">ncol =</span> 1L), <span class="at">epochs =</span> 100L,</span>
<span id="cb326-20"><a href="introduction.html#cb326-20" aria-hidden="true" tabindex="-1"></a>      <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb326-21"><a href="introduction.html#cb326-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb326-22"><a href="introduction.html#cb326-22" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_task_41-1.png" width="672" /></p>
<div class="sourceCode" id="cb327"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb327-1"><a href="introduction.html#cb327-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb327-2"><a href="introduction.html#cb327-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">evaluate</span>(x, y)</span></code></pre></div>
<pre><code>##     loss 
## 105.1682</code></pre>
<div class="sourceCode" id="cb329"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb329-1"><a href="introduction.html#cb329-1" aria-hidden="true" tabindex="-1"></a>pred_keras <span class="ot">=</span> <span class="fu">predict</span>(model, x)</span>
<span id="cb329-2"><a href="introduction.html#cb329-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb329-3"><a href="introduction.html#cb329-3" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">lm</span>(Ozone <span class="sc">~</span> ., <span class="at">data =</span> data)</span>
<span id="cb329-4"><a href="introduction.html#cb329-4" aria-hidden="true" tabindex="-1"></a>pred_lm <span class="ot">=</span> <span class="fu">predict</span>(fit, data)</span>
<span id="cb329-5"><a href="introduction.html#cb329-5" aria-hidden="true" tabindex="-1"></a>rmse_lm <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_lm)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb329-6"><a href="introduction.html#cb329-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb329-7"><a href="introduction.html#cb329-7" aria-hidden="true" tabindex="-1"></a>rmse_keras <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_keras)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb329-8"><a href="introduction.html#cb329-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb329-9"><a href="introduction.html#cb329-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_lm)</span></code></pre></div>
<pre><code>## [1] 14.78897</code></pre>
<div class="sourceCode" id="cb331"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb331-1"><a href="introduction.html#cb331-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_keras)</span></code></pre></div>
<pre><code>## [1] 7.798208</code></pre>
<p>You see, the more complex model works better, because it can learn the coherences better.
But keep the overfitting problem in mind!</p>
<p><strong>Look at the little change in learning rates for the next 2 models and compare the loss plot and the accuracy in contrast to the former.</strong></p>
<div class="sourceCode" id="cb333"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb333-1"><a href="introduction.html#cb333-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb333-2"><a href="introduction.html#cb333-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb333-3"><a href="introduction.html#cb333-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb333-4"><a href="introduction.html#cb333-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb333-5"><a href="introduction.html#cb333-5" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb333-6"><a href="introduction.html#cb333-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb333-7"><a href="introduction.html#cb333-7" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb333-8"><a href="introduction.html#cb333-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(5L)) <span class="sc">%&gt;%</span></span>
<span id="cb333-9"><a href="introduction.html#cb333-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L) <span class="sc">%&gt;%</span></span>
<span id="cb333-10"><a href="introduction.html#cb333-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 30L) <span class="sc">%&gt;%</span></span>
<span id="cb333-11"><a href="introduction.html#cb333-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L) <span class="sc">%&gt;%</span></span>
<span id="cb333-12"><a href="introduction.html#cb333-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;linear&quot;</span>)</span>
<span id="cb333-13"><a href="introduction.html#cb333-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb333-14"><a href="introduction.html#cb333-14" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb333-15"><a href="introduction.html#cb333-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.1</span>))</span>
<span id="cb333-16"><a href="introduction.html#cb333-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb333-17"><a href="introduction.html#cb333-17" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb333-18"><a href="introduction.html#cb333-18" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb333-19"><a href="introduction.html#cb333-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> x, <span class="at">y =</span> <span class="fu">matrix</span>(y, <span class="at">ncol =</span> 1L), <span class="at">epochs =</span> 100L,</span>
<span id="cb333-20"><a href="introduction.html#cb333-20" aria-hidden="true" tabindex="-1"></a>      <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb333-21"><a href="introduction.html#cb333-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb333-22"><a href="introduction.html#cb333-22" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_task_42-1.png" width="672" /></p>
<div class="sourceCode" id="cb334"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb334-1"><a href="introduction.html#cb334-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb334-2"><a href="introduction.html#cb334-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">evaluate</span>(x, y)</span></code></pre></div>
<pre><code>##     loss 
## 116.6115</code></pre>
<div class="sourceCode" id="cb336"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb336-1"><a href="introduction.html#cb336-1" aria-hidden="true" tabindex="-1"></a>pred_keras <span class="ot">=</span> <span class="fu">predict</span>(model, x)</span>
<span id="cb336-2"><a href="introduction.html#cb336-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb336-3"><a href="introduction.html#cb336-3" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">lm</span>(Ozone <span class="sc">~</span> ., <span class="at">data =</span> data)</span>
<span id="cb336-4"><a href="introduction.html#cb336-4" aria-hidden="true" tabindex="-1"></a>pred_lm <span class="ot">=</span> <span class="fu">predict</span>(fit, data)</span>
<span id="cb336-5"><a href="introduction.html#cb336-5" aria-hidden="true" tabindex="-1"></a>rmse_lm <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_lm)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb336-6"><a href="introduction.html#cb336-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb336-7"><a href="introduction.html#cb336-7" aria-hidden="true" tabindex="-1"></a>rmse_keras <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_keras)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb336-8"><a href="introduction.html#cb336-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb336-9"><a href="introduction.html#cb336-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_lm)</span></code></pre></div>
<pre><code>## [1] 14.78897</code></pre>
<div class="sourceCode" id="cb338"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb338-1"><a href="introduction.html#cb338-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_keras)</span></code></pre></div>
<pre><code>## [1] 8.247861</code></pre>
<p>You can see, the higher learning rate yields a little bit worse results. The optimum is jumped over.</p>
<div class="sourceCode" id="cb340"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb340-1"><a href="introduction.html#cb340-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb340-2"><a href="introduction.html#cb340-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb340-3"><a href="introduction.html#cb340-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb340-4"><a href="introduction.html#cb340-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb340-5"><a href="introduction.html#cb340-5" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb340-6"><a href="introduction.html#cb340-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb340-7"><a href="introduction.html#cb340-7" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb340-8"><a href="introduction.html#cb340-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(5L)) <span class="sc">%&gt;%</span></span>
<span id="cb340-9"><a href="introduction.html#cb340-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L) <span class="sc">%&gt;%</span></span>
<span id="cb340-10"><a href="introduction.html#cb340-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 30L) <span class="sc">%&gt;%</span></span>
<span id="cb340-11"><a href="introduction.html#cb340-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L) <span class="sc">%&gt;%</span></span>
<span id="cb340-12"><a href="introduction.html#cb340-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="st">&quot;linear&quot;</span>)</span>
<span id="cb340-13"><a href="introduction.html#cb340-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb340-14"><a href="introduction.html#cb340-14" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb340-15"><a href="introduction.html#cb340-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_mean_squared_error, <span class="fu">optimizer_adamax</span>(<span class="at">learning_rate =</span> <span class="fl">0.01</span>))</span>
<span id="cb340-16"><a href="introduction.html#cb340-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb340-17"><a href="introduction.html#cb340-17" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb340-18"><a href="introduction.html#cb340-18" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb340-19"><a href="introduction.html#cb340-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">x =</span> x, <span class="at">y =</span> <span class="fu">matrix</span>(y, <span class="at">ncol =</span> 1L), <span class="at">epochs =</span> 100L,</span>
<span id="cb340-20"><a href="introduction.html#cb340-20" aria-hidden="true" tabindex="-1"></a>      <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb340-21"><a href="introduction.html#cb340-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb340-22"><a href="introduction.html#cb340-22" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<p><img src="_main_files/figure-html/chunk_chapter3_task_43-1.png" width="672" /></p>
<div class="sourceCode" id="cb341"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb341-1"><a href="introduction.html#cb341-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb341-2"><a href="introduction.html#cb341-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">evaluate</span>(x, y)</span></code></pre></div>
<pre><code>##     loss 
## 238.9949</code></pre>
<div class="sourceCode" id="cb343"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb343-1"><a href="introduction.html#cb343-1" aria-hidden="true" tabindex="-1"></a>pred_keras <span class="ot">=</span> <span class="fu">predict</span>(model, x)</span>
<span id="cb343-2"><a href="introduction.html#cb343-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb343-3"><a href="introduction.html#cb343-3" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">lm</span>(Ozone <span class="sc">~</span> ., <span class="at">data =</span> data)</span>
<span id="cb343-4"><a href="introduction.html#cb343-4" aria-hidden="true" tabindex="-1"></a>pred_lm <span class="ot">=</span> <span class="fu">predict</span>(fit, data)</span>
<span id="cb343-5"><a href="introduction.html#cb343-5" aria-hidden="true" tabindex="-1"></a>rmse_lm <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_lm)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb343-6"><a href="introduction.html#cb343-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb343-7"><a href="introduction.html#cb343-7" aria-hidden="true" tabindex="-1"></a>rmse_keras <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">sqrt</span>((y <span class="sc">-</span> pred_keras)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb343-8"><a href="introduction.html#cb343-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb343-9"><a href="introduction.html#cb343-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_lm)</span></code></pre></div>
<pre><code>## [1] 14.78897</code></pre>
<div class="sourceCode" id="cb345"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb345-1"><a href="introduction.html#cb345-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rmse_keras)</span></code></pre></div>
<pre><code>## [1] 11.58784</code></pre>
<p>You can see, that for the lower learning rate, the optimum (compared to the run with learning rate 0.05) is not yet reached (to few epochs have gone by).
But also here, mind the overfitting problem. For too many epochs, things might get worse!</p>
    </p>
  </details>
  <br/>
  <hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
<p>This task is about the airquality example, go through the code line by line and try to understand it.
Note, this is TensorFlow intermingled with Keras.</p>
<div class="sourceCode" id="cb347"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb347-1"><a href="introduction.html#cb347-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb347-2"><a href="introduction.html#cb347-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb347-3"><a href="introduction.html#cb347-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb347-4"><a href="introduction.html#cb347-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb347-5"><a href="introduction.html#cb347-5" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> airquality</span>
<span id="cb347-6"><a href="introduction.html#cb347-6" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> data[<span class="fu">complete.cases</span>(data),]  <span class="co"># Remove NAs.</span></span>
<span id="cb347-7"><a href="introduction.html#cb347-7" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">scale</span>(data[,<span class="dv">2</span><span class="sc">:</span><span class="dv">6</span>])</span>
<span id="cb347-8"><a href="introduction.html#cb347-8" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> data[,<span class="dv">1</span>]</span>
<span id="cb347-9"><a href="introduction.html#cb347-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb347-10"><a href="introduction.html#cb347-10" aria-hidden="true" tabindex="-1"></a>layers <span class="ot">=</span> tf<span class="sc">$</span>keras<span class="sc">$</span>layers</span>
<span id="cb347-11"><a href="introduction.html#cb347-11" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> tf<span class="sc">$</span>keras<span class="sc">$</span>models<span class="sc">$</span><span class="fu">Sequential</span>(</span>
<span id="cb347-12"><a href="introduction.html#cb347-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>(</span>
<span id="cb347-13"><a href="introduction.html#cb347-13" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">InputLayer</span>(<span class="at">input_shape =</span> <span class="fu">list</span>(5L)),</span>
<span id="cb347-14"><a href="introduction.html#cb347-14" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">Dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> tf<span class="sc">$</span>nn<span class="sc">$</span>relu),</span>
<span id="cb347-15"><a href="introduction.html#cb347-15" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">Dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> tf<span class="sc">$</span>nn<span class="sc">$</span>relu),</span>
<span id="cb347-16"><a href="introduction.html#cb347-16" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">Dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> tf<span class="sc">$</span>nn<span class="sc">$</span>relu),</span>
<span id="cb347-17"><a href="introduction.html#cb347-17" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">Dense</span>(<span class="at">units =</span> 1L, <span class="at">activation =</span> <span class="cn">NULL</span>) <span class="co"># No activation == &quot;linear&quot;.</span></span>
<span id="cb347-18"><a href="introduction.html#cb347-18" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb347-19"><a href="introduction.html#cb347-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb347-20"><a href="introduction.html#cb347-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb347-21"><a href="introduction.html#cb347-21" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> 200L</span>
<span id="cb347-22"><a href="introduction.html#cb347-22" aria-hidden="true" tabindex="-1"></a>optimizer <span class="ot">=</span> tf<span class="sc">$</span>keras<span class="sc">$</span>optimizers<span class="sc">$</span><span class="fu">Adamax</span>(<span class="fl">0.01</span>)</span>
<span id="cb347-23"><a href="introduction.html#cb347-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb347-24"><a href="introduction.html#cb347-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Stochastic gradient optimization is more efficient</span></span>
<span id="cb347-25"><a href="introduction.html#cb347-25" aria-hidden="true" tabindex="-1"></a><span class="co"># in each optimization step, we use a random subset of the data.</span></span>
<span id="cb347-26"><a href="introduction.html#cb347-26" aria-hidden="true" tabindex="-1"></a>get_batch <span class="ot">=</span> <span class="cf">function</span>(<span class="at">batch_size =</span> 32L){</span>
<span id="cb347-27"><a href="introduction.html#cb347-27" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(x), <span class="at">size =</span> batch_size)</span>
<span id="cb347-28"><a href="introduction.html#cb347-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">bX =</span> x[indices,], <span class="at">bY =</span> y[indices]))</span>
<span id="cb347-29"><a href="introduction.html#cb347-29" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb347-30"><a href="introduction.html#cb347-30" aria-hidden="true" tabindex="-1"></a><span class="fu">get_batch</span>() <span class="co"># Try out this function.</span></span></code></pre></div>
<pre><code>## $bX
##         Solar.R        Wind        Temp      Month        Day
## 87  -1.13877323 -0.37654514  0.44147123 -0.1467431  1.1546835
## 117  0.58361881 -1.83815816  0.33653910  0.5319436  1.0398360
## 129 -1.01809608  1.56290291  0.65133550  1.2106304 -1.1422676
## 121  0.44100036 -2.14734553  1.70065685  0.5319436  1.4992262
## 91   0.74817856 -0.71384046  0.54640337 -0.1467431  1.6140738
## 137 -1.76410028  0.26993754 -0.71278225  1.2106304 -0.2234871
## 21  -1.93963068 -0.06735777 -1.97196786 -1.5041165  0.5804458
## 141 -1.73118833  0.10128988 -0.18812157  1.2106304  0.2359031
## 78   0.97856221  0.10128988  0.44147123 -0.1467431  0.1210555
## 15  -1.31430363  0.91642022 -2.07689999 -1.5041165 -0.1086396
## 38  -0.63412333 -0.06735777  0.44147123 -0.8254298 -1.0274200
## 49  -1.62148183 -0.20789749 -1.34237505 -0.8254298  0.2359031
## 123  0.03508631 -1.02302783  1.70065685  0.5319436  1.7289213
## 136  0.58361881 -1.02302783 -0.08318944  1.2106304 -0.3383347
## 120  0.19964606 -0.06735777  2.01545325  0.5319436  1.3843787
## 114 -1.63245248  1.22560759 -0.60785011  0.5319436  0.6952933
## 145 -1.87380678 -0.20789749 -0.71278225  1.2106304  0.6952933
## 140  0.43002971  1.08506788 -1.13251078  1.2106304  0.1210555
## 64   0.56167751 -0.20789749  0.33653910 -0.1467431 -1.4868103
## 118  0.33129386 -0.54519280  0.86119977  0.5319436  1.1546835
## 128 -0.98518413 -0.71384046  0.96613190  1.2106304 -1.2571152
## 62   0.92370896 -1.64140257  0.65133550 -0.1467431 -1.7165054
## 125  0.13382216 -1.36032314  1.49079258  1.2106304 -1.6016578
## 4    1.40641756  0.43858520 -1.65717146 -1.5041165 -1.3719627
## 79   1.09923936 -1.02302783  0.65133550 -0.1467431  0.2359031
## 82  -1.95060133 -0.85438017 -0.39798584 -0.1467431  0.5804458
## 149  0.08993956 -0.85438017 -0.81771438  1.2106304  1.1546835
## 17   1.34059366  0.57912491 -1.23744292 -1.5041165  0.1210555
## 48   1.08826871  3.02451593 -0.60785011 -0.8254298  0.1210555
## 130  0.73720791  0.26993754  0.23160696  1.2106304 -1.0274200
## 132  0.49585361  0.26993754 -0.29305371  1.2106304 -0.7977249
## 30   0.41905906 -1.19167548  0.12667483 -1.5041165  1.6140738
## 
## $bY
##  [1]  20 168  32 118  64   9   1  13  35  18  29  20  85  28  76   9  23  18  32  73  47 135  78  18  61  16  30  34  37  20
## [31]  21 115</code></pre>
<div class="sourceCode" id="cb349"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb349-1"><a href="introduction.html#cb349-1" aria-hidden="true" tabindex="-1"></a>steps <span class="ot">=</span> <span class="fu">floor</span>(<span class="fu">nrow</span>(x)<span class="sc">/</span><span class="dv">32</span>) <span class="sc">*</span> epochs  <span class="co"># We need nrow(x)/32 steps for each epoch.</span></span>
<span id="cb349-2"><a href="introduction.html#cb349-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>steps){</span>
<span id="cb349-3"><a href="introduction.html#cb349-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Get data.</span></span>
<span id="cb349-4"><a href="introduction.html#cb349-4" aria-hidden="true" tabindex="-1"></a>  batch <span class="ot">=</span> <span class="fu">get_batch</span>()</span>
<span id="cb349-5"><a href="introduction.html#cb349-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb349-6"><a href="introduction.html#cb349-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Transform it into tensors.</span></span>
<span id="cb349-7"><a href="introduction.html#cb349-7" aria-hidden="true" tabindex="-1"></a>  bX <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(batch<span class="sc">$</span>bX)</span>
<span id="cb349-8"><a href="introduction.html#cb349-8" aria-hidden="true" tabindex="-1"></a>  bY <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(<span class="fu">matrix</span>(batch<span class="sc">$</span>bY, <span class="at">ncol =</span> 1L))</span>
<span id="cb349-9"><a href="introduction.html#cb349-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb349-10"><a href="introduction.html#cb349-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Automatic differentiation:</span></span>
<span id="cb349-11"><a href="introduction.html#cb349-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Record computations with respect to our model variables.</span></span>
<span id="cb349-12"><a href="introduction.html#cb349-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">with</span>(tf<span class="sc">$</span><span class="fu">GradientTape</span>() <span class="sc">%as%</span> tape,</span>
<span id="cb349-13"><a href="introduction.html#cb349-13" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb349-14"><a href="introduction.html#cb349-14" aria-hidden="true" tabindex="-1"></a>      pred <span class="ot">=</span> <span class="fu">model</span>(bX) <span class="co"># We record the operation for our model weights.</span></span>
<span id="cb349-15"><a href="introduction.html#cb349-15" aria-hidden="true" tabindex="-1"></a>      loss <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">reduce_mean</span>(tf<span class="sc">$</span>keras<span class="sc">$</span>losses<span class="sc">$</span><span class="fu">mean_squared_error</span>(bY, pred))</span>
<span id="cb349-16"><a href="introduction.html#cb349-16" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb349-17"><a href="introduction.html#cb349-17" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb349-18"><a href="introduction.html#cb349-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb349-19"><a href="introduction.html#cb349-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Calculate the gradients for our model$weights at the loss / backpropagation.</span></span>
<span id="cb349-20"><a href="introduction.html#cb349-20" aria-hidden="true" tabindex="-1"></a>  gradients <span class="ot">=</span> tape<span class="sc">$</span><span class="fu">gradient</span>(loss, model<span class="sc">$</span>weights) </span>
<span id="cb349-21"><a href="introduction.html#cb349-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb349-22"><a href="introduction.html#cb349-22" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Update our model weights with the learning rate specified above.</span></span>
<span id="cb349-23"><a href="introduction.html#cb349-23" aria-hidden="true" tabindex="-1"></a>  optimizer<span class="sc">$</span><span class="fu">apply_gradients</span>(purrr<span class="sc">::</span><span class="fu">transpose</span>(<span class="fu">list</span>(gradients, model<span class="sc">$</span>weights))) </span>
<span id="cb349-24"><a href="introduction.html#cb349-24" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="sc">!</span> i<span class="sc">%%</span><span class="dv">30</span>){</span>
<span id="cb349-25"><a href="introduction.html#cb349-25" aria-hidden="true" tabindex="-1"></a>    <span class="fu">cat</span>(<span class="st">&quot;Loss: &quot;</span>, loss<span class="sc">$</span><span class="fu">numpy</span>(), <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>) <span class="co"># Print loss every 30 steps (not epochs!).</span></span>
<span id="cb349-26"><a href="introduction.html#cb349-26" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb349-27"><a href="introduction.html#cb349-27" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<pre><code>## Loss:  645.1247 
## Loss:  257.9622 
## Loss:  257.9248 
## Loss:  424.3474 
## Loss:  132.1914 
## Loss:  201.8619 
## Loss:  225.3891 
## Loss:  111.7508 
## Loss:  343.3166 
## Loss:  255.3797 
## Loss:  245.1779 
## Loss:  227.4516 
## Loss:  222.4553 
## Loss:  348.0878 
## Loss:  365.9766 
## Loss:  178.8896 
## Loss:  220.2557 
## Loss:  344.3786 
## Loss:  238.2619 
## Loss:  324.3968</code></pre>
<p>Now change the code from above for the iris data set.
Tip: In tf$keras$losses$… you can find various loss functions.</p>
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
<div class="sourceCode" id="cb351"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb351-1"><a href="introduction.html#cb351-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb351-2"><a href="introduction.html#cb351-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb351-3"><a href="introduction.html#cb351-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set_random_seed</span>(321L, <span class="at">disable_gpu =</span> <span class="cn">FALSE</span>)  <span class="co"># Already sets R&#39;s random seed.</span></span>
<span id="cb351-4"><a href="introduction.html#cb351-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb351-5"><a href="introduction.html#cb351-5" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">scale</span>(iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span>
<span id="cb351-6"><a href="introduction.html#cb351-6" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> iris[,<span class="dv">5</span>]</span>
<span id="cb351-7"><a href="introduction.html#cb351-7" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> keras<span class="sc">::</span><span class="fu">to_categorical</span>(<span class="fu">as.integer</span>(Y)<span class="sc">-</span>1L, <span class="dv">3</span>)</span>
<span id="cb351-8"><a href="introduction.html#cb351-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb351-9"><a href="introduction.html#cb351-9" aria-hidden="true" tabindex="-1"></a>layers <span class="ot">=</span> tf<span class="sc">$</span>keras<span class="sc">$</span>layers</span>
<span id="cb351-10"><a href="introduction.html#cb351-10" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> tf<span class="sc">$</span>keras<span class="sc">$</span>models<span class="sc">$</span><span class="fu">Sequential</span>(</span>
<span id="cb351-11"><a href="introduction.html#cb351-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>(</span>
<span id="cb351-12"><a href="introduction.html#cb351-12" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">InputLayer</span>(<span class="at">input_shape =</span> <span class="fu">list</span>(4L)),</span>
<span id="cb351-13"><a href="introduction.html#cb351-13" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">Dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> tf<span class="sc">$</span>nn<span class="sc">$</span>relu),</span>
<span id="cb351-14"><a href="introduction.html#cb351-14" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">Dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> tf<span class="sc">$</span>nn<span class="sc">$</span>relu),</span>
<span id="cb351-15"><a href="introduction.html#cb351-15" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">Dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> tf<span class="sc">$</span>nn<span class="sc">$</span>relu),</span>
<span id="cb351-16"><a href="introduction.html#cb351-16" aria-hidden="true" tabindex="-1"></a>    layers<span class="sc">$</span><span class="fu">Dense</span>(<span class="at">units =</span> 3L, <span class="at">activation =</span> tf<span class="sc">$</span>nn<span class="sc">$</span>softmax)</span>
<span id="cb351-17"><a href="introduction.html#cb351-17" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb351-18"><a href="introduction.html#cb351-18" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb351-19"><a href="introduction.html#cb351-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb351-20"><a href="introduction.html#cb351-20" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> 200L</span>
<span id="cb351-21"><a href="introduction.html#cb351-21" aria-hidden="true" tabindex="-1"></a>optimizer <span class="ot">=</span> tf<span class="sc">$</span>keras<span class="sc">$</span>optimizers<span class="sc">$</span><span class="fu">Adamax</span>(<span class="fl">0.01</span>)</span>
<span id="cb351-22"><a href="introduction.html#cb351-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb351-23"><a href="introduction.html#cb351-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Stochastic gradient optimization is more efficient.</span></span>
<span id="cb351-24"><a href="introduction.html#cb351-24" aria-hidden="true" tabindex="-1"></a>get_batch <span class="ot">=</span> <span class="cf">function</span>(<span class="at">batch_size =</span> 32L){</span>
<span id="cb351-25"><a href="introduction.html#cb351-25" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">=</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(x), <span class="at">size =</span> batch_size)</span>
<span id="cb351-26"><a href="introduction.html#cb351-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">bX =</span> x[indices,], <span class="at">bY =</span> y[indices,]))</span>
<span id="cb351-27"><a href="introduction.html#cb351-27" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb351-28"><a href="introduction.html#cb351-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb351-29"><a href="introduction.html#cb351-29" aria-hidden="true" tabindex="-1"></a>steps <span class="ot">=</span> <span class="fu">floor</span>(<span class="fu">nrow</span>(x)<span class="sc">/</span><span class="dv">32</span>) <span class="sc">*</span> epochs <span class="co"># We need nrow(x)/32 steps for each epoch.</span></span>
<span id="cb351-30"><a href="introduction.html#cb351-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb351-31"><a href="introduction.html#cb351-31" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>steps){</span>
<span id="cb351-32"><a href="introduction.html#cb351-32" aria-hidden="true" tabindex="-1"></a>  batch <span class="ot">=</span> <span class="fu">get_batch</span>()</span>
<span id="cb351-33"><a href="introduction.html#cb351-33" aria-hidden="true" tabindex="-1"></a>  bX <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(batch<span class="sc">$</span>bX)</span>
<span id="cb351-34"><a href="introduction.html#cb351-34" aria-hidden="true" tabindex="-1"></a>  bY <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(batch<span class="sc">$</span>bY)</span>
<span id="cb351-35"><a href="introduction.html#cb351-35" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb351-36"><a href="introduction.html#cb351-36" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Automatic differentiation.</span></span>
<span id="cb351-37"><a href="introduction.html#cb351-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">with</span>(tf<span class="sc">$</span><span class="fu">GradientTape</span>() <span class="sc">%as%</span> tape,</span>
<span id="cb351-38"><a href="introduction.html#cb351-38" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb351-39"><a href="introduction.html#cb351-39" aria-hidden="true" tabindex="-1"></a>      pred <span class="ot">=</span> <span class="fu">model</span>(bX) <span class="co"># we record the operation for our model weights</span></span>
<span id="cb351-40"><a href="introduction.html#cb351-40" aria-hidden="true" tabindex="-1"></a>      loss <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">reduce_mean</span>(tf<span class="sc">$</span>keras<span class="sc">$</span>losses<span class="sc">$</span><span class="fu">categorical_crossentropy</span>(bY, pred))</span>
<span id="cb351-41"><a href="introduction.html#cb351-41" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb351-42"><a href="introduction.html#cb351-42" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb351-43"><a href="introduction.html#cb351-43" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb351-44"><a href="introduction.html#cb351-44" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Calculate the gradients for the loss at our model$weights / backpropagation.</span></span>
<span id="cb351-45"><a href="introduction.html#cb351-45" aria-hidden="true" tabindex="-1"></a>  gradients <span class="ot">=</span> tape<span class="sc">$</span><span class="fu">gradient</span>(loss, model<span class="sc">$</span>weights)</span>
<span id="cb351-46"><a href="introduction.html#cb351-46" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb351-47"><a href="introduction.html#cb351-47" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Update our model weights with the learning rate specified above.</span></span>
<span id="cb351-48"><a href="introduction.html#cb351-48" aria-hidden="true" tabindex="-1"></a>  optimizer<span class="sc">$</span><span class="fu">apply_gradients</span>(purrr<span class="sc">::</span><span class="fu">transpose</span>(<span class="fu">list</span>(gradients, model<span class="sc">$</span>weights)))</span>
<span id="cb351-49"><a href="introduction.html#cb351-49" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb351-50"><a href="introduction.html#cb351-50" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="sc">!</span> i<span class="sc">%%</span><span class="dv">30</span>){</span>
<span id="cb351-51"><a href="introduction.html#cb351-51" aria-hidden="true" tabindex="-1"></a>    <span class="fu">cat</span>(<span class="st">&quot;Loss: &quot;</span>, loss<span class="sc">$</span><span class="fu">numpy</span>(), <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>) <span class="co"># Print loss every 30 steps (not epochs!).</span></span>
<span id="cb351-52"><a href="introduction.html#cb351-52" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb351-53"><a href="introduction.html#cb351-53" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<pre><code>## Loss:  0.002592293 
## Loss:  0.0004166076 
## Loss:  0.0005878588 
## Loss:  0.0001814875 
## Loss:  0.0003771908 
## Loss:  0.0006105488 
## Loss:  0.0003895137 
## Loss:  0.0001911997 
## Loss:  0.0002297242 
## Loss:  0.0001141025 
## Loss:  0.0002618307 
## Loss:  0.0001288063 
## Loss:  5.751499e-05 
## Loss:  0.0002563585 
## Loss:  0.0002148754 
## Loss:  0.0001434369 
## Loss:  0.0001919963 
## Loss:  0.0001954481 
## Loss:  7.472201e-05 
## Loss:  2.273075e-05 
## Loss:  0.0001157298 
## Loss:  2.059802e-05 
## Loss:  7.065437e-05 
## Loss:  1.294948e-05 
## Loss:  6.738135e-05 
## Loss:  2.542896e-05</code></pre>
<p>Remarks:</p>
<ul>
<li>Mind the different input and output layer numbers.</li>
<li>The loss function increases randomly, because different subsets of the data were drawn.
This is a downside of stochastic gradient descent.</li>
<li>A positive thing about stochastic gradient descent is, that local valleys or hills may be left and global ones can be found instead.</li>
</ul>
    </p>
  </details>
  <br/><hr/>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="reminder.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="fundamental.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

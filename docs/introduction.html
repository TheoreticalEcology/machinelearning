<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2 Introduction to Machine Learning | Machine Learning and AI in TensorFlow and R</title>
  <meta name="description" content="2 Introduction to Machine Learning | Machine Learning and AI in TensorFlow and R" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="2 Introduction to Machine Learning | Machine Learning and AI in TensorFlow and R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="2 Introduction to Machine Learning | Machine Learning and AI in TensorFlow and R" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2 Introduction to Machine Learning | Machine Learning and AI in TensorFlow and R" />
  
  <meta name="twitter:description" content="2 Introduction to Machine Learning | Machine Learning and AI in TensorFlow and R" />
  

<meta name="author" content="Maximilian Pichler and Florian Hartig" />


<meta name="date" content="2021-05-06" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="fund.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<script src="libs/viz-1.8.2/viz.js"></script>
<link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="libs/grViz-binding-1.0.6.1/grViz.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #ffffff;
    color: #a0a0a0;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
div.sourceCode
  { color: #1f1c1b; background-color: #ffffff; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span { color: #1f1c1b; } /* Normal */
code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
code span.an { color: #ca60ca; } /* Annotation */
code span.at { color: #0057ae; } /* Attribute */
code span.bn { color: #b08000; } /* BaseN */
code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #924c9d; } /* Char */
code span.cn { color: #aa5500; } /* Constant */
code span.co { color: #898887; } /* Comment */
code span.cv { color: #0095ff; } /* CommentVar */
code span.do { color: #607880; } /* Documentation */
code span.dt { color: #0057ae; } /* DataType */
code span.dv { color: #b08000; } /* DecVal */
code span.er { color: #bf0303; text-decoration: underline; } /* Error */
code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
code span.fl { color: #b08000; } /* Float */
code span.fu { color: #644a9b; } /* Function */
code span.im { color: #ff5500; } /* Import */
code span.in { color: #b08000; } /* Information */
code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
code span.op { color: #1f1c1b; } /* Operator */
code span.ot { color: #006e28; } /* Other */
code span.pp { color: #006e28; } /* Preprocessor */
code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #ff5500; } /* SpecialString */
code span.st { color: #bf0303; } /* String */
code span.va { color: #0057ae; } /* Variable */
code span.vs { color: #bf0303; } /* VerbatimString */
code span.wa { color: #bf0303; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction to Machine Learning</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#unsupervised-learning"><i class="fa fa-check"></i><b>2.1</b> Unsupervised learning</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="introduction.html"><a href="introduction.html#hierarchical-clustering"><i class="fa fa-check"></i><b>2.1.1</b> Hierarchical clustering</a></li>
<li class="chapter" data-level="2.1.2" data-path="introduction.html"><a href="introduction.html#k-means-clustering"><i class="fa fa-check"></i><b>2.1.2</b> k-means clustering</a></li>
<li class="chapter" data-level="2.1.3" data-path="introduction.html"><a href="introduction.html#density-based-clustering"><i class="fa fa-check"></i><b>2.1.3</b> Density-based clustering</a></li>
<li class="chapter" data-level="2.1.4" data-path="introduction.html"><a href="introduction.html#model-based-clustering"><i class="fa fa-check"></i><b>2.1.4</b> Model-based clustering</a></li>
<li class="chapter" data-level="2.1.5" data-path="introduction.html"><a href="introduction.html#ordination"><i class="fa fa-check"></i><b>2.1.5</b> Ordination</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#supervised-learning-regression-and-classification"><i class="fa fa-check"></i><b>2.2</b> Supervised learning: regression and classification</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="introduction.html"><a href="introduction.html#supervised-regression-using-random-forest"><i class="fa fa-check"></i><b>2.2.1</b> Supervised regression using Random Forest</a></li>
<li class="chapter" data-level="2.2.2" data-path="introduction.html"><a href="introduction.html#supervised-classification-using-random-forest"><i class="fa fa-check"></i><b>2.2.2</b> Supervised classification using Random Forest</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#introduction-to-tensorflow"><i class="fa fa-check"></i><b>2.3</b> Introduction to Tensorflow</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="introduction.html"><a href="introduction.html#tensorflow-data-containers"><i class="fa fa-check"></i><b>2.3.1</b> Tensorflow data containers</a></li>
<li class="chapter" data-level="2.3.2" data-path="introduction.html"><a href="introduction.html#tensorflow-data-types---good-practise-with-r-tf"><i class="fa fa-check"></i><b>2.3.2</b> Tensorflow data types - good practise with R-TF</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="introduction.html"><a href="introduction.html#introduction-to-pytorch"><i class="fa fa-check"></i><b>2.4</b> Introduction to PyTorch</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="introduction.html"><a href="introduction.html#pytorch-data-containers"><i class="fa fa-check"></i><b>2.4.1</b> PyTorch data containers</a></li>
<li class="chapter" data-level="2.4.2" data-path="introduction.html"><a href="introduction.html#torch-data-types---good-practise-with-r-tf"><i class="fa fa-check"></i><b>2.4.2</b> Torch data types - good practise with R-TF</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="introduction.html"><a href="introduction.html#first-steps-with-the-keras-framework"><i class="fa fa-check"></i><b>2.5</b> First steps with the keras framework</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="introduction.html"><a href="introduction.html#example-workflow-in-keras"><i class="fa fa-check"></i><b>2.5.1</b> Example workflow in keras</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="fund.html"><a href="fund.html"><i class="fa fa-check"></i><b>3</b> Fundamental principles and techniques</a>
<ul>
<li class="chapter" data-level="3.1" data-path="fund.html"><a href="fund.html#machine-learning-principles"><i class="fa fa-check"></i><b>3.1</b> Machine learning principles</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="fund.html"><a href="fund.html#optimization"><i class="fa fa-check"></i><b>3.1.1</b> Optimization</a></li>
<li class="chapter" data-level="3.1.2" data-path="fund.html"><a href="fund.html#regularization"><i class="fa fa-check"></i><b>3.1.2</b> Regularization</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="fund.html"><a href="fund.html#tree-based-ml-algorithms"><i class="fa fa-check"></i><b>3.2</b> Tree-based ML algorithms</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="fund.html"><a href="fund.html#classification-and-regression-trees"><i class="fa fa-check"></i><b>3.2.1</b> Classification and Regression Trees</a></li>
<li class="chapter" data-level="3.2.2" data-path="fund.html"><a href="fund.html#random-forest"><i class="fa fa-check"></i><b>3.2.2</b> Random Forest</a></li>
<li class="chapter" data-level="3.2.3" data-path="fund.html"><a href="fund.html#boosted-regression-trees"><i class="fa fa-check"></i><b>3.2.3</b> Boosted regression trees</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="fund.html"><a href="fund.html#distance-based-algorithms"><i class="fa fa-check"></i><b>3.3</b> Distance-based algorithms</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="fund.html"><a href="fund.html#k-nearest-neighbor"><i class="fa fa-check"></i><b>3.3.1</b> k-nearest-neighbor</a></li>
<li class="chapter" data-level="3.3.2" data-path="fund.html"><a href="fund.html#support-vector-machines-svm"><i class="fa fa-check"></i><b>3.3.2</b> Support Vector Machines (SVM)</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="fund.html"><a href="fund.html#artificial-neural-networks"><i class="fa fa-check"></i><b>3.4</b> Artificial neural networks</a></li>
<li class="chapter" data-level="3.5" data-path="fund.html"><a href="fund.html#the-standard-ml-pipeline-at-the-example-of-the-titanic-dataset"><i class="fa fa-check"></i><b>3.5</b> The standard ML pipeline at the example of the titanic dataset</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="fund.html"><a href="fund.html#data-cleaning"><i class="fa fa-check"></i><b>3.5.1</b> Data cleaning</a></li>
<li class="chapter" data-level="3.5.2" data-path="fund.html"><a href="fund.html#pre-processing-and-feature-selection"><i class="fa fa-check"></i><b>3.5.2</b> Pre-processing and feature selection</a></li>
<li class="chapter" data-level="3.5.3" data-path="fund.html"><a href="fund.html#split-data-for-training-and-testing"><i class="fa fa-check"></i><b>3.5.3</b> Split data for training and testing</a></li>
<li class="chapter" data-level="3.5.4" data-path="fund.html"><a href="fund.html#model-fitting"><i class="fa fa-check"></i><b>3.5.4</b> Model fitting</a></li>
<li class="chapter" data-level="3.5.5" data-path="fund.html"><a href="fund.html#model-evaluation"><i class="fa fa-check"></i><b>3.5.5</b> Model evaluation</a></li>
<li class="chapter" data-level="3.5.6" data-path="fund.html"><a href="fund.html#predictions-and-submission"><i class="fa fa-check"></i><b>3.5.6</b> Predictions and submission</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="fund.html"><a href="fund.html#mlr"><i class="fa fa-check"></i><b>3.6</b> Bonus - ML pipelines with mlr3</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="fund.html"><a href="fund.html#mlr3---the-basic-workflow"><i class="fa fa-check"></i><b>3.6.1</b> mlr3 - the basic workflow</a></li>
<li class="chapter" data-level="3.6.2" data-path="fund.html"><a href="fund.html#mlr3---hyper-parameter-tuning"><i class="fa fa-check"></i><b>3.6.2</b> mlr3 - hyper-parameter tuning</a></li>
<li class="chapter" data-level="3.6.3" data-path="fund.html"><a href="fund.html#mlr3---hyper-parameter-tuning-with-oversampling"><i class="fa fa-check"></i><b>3.6.3</b> mlr3 - hyper-parameter tuning with oversampling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Deep.html"><a href="Deep.html"><i class="fa fa-check"></i><b>4</b> Deep learning</a>
<ul>
<li class="chapter" data-level="4.1" data-path="Deep.html"><a href="Deep.html#network-architectures"><i class="fa fa-check"></i><b>4.1</b> Network architectures</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="Deep.html"><a href="Deep.html#deep-neural-networks-dnns"><i class="fa fa-check"></i><b>4.1.1</b> Deep neural networks (DNNs)</a></li>
<li class="chapter" data-level="4.1.2" data-path="Deep.html"><a href="Deep.html#convolutional-neural-networks-dnns"><i class="fa fa-check"></i><b>4.1.2</b> Convolutional neural networks (DNNs)</a></li>
<li class="chapter" data-level="4.1.3" data-path="Deep.html"><a href="Deep.html#recurrent-neural-networks-rnns"><i class="fa fa-check"></i><b>4.1.3</b> Recurrent neural networks (RNNs)</a></li>
<li class="chapter" data-level="4.1.4" data-path="Deep.html"><a href="Deep.html#natural-language-processing-nlp"><i class="fa fa-check"></i><b>4.1.4</b> Natural language processing (NLP)</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="Deep.html"><a href="Deep.html#case-study-dropout-and-early-stopping-in-a-deep-neural-network"><i class="fa fa-check"></i><b>4.2</b> Case study: dropout and early stopping in a deep neural network</a></li>
<li class="chapter" data-level="4.3" data-path="Deep.html"><a href="Deep.html#case-study---fitting-a-convolutional-neural-networks-on-mnist"><i class="fa fa-check"></i><b>4.3</b> Case study - fitting a Convolutional Neural Networks on MNIST</a></li>
<li class="chapter" data-level="4.4" data-path="Deep.html"><a href="Deep.html#advanced-training-techniques"><i class="fa fa-check"></i><b>4.4</b> Advanced training techniques</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="Deep.html"><a href="Deep.html#data-augmentation"><i class="fa fa-check"></i><b>4.4.1</b> Data Augmentation</a></li>
<li class="chapter" data-level="4.4.2" data-path="Deep.html"><a href="Deep.html#transfer"><i class="fa fa-check"></i><b>4.4.2</b> Transfer learning</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html"><i class="fa fa-check"></i><b>5</b> Interpretation and causality with machine learning</a>
<ul>
<li class="chapter" data-level="5.1" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#explainable-ai"><i class="fa fa-check"></i><b>5.1</b> Explainable AI</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#a-practical-example"><i class="fa fa-check"></i><b>5.1.1</b> A practical example</a></li>
<li class="chapter" data-level="5.1.2" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#feature-importance"><i class="fa fa-check"></i><b>5.1.2</b> Feature Importance</a></li>
<li class="chapter" data-level="5.1.3" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#partial-dependencies"><i class="fa fa-check"></i><b>5.1.3</b> Partial dependencies</a></li>
<li class="chapter" data-level="5.1.4" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#accumulated-local-effects"><i class="fa fa-check"></i><b>5.1.4</b> Accumulated local effects</a></li>
<li class="chapter" data-level="5.1.5" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#friedmans-h-statistic"><i class="fa fa-check"></i><b>5.1.5</b> Friedmans H-statistic</a></li>
<li class="chapter" data-level="5.1.6" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#global-explainer---simplifying-the-ml-model"><i class="fa fa-check"></i><b>5.1.6</b> Global explainer - Simplifying the ML model</a></li>
<li class="chapter" data-level="5.1.7" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#local-explainer---lime-explaining-single-instances-observations"><i class="fa fa-check"></i><b>5.1.7</b> Local explainer - LIME explaining single instances (observations)</a></li>
<li class="chapter" data-level="5.1.8" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#local-explainer---shapley"><i class="fa fa-check"></i><b>5.1.8</b> Local explainer - Shapley</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#causal-inference-and-machine-learning"><i class="fa fa-check"></i><b>5.2</b> Causal inference and machine learning</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#causal-inference-on-static-data"><i class="fa fa-check"></i><b>5.2.1</b> Causal inference on static data</a></li>
<li class="chapter" data-level="5.2.2" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#structural-equation-models"><i class="fa fa-check"></i><b>5.2.2</b> Structural equation models</a></li>
<li class="chapter" data-level="5.2.3" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#automatic-causal-discovery"><i class="fa fa-check"></i><b>5.2.3</b> Automatic causal discovery</a></li>
<li class="chapter" data-level="5.2.4" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#causal-inference-on-dynamic-data"><i class="fa fa-check"></i><b>5.2.4</b> Causal inference on dynamic data</a></li>
<li class="chapter" data-level="5.2.5" data-path="interpretation-and-causality-with-machine-learning.html"><a href="interpretation-and-causality-with-machine-learning.html#outlook-for-machine-learning"><i class="fa fa-check"></i><b>5.2.5</b> Outlook for machine learning</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="generative-modeling-and-reinforcement-learning.html"><a href="generative-modeling-and-reinforcement-learning.html"><i class="fa fa-check"></i><b>6</b> Generative modeling and reinforcement learning</a>
<ul>
<li class="chapter" data-level="6.1" data-path="generative-modeling-and-reinforcement-learning.html"><a href="generative-modeling-and-reinforcement-learning.html#autoencoder"><i class="fa fa-check"></i><b>6.1</b> Autoencoder</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="generative-modeling-and-reinforcement-learning.html"><a href="generative-modeling-and-reinforcement-learning.html#autoencoder---dnn-mnist"><i class="fa fa-check"></i><b>6.1.1</b> Autoencoder - DNN MNIST</a></li>
<li class="chapter" data-level="6.1.2" data-path="generative-modeling-and-reinforcement-learning.html"><a href="generative-modeling-and-reinforcement-learning.html#autoencoder---mnist-cnn"><i class="fa fa-check"></i><b>6.1.2</b> Autoencoder - MNIST CNN</a></li>
<li class="chapter" data-level="6.1.3" data-path="generative-modeling-and-reinforcement-learning.html"><a href="generative-modeling-and-reinforcement-learning.html#varational-autoencoder"><i class="fa fa-check"></i><b>6.1.3</b> Varational Autoencoder</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="generative-modeling-and-reinforcement-learning.html"><a href="generative-modeling-and-reinforcement-learning.html#generative-adversarial-network-gans"><i class="fa fa-check"></i><b>6.2</b> Generative adversarial network (GANs)</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="generative-modeling-and-reinforcement-learning.html"><a href="generative-modeling-and-reinforcement-learning.html#mnist---gan-based-on-dnns"><i class="fa fa-check"></i><b>6.2.1</b> MNIST - GAN based on DNNs</a></li>
<li class="chapter" data-level="6.2.2" data-path="generative-modeling-and-reinforcement-learning.html"><a href="generative-modeling-and-reinforcement-learning.html#flower---gan"><i class="fa fa-check"></i><b>6.2.2</b> Flower - GAN</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="generative-modeling-and-reinforcement-learning.html"><a href="generative-modeling-and-reinforcement-learning.html#reinforcement-learning"><i class="fa fa-check"></i><b>6.3</b> Reinforcement learning</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="datasets.html"><a href="datasets.html"><i class="fa fa-check"></i><b>7</b> Datasets</a>
<ul>
<li class="chapter" data-level="7.1" data-path="datasets.html"><a href="datasets.html#titanic"><i class="fa fa-check"></i><b>7.1</b> Titanic</a></li>
<li class="chapter" data-level="7.2" data-path="datasets.html"><a href="datasets.html#plant-pollinator-database"><i class="fa fa-check"></i><b>7.2</b> Plant-pollinator database</a></li>
<li class="chapter" data-level="7.3" data-path="datasets.html"><a href="datasets.html#wine"><i class="fa fa-check"></i><b>7.3</b> Wine</a></li>
<li class="chapter" data-level="7.4" data-path="datasets.html"><a href="datasets.html#nasa"><i class="fa fa-check"></i><b>7.4</b> Nasa</a></li>
<li class="chapter" data-level="7.5" data-path="datasets.html"><a href="datasets.html#flower"><i class="fa fa-check"></i><b>7.5</b> Flower</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning and AI in TensorFlow and R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introduction" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Introduction to Machine Learning</h1>
<p>There are three basic ML tasks</p>
<ul>
<li>Unsupervised learning</li>
<li>Supervised learning</li>
<li>Reinforcement learning</li>
</ul>
<p><strong>Unsupervised learning</strong> is a technique, where one does not need to supervise the model. Instead, you allow the model to work on its own to discover information.</p>
<p>In <strong>supervised learning</strong>, you train an algorithm using labeled data, which means that you already know the correct answer for a part of the data (the so called tracings data).</p>
<p><strong>Reinforcement learning</strong> is a technique that emulates a game-like situation. The algorithm comes up with a solution by try and error and gets for the actions ether rewards or penalties. As in games, the goal is to maximize the rewards. We will talk on the last day more about this technique.</p>
<p>For the moment, we will focus on the first two tasks, supervised and unsupervised learning. To do so, we will first start with a small example, but before you start with the code, here a video to remind you of what we talked about in the class:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/1AVrWvRvfxs" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<div id="unsupervised-learning" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Unsupervised learning</h2>
<p>In unsupervised learning, we want to identify patterns in data without having any examples (supervision) about what the correct patterns / classes are. As an example, consider our iris dataset. Here, we have 150 observations of 4 floral traits</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="introduction.html#cb4-1" aria-hidden="true" tabindex="-1"></a>colors <span class="ot">=</span> <span class="fu">hcl.colors</span>(<span class="dv">3</span>)</span>
<span id="cb4-2"><a href="introduction.html#cb4-2" aria-hidden="true" tabindex="-1"></a>traits <span class="ot">=</span> <span class="fu">as.matrix</span>(iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>]) </span>
<span id="cb4-3"><a href="introduction.html#cb4-3" aria-hidden="true" tabindex="-1"></a>species <span class="ot">=</span> iris<span class="sc">$</span>Species</span>
<span id="cb4-4"><a href="introduction.html#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="fu">image</span>(<span class="at">y =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, <span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(species) , <span class="at">z =</span> traits, </span>
<span id="cb4-5"><a href="introduction.html#cb4-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">ylab =</span> <span class="st">&quot;Floral trait&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;Individual&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-6-1.png" width="960" /></p>
<p>The observations are from 3 species, and indeed those species tend to have different traits, meaning that the observations form 3 clusters.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="introduction.html#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(traits, <span class="at">pch =</span> <span class="fu">as.integer</span>(species), <span class="at">col =</span> colors[<span class="fu">as.integer</span>(species)])</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>However, imagine we didn’t know what species are, which is basically the situation in which people in the antique have been. The people just noted that some plants have different flowers than others, and decided to give them different names. This kind of process is what unsupervised learning does.</p>
<div id="hierarchical-clustering" class="section level3" number="2.1.1">
<h3><span class="header-section-number">2.1.1</span> Hierarchical clustering</h3>
<p>Build up a hierarchy (tree) between data points</p>
<ul>
<li>Agglomerative: start with each data point in their own cluster, merge them up hierarchically</li>
<li>Divisive: start with all data in one cluster, and split hierarchically</li>
</ul>
<p>Merges / splits are done according to linkage criterion, which measures distance between (potential) clusters. Cut the tree at a certain height to get clusters.</p>
<p>Here an example</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="introduction.html#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb6-2"><a href="introduction.html#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="introduction.html#cb6-3" aria-hidden="true" tabindex="-1"></a>d <span class="ot">=</span> <span class="fu">dist</span>(traits)</span>
<span id="cb6-4"><a href="introduction.html#cb6-4" aria-hidden="true" tabindex="-1"></a>hc <span class="ot">&lt;-</span> <span class="fu">hclust</span>(d, <span class="at">method =</span> <span class="st">&quot;complete&quot;</span>)</span>
<span id="cb6-5"><a href="introduction.html#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="introduction.html#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(hc)</span>
<span id="cb6-7"><a href="introduction.html#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="fu">rect.hclust</span>(hc, <span class="at">k =</span> <span class="dv">3</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>Same plot, but with colors for true species identity</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="introduction.html#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ape)</span>
<span id="cb7-2"><a href="introduction.html#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">as.phylo</span>(hc), </span>
<span id="cb7-3"><a href="introduction.html#cb7-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">tip.color =</span> colors[<span class="fu">as.integer</span>(species)], </span>
<span id="cb7-4"><a href="introduction.html#cb7-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">direction =</span> <span class="st">&quot;downwards&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="introduction.html#cb8-1" aria-hidden="true" tabindex="-1"></a>hcRes3 <span class="ot">&lt;-</span> <span class="fu">cutree</span>(hc, <span class="at">k =</span> <span class="dv">3</span>)</span></code></pre></div>
<p>Calculate confusion matrix - note we switching labels here so that it fits to the species</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="introduction.html#cb9-1" aria-hidden="true" tabindex="-1"></a>tmp <span class="ot">&lt;-</span> hcRes3</span>
<span id="cb9-2"><a href="introduction.html#cb9-2" aria-hidden="true" tabindex="-1"></a>tmp[hcRes3 <span class="sc">==</span> <span class="dv">2</span>] <span class="ot">=</span> <span class="dv">3</span></span>
<span id="cb9-3"><a href="introduction.html#cb9-3" aria-hidden="true" tabindex="-1"></a>tmp[hcRes3 <span class="sc">==</span> <span class="dv">3</span>] <span class="ot">=</span> <span class="dv">2</span></span>
<span id="cb9-4"><a href="introduction.html#cb9-4" aria-hidden="true" tabindex="-1"></a>hcRes3 <span class="ot">&lt;-</span> tmp</span>
<span id="cb9-5"><a href="introduction.html#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(hcRes3, species)</span></code></pre></div>
<pre><code>##       species
## hcRes3 setosa versicolor virginica
##      1     50          0         0
##      2      0         27         1
##      3      0         23        49</code></pre>
<p>Note that results might change if you choose a different agglomeration method, distance metric, or whether you scale your variables. Compare, e.g. to this example</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="introduction.html#cb11-1" aria-hidden="true" tabindex="-1"></a>hc <span class="ot">&lt;-</span> <span class="fu">hclust</span>(d, <span class="at">method =</span> <span class="st">&quot;ward.D2&quot;</span>)</span>
<span id="cb11-2"><a href="introduction.html#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="introduction.html#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">as.phylo</span>(hc), </span>
<span id="cb11-4"><a href="introduction.html#cb11-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">tip.color =</span> colors[<span class="fu">as.integer</span>(species)], </span>
<span id="cb11-5"><a href="introduction.html#cb11-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">direction =</span> <span class="st">&quot;downwards&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="introduction.html#cb12-1" aria-hidden="true" tabindex="-1"></a>hcRes3 <span class="ot">&lt;-</span> <span class="fu">cutree</span>(hc, <span class="at">k =</span> <span class="dv">3</span>)</span>
<span id="cb12-2"><a href="introduction.html#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(hcRes3, species)</span></code></pre></div>
<pre><code>##       species
## hcRes3 setosa versicolor virginica
##      1     50          0         0
##      2      0         49        15
##      3      0          1        35</code></pre>
<p>Which method is best?</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="introduction.html#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dendextend)</span></code></pre></div>
<pre><code>## 
## ---------------------
## Welcome to dendextend version 1.14.0
## Type citation(&#39;dendextend&#39;) for how to cite the package.
## 
## Type browseVignettes(package = &#39;dendextend&#39;) for the package vignette.
## The github page is: https://github.com/talgalili/dendextend/
## 
## Suggestions and bug-reports can be submitted at: https://github.com/talgalili/dendextend/issues
## Or contact: &lt;tal.galili@gmail.com&gt;
## 
##  To suppress this message use:  suppressPackageStartupMessages(library(dendextend))
## ---------------------</code></pre>
<pre><code>## 
## Attaching package: &#39;dendextend&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:ape&#39;:
## 
##     ladderize, rotate</code></pre>
<pre><code>## The following object is masked from &#39;package:stats&#39;:
## 
##     cutree</code></pre>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="introduction.html#cb19-1" aria-hidden="true" tabindex="-1"></a>methods <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;ward.D&quot;</span>, <span class="st">&quot;single&quot;</span>, <span class="st">&quot;complete&quot;</span>, <span class="st">&quot;average&quot;</span>, <span class="st">&quot;mcquitty&quot;</span>, <span class="st">&quot;median&quot;</span>, <span class="st">&quot;centroid&quot;</span>, <span class="st">&quot;ward.D2&quot;</span>)</span>
<span id="cb19-2"><a href="introduction.html#cb19-2" aria-hidden="true" tabindex="-1"></a>out <span class="ot">&lt;-</span> <span class="fu">dendlist</span>()</span>
<span id="cb19-3"><a href="introduction.html#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="fu">seq_along</span>(methods)) {</span>
<span id="cb19-4"><a href="introduction.html#cb19-4" aria-hidden="true" tabindex="-1"></a>  res <span class="ot">&lt;-</span> <span class="fu">hclust</span>(d, <span class="at">method =</span> methods[i])   </span>
<span id="cb19-5"><a href="introduction.html#cb19-5" aria-hidden="true" tabindex="-1"></a>  out <span class="ot">&lt;-</span> <span class="fu">dendlist</span>(out, <span class="fu">as.dendrogram</span>(res))</span>
<span id="cb19-6"><a href="introduction.html#cb19-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb19-7"><a href="introduction.html#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(out) <span class="ot">&lt;-</span> methods</span>
<span id="cb19-8"><a href="introduction.html#cb19-8" aria-hidden="true" tabindex="-1"></a>out</span></code></pre></div>
<pre><code>## $ward.D
## &#39;dendrogram&#39; with 2 branches and 150 members total, at height 199.6205 
## 
## $single
## &#39;dendrogram&#39; with 2 branches and 150 members total, at height 1.640122 
## 
## $complete
## &#39;dendrogram&#39; with 2 branches and 150 members total, at height 7.085196 
## 
## $average
## &#39;dendrogram&#39; with 2 branches and 150 members total, at height 4.062683 
## 
## $mcquitty
## &#39;dendrogram&#39; with 2 branches and 150 members total, at height 4.497283 
## 
## $median
## &#39;dendrogram&#39; with 2 branches and 150 members total, at height 2.82744 
## 
## $centroid
## &#39;dendrogram&#39; with 2 branches and 150 members total, at height 2.994307 
## 
## $ward.D2
## &#39;dendrogram&#39; with 2 branches and 150 members total, at height 32.44761 
## 
## attr(,&quot;class&quot;)
## [1] &quot;dendlist&quot;</code></pre>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="introduction.html#cb21-1" aria-hidden="true" tabindex="-1"></a>get_ordered_3_clusters <span class="ot">&lt;-</span> <span class="cf">function</span>(dend) {</span>
<span id="cb21-2"><a href="introduction.html#cb21-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cutree</span>(dend, <span class="at">k =</span> <span class="dv">3</span>)[<span class="fu">order.dendrogram</span>(dend)]</span>
<span id="cb21-3"><a href="introduction.html#cb21-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb21-4"><a href="introduction.html#cb21-4" aria-hidden="true" tabindex="-1"></a>dend_3_clusters <span class="ot">&lt;-</span> <span class="fu">lapply</span>(out, get_ordered_3_clusters)</span>
<span id="cb21-5"><a href="introduction.html#cb21-5" aria-hidden="true" tabindex="-1"></a>compare_clusters_to_iris <span class="ot">&lt;-</span> <span class="cf">function</span>(clus) {<span class="fu">FM_index</span>(clus, <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="at">each =</span> <span class="dv">50</span>), <span class="at">assume_sorted_vectors =</span> <span class="cn">TRUE</span>)}</span>
<span id="cb21-6"><a href="introduction.html#cb21-6" aria-hidden="true" tabindex="-1"></a>clusters_performance <span class="ot">&lt;-</span> <span class="fu">sapply</span>(dend_3_clusters, compare_clusters_to_iris)</span>
<span id="cb21-7"><a href="introduction.html#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="fu">dotchart</span>(<span class="fu">sort</span>(clusters_performance), <span class="at">xlim =</span> <span class="fu">c</span>(<span class="fl">0.3</span>,<span class="dv">1</span>),</span>
<span id="cb21-8"><a href="introduction.html#cb21-8" aria-hidden="true" tabindex="-1"></a>         <span class="at">xlab =</span> <span class="st">&quot;Fowlkes-Mallows index&quot;</span>,</span>
<span id="cb21-9"><a href="introduction.html#cb21-9" aria-hidden="true" tabindex="-1"></a>         <span class="at">main =</span> <span class="st">&quot;Performance of linkage methods </span><span class="sc">\n</span><span class="st"> in detecting the 3 species&quot;</span>,</span>
<span id="cb21-10"><a href="introduction.html#cb21-10" aria-hidden="true" tabindex="-1"></a>         <span class="at">pch =</span> <span class="dv">19</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>We might conclude here that ward.D2 works best. However, as we will learn later, optimizing the method without a hold-out for testing means that we may be overfitting. We should check this using cross-validation.</p>
</div>
<div id="k-means-clustering" class="section level3" number="2.1.2">
<h3><span class="header-section-number">2.1.2</span> k-means clustering</h3>
<p>Another example for an unsupervised learning algorithm is k-means clustering, one of the simplest and most popular unsupervised machine learning algorithms.</p>
<p>A cluster refers to a collection of data points aggregated together because of certain similarities. In our example from above this similarities could be similar flowers aggregated together to a plant.</p>
<p>To start with the algorithm, you first have to specify the number of clusters (for our example the number of species). Each cluster has a centroid, which is the imaginary or real location representing the center of the cluster (for our example this would be how an average plant of a specific species would look like). The algorithm starts by randomly putting centroids somewhere and then adds each new data point to the cluster which minimizes the overall in-cluster sum of squares. After the algorithm has assigned a new data point to a cluster the centroid gets updated. By iterating this procedure for all data points and then starting again, the algorithm can find the optimum centroids and the data-points belonging to this cluster.</p>
<p>The k in K-means refers to the number of clusters and the ‘means’ refers to averaging of the data-points to find the centroids.</p>
<p>A typical pipeline for using kmeans clustering looks the same as for the other algortihms. After having visualized the data, we fit the model, visualize the results and have a look at the performance by use of the confusion matrix.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="introduction.html#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb22-2"><a href="introduction.html#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="introduction.html#cb22-3" aria-hidden="true" tabindex="-1"></a>kc <span class="ot">&lt;-</span> <span class="fu">kmeans</span>(traits, <span class="dv">3</span>)</span>
<span id="cb22-4"><a href="introduction.html#cb22-4" aria-hidden="true" tabindex="-1"></a>kc</span></code></pre></div>
<pre><code>## K-means clustering with 3 clusters of sizes 50, 62, 38
## 
## Cluster means:
##   Sepal.Length Sepal.Width Petal.Length Petal.Width
## 1     5.006000    3.428000     1.462000    0.246000
## 2     5.901613    2.748387     4.393548    1.433871
## 3     6.850000    3.073684     5.742105    2.071053
## 
## Clustering vector:
##   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
##  [75] 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 3 3 3 3 2 3 3 3 3 3 3 2 2 3 3 3 3 2 3 2 3 2 3 3 2 2 3 3 3 3 3 2 3 3 3 3 2 3 3 3 2 3 3 3 2 3
## [149] 3 2
## 
## Within cluster sum of squares by cluster:
## [1] 15.15100 39.82097 23.87947
##  (between_SS / total_SS =  88.4 %)
## 
## Available components:
## 
## [1] &quot;cluster&quot;      &quot;centers&quot;      &quot;totss&quot;        &quot;withinss&quot;     &quot;tot.withinss&quot; &quot;betweenss&quot;    &quot;size&quot;         &quot;iter&quot;         &quot;ifault&quot;</code></pre>
<p>Visualizing the results. Color codes true species identity, symbol shows cluster result</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="introduction.html#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(iris[<span class="fu">c</span>(<span class="st">&quot;Sepal.Length&quot;</span>, <span class="st">&quot;Sepal.Width&quot;</span>)], <span class="at">col =</span>  colors[<span class="fu">as.integer</span>(species)], <span class="at">pch =</span> kc<span class="sc">$</span>cluster)</span>
<span id="cb24-2"><a href="introduction.html#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(kc<span class="sc">$</span>centers[, <span class="fu">c</span>(<span class="st">&quot;Sepal.Length&quot;</span>, <span class="st">&quot;Sepal.Width&quot;</span>)], <span class="at">col =</span> colors, <span class="at">pch =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="at">cex =</span> <span class="dv">3</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>We see that there are are some discrepancies. Confusion matrix:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="introduction.html#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(iris<span class="sc">$</span>Species, kc<span class="sc">$</span>cluster)</span></code></pre></div>
<pre><code>##             
##               1  2  3
##   setosa     50  0  0
##   versicolor  0 48  2
##   virginica   0 14 36</code></pre>
<p>If you want to animate the clustering process, you could run</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="introduction.html#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(animation)</span>
<span id="cb27-2"><a href="introduction.html#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="fu">saveGIF</span>(<span class="fu">kmeans.ani</span>(<span class="at">x =</span> traits[,<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>], <span class="at">col =</span> colors), <span class="at">interval =</span> <span class="dv">1</span>, <span class="at">ani.width =</span> <span class="dv">800</span>, <span class="at">ani.height =</span> <span class="dv">800</span>)</span></code></pre></div>
<p>Ellbow technique to determine the number of clusters</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="introduction.html#cb28-1" aria-hidden="true" tabindex="-1"></a>getSumSq <span class="ot">&lt;-</span> <span class="cf">function</span>(k){<span class="fu">kmeans</span>(traits, k, <span class="at">nstart=</span><span class="dv">25</span>)<span class="sc">$</span>tot.withinss}</span>
<span id="cb28-2"><a href="introduction.html#cb28-2" aria-hidden="true" tabindex="-1"></a>iris.kmeans1to10 <span class="ot">&lt;-</span> <span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>, getSumSq)</span>
<span id="cb28-3"><a href="introduction.html#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>, iris.kmeans1to10, <span class="at">type=</span><span class="st">&quot;b&quot;</span>, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">frame =</span> <span class="cn">FALSE</span>, </span>
<span id="cb28-4"><a href="introduction.html#cb28-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">&quot;Number of clusters K&quot;</span>,</span>
<span id="cb28-5"><a href="introduction.html#cb28-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">&quot;Total within-clusters sum of squares&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
</div>
<div id="density-based-clustering" class="section level3" number="2.1.3">
<h3><span class="header-section-number">2.1.3</span> Density-based clustering</h3>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="introduction.html#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb29-2"><a href="introduction.html#cb29-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-3"><a href="introduction.html#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dbscan)</span>
<span id="cb29-4"><a href="introduction.html#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="fu">kNNdistplot</span>(traits, <span class="at">k =</span>  <span class="dv">4</span>)</span>
<span id="cb29-5"><a href="introduction.html#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="fl">0.4</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="introduction.html#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fpc package</span></span>
<span id="cb30-2"><a href="introduction.html#cb30-2" aria-hidden="true" tabindex="-1"></a>dc <span class="ot">&lt;-</span> <span class="fu">dbscan</span>(traits, <span class="at">eps =</span> <span class="fl">0.4</span>, <span class="at">minPts =</span> <span class="dv">6</span>)</span>
<span id="cb30-3"><a href="introduction.html#cb30-3" aria-hidden="true" tabindex="-1"></a>dc</span></code></pre></div>
<pre><code>## DBSCAN clustering for 150 objects.
## Parameters: eps = 0.4, minPts = 6
## The clustering contains 4 cluster(s) and 32 noise points.
## 
##  0  1  2  3  4 
## 32 46 36 14 22 
## 
## Available fields: cluster, eps, minPts</code></pre>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="introduction.html#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(factoextra)</span></code></pre></div>
<pre><code>## Loading required package: ggplot2</code></pre>
<pre><code>## Welcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa</code></pre>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="introduction.html#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_cluster</span>(dc, traits, <span class="at">geom =</span> <span class="st">&quot;point&quot;</span>, <span class="at">ggtheme =</span> <span class="fu">theme_light</span>())</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-18-2.png" width="672" /></p>
</div>
<div id="model-based-clustering" class="section level3" number="2.1.4">
<h3><span class="header-section-number">2.1.4</span> Model-based clustering</h3>
<p>The last class of methods for unsupervised clustering are so-called model-based clustering methods.</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="introduction.html#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mclust)</span></code></pre></div>
<pre><code>##     __  ___________    __  _____________
##    /  |/  / ____/ /   / / / / ___/_  __/
##   / /|_/ / /   / /   / / / /\__ \ / /   
##  / /  / / /___/ /___/ /_/ /___/ // /    
## /_/  /_/\____/_____/\____//____//_/    version 5.4.7
## Type &#39;citation(&quot;mclust&quot;)&#39; for citing this R package in publications.</code></pre>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="introduction.html#cb38-1" aria-hidden="true" tabindex="-1"></a>mb <span class="ot">=</span> <span class="fu">Mclust</span>(traits)</span></code></pre></div>
<pre><code>## fitting ...
## 
  |                                                                                                                                                      
  |                                                                                                                                                |   0%
  |                                                                                                                                                      
  |=                                                                                                                                               |   1%
  |                                                                                                                                                      
  |==                                                                                                                                              |   2%
  |                                                                                                                                                      
  |===                                                                                                                                             |   2%
  |                                                                                                                                                      
  |=====                                                                                                                                           |   3%
  |                                                                                                                                                      
  |======                                                                                                                                          |   4%
  |                                                                                                                                                      
  |=======                                                                                                                                         |   5%
  |                                                                                                                                                      
  |========                                                                                                                                        |   6%
  |                                                                                                                                                      
  |=========                                                                                                                                       |   6%
  |                                                                                                                                                      
  |==========                                                                                                                                      |   7%
  |                                                                                                                                                      
  |===========                                                                                                                                     |   8%
  |                                                                                                                                                      
  |============                                                                                                                                    |   9%
  |                                                                                                                                                      
  |==============                                                                                                                                  |   9%
  |                                                                                                                                                      
  |===============                                                                                                                                 |  10%
  |                                                                                                                                                      
  |================                                                                                                                                |  11%
  |                                                                                                                                                      
  |=================                                                                                                                               |  12%
  |                                                                                                                                                      
  |==================                                                                                                                              |  13%
  |                                                                                                                                                      
  |===================                                                                                                                             |  13%
  |                                                                                                                                                      
  |====================                                                                                                                            |  14%
  |                                                                                                                                                      
  |======================                                                                                                                          |  15%
  |                                                                                                                                                      
  |=======================                                                                                                                         |  16%
  |                                                                                                                                                      
  |========================                                                                                                                        |  17%
  |                                                                                                                                                      
  |=========================                                                                                                                       |  17%
  |                                                                                                                                                      
  |==========================                                                                                                                      |  18%
  |                                                                                                                                                      
  |===========================                                                                                                                     |  19%
  |                                                                                                                                                      
  |============================                                                                                                                    |  20%
  |                                                                                                                                                      
  |=============================                                                                                                                   |  20%
  |                                                                                                                                                      
  |===============================                                                                                                                 |  21%
  |                                                                                                                                                      
  |================================                                                                                                                |  22%
  |                                                                                                                                                      
  |=================================                                                                                                               |  23%
  |                                                                                                                                                      
  |==================================                                                                                                              |  24%
  |                                                                                                                                                      
  |===================================                                                                                                             |  24%
  |                                                                                                                                                      
  |====================================                                                                                                            |  25%
  |                                                                                                                                                      
  |=====================================                                                                                                           |  26%
  |                                                                                                                                                      
  |=======================================                                                                                                         |  27%
  |                                                                                                                                                      
  |========================================                                                                                                        |  28%
  |                                                                                                                                                      
  |=========================================                                                                                                       |  28%
  |                                                                                                                                                      
  |==========================================                                                                                                      |  29%
  |                                                                                                                                                      
  |===========================================                                                                                                     |  30%
  |                                                                                                                                                      
  |============================================                                                                                                    |  31%
  |                                                                                                                                                      
  |=============================================                                                                                                   |  31%
  |                                                                                                                                                      
  |==============================================                                                                                                  |  32%
  |                                                                                                                                                      
  |================================================                                                                                                |  33%
  |                                                                                                                                                      
  |=================================================                                                                                               |  34%
  |                                                                                                                                                      
  |==================================================                                                                                              |  35%
  |                                                                                                                                                      
  |===================================================                                                                                             |  35%
  |                                                                                                                                                      
  |====================================================                                                                                            |  36%
  |                                                                                                                                                      
  |=====================================================                                                                                           |  37%
  |                                                                                                                                                      
  |======================================================                                                                                          |  38%
  |                                                                                                                                                      
  |========================================================                                                                                        |  39%
  |                                                                                                                                                      
  |=========================================================                                                                                       |  39%
  |                                                                                                                                                      
  |==========================================================                                                                                      |  40%
  |                                                                                                                                                      
  |===========================================================                                                                                     |  41%
  |                                                                                                                                                      
  |============================================================                                                                                    |  42%
  |                                                                                                                                                      
  |=============================================================                                                                                   |  43%
  |                                                                                                                                                      
  |==============================================================                                                                                  |  43%
  |                                                                                                                                                      
  |===============================================================                                                                                 |  44%
  |                                                                                                                                                      
  |=================================================================                                                                               |  45%
  |                                                                                                                                                      
  |==================================================================                                                                              |  46%
  |                                                                                                                                                      
  |===================================================================                                                                             |  46%
  |                                                                                                                                                      
  |====================================================================                                                                            |  47%
  |                                                                                                                                                      
  |=====================================================================                                                                           |  48%
  |                                                                                                                                                      
  |======================================================================                                                                          |  49%
  |                                                                                                                                                      
  |=======================================================================                                                                         |  50%
  |                                                                                                                                                      
  |=========================================================================                                                                       |  50%
  |                                                                                                                                                      
  |==========================================================================                                                                      |  51%
  |                                                                                                                                                      
  |===========================================================================                                                                     |  52%
  |                                                                                                                                                      
  |============================================================================                                                                    |  53%
  |                                                                                                                                                      
  |=============================================================================                                                                   |  54%
  |                                                                                                                                                      
  |==============================================================================                                                                  |  54%
  |                                                                                                                                                      
  |===============================================================================                                                                 |  55%
  |                                                                                                                                                      
  |=================================================================================                                                               |  56%
  |                                                                                                                                                      
  |==================================================================================                                                              |  57%
  |                                                                                                                                                      
  |===================================================================================                                                             |  57%
  |                                                                                                                                                      
  |====================================================================================                                                            |  58%
  |                                                                                                                                                      
  |=====================================================================================                                                           |  59%
  |                                                                                                                                                      
  |======================================================================================                                                          |  60%
  |                                                                                                                                                      
  |=======================================================================================                                                         |  61%
  |                                                                                                                                                      
  |========================================================================================                                                        |  61%
  |                                                                                                                                                      
  |==========================================================================================                                                      |  62%
  |                                                                                                                                                      
  |===========================================================================================                                                     |  63%
  |                                                                                                                                                      
  |============================================================================================                                                    |  64%
  |                                                                                                                                                      
  |=============================================================================================                                                   |  65%
  |                                                                                                                                                      
  |==============================================================================================                                                  |  65%
  |                                                                                                                                                      
  |===============================================================================================                                                 |  66%
  |                                                                                                                                                      
  |================================================================================================                                                |  67%
  |                                                                                                                                                      
  |==================================================================================================                                              |  68%
  |                                                                                                                                                      
  |===================================================================================================                                             |  69%
  |                                                                                                                                                      
  |====================================================================================================                                            |  69%
  |                                                                                                                                                      
  |=====================================================================================================                                           |  70%
  |                                                                                                                                                      
  |======================================================================================================                                          |  71%
  |                                                                                                                                                      
  |=======================================================================================================                                         |  72%
  |                                                                                                                                                      
  |========================================================================================================                                        |  72%
  |                                                                                                                                                      
  |=========================================================================================================                                       |  73%
  |                                                                                                                                                      
  |===========================================================================================================                                     |  74%
  |                                                                                                                                                      
  |============================================================================================================                                    |  75%
  |                                                                                                                                                      
  |=============================================================================================================                                   |  76%
  |                                                                                                                                                      
  |==============================================================================================================                                  |  76%
  |                                                                                                                                                      
  |===============================================================================================================                                 |  77%
  |                                                                                                                                                      
  |================================================================================================================                                |  78%
  |                                                                                                                                                      
  |=================================================================================================================                               |  79%
  |                                                                                                                                                      
  |===================================================================================================================                             |  80%
  |                                                                                                                                                      
  |====================================================================================================================                            |  80%
  |                                                                                                                                                      
  |=====================================================================================================================                           |  81%
  |                                                                                                                                                      
  |======================================================================================================================                          |  82%
  |                                                                                                                                                      
  |=======================================================================================================================                         |  83%
  |                                                                                                                                                      
  |========================================================================================================================                        |  83%
  |                                                                                                                                                      
  |=========================================================================================================================                       |  84%
  |                                                                                                                                                      
  |==========================================================================================================================                      |  85%
  |                                                                                                                                                      
  |============================================================================================================================                    |  86%
  |                                                                                                                                                      
  |=============================================================================================================================                   |  87%
  |                                                                                                                                                      
  |==============================================================================================================================                  |  87%
  |                                                                                                                                                      
  |===============================================================================================================================                 |  88%
  |                                                                                                                                                      
  |================================================================================================================================                |  89%
  |                                                                                                                                                      
  |=================================================================================================================================               |  90%
  |                                                                                                                                                      
  |==================================================================================================================================              |  91%
  |                                                                                                                                                      
  |====================================================================================================================================            |  91%
  |                                                                                                                                                      
  |=====================================================================================================================================           |  92%
  |                                                                                                                                                      
  |======================================================================================================================================          |  93%
  |                                                                                                                                                      
  |=======================================================================================================================================         |  94%
  |                                                                                                                                                      
  |========================================================================================================================================        |  94%
  |                                                                                                                                                      
  |=========================================================================================================================================       |  95%
  |                                                                                                                                                      
  |==========================================================================================================================================      |  96%
  |                                                                                                                                                      
  |===========================================================================================================================================     |  97%
  |                                                                                                                                                      
  |=============================================================================================================================================   |  98%
  |                                                                                                                                                      
  |==============================================================================================================================================  |  98%
  |                                                                                                                                                      
  |=============================================================================================================================================== |  99%
  |                                                                                                                                                      
  |================================================================================================================================================| 100%</code></pre>
<p>Mclust automatically compares a number of candidate models (#clusters, shape) according to BIC. We can look at the selected model via</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="introduction.html#cb40-1" aria-hidden="true" tabindex="-1"></a>mb<span class="sc">$</span>G <span class="co"># two clusters</span></span></code></pre></div>
<pre><code>## [1] 2</code></pre>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="introduction.html#cb42-1" aria-hidden="true" tabindex="-1"></a>mb<span class="sc">$</span>modelName <span class="co"># &gt; ellipsoidal, equal shape</span></span></code></pre></div>
<pre><code>## [1] &quot;VEV&quot;</code></pre>
<p>We see that the algorithm prefers to have 2 clusters. For better comparability to the other 2 methods, we will overrule this by setting:</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="introduction.html#cb44-1" aria-hidden="true" tabindex="-1"></a>mb3 <span class="ot">=</span> <span class="fu">Mclust</span>(traits, <span class="dv">3</span>)</span></code></pre></div>
<pre><code>## fitting ...
## 
  |                                                                                                                                                      
  |                                                                                                                                                |   0%
  |                                                                                                                                                      
  |==========                                                                                                                                      |   7%
  |                                                                                                                                                      
  |===================                                                                                                                             |  13%
  |                                                                                                                                                      
  |=============================                                                                                                                   |  20%
  |                                                                                                                                                      
  |======================================                                                                                                          |  27%
  |                                                                                                                                                      
  |================================================                                                                                                |  33%
  |                                                                                                                                                      
  |==========================================================                                                                                      |  40%
  |                                                                                                                                                      
  |===================================================================                                                                             |  47%
  |                                                                                                                                                      
  |=============================================================================                                                                   |  53%
  |                                                                                                                                                      
  |======================================================================================                                                          |  60%
  |                                                                                                                                                      
  |================================================================================================                                                |  67%
  |                                                                                                                                                      
  |==========================================================================================================                                      |  73%
  |                                                                                                                                                      
  |===================================================================================================================                             |  80%
  |                                                                                                                                                      
  |=============================================================================================================================                   |  87%
  |                                                                                                                                                      
  |======================================================================================================================================          |  93%
  |                                                                                                                                                      
  |================================================================================================================================================| 100%</code></pre>
<p>Result in terms of the predicted densities for the 3 clusters</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="introduction.html#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mb3, <span class="st">&quot;density&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<p>Predicted clusters</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="introduction.html#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mb3, <span class="at">what=</span><span class="fu">c</span>(<span class="st">&quot;classification&quot;</span>), <span class="at">add =</span> T)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p>Confusion matrix</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="introduction.html#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(iris<span class="sc">$</span>Species, mb3<span class="sc">$</span>classification)</span></code></pre></div>
<pre><code>##             
##               1  2  3
##   setosa     50  0  0
##   versicolor  0 45  5
##   virginica   0  0 50</code></pre>
</div>
<div id="ordination" class="section level3" number="2.1.5">
<h3><span class="header-section-number">2.1.5</span> Ordination</h3>
<p>Note the relationship between clustering and ordination. Here a PCA ordination on on the</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="introduction.html#cb50-1" aria-hidden="true" tabindex="-1"></a>pcTraits <span class="ot">&lt;-</span> <span class="fu">prcomp</span>(traits, <span class="at">center =</span> <span class="cn">TRUE</span>,<span class="at">scale. =</span> <span class="cn">TRUE</span>)</span>
<span id="cb50-2"><a href="introduction.html#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="fu">biplot</span>(pcTraits, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.25</span>,<span class="fl">0.25</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.25</span>,<span class="fl">0.25</span>))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<p>You can cluster the results of this ordination, ordinate before clustering, or superimpose one on the other.</p>
</div>
</div>
<div id="supervised-learning-regression-and-classification" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Supervised learning: regression and classification</h2>
<p>The two most prominent branches of supervised learning are regression and classification. Fundamentally, classification is about predicting a label and regression is about predicting a quantity. The following video explains that in more depth:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/i04Pfrb71vk" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<div id="supervised-regression-using-random-forest" class="section level3" number="2.2.1">
<h3><span class="header-section-number">2.2.1</span> Supervised regression using Random Forest</h3>
<p>The random forest (RF) algorithm is possibly the most widely used ML algorithm and can be used for regression and classification. We will talk more about the algorithm on Day 2.</p>
<p>For the moment, we want to go through typical workflow for a supervised regression: First, we visualize the data. Next, we fit the model and lastly we visualize the results. We will again use the iris dataset that we used before. The goal is now to predict Sepal.Length based on the infomration about the other variables (including species).</p>
<p>Fitting the model</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="introduction.html#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span></code></pre></div>
<pre><code>## randomForest 4.6-14</code></pre>
<pre><code>## Type rfNews() to see new features/changes/bug fixes.</code></pre>
<pre><code>## 
## Attaching package: &#39;randomForest&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:ggplot2&#39;:
## 
##     margin</code></pre>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="introduction.html#cb56-1" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(Sepal.Length <span class="sc">~</span> ., <span class="at">data =</span> iris)</span>
<span id="cb56-2"><a href="introduction.html#cb56-2" aria-hidden="true" tabindex="-1"></a><span class="co"># str(m1)</span></span>
<span id="cb56-3"><a href="introduction.html#cb56-3" aria-hidden="true" tabindex="-1"></a><span class="co"># m1$type</span></span>
<span id="cb56-4"><a href="introduction.html#cb56-4" aria-hidden="true" tabindex="-1"></a><span class="co"># predict(m1)</span></span>
<span id="cb56-5"><a href="introduction.html#cb56-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(m1)</span></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = Sepal.Length ~ ., data = iris) 
##                Type of random forest: regression
##                      Number of trees: 500
## No. of variables tried at each split: 1
## 
##           Mean of squared residuals: 0.1364625
##                     % Var explained: 79.97</code></pre>
<p>Visualization of the results</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="introduction.html#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb58-2"><a href="introduction.html#cb58-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">predict</span>(m1), iris<span class="sc">$</span>Sepal.Length, <span class="at">xlab =</span> <span class="st">&quot;predicted&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;observed&quot;</span>)</span>
<span id="cb58-3"><a href="introduction.html#cb58-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb58-4"><a href="introduction.html#cb58-4" aria-hidden="true" tabindex="-1"></a><span class="fu">varImpPlot</span>(m1)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-28-1.png" width="672" />
To understand, the structure of a RF in more detail, we can use a package from GitHub</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="introduction.html#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co"># devtools::install_github(&#39;araastat/reprtree&#39;)</span></span>
<span id="cb59-2"><a href="introduction.html#cb59-2" aria-hidden="true" tabindex="-1"></a>reprtree<span class="sc">:::</span><span class="fu">plot.getTree</span>(m1, iris)</span></code></pre></div>
<pre><code>## Loading required package: plotrix</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
</div>
<div id="supervised-classification-using-random-forest" class="section level3" number="2.2.2">
<h3><span class="header-section-number">2.2.2</span> Supervised classification using Random Forest</h3>
<p>With the RF, we can also do classification. The steps are the same as for regression tasks, but we can additionally, see how well it performed by looking at the so called confusion matrix. Each row of this matrix contains the instances in a predicted class and each column represent the instances in an actual class. Thus the diagonals are the correctly predicted classes and the off-diagnoal elements are the falsly classified elements.</p>
<p>Fitting the model:</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="introduction.html#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb61-2"><a href="introduction.html#cb61-2" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(Species <span class="sc">~</span> ., <span class="at">data =</span> iris)</span>
<span id="cb61-3"><a href="introduction.html#cb61-3" aria-hidden="true" tabindex="-1"></a><span class="co"># str(m1)</span></span>
<span id="cb61-4"><a href="introduction.html#cb61-4" aria-hidden="true" tabindex="-1"></a><span class="co"># m1$type</span></span>
<span id="cb61-5"><a href="introduction.html#cb61-5" aria-hidden="true" tabindex="-1"></a><span class="co"># predict(m1)</span></span>
<span id="cb61-6"><a href="introduction.html#cb61-6" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(m1)</span></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = Species ~ ., data = iris) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 2
## 
##         OOB estimate of  error rate: 4.67%
## Confusion matrix:
##            setosa versicolor virginica class.error
## setosa         50          0         0        0.00
## versicolor      0         47         3        0.06
## virginica       0          4        46        0.08</code></pre>
<p>Visualizing the fitted model:</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="introduction.html#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb63-2"><a href="introduction.html#cb63-2" aria-hidden="true" tabindex="-1"></a>reprtree<span class="sc">:::</span><span class="fu">plot.getTree</span>(m1, iris)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<p>Visualizing results ecologically:</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="introduction.html#cb64-1" aria-hidden="true" tabindex="-1"></a>oldpar <span class="ot">&lt;-</span> <span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb64-2"><a href="introduction.html#cb64-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(iris<span class="sc">$</span>Petal.Width, iris<span class="sc">$</span>Petal.Length, <span class="at">col =</span> iris<span class="sc">$</span>Species, <span class="at">main =</span> <span class="st">&quot;observed&quot;</span>)</span>
<span id="cb64-3"><a href="introduction.html#cb64-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(iris<span class="sc">$</span>Petal.Width, iris<span class="sc">$</span>Petal.Length, <span class="at">col =</span> <span class="fu">predict</span>(m1), <span class="at">main =</span> <span class="st">&quot;predicted&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<p>Confusion matrix:</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="introduction.html#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(<span class="fu">predict</span>(m1),iris<span class="sc">$</span>Species)</span></code></pre></div>
<pre><code>##             
##              setosa versicolor virginica
##   setosa         50          0         0
##   versicolor      0         47         4
##   virginica       0          3        46</code></pre>
</div>
</div>
<div id="introduction-to-tensorflow" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Introduction to Tensorflow</h2>
<p>All operations in TF are written in C++ and are highly optimized. But dont worry, we don’t have to use C++ to use TF because there are several bindings for other languages. TensorFlow officialy supports a Python API, but meanwhile there are several community carried APIs for other languages:</p>
<ul>
<li>R</li>
<li>Go</li>
<li>Rust</li>
<li>Swift</li>
<li>JavaScript</li>
</ul>
<p>In this course we will use TF with the <a href="https://tensorflow.rstudio.com/" class="uri">https://tensorflow.rstudio.com/</a> binding, that was developed and published 2017 by the RStudio
Team. They developed first a R package (reticulate) to call python in R. Actually, we are using in R the python TF module (more about this later).
TF offers different levels of API. We could implement a neural network completly by ourselves, or we could use Keras which is provided by TF as a submodule. Keras is a powerful module for building and training neural networks. It allows us to build and train neural networks in a few lines of codes. Since the end of 2018, Keras and TF are completly interoperable, allowing us to utilize the best of both. In this course, we will show how we can use Keras
for neural networks but also how we can use the TF’s automatic differenation for using complex objective functions.</p>
<p>One of the most commonly used frameworks for machine learning is TensorFlow. TensorFlow is a open source linear algebra library with a focus on neural networks, published by Google in 2015. TF supports several interesting features, im particular automatic differentiation, several gradient optimizers and CPU and GPU parallelization.</p>
<p>These advantages are nicely explained in the following video:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/MotG3XI2qSs" frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<p>To sum the most important points of the video up:</p>
<ul>
<li>TF is a math library which is highly optimized for neural networks</li>
<li>If a GPU is available, computations can be easily run on the GPU but even on a CPU is TF still very fast</li>
<li>The “backend” (i.e. all the functions and all computations) are written in C++ and CUDA (CUDA is a programming language for the GPU)</li>
<li>The interface (the part of TF that we use) is written in python and is also available in R, which means, we can write the code in R/Python but it will be executed by the (compiled) C++ backend.</li>
</ul>
<p>All operations in TF are written in C++ and are highly optimized. But dont worry, we don’t have to use C++ to use TF, because there are several bindings for other languages. Officially, TensorFlow only supports a Python API, but meanwhile there are several community carried APIs for other languages, including R, Go, Rust, Swift or JavaScript. In this book, we will use TF with the <a href="https://tensorflow.rstudio.com/" class="uri">https://tensorflow.rstudio.com/</a> binding that was developed and published 2017 by the RStudio Team. They developed first a R package (reticulate) to call python in R. Actually, we are using in R the python TF module (more about this later).</p>
<p>Useful links:</p>
<ul>
<li><a href="https://www.tensorflow.org/api_docs/python/tf">TensorFlow documentation</a> (which is for the python API, but just replace the ‘.’ with ‘$’)</li>
<li><a href="https://tensorflow.rstudio.com/">Rstudio tensorflow website</a></li>
</ul>
<div id="tensorflow-data-containers" class="section level3" number="2.3.1">
<h3><span class="header-section-number">2.3.1</span> Tensorflow data containers</h3>
<p>TF has two data containers (structures):</p>
<ul>
<li>constant (tf$constant) :creates a constant (immutable) value in the computation graph</li>
<li>variable (tf$Variable): creates a mutable value in the computation graph (used as parameter/weight in models)</li>
</ul>
<p>To get started with tensorflow, we have to load the library and check if the installation worked.</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="introduction.html#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb67-2"><a href="introduction.html#cb67-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Don&#39;t worry about weird messages. TF supports additional optimizations</span></span>
<span id="cb67-3"><a href="introduction.html#cb67-3" aria-hidden="true" tabindex="-1"></a><span class="fu">exists</span>(<span class="st">&quot;tf&quot;</span>)</span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>Don’t worry about weird messages (they will only appear once at the start of the session).</p>
<p>We now can define the variables and do some math with them:</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="introduction.html#cb69-1" aria-hidden="true" tabindex="-1"></a>a <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(<span class="dv">5</span>)</span>
<span id="cb69-2"><a href="introduction.html#cb69-2" aria-hidden="true" tabindex="-1"></a>b <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(<span class="dv">10</span>)</span>
<span id="cb69-3"><a href="introduction.html#cb69-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(a)</span></code></pre></div>
<pre><code>## tf.Tensor(5.0, shape=(), dtype=float32)</code></pre>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="introduction.html#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(b)</span></code></pre></div>
<pre><code>## tf.Tensor(10.0, shape=(), dtype=float32)</code></pre>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="introduction.html#cb73-1" aria-hidden="true" tabindex="-1"></a>c <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">add</span>(a, b)</span>
<span id="cb73-2"><a href="introduction.html#cb73-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(c)</span></code></pre></div>
<pre><code>## tf.Tensor(15.0, shape=(), dtype=float32)</code></pre>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="introduction.html#cb75-1" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span><span class="fu">print</span>(c)</span></code></pre></div>
<p>Normal R methods such as print() are provided by the R package “tensorflow.”</p>
<p>The tensorflow library (created by the RStudio team) built R methods for all common operations:</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="introduction.html#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="st">`</span><span class="at">+.tensorflow.tensor</span><span class="st">`</span> <span class="ot">=</span> <span class="cf">function</span>(a, b) <span class="fu">return</span>(tf<span class="sc">$</span><span class="fu">add</span>(a,b))</span>
<span id="cb76-2"><a href="introduction.html#cb76-2" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span><span class="fu">print</span>(a<span class="sc">+</span>b)</span></code></pre></div>
<p>Their operators also transfrom automatically R numbers into constant tensors when attempting to add a tensor to a R number:</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="introduction.html#cb77-1" aria-hidden="true" tabindex="-1"></a>d <span class="ot">=</span> c <span class="sc">+</span> <span class="dv">5</span>  <span class="co"># 5 is automatically converted to a tensor</span></span>
<span id="cb77-2"><a href="introduction.html#cb77-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(d)</span></code></pre></div>
<pre><code>## tf.Tensor(20.0, shape=(), dtype=float32)</code></pre>
<p>TF container are objects, which means that they are not just simple variables of type numeric (class(5)), but they instead have so called methods. Methods are changing the state of a class (which for most of our purposes here is the values of the object)
For instance, there is a method to transform the tensor object back to a R object:</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="introduction.html#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(d)</span></code></pre></div>
<pre><code>## [1] &quot;tensorflow.tensor&quot;                                &quot;tensorflow.python.framework.ops.EagerTensor&quot;     
## [3] &quot;tensorflow.python.framework.ops._EagerTensorBase&quot; &quot;tensorflow.python.framework.ops.Tensor&quot;          
## [5] &quot;tensorflow.python.types.internal.NativeObject&quot;    &quot;tensorflow.python.types.core.Tensor&quot;             
## [7] &quot;python.builtin.object&quot;</code></pre>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="introduction.html#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(d<span class="sc">$</span><span class="fu">numpy</span>())</span></code></pre></div>
<pre><code>## [1] &quot;numeric&quot;</code></pre>
</div>
<div id="tensorflow-data-types---good-practise-with-r-tf" class="section level3" number="2.3.2">
<h3><span class="header-section-number">2.3.2</span> Tensorflow data types - good practise with R-TF</h3>
<p>R uses dynamic typing, which means you can assign to a variable a number, character, function or whatever, and the the type is automatically infered.
In other languages you have to state explicitly the type, e.g. in C: int a = 5; float a = 5.0; char a = “a”;
While TF tries to infer dynamically the type, often you must state it explicitly.
Common important types:
- float32 (floating point number with 32bits, “single precision”)
- float64 (floating point number with 64bits, “double precision”)
- int8 (integer with 8bits)
The reason why TF is so explicit about the types is that many GPUs (e.g. the NVIDIA geforces) can handle only up to 32bit numbers! (you do not need high precision in graphical modeling)</p>
<p>But let us see in practice, what we have to do with these types and how to specifcy them:</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="introduction.html#cb83-1" aria-hidden="true" tabindex="-1"></a>r_matrix <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(<span class="dv">10</span><span class="sc">*</span><span class="dv">10</span>), <span class="dv">10</span>,<span class="dv">10</span>)</span>
<span id="cb83-2"><a href="introduction.html#cb83-2" aria-hidden="true" tabindex="-1"></a>m <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(r_matrix, <span class="at">dtype =</span> <span class="st">&quot;float32&quot;</span>) </span>
<span id="cb83-3"><a href="introduction.html#cb83-3" aria-hidden="true" tabindex="-1"></a>b <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(<span class="fl">2.0</span>, <span class="at">dtype =</span> <span class="st">&quot;float64&quot;</span>)</span>
<span id="cb83-4"><a href="introduction.html#cb83-4" aria-hidden="true" tabindex="-1"></a>c <span class="ot">=</span> m <span class="sc">/</span> b <span class="co"># doesn&#39;t work! we try to divide float32/float64</span></span></code></pre></div>
<p>So what went wrong here: we tried to divide a float32 to a float64 number, but, we can only divide numbers of the same type!</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="introduction.html#cb84-1" aria-hidden="true" tabindex="-1"></a>r_matrix <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(<span class="dv">10</span><span class="sc">*</span><span class="dv">10</span>), <span class="dv">10</span>,<span class="dv">10</span>)</span>
<span id="cb84-2"><a href="introduction.html#cb84-2" aria-hidden="true" tabindex="-1"></a>m <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(r_matrix, <span class="at">dtype =</span> <span class="st">&quot;float64&quot;</span>)</span>
<span id="cb84-3"><a href="introduction.html#cb84-3" aria-hidden="true" tabindex="-1"></a>b <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(<span class="fl">2.0</span>, <span class="at">dtype =</span> <span class="st">&quot;float64&quot;</span>)</span>
<span id="cb84-4"><a href="introduction.html#cb84-4" aria-hidden="true" tabindex="-1"></a>c <span class="ot">=</span> m <span class="sc">/</span> b <span class="co"># now it works</span></span></code></pre></div>
<p>We can also specify the type of the object by providing an object e.g. tf$float64.</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="introduction.html#cb85-1" aria-hidden="true" tabindex="-1"></a>r_matrix <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(<span class="dv">10</span><span class="sc">*</span><span class="dv">10</span>), <span class="dv">10</span>,<span class="dv">10</span>)</span>
<span id="cb85-2"><a href="introduction.html#cb85-2" aria-hidden="true" tabindex="-1"></a>m <span class="ot">=</span> tf<span class="sc">$</span><span class="fu">constant</span>(r_matrix, <span class="at">dtype =</span> tf<span class="sc">$</span>float64)</span></code></pre></div>
<p>Tensorflow arguments often require exact/explicit data types:
TF often expects for arguments integers. In R however an integer is normally saved as float.
Thus, we have to use a “L” after an integer to tell the R interpreter that it should be treated as an integer:</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="introduction.html#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="fu">is.integer</span>(<span class="dv">5</span>)</span>
<span id="cb86-2"><a href="introduction.html#cb86-2" aria-hidden="true" tabindex="-1"></a><span class="fu">is.integer</span>(5L)</span>
<span id="cb86-3"><a href="introduction.html#cb86-3" aria-hidden="true" tabindex="-1"></a><span class="fu">matrix</span>(<span class="fu">t</span>(r_matrix), <span class="dv">5</span>, <span class="dv">20</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb86-4"><a href="introduction.html#cb86-4" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span><span class="fu">reshape</span>(r_matrix, <span class="at">shape =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">20</span>))<span class="sc">$</span><span class="fu">numpy</span>()</span>
<span id="cb86-5"><a href="introduction.html#cb86-5" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span><span class="fu">reshape</span>(r_matrix, <span class="at">shape =</span> <span class="fu">c</span>(5L, 20L))<span class="sc">$</span><span class="fu">numpy</span>()</span></code></pre></div>
<p>Skipping the “L” is one of the most common errors when using R-TF!</p>
</div>
</div>
<div id="introduction-to-pytorch" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> Introduction to PyTorch</h2>
<p>PyTorch is another famous library for deep learning. As for tensorflow, torch itself is written in c++ but the API in python. Last year, the RStudio team released R-torch, and while r-tensorflow calls the python API in the background, the r-torch API is built directly on the c++ torch library!</p>
<p>Useful links:</p>
<ul>
<li><a href="https://pytorch.org/docs/stable/index.html">PyTorch documentation</a> (which is for the python API, bust just replace the ‘.’ with ‘$’)</li>
<li><a href="https://torch.mlverse.org/">R-torch website</a></li>
</ul>
<div id="pytorch-data-containers" class="section level3" number="2.4.1">
<h3><span class="header-section-number">2.4.1</span> PyTorch data containers</h3>
<p>TF has two data containers (structures):</p>
<ul>
<li>constant (tf_tensor(…)) :creates a constant (immutable) value in the computation graph</li>
<li>variable (tf_$Variable_tensor(…, requires_grad=TRUE)): creates a mutable value in the computation graph (used as parameter/weight in models)</li>
</ul>
<p>To get started with torch, we have to load the library and check if the installation worked.</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="introduction.html#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span></code></pre></div>
<p>Don’t worry about weird messages (they will only appear once at the start of the session).</p>
<p>We now can define the variables and do some math with them:</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="introduction.html#cb88-1" aria-hidden="true" tabindex="-1"></a>a <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fl">5.</span>)</span>
<span id="cb88-2"><a href="introduction.html#cb88-2" aria-hidden="true" tabindex="-1"></a>b <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fl">10.</span>)</span>
<span id="cb88-3"><a href="introduction.html#cb88-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(a)</span></code></pre></div>
<pre><code>## torch_tensor
##  5
## [ CPUFloatType{1} ]</code></pre>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="introduction.html#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(b)</span></code></pre></div>
<pre><code>## torch_tensor
##  10
## [ CPUFloatType{1} ]</code></pre>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="introduction.html#cb92-1" aria-hidden="true" tabindex="-1"></a>c <span class="ot">=</span> a<span class="sc">$</span><span class="fu">add</span>( b )</span>
<span id="cb92-2"><a href="introduction.html#cb92-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(c)</span></code></pre></div>
<pre><code>## torch_tensor
##  15
## [ CPUFloatType{1} ]</code></pre>
<p>The r-torch package provides all common methods (an advantage over tensorflow)</p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="introduction.html#cb94-1" aria-hidden="true" tabindex="-1"></a>a <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fl">5.</span>)</span>
<span id="cb94-2"><a href="introduction.html#cb94-2" aria-hidden="true" tabindex="-1"></a>b <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fl">10.</span>)</span>
<span id="cb94-3"><a href="introduction.html#cb94-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(a<span class="sc">+</span>b)</span></code></pre></div>
<pre><code>## torch_tensor
##  15
## [ CPUFloatType{1} ]</code></pre>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="introduction.html#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(a<span class="sc">/</span>b)</span></code></pre></div>
<pre><code>## torch_tensor
##  0.5000
## [ CPUFloatType{1} ]</code></pre>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="introduction.html#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(a<span class="sc">*</span>b)</span></code></pre></div>
<pre><code>## torch_tensor
##  50
## [ CPUFloatType{1} ]</code></pre>
<p>Their operators also transfrom automatically R numbers into tensors when attempting to add a tensor to a R number:</p>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="introduction.html#cb100-1" aria-hidden="true" tabindex="-1"></a>d <span class="ot">=</span> a <span class="sc">+</span> <span class="dv">5</span>  <span class="co"># 5 is automatically converted to a tensor</span></span>
<span id="cb100-2"><a href="introduction.html#cb100-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(d)</span></code></pre></div>
<pre><code>## torch_tensor
##  10
## [ CPUFloatType{1} ]</code></pre>
<p>As for tensorflow, we have to explicitly transform the tensors back to R:</p>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="introduction.html#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(d)</span></code></pre></div>
<pre><code>## [1] &quot;torch_tensor&quot; &quot;R7&quot;</code></pre>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="introduction.html#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(<span class="fu">as.numeric</span>(d))</span></code></pre></div>
<pre><code>## [1] &quot;numeric&quot;</code></pre>
</div>
<div id="torch-data-types---good-practise-with-r-tf" class="section level3" number="2.4.2">
<h3><span class="header-section-number">2.4.2</span> Torch data types - good practise with R-TF</h3>
<p>Similar to tensorflow:</p>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="introduction.html#cb106-1" aria-hidden="true" tabindex="-1"></a>r_matrix <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(<span class="dv">10</span><span class="sc">*</span><span class="dv">10</span>), <span class="dv">10</span>,<span class="dv">10</span>)</span>
<span id="cb106-2"><a href="introduction.html#cb106-2" aria-hidden="true" tabindex="-1"></a>m <span class="ot">=</span> <span class="fu">torch_tensor</span>(r_matrix, <span class="at">dtype =</span> <span class="fu">torch_float32</span>()) </span>
<span id="cb106-3"><a href="introduction.html#cb106-3" aria-hidden="true" tabindex="-1"></a>b <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fl">2.0</span>, <span class="at">dtype =</span> <span class="fu">torch_float64</span>())</span>
<span id="cb106-4"><a href="introduction.html#cb106-4" aria-hidden="true" tabindex="-1"></a>c <span class="ot">=</span> m <span class="sc">/</span> b </span></code></pre></div>
<p>But here’s a difference! With tensorfow we would get an error, but with r-torch, m is automatically casted to a double (float64). However, this is still bad practise!</p>
<p>During the course we will try to provide for all keras/tensorflow examples the corresponding pytorch code snippets.</p>
</div>
</div>
<div id="first-steps-with-the-keras-framework" class="section level2" number="2.5">
<h2><span class="header-section-number">2.5</span> First steps with the keras framework</h2>
<p>We have seen that we can use TF directly from R, and we could use this knowledge to implement a neural network in TF directly from R. However, this can be quite cumbersome. For simple problems, it is usually faster to use a higher-level API that helps us with implementing the machine learning models in TF. The most common of those is Keras.</p>
<p>Keras is a powerful framework for building and training neural networks with a few lines of codes. Since the end of 2018, Keras and TF are completely interoperable, allowing us to utilize the best of both.</p>
<p>The objective of this lesson is to familiarize yourself with keras. If you have TF installed, Keras can be found within TF: tf.keras. However, the RStudio team has built an R package on top of tf.keras, and it is more convenient to use this. To load the keras package, type</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="introduction.html#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span></code></pre></div>
<div id="example-workflow-in-keras" class="section level3" number="2.5.1">
<h3><span class="header-section-number">2.5.1</span> Example workflow in keras</h3>
<p>To show how keras works, we will now build a small classifier in keras to predict the three species of the iris dataset. Load the necessary packages and datasets:</p>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="introduction.html#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb108-2"><a href="introduction.html#cb108-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb108-3"><a href="introduction.html#cb108-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(iris)</span>
<span id="cb108-4"><a href="introduction.html#cb108-4" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(iris)</span></code></pre></div>
<pre><code>##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species
## 1          5.1         3.5          1.4         0.2  setosa
## 2          4.9         3.0          1.4         0.2  setosa
## 3          4.7         3.2          1.3         0.2  setosa
## 4          4.6         3.1          1.5         0.2  setosa
## 5          5.0         3.6          1.4         0.2  setosa
## 6          5.4         3.9          1.7         0.4  setosa</code></pre>
<p>It is beneficial for neural networks to scale the predictors (scaling = centering and standardization, see ?scale)
We also split our data into the predictors (X) and the response (Y = the three species).</p>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="introduction.html#cb110-1" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">scale</span>(iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span>
<span id="cb110-2"><a href="introduction.html#cb110-2" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span> iris[,<span class="dv">5</span>]</span></code></pre></div>
<p>Additionally, keras/tf cannot handle factors and we have to create contrasts (one-hot encoding):
To do so, we have to specify the number of categories. This can be tricky for a beginner, because in other programming languages like python and C++ on which TF is built, arrays start at zero. Thus, when we would specify 3 as number of classes for our three species, we would have the classes 0,1,2,3. Therefore, we have to substract it.</p>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="introduction.html#cb111-1" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span> <span class="fu">to_categorical</span>(<span class="fu">as.integer</span>(Y)<span class="sc">-</span>1L, <span class="dv">3</span>)</span>
<span id="cb111-2"><a href="introduction.html#cb111-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(Y) <span class="co"># 3 colums, one for each level in the response</span></span></code></pre></div>
<pre><code>##      [,1] [,2] [,3]
## [1,]    1    0    0
## [2,]    1    0    0
## [3,]    1    0    0
## [4,]    1    0    0
## [5,]    1    0    0
## [6,]    1    0    0</code></pre>
<p>After having prepared the data, we will now see a typical workflow to specify a model in keras.</p>
<p><strong>1. Initiliaze a sequential model in keras:</strong></p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="introduction.html#cb113-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">keras_model_sequential</span>()</span></code></pre></div>
<p>A sequential keras model is a higher order type of model within keras and consists of one input and one output model.</p>
<p><strong>2. Add hidden layers to the model (we will learn more about hidden layers during the next days).</strong>
When specifiying the hidden layers, we also have to specify a so called activation function and their shape.
You can think of the activation function as decisive for what is forwarded to the next neuron (but we will learn more about it later). The shape of the input is the number of predictors (here 4) and the shape of the output is the number of classes (here 3).</p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="introduction.html#cb114-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb114-2"><a href="introduction.html#cb114-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">input_shape =</span> <span class="fu">list</span>(4L)) <span class="sc">%&gt;%</span></span>
<span id="cb114-3"><a href="introduction.html#cb114-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L) <span class="sc">%&gt;%</span></span>
<span id="cb114-4"><a href="introduction.html#cb114-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 20L) <span class="sc">%&gt;%</span></span>
<span id="cb114-5"><a href="introduction.html#cb114-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> 3L, <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>) </span></code></pre></div>
<ul>
<li>softmax scales a potential multidimensional vector to the interval (0,1]</li>
</ul>
<details>
<summary>
<strong><span style="color: #CC2FAA">torch</span></strong>
</summary>
<p>
<p>The torch syntax is very similar, we will give a list of layers to ‘nn_sequential’ function. Here, we have to specify the softmax activation function as an extra layer:</p>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="introduction.html#cb115-1" aria-hidden="true" tabindex="-1"></a>model_torch <span class="ot">=</span> </span>
<span id="cb115-2"><a href="introduction.html#cb115-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nn_sequential</span>(</span>
<span id="cb115-3"><a href="introduction.html#cb115-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(4L, 20L),</span>
<span id="cb115-4"><a href="introduction.html#cb115-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 20L),</span>
<span id="cb115-5"><a href="introduction.html#cb115-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 20L),</span>
<span id="cb115-6"><a href="introduction.html#cb115-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_linear</span>(20L, 3L),</span>
<span id="cb115-7"><a href="introduction.html#cb115-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nn_softmax</span>(<span class="dv">2</span>)</span>
<span id="cb115-8"><a href="introduction.html#cb115-8" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
</details>
<p><br/></p>
<p><strong>3. Compile the model with a loss function (here: cross entropy) and an optimizer (here: Adamax).</strong></p>
<p>We will leaern about other options later, so for now, do not worry about the “lr” argument, crossentropy or the optimizer.</p>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="introduction.html#cb116-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span></span>
<span id="cb116-2"><a href="introduction.html#cb116-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(<span class="at">loss =</span> loss_categorical_crossentropy, keras<span class="sc">::</span><span class="fu">optimizer_adamax</span>(<span class="at">lr =</span> <span class="fl">0.001</span>))</span>
<span id="cb116-3"><a href="introduction.html#cb116-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## Model: &quot;sequential&quot;
## __________________________________________________________________________________________________________________________________________________________
## Layer (type)                                                         Output Shape                                                 Param #                 
## ==========================================================================================================================================================
## dense (Dense)                                                        (None, 20)                                                   100                     
## __________________________________________________________________________________________________________________________________________________________
## dense_1 (Dense)                                                      (None, 20)                                                   420                     
## __________________________________________________________________________________________________________________________________________________________
## dense_2 (Dense)                                                      (None, 20)                                                   420                     
## __________________________________________________________________________________________________________________________________________________________
## dense_3 (Dense)                                                      (None, 3)                                                    63                      
## ==========================================================================================================================================================
## Total params: 1,003
## Trainable params: 1,003
## Non-trainable params: 0
## __________________________________________________________________________________________________________________________________________________________</code></pre>
<details>
<summary>
<strong><span style="color: #CC2FAA">torch</span></strong>
</summary>
<p>
<p>Specify optimizer and the parameters which will be trained (in our case the parameters of the network)</p>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb118-1"><a href="introduction.html#cb118-1" aria-hidden="true" tabindex="-1"></a>optimizer_torch <span class="ot">=</span> <span class="fu">optim_adam</span>(<span class="at">params =</span> model_torch<span class="sc">$</span>parameters, <span class="at">lr =</span> <span class="fl">0.01</span>)</span></code></pre></div>
</details>
<p><br/></p>
<p><strong>4. Fit model in 30 iterations(epochs)</strong></p>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="introduction.html#cb119-1" aria-hidden="true" tabindex="-1"></a>model_history <span class="ot">=</span></span>
<span id="cb119-2"><a href="introduction.html#cb119-2" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">%&gt;%</span></span>
<span id="cb119-3"><a href="introduction.html#cb119-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(<span class="at">x =</span> X, <span class="at">y =</span> <span class="fu">apply</span>(Y,<span class="dv">2</span>,as.integer), <span class="at">epochs =</span> 30L, <span class="at">batch_size =</span> 20L, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<details>
<summary>
<strong><span style="color: #CC2FAA">torch</span></strong>
</summary>
<p>
<p>In torch, we jump directly to the training loop, however, here we have to write our own training loop:</p>
<ol style="list-style-type: decimal">
<li>get a batch of data</li>
<li>predict on batch</li>
<li>calculate loss between predictions and true labels</li>
<li>backpropagate error</li>
<li>update weights</li>
<li>go to step 1 and repeat</li>
</ol>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="introduction.html#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate number of training steps</span></span>
<span id="cb120-2"><a href="introduction.html#cb120-2" aria-hidden="true" tabindex="-1"></a>epochs <span class="ot">=</span> <span class="dv">30</span></span>
<span id="cb120-3"><a href="introduction.html#cb120-3" aria-hidden="true" tabindex="-1"></a>batch_size <span class="ot">=</span> <span class="dv">20</span></span>
<span id="cb120-4"><a href="introduction.html#cb120-4" aria-hidden="true" tabindex="-1"></a>steps <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">nrow</span>(X)<span class="sc">/</span>batch_size<span class="sc">*</span><span class="dv">30</span>)</span>
<span id="cb120-5"><a href="introduction.html#cb120-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-6"><a href="introduction.html#cb120-6" aria-hidden="true" tabindex="-1"></a>X_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(X)</span>
<span id="cb120-7"><a href="introduction.html#cb120-7" aria-hidden="true" tabindex="-1"></a>Y_torch <span class="ot">=</span> <span class="fu">torch_tensor</span>(<span class="fu">apply</span>(Y, <span class="dv">1</span>, which.max)) </span>
<span id="cb120-8"><a href="introduction.html#cb120-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-9"><a href="introduction.html#cb120-9" aria-hidden="true" tabindex="-1"></a><span class="co"># set model into training status</span></span>
<span id="cb120-10"><a href="introduction.html#cb120-10" aria-hidden="true" tabindex="-1"></a>model_torch<span class="sc">$</span><span class="fu">train</span>()</span>
<span id="cb120-11"><a href="introduction.html#cb120-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-12"><a href="introduction.html#cb120-12" aria-hidden="true" tabindex="-1"></a>log_losses <span class="ot">=</span> <span class="cn">NULL</span></span>
<span id="cb120-13"><a href="introduction.html#cb120-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-14"><a href="introduction.html#cb120-14" aria-hidden="true" tabindex="-1"></a><span class="co"># training loop</span></span>
<span id="cb120-15"><a href="introduction.html#cb120-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>steps) {</span>
<span id="cb120-16"><a href="introduction.html#cb120-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># get batch</span></span>
<span id="cb120-17"><a href="introduction.html#cb120-17" aria-hidden="true" tabindex="-1"></a>  indices <span class="ot">=</span> <span class="fu">sample.int</span>( <span class="fu">nrow</span>(X), batch_size)</span>
<span id="cb120-18"><a href="introduction.html#cb120-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb120-19"><a href="introduction.html#cb120-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># reset backpropagation</span></span>
<span id="cb120-20"><a href="introduction.html#cb120-20" aria-hidden="true" tabindex="-1"></a>  optimizer_torch<span class="sc">$</span><span class="fu">zero_grad</span>()</span>
<span id="cb120-21"><a href="introduction.html#cb120-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb120-22"><a href="introduction.html#cb120-22" aria-hidden="true" tabindex="-1"></a>  <span class="co"># predict and calculate loss</span></span>
<span id="cb120-23"><a href="introduction.html#cb120-23" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">=</span> <span class="fu">model_torch</span>(X_torch[indices, ])</span>
<span id="cb120-24"><a href="introduction.html#cb120-24" aria-hidden="true" tabindex="-1"></a>  loss <span class="ot">=</span> <span class="fu">nnf_cross_entropy</span>(pred, Y_torch[indices])</span>
<span id="cb120-25"><a href="introduction.html#cb120-25" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb120-26"><a href="introduction.html#cb120-26" aria-hidden="true" tabindex="-1"></a>  <span class="co"># backprop and weight update</span></span>
<span id="cb120-27"><a href="introduction.html#cb120-27" aria-hidden="true" tabindex="-1"></a>  loss<span class="sc">$</span><span class="fu">backward</span>()</span>
<span id="cb120-28"><a href="introduction.html#cb120-28" aria-hidden="true" tabindex="-1"></a>  optimizer_torch<span class="sc">$</span><span class="fu">step</span>()</span>
<span id="cb120-29"><a href="introduction.html#cb120-29" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb120-30"><a href="introduction.html#cb120-30" aria-hidden="true" tabindex="-1"></a>  log_losses[i] <span class="ot">=</span> <span class="fu">as.numeric</span>(loss)</span>
<span id="cb120-31"><a href="introduction.html#cb120-31" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
</details>
<p><br/></p>
<p><strong>5. Plot training history:</strong></p>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="introduction.html#cb121-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_history)</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-62-1.png" width="672" /></p>
<details>
<summary>
<strong><span style="color: #CC2FAA">torch</span></strong>
</summary>
<p>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="introduction.html#cb123-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(log_losses, <span class="at">xlab =</span> <span class="st">&quot;steps&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;loss&quot;</span>, <span class="at">las =</span> <span class="dv">1</span>)</span></code></pre></div>
<img src="_main_files/figure-html/unnamed-chunk-63-1.png" width="672" />
</details>
<p><br/></p>
<p><strong>6. Create predictions:</strong></p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="introduction.html#cb124-1" aria-hidden="true" tabindex="-1"></a>predictions <span class="ot">=</span> <span class="fu">predict</span>(model, X) <span class="co"># probabilities for each class</span></span></code></pre></div>
<p>We will get probabilites:</p>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="introduction.html#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(predictions) <span class="co"># quasi-probabilities for each species</span></span></code></pre></div>
<pre><code>##           [,1]        [,2]         [,3]
## [1,] 0.9960687 0.002847936 0.0010832436
## [2,] 0.9627200 0.032958280 0.0043216636
## [3,] 0.9926478 0.005417078 0.0019352434
## [4,] 0.9895927 0.007696305 0.0027109848
## [5,] 0.9977964 0.001502181 0.0007014087
## [6,] 0.9962399 0.002326754 0.0014333621</code></pre>
<p>For each plant, we want to know for which species we got the highest probability:</p>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="introduction.html#cb127-1" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">=</span> <span class="fu">apply</span>(predictions, <span class="dv">1</span>, which.max) </span>
<span id="cb127-2"><a href="introduction.html#cb127-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(preds)</span></code></pre></div>
<pre><code>##   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 3 3 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2
##  [75] 2 2 2 3 2 2 2 2 2 3 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3
## [149] 3 3</code></pre>
<details>
<summary>
<strong><span style="color: #CC2FAA">torch</span></strong>
</summary>
<p>
<p>The torch syntax is very similar, we will give a list of layers to ‘nn_sequential’ function. Here, we have to specify the softmax activation function as an extra layer:</p>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="introduction.html#cb129-1" aria-hidden="true" tabindex="-1"></a>model_torch<span class="sc">$</span><span class="fu">eval</span>()</span>
<span id="cb129-2"><a href="introduction.html#cb129-2" aria-hidden="true" tabindex="-1"></a>preds_torch <span class="ot">=</span> <span class="fu">model_torch</span>(<span class="fu">torch_tensor</span>(X))</span>
<span id="cb129-3"><a href="introduction.html#cb129-3" aria-hidden="true" tabindex="-1"></a>preds_torch <span class="ot">=</span> <span class="fu">apply</span>(preds_torch, <span class="dv">1</span>, which.max) </span>
<span id="cb129-4"><a href="introduction.html#cb129-4" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(preds_torch)</span></code></pre></div>
<pre><code>##   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2
##  [75] 2 2 2 3 2 2 2 2 2 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
## [149] 3 3</code></pre>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="introduction.html#cb131-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(preds_torch <span class="sc">==</span> <span class="fu">as.integer</span>(iris<span class="sc">$</span>Species))</span></code></pre></div>
<pre><code>## [1] 0.9733333</code></pre>
</details>
<p><br/></p>
<p><strong>7. Calculate Accuracy (how often we have been correct):</strong></p>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb133-1"><a href="introduction.html#cb133-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(preds <span class="sc">==</span> <span class="fu">as.integer</span>(iris<span class="sc">$</span>Species))</span></code></pre></div>
<pre><code>## [1] 0.9266667</code></pre>
<p><strong>8. Plot predictions, to see if we have done a good job:</strong></p>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb135-1"><a href="introduction.html#cb135-1" aria-hidden="true" tabindex="-1"></a>oldpar <span class="ot">=</span> <span class="fu">par</span>()</span>
<span id="cb135-2"><a href="introduction.html#cb135-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb135-3"><a href="introduction.html#cb135-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(iris<span class="sc">$</span>Sepal.Length, iris<span class="sc">$</span>Petal.Length, <span class="at">col =</span> iris<span class="sc">$</span>Species, <span class="at">main =</span> <span class="st">&quot;Observed&quot;</span>)</span>
<span id="cb135-4"><a href="introduction.html#cb135-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(iris<span class="sc">$</span>Sepal.Length, iris<span class="sc">$</span>Petal.Length, <span class="at">col =</span> preds, <span class="at">main =</span> <span class="st">&quot;Predicted&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-69-1.png" width="672" /></p>
<p>So you see, building a neural network is with keras very easy and you can already do it on your own.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="fund.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
